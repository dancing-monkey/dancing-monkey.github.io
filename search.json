[{"title":"Dashboard安装及使用","url":"/2022/03/14/K8S/Dashboard%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/","content":"Dashboard安装\n安装文件和image\n[root@localhost kubeConfig]# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.5.1/aio/deploy/recommended.yaml -O dashboard.yaml[root@localhost kubeConfig]# sed -i -e &#x27;s/namespace: kubernetes-dashboard/namespace: kube-system/g&#x27; -e &#x27;s/namespace=kubernetes-dashboard/namespace=kube-system/g&#x27; dashboard.yaml[root@localhost kubeConfig]# kubectl apply -f dashboard.yaml\n查看pod是否启动正常\n[root@localhost kubeConfig]# kubectl get pods --namespace=kube-systemNAME                                            READY   STATUS    RESTARTS   AGEcoredns-59d64cd4d4-fnmnr                        1/1     Running   1          4dcoredns-59d64cd4d4-t5k8h                        1/1     Running   1          4ddashboard-metrics-scraper-c45b7869d-jkspw       1/1     Running   0          6m36setcd-localhost.localdomain                      1/1     Running   2          4dkube-apiserver-localhost.localdomain            1/1     Running   2          4dkube-controller-manager-localhost.localdomain   1/1     Running   2          4dkube-flannel-ds-f5zcs                           1/1     Running   1          3d22hkube-proxy-xbl8g                                1/1     Running   2          4dkube-scheduler-localhost.localdomain            1/1     Running   2          4dkubernetes-dashboard-b48fbfb7d-v6d8j            1/1     Running   0          6m36s\n配置外网访问\n\n修改service配置，将type: ClusterIP改成NodePortkubectl edit service kubernetes-dashboard --namespace=kube-system\n# Please edit the object below. Lines beginning with a &#x27;#&#x27; will be ignored,# and an empty file will abort the edit. If an error occurs while saving this file will be# reopened with the relevant failures.#apiVersion: v1kind: Servicemetadata:  annotations:    kubectl.kubernetes.io/last-applied-configuration: |      &#123;&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Service&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;k8s-app&quot;:&quot;kubernetes-dashboard&quot;&#125;,&quot;name&quot;:&quot;kubernetes-dashboard&quot;,&quot;namespace&quot;:&quot;kube-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;ports&quot;:[&#123;&quot;port&quot;:443,&quot;targetPort&quot;:8443&#125;],&quot;selector&quot;:&#123;&quot;k8s-app&quot;:&quot;kubernetes-dashboard&quot;&#125;&#125;&#125;  creationTimestamp: &quot;2022-05-31T06:59:44Z&quot;  labels:    k8s-app: kubernetes-dashboard  name: kubernetes-dashboard  namespace: kube-system  resourceVersion: &quot;43685&quot;  uid: d3fe1318-195f-444e-9f20-6c81c796583bspec:  clusterIP: 172.22.154.95  clusterIPs:  - 172.22.154.95  ipFamilies:  - IPv4  ipFamilyPolicy: SingleStack  ports:  - port: 443    protocol: TCP    targetPort: 8443  selector:    k8s-app: kubernetes-dashboard  sessionAffinity: None  type: NodePort #修改此项为NodePortstatus:  loadBalancer: &#123;&#125;\n查看dashboard暴露端口,发现为31282端口,外部访问地址为：https://&lt;VIRTUAL-IP&gt;:31282/\n[root@localhost kubeConfig]# kubectl get service --namespace=kube-systemNAME                        TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                  AGEdashboard-metrics-scraper   ClusterIP   172.22.231.121   &lt;none&gt;        8000/TCP                 8m52skube-dns                    ClusterIP   172.22.0.10      &lt;none&gt;        53/UDP,53/TCP,9153/TCP   4dkubernetes-dashboard        NodePort    172.22.154.95    &lt;none&gt;        443:31282/TCP            8m53s\n\n\n\n访问Dashboard创建dashboard用户\n[root@localhost kubeConfig]# vi admin-token.yamlkind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1beta1metadata:  name: dashboard-admin  annotations:    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;roleRef:  kind: ClusterRole  name: cluster-admin  apiGroup: rbac.authorization.k8s.iosubjects:  - kind: ServiceAccount    name: dashboard-admin    namespace: kube-system---apiVersion: v1kind: ServiceAccountmetadata:  name: dashboard-admin  namespace: kube-system  labels:    kubernetes.io/cluster-service: &quot;true&quot;    addonmanager.kubernetes.io/mode: Reconcile[root@localhost kubeConfig]#  kubectl apply -f admin-token.yaml\n\n通过token的方式登录[root@localhost kubeConfig]#  kubectl describe secret/$(kubectl get secret -n=kube-system |grep admin|awk &#x27;&#123;print $1&#125;&#x27;) -n=kube-systemName:         dashboard-admin-token-l97t2Namespace:    kube-systemLabels:       &lt;none&gt;Annotations:  kubernetes.io/service-account.name: dashboard-admin              kubernetes.io/service-account.uid: 9c1e7664-fedc-4cb8-a1dc-8c922a9bd6d6Type:  kubernetes.io/service-account-tokenData====ca.crt:     1066 bytesnamespace:  11 bytestoken:      &lt;Token&gt;\n\n\n通过kubeconfig的方式登录[root@localhost dashboard]# kubectl get sa -n kube-system  | grep admindashboard-admin                      1         61m[root@localhost dashboard]# kubectl get secrets -n kube-system | grep admindashboard-admin-token-l97t2                      kubernetes.io/service-account-token   3      61m\n\n[root@localhost ~]# DASH_TOCKEN=$(kubectl get secret -n kube-system dashboard-admin-token-&lt;SECRETS_SUFFIX&gt; -o jsonpath=&#123;.data.token&#125;|base64 -d)[root@localhost ~]# kubectl config set-cluster kubernetes --server=&lt;HOST&gt;:6443 --kubeconfig=/root/dashbord-admin.conf[root@localhost ~]# kubectl config set-credentials dashboard-admin --token=$DASH_TOCKEN --kubeconfig=/root/dashbord-admin.conf[root@localhost ~]# kubectl config set-context dashboard-admin@kubernetes --cluster=kubernetes --user=dashboard-admin --kubeconfig=/root/dashbord-admin.conf[root@localhost ~]# kubectl config use-context dashboard-admin@kubernetes --kubeconfig=/root/dashbord-admin.conf\n\n将生成的dashbord-admin.conf文件拷贝到待登录的机器上，在登录时选择kubeconfig方式进行登录\n\ntroubleshooting一些使用信息不显示安装完dashboard后发现CPU 使用率 (cores)与内存使用 (bytes)未正确显示\n\n通过命令未发现metrics-server这个pod，并且kubectl top node也无法正常显示资源使用信息\n[root@localhost dashboard]# k get pods -n=kube-systemNAME                                            READY   STATUS    RESTARTS   AGEcoredns-59d64cd4d4-fnmnr                        1/1     Running   1          5d5hcoredns-59d64cd4d4-t5k8h                        1/1     Running   1          5d5hdashboard-metrics-scraper-c45b7869d-cxw75       1/1     Running   0          22hetcd-localhost.localdomain                      1/1     Running   2          5d5hkube-apiserver-localhost.localdomain            1/1     Running   2          5d5hkube-controller-manager-localhost.localdomain   1/1     Running   2          5d5hkube-flannel-ds-f5zcs                           1/1     Running   1          5d2hkube-proxy-xbl8g                                1/1     Running   2          5d4hkube-scheduler-localhost.localdomain            1/1     Running   2          5d5hkubernetes-dashboard-b48fbfb7d-f99ck            1/1     Running   0          22h[root@localhost dashboard]# k top nodeW0601 19:14:45.409109 1488120 top_node.go:119] Using json format to get metrics. Next release will switch to protocol-buffers, switch early by passing --use-protocol-buffers flagerror: Metrics API not available\n\n\nMetrics Server是Kubernetes内置自动伸缩管道的一个可伸缩、高效的容器资源度量来源。\nMetrics Server从Kubelets收集资源指标，并通过Metrics API将它们暴露在Kubernetes apiserver中，供水平Pod Autoscaler和垂直Pod Autoscaler使用。kubectl top还可以访问Metrics API，这使得调试自动伸缩管道变得更容易。\nMetrics Server不是用于非自动伸缩的目的。例如，不要将其用于将指标转发给监视解决方案，或者作为监视解决方案指标的来源。在这种情况下，请直接从Kubelet /metrics/resource端点收集度量。\nMetrics Server提供\n\n在大多数集群上工作的单个部署\n快速自动缩放，每15秒收集一次指标\n资源效率，为集群中的每个节点使用1毫秒的CPU内核和2 MB的内存\n可扩展支持多达5000个节点群集\n\n\n\n下载metrics server由于安装的k8s版本为v1.21.5，所以可以下载此时最新的metric server，即v0.6.1wget https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.6.1/components.yaml -O metrics-server.yaml\n\n添加参数，不进行tls验证\n...apiVersion: apps/v1kind: Deploymentmetadata:  labels:    k8s-app: metrics-server  name: metrics-server  namespace: kube-systemspec:  selector:    matchLabels:      k8s-app: metrics-server  strategy:    rollingUpdate:      maxUnavailable: 0  template:    metadata:      labels:        k8s-app: metrics-server    spec:      containers:      - args:        - --cert-dir=/tmp        - --secure-port=4443        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname        - --kubelet-use-node-status-port        - --metric-resolution=15s        - --kubelet-insecure-tls=true #添加此参数        - --kubelet-preferred-address-types=InternalIP #添加此参数        image: k8s.gcr.io/metrics-server/metrics-server:v0.6.1        imagePullPolicy: IfNotPresent        livenessProbe:          failureThreshold: 3          httpGet:...\n启动pod\n[root@localhost dashboard]# k apply -f metrics-server.yamlserviceaccount/metrics-server createdclusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader createdclusterrole.rbac.authorization.k8s.io/system:metrics-server createdrolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader createdclusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator createdclusterrolebinding.rbac.authorization.k8s.io/system:metrics-server createdservice/metrics-server createddeployment.apps/metrics-server createdapiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created[root@localhost dashboard]# k get pod -ANAMESPACE     NAME                                            READY   STATUS    RESTARTS   AGEkube-system   coredns-59d64cd4d4-fnmnr                        1/1     Running   1          5d5hkube-system   coredns-59d64cd4d4-t5k8h                        1/1     Running   1          5d5hkube-system   dashboard-metrics-scraper-c45b7869d-cxw75       1/1     Running   0          23hkube-system   etcd-localhost.localdomain                      1/1     Running   2          5d5hkube-system   kube-apiserver-localhost.localdomain            1/1     Running   2          5d5hkube-system   kube-controller-manager-localhost.localdomain   1/1     Running   2          5d5hkube-system   kube-flannel-ds-f5zcs                           1/1     Running   1          5d2hkube-system   kube-proxy-xbl8g                                1/1     Running   2          5d5hkube-system   kube-scheduler-localhost.localdomain            1/1     Running   2          5d5hkube-system   kubernetes-dashboard-b48fbfb7d-f99ck            1/1     Running   0          23hkube-system   metrics-server-74f4884cb6-sbgn5                 1/1     Running   0          32stitan         nginx                                           1/1     Running   0          23h\n\n","categories":["K8S"],"tags":["K8S"]},{"title":"Kubeadm安装k8s","url":"/2022/03/14/K8S/Kubeadm%E5%AE%89%E8%A3%85k8s/","content":"环境准备通过虚拟机进行部署，网络模式为NAT，共分为三台虚拟机，各虚拟机环境信息如下：\n\ncentos版本：CentOS Linux release 8.5.2111\nk8s版本：1.21.5\ndocker-ce版本：20.10.8\n\n\n\n\nIP\nhostName\ncpu\nmemory\n\n\n\n192.168.8.2\nmaster\n4\n8G\n\n\n192.168.8.3\nslave1\n2\n4G\n\n\n192.168.8.4\nslave2\n2\n4G\n\n\n修改yum源清华大学镜像源安装：https://mirror.tuna.tsinghua.edu.cn/help/centos/\nCentOS 8 （非 Stream 版）已提前进入 EOL 停止服务阶段，因此镜像已被官方移动。\nsed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \\-e &#x27;s|^#baseurl=http://mirror.centos.org/$contentdir|baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos-vault/centos|g&#x27; \\-i /etc/yum.repos.d/CentOS-*.repo\n\n最后，更新软件包缓存\nyum makecache  &amp; yum update -y\n\nK8S环境准备master&amp;node(以master为例)\n修改/etc/hosts文件\n[root@master ~]# cat &gt;&gt; /etc/hosts &lt;&lt; E192.198.8.2 masterE\n关闭swap分区，也可以在安装系统时，手动分盘将swap分区删除。如果不关闭，默认配置的kubelet将无法启动\n\nswapoff -a\n删除 /etc/fstab swap swap defaults 0 0 这一行或者注释掉这一行\n\n\n禁用SELINUX\n[root@master ~]# setenforce 0[root@master ~]# sed -i &quot;s/^SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/sysconfig/selinux[root@master ~]# sed -i &quot;s/^SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config[root@master ~]# sed -i &quot;s/^SELINUX=permissive/SELINUX=disabled/g&quot; /etc/sysconfig/selinux[root@master ~]# sed -i &quot;s/^SELINUX=permissive/SELINUX=disabled/g&quot; /etc/selinux/config\n关闭防火墙\n[root@master ~]# systemctl stop firewalld.service[root@master ~]# systemctl disable firewalld.serviceRemoved /etc/systemd/system/multi-user.target.wants/firewalld.service.Removed /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.[root@master ~]# systemctl status firewalld.service● firewalld.service - firewalld - dynamic firewall daemon   Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: enabled)   Active: inactive (dead)     Docs: man:firewalld(1)Mar 28 01:04:37 master systemd[1]: Stopping firewalld - dynamic firewall daemon...Mar 28 01:04:37 master systemd[1]: firewalld.service: Succeeded.Mar 28 01:04:37 master systemd[1]: Stopped firewalld - dynamic firewall daemon.Mar 28 01:04:37 master systemd[1]: Starting firewalld - dynamic firewall daemon...Mar 28 01:04:37 master systemd[1]: Started firewalld - dynamic firewall daemon.Mar 28 01:04:37 master firewalld[10697]: WARNING: AllowZoneDrifting is enabled. This is considered an insecure configura&gt;Mar 28 01:05:01 master firewalld[10697]: WARNING: AllowZoneDrifting is enabled. This is considered an insecure configura&gt;Mar 28 05:23:12 master systemd[1]: Stopping firewalld - dynamic firewall daemon...Mar 28 05:23:14 master systemd[1]: firewalld.service: Succeeded.Mar 28 05:23:14 master systemd[1]: Stopped firewalld - dynamic firewall daemon.lines 1-15/15 (END)\n创建k8s配置文件\n[root@master ~]# cat &gt;&gt;/etc/sysctl.d/k8s.conf &lt;&lt; Enet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward = 1E\n\n使命令生效\n[root@master ~]# modprobe br_netfilter[root@master ~]# sysctl -p /etc/sysctl.d/k8s.conf\n加载ipvs模块\n[root@master ~]# modprobe -- ip_vs[root@master ~]# modprobe -- ip_vs_rr[root@master ~]# modprobe -- ip_vs_wrr[root@master ~]# modprobe -- ip_vs_sh[root@master ~]# modprobe -- nf_conntrack[root@master ~]# yum install -y ipvsadm ipset\n安装Docker\n添加yum源\n[root@master ~]# yum install -y yum-utils device-mapper-persistent-data lvm2[root@master ~]# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo[root@master ~]# yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo[root@master ~]# yum makecache timer\n\n查看docker-ce版本\n[root@master ~]# yum list docker-ce.x86_64 --showduplicates |sort -rdocker-ce.x86_64                3:20.10.9-3.el8                 docker-ce-stabledocker-ce.x86_64                3:20.10.8-3.el8                 docker-ce-stabledocker-ce.x86_64                3:20.10.7-3.el8                 docker-ce-stabledocker-ce.x86_64                3:20.10.6-3.el8                 docker-ce-stabledocker-ce.x86_64                3:20.10.5-3.el8                 docker-ce-stabledocker-ce.x86_64                3:20.10.4-3.el8                 docker-ce-stabledocker-ce.x86_64                3:20.10.3-3.el8                 docker-ce-stabledocker-ce.x86_64                3:20.10.2-3.el8                 docker-ce-stabledocker-ce.x86_64                3:20.10.14-3.el8                docker-ce-stabledocker-ce.x86_64                3:20.10.1-3.el8                 docker-ce-stabledocker-ce.x86_64                3:20.10.13-3.el8                docker-ce-stabledocker-ce.x86_64                3:20.10.12-3.el8                docker-ce-stabledocker-ce.x86_64                3:20.10.11-3.el8                docker-ce-stabledocker-ce.x86_64                3:20.10.10-3.el8                docker-ce-stabledocker-ce.x86_64                3:20.10.0-3.el8                 docker-ce-stabledocker-ce.x86_64                3:19.03.15-3.el8                docker-ce-stabledocker-ce.x86_64                3:19.03.14-3.el8                docker-ce-stabledocker-ce.x86_64                3:19.03.13-3.el8                docker-ce-stable\n\n安装docker\n[root@master ~]# yum remove docker-ce docker-ce-cli containerd.io -y[root@master ~]# yum remove podman -y[root@master ~]# yum install docker-ce-20.10.8 docker-ce-cli-20.10.8 containerd.io-1.4.10 -y --allowerasing[root@master ~]# systemctl start docker[root@master ~]# systemctl enable docker --now\n\n设置docker镜像加速器\n[root@master ~]# vi /etc/docker/daemon.json&#123;&quot;registry-mirrors&quot;: [&quot;https://registry.cn-hangzhou.aliyuncs.com&quot;],&quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]&#125;[root@master ~]# systemctl daemon-reload[root@master ~]# systemctl restart docker\n\nKubeadm, Kubelet, Kubectl 安装 (master and node)kubeadm 是 kubernetes 的集群安装工具，能够快速安装 kubernetes 集群。 能完成下面的拓扑安装。\n\n单节点k8s(1+0)\n单master 和多node的k8s系统(1+n)\nMater HA 和多node的k8s系统(m*1+n)\n\nkubeadm在整个 K8S 架构里的位置\n\n\nkubeadm init 启动一个Kubernetes主节点\nkubeadm join 启动一个Kubernetes工作节点并将其加入到集群\nkubeadm upgrade 更新一个Kubernetes集群到新版本\nkubeadm config 如果你使用kubeadm v1.7.x或者更低版本，你需要对你的集 群做一些配置以便使用kubeadm upgrade命令\nkubeadm reset 还原之前使用kubeadm init或者kubeadm join对节点产生的改变\nkubeadm token 用来管理令牌，https\nkubeadm version 查看Kubernetes版本信息\nkubeadm alpha 预览一组可用的新功能以便从社区搜集反馈\n\n添加yum源并安装kubeadm、kubectl、kubelet需要保证版本一致\n[root@master ~]# cat &gt;&gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; E[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgE[root@master ~]# yum list kubeadm --showduplicates -y |sort -r[root@master ~]# yum remove kubeadm.x86_64 kubectl.x86_64 kubelet.x86_64 -y#[root@master ~]# yum install kubeadm-1.18.3 kubectl-1.18.3 kubelet-1.18.3 -y[root@master ~]# yum install kubeadm-1.21.5 kubectl-1.21.5 kubelet-1.21.5 -y\n\n启动kubelet[root@master ~]# systemctl daemon-reload[root@master ~]# systemctl start kubelet.service[root@master ~]# systemctl enable kubelet.serviceCreated symlink /etc/systemd/system/multi-user.target.wants/kubelet.service → /usr/lib/systemd/system/kubelet.service.[root@master ~]# systemctl status kubelet.service● kubelet.service - kubelet: The Kubernetes Node Agent   Loaded: loaded (/usr/lib/systemd/system/kubelet.service; enabled; vendor preset: disabled)  Drop-In: /usr/lib/systemd/system/kubelet.service.d           └─10-kubeadm.conf   Active: activating (auto-restart) (Result: exit-code) since Mon 2022-03-28 22:36:53 EDT; 2s ago     Docs: https://kubernetes.io/docs/  Process: 6932 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS (code=exited&gt; Main PID: 6932 (code=exited, status=1/FAILURE)Mar 28 22:36:53 master systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILUREMar 28 22:36:53 master systemd[1]: kubelet.service: Failed with result &#x27;exit-code&#x27;.\n\n集群安装命令行安装k8s所有节点安装之前记得先把镜像准备好，否则将无法启动，也不报错。集群只需要master进行安装，工作节点不需要进行安装，master安装好后需要记录安装成功后的信息。\n待准备参数\n--pod-network-cidrpod网络地址(相当于docker网络地址),可以确定参数：--pod-network-cidr=172.17.0.1/16\n[root@master ~]# ifconfigdocker0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt;  mtu 1500        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255        ether 02:42:86:93:f9:48  txqueuelen 0  (Ethernet)        RX packets 0  bytes 0 (0.0 B)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 0  bytes 0 (0.0 B)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n--service-cidrservice地址，用来service寻址用：--service-cidr=172.18.0.1/16 注意，pod网段跟service网段不能重复\n\n--image-repository镜像仓库：--image-repository registry.aliyuncs.com/google_containers\n\n--apiserver-advertise-address\n本机地址：--apiserver-advertise-address=192.168.8.2\n[root@master ~]# ifconfigens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 192.168.8.2  netmask 255.255.255.0  broadcast 192.168.8.255        inet6 fe80::dd55:58a3:1169:d0e6  prefixlen 64  scopeid 0x20&lt;link&gt;        ether 00:0c:29:4a:4d:94  txqueuelen 1000  (Ethernet)        RX packets 196430  bytes 234256981 (223.4 MiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 84288  bytes 10496655 (10.0 MiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n安装命令：kubeadm init --image-repository registry.aliyuncs.com/google_containers --kubernetes-version=v1.21.5 --pod-network-cidr=172.17.0.1/16 --service-cidr=172.18.0.1/16 --apiserver-advertise-address=192.168.8.2\n安装成功后需要记录token并执行以下脚本\nYour Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user:# 执行此三个命令  mkdir -p $HOME/.kube  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config  sudo chown $(id -u):$(id -g) $HOME/.kube/configAlternatively, if you are the root user, you can run:  export KUBECONFIG=/etc/kubernetes/admin.confYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:  https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:# 记录此命令kubeadm join 192.168.8.2:6443 --token xxffo1.ii2aihfyhisk2j01 \\        --discovery-token-ca-cert-hash sha256:9dff6188ab35c6cdee9465e00dd1f5c14c413763e35405258026592fa82f0269\n\n修改负载均衡模式[root@master manifests]# kubectl describe cm -n kube-system kube-proxy...kind: KubeProxyConfigurationmetricsBindAddress: &quot;&quot;mode: &quot;&quot; #此项为待修改项nodePortAddresses: nulloomScoreAdj: nullportRange: &quot;&quot;showHiddenMetricsForVersion: &quot;&quot;udpIdleTimeout: 0swinkernel:  enableDSR: false  networkName: &quot;&quot;  sourceVip: &quot;&quot;kubeconfig.conf:...\n\n[root@master ~]# kubectl edit cm -n kube-system kube-proxy...kind: KubeProxyConfigurationmetricsBindAddress: &quot;&quot;mode: &quot;ipvs&quot; #修改为ipvsnodePortAddresses: nulloomScoreAdj: nullportRange: &quot;&quot;showHiddenMetricsForVersion: &quot;&quot;udpIdleTimeout: 0swinkernel:  enableDSR: false  networkName: &quot;&quot;  sourceVip: &quot;&quot;kubeconfig.conf:...\n\n安装网络插件POD network Flannel (DamonSet)[root@master ~]# wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml[root@master ~]# kubectl apply -f kube-flannel.yml\n\n\n如果有多网卡的情况，需要配置具体网卡\n...containers:      - name: kube-flannel       #image: flannelcni/flannel:v0.17.0 for ppc64le and mips64le (dockerhub limitations may apply)        image: rancher/mirrored-flannelcni-flannel:v0.17.0        command:        - /opt/bin/flanneld        args:        - --ip-masq        - --kube-subnet-mgr        - --iface=&lt;网卡名称&gt; #需要添加此项        resources:          requests:            cpu: &quot;100m&quot;            memory: &quot;50Mi&quot;          limits:            cpu: &quot;100m&quot;            memory: &quot;50Mi&quot;        securityContext:          privileged: false          capabilities:            add: [&quot;NET_ADMIN&quot;, &quot;NET_RAW&quot;]...\n\n安装好flannel后，集群状态正常\n[root@master ~]# kubectl get pod -ANAMESPACE     NAME                             READY   STATUS    RESTARTS   AGEkube-system   coredns-59d64cd4d4-2nqw9         1/1     Running   0          16hkube-system   coredns-59d64cd4d4-glgcv         1/1     Running   0          16hkube-system   etcd-master                      1/1     Running   1          16hkube-system   kube-apiserver-master            1/1     Running   1          16hkube-system   kube-controller-manager-master   1/1     Running   1          16hkube-system   kube-flannel-ds-5wlkj            1/1     Running   0          4m52skube-system   kube-proxy-rdxvn                 1/1     Running   1          16hkube-system   kube-scheduler-master            1/1     Running   1          16h[root@master ~]# kubectl get nodeNAME     STATUS   ROLES                  AGE   VERSIONmaster   Ready    control-plane,master   16h   v1.21.5[root@master ~]# systemctl status kubelet● kubelet.service - kubelet: The Kubernetes Node Agent   Loaded: loaded (/usr/lib/systemd/system/kubelet.service; enabled; vendor preset: disabled)  Drop-In: /usr/lib/systemd/system/kubelet.service.d           └─10-kubeadm.conf   Active: active (running) since Tue 2022-03-29 21:31:06 EDT; 40min ago     Docs: https://kubernetes.io/docs/ Main PID: 1018 (kubelet)    Tasks: 15 (limit: 49304)   Memory: 155.6M   CGroup: /system.slice/kubelet.service           └─1018 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml --network-plugin=cni --pod-infra-container-image=registry.a&gt;\n\n\n\n卸载安装[root@master ~]# kubeadm reset[root@master ~]# ifconfig cni0 down &amp;&amp; ip link delete cni0[root@master ~]# ifconfig flannel.1 down &amp;&amp; ip link delete flannel.1[root@master ~]# rm -rf /var/lib/cni[root@master ~]# rm -rf /etc/kubenetes[root@master ~]# rm -rf /root/.kube/config[root@master ~]# rm -rf /var/lib/etcd\n\nkubectl准备下面的命令是配置如何使用kubectl访问集群，kubectl是访问集群的工具，并不是k8s集群必须配备的组件。\nmkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nMaster Node 参与工作负载使用kubeadm初始化的集群，Pod不会被调度到Master Node上，也就是说Master Node不参与工作负载。这是因为当前的master节点被打上了node-role.kubernetes.io/master:NoScheduler的污点\n[root@master ~]# kubectl describe node master | grep TaintTaints:             node-role.kubernetes.io/master:NoSchedule\n\n让Master Node参与工作负载kubectl taint nodes master node-role.kubernetes.io/master-\nNode Join(slave)Kubernetes通过将容器放入在节点(Node)上运行的Pod中来执行你的工作负载。节点可以是一个虚拟机或者物理机器，取决于所在的集群配置。每个节点包含运行Pods所需的服务；这些节点由控制面负责管理。通常集群中会有若干个节点；而在一个学习用或者资源受限的环境中，你的集群中也可能只有一个节点。节点上的组件包括kubelet、容器运行时以及kube-proxy。\n一个节点的状态包含以下信息：地址、状况、容量与可分配等。可以通过kubectl命令来查看节点状态和详细信息：kubectl describe node master\nnode环境准备好后执行join命令\n[root@slave2 ~]# kubeadm join 192.168.8.2:6443 --token xxffo1.ii2aihfyhisk2j01 \\&gt;         --discovery-token-ca-cert-hash sha256:9dff6188ab35c6cdee9465e00dd1f5c14c413763e35405258026592fa82f0269[preflight] Running pre-flight checks        [WARNING FileExisting-tc]: tc not found in system path[preflight] Reading configuration from the cluster...[preflight] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -o yaml&#x27;[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;[kubelet-start] Starting the kubelet[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...This node has joined the cluster:* Certificate signing request was sent to apiserver and a response was received.* The Kubelet was informed of the new secure connection details.Run &#x27;kubectl get nodes&#x27; on the control-plane to see this node join the cluster.\n\n待两个slave均join后，在master上可以看到node信息\n[root@master ~]# kubectl get nodesNAME     STATUS   ROLES                  AGE     VERSIONmaster   Ready    control-plane,master   19h     v1.21.5slave1   Ready    &lt;none&gt;                 93m     v1.21.5slave2   Ready    &lt;none&gt;                 2m25s   v1.21.5\n\n现在在slave上并不能执行kubectl命令，如果想在slave上也可以执行kubectl命令查看集群状态的话，需要将/root/.kube/config文件拷贝到slave上。\n[root@master ~]# scp /root/.kube/config root@slave1:/root/.kube/config[root@master ~]# scp /root/.kube/config root@slave2:/root/.kube/config\n\n给slave1和slave2添加标签\n[root@master ~]# kubectl label nodes slave1 slave2 node-role.kubernetes.io/node=node/slave1 labelednode/slave2 labeled[root@master ~]# kubectl get nodeNAME     STATUS   ROLES                  AGE    VERSIONmaster   Ready    control-plane,master   20h    v1.21.5slave1   Ready    node                   125m   v1.21.5slave2   Ready    node                   34m    v1.21.5\n\ntoken默认可以使用时间为24小时，如果24小时后还有其他node想加入到k8s集群则需要重新生成token\n[root@master ~]# kubeadm token create --print-join-commandkubeadm join 192.168.8.2:6443 --token 47tlq4.ny5iqikykgg2e9g4 --discovery-token-ca-cert-hash sha256:9dff6188ab35c6cdee9465e00dd1f5c14c413763e35405258026592fa82f0269\n\nNamespaceKubernetes支持多个虚拟集群，它们底层依赖于同一个物理集群。这些虚拟集群被称为名字空间。在一些文档里名字空间也称为命名空间。\n\n何时使用多个名字空间名字空间适用于存在很多跨多个团队或项目的用户的场景。对于只有几到几十个用户的集群，根本不需要创建或考虑名字空间。当需要名称空间提供的功能时，请开始使用它们。名字空间为名称提供了一个范围。资源的名称需要在名字空间内是唯一的，但不能跨名字空间。名字空间不能相互嵌套，每个Kubernetes资源只能在一个名字空间中。名字空间是在多个用户之间划分集群资源的一种方法(通过资源配额)。不必使用多个名字空间来分隔仅仅轻微不同的资源，例如同一软件的不同版本。应该使用标签来区分同一名字空间中的不同资源。\n查看名字空间[root@master ~]# kubectl get namespaceNAME              STATUS   AGEdefault           Active   21hkube-node-lease   Active   21hkube-public       Active   21hkube-system       Active   21h\n\nKubernetes会创建四个初始名字空间：\n\ndefault 没有指明使用其它名字空间的对象所使用的默认名字空间\nkube-system Kubernetes系统创建对象所使用的名字空间\nkube-public 这个名字空间是自动创建的，所有用户(包括未经过身份验证的用户)都可以读取它。这个名字空间主要用于集群使用，以防某些资源在整个集群中应该是可见和可读的。这个名字空间的公共方面只是一种约定，而不是要求。\nkube-node-lease 此名字空间用于与各个节点相关的租期(Lease)对象,此对象的设计使得集群规模很大时节点心跳检测性能得到提升。\n\n名字空间操作\n创建/删除名字空间\n[root@master ~]# kubectl create namespace developnamespace/develop created[root@master ~]# kubectl get namespaceNAME              STATUS   AGEdefault           Active   22hdevelop           Active   7skube-node-lease   Active   22hkube-public       Active   22hkube-system       Active   22h[root@master ~]# kubectl delete namespace developnamespace &quot;develop&quot; deleted[root@master ~]# kubectl get namespaceNAME              STATUS   AGEdefault           Active   22hkube-node-lease   Active   22hkube-public       Active   22hkube-system       Active   22h\n查看名字空间下的pod\n[root@master ~]# kubectl get pod -n kube-systemNAME                             READY   STATUS    RESTARTS   AGEcoredns-59d64cd4d4-2nqw9         1/1     Running   1          22hcoredns-59d64cd4d4-glgcv         1/1     Running   1          22hetcd-master                      1/1     Running   2          22hkube-apiserver-master            1/1     Running   2          22hkube-controller-manager-master   1/1     Running   2          21hkube-flannel-ds-5wlkj            1/1     Running   1          5h34mkube-flannel-ds-v2w4c            1/1     Running   0          134mkube-flannel-ds-vvqkb            1/1     Running   0          3h45mkube-proxy-2v62k                 1/1     Running   0          134mkube-proxy-rdxvn                 1/1     Running   2          22hkube-proxy-x94l2                 1/1     Running   0          3h45mkube-scheduler-master            1/1     Running   2          21h\n查看pod在哪个节点上\n[root@master ~]# kubectl get pod -A -owideNAMESPACE     NAME                             READY   STATUS    RESTARTS   AGE     IP            NODE     NOMINATED NODE   READINESS GATESkube-system   coredns-59d64cd4d4-2nqw9         1/1     Running   1          22h     172.17.0.5    master   &lt;none&gt;           &lt;none&gt;kube-system   coredns-59d64cd4d4-glgcv         1/1     Running   1          22h     172.17.0.4    master   &lt;none&gt;           &lt;none&gt;kube-system   etcd-master                      1/1     Running   2          22h     192.168.8.2   master   &lt;none&gt;           &lt;none&gt;kube-system   kube-apiserver-master            1/1     Running   2          22h     192.168.8.2   master   &lt;none&gt;           &lt;none&gt;kube-system   kube-controller-manager-master   1/1     Running   2          21h     192.168.8.2   master   &lt;none&gt;           &lt;none&gt;kube-system   kube-flannel-ds-5wlkj            1/1     Running   1          5h37m   192.168.8.2   master   &lt;none&gt;           &lt;none&gt;kube-system   kube-flannel-ds-v2w4c            1/1     Running   0          137m    192.168.8.4   slave2   &lt;none&gt;           &lt;none&gt;kube-system   kube-flannel-ds-vvqkb            1/1     Running   0          3h48m   192.168.8.3   slave1   &lt;none&gt;           &lt;none&gt;kube-system   kube-proxy-2v62k                 1/1     Running   0          137m    192.168.8.4   slave2   &lt;none&gt;           &lt;none&gt;kube-system   kube-proxy-rdxvn                 1/1     Running   2          22h     192.168.8.2   master   &lt;none&gt;           &lt;none&gt;kube-system   kube-proxy-x94l2                 1/1     Running   0          3h48m   192.168.8.3   slave1   &lt;none&gt;           &lt;none&gt;kube-system   kube-scheduler-master            1/1     Running   2          21h     192.168.8.2   master   &lt;none&gt;           &lt;none&gt;\n\nK8S HA集群安装堆叠(Stacked) HA集群是一种这样的拓扑，其中etcd分布式数据存储集群堆叠在kubeadm管理的控制平面节点上，作为控制平面的一个组件运行。每个控制平面节点运行kube-apiserver,kube-scheduler和kube-controller-manager实例。kube-apiserver使用负载均衡器暴露给工作节点。每个控制平面节点创建一个本地etcd成员(member)，这个etcd成员只与该节点的kube-apiserver通信。这同样适用于本地kube-controller-manager和kube-scheduler实例。这种拓扑将控制平面和etcd成员耦合在同一节点上。相对使用外部etcd集群，设置起来更简单，而且更易于副本管理。然而，堆叠集群存在耦合失败的风险。如果一个节点发生故障，则etcd成员和控制平面实例都将丢失，并且冗余会受到影响。您可以通过添加更多控制平面节点来降低此风险。因此，您应该为HA集群运行至少三个堆叠的控制平面节点。这是kubeadm中的默认拓扑。当使用kubeadm init和kubeadm join --control-plane时，在控制平面节点上会自动创建本地etcd成员。\n\ntroubleshooting组件unhealthy通过kubeadm安装好kubenetes,查看集群状态，发现controller-manager和scheduler状态为Unhealthy\n[root@master ~]# kubectl get csWarning: v1 ComponentStatus is deprecated in v1.19+NAME                 STATUS      MESSAGE   \t                                                                               controller-manager   Unhealthy   Get &quot;http://127.0.0.1:10252/healthz&quot;: dial tcp 127.0.0.1:10252: connect: connection refusedscheduler            Unhealthy   Get &quot;http://127.0.0.1:10251/healthz&quot;: dial tcp 127.0.0.1:10251: connect: connection refusedetcd-0               Healthy     &#123;&quot;health&quot;:&quot;true&quot;&#125;\n\n检查kube-scheduler和kube-controller-manager组件配置是否禁用了非安全端口\nvim /etc/kubernetes/manifests/kube-scheduler.yaml\n...spec:  containers:  - command:    - kube-scheduler    - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf    - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf    - --bind-address=127.0.0.1    - --kubeconfig=/etc/kubernetes/scheduler.conf    - --leader-elect=true#    - --port=0 #将此行注释掉...\n\nvim /etc/kubernetes/manifests/kube-controller-manager.yaml\n...spec:  containers:  - command:    - kube-controller-manager    - --allocate-node-cidrs=true    - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf    - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf    - --bind-address=127.0.0.1    - --client-ca-file=/etc/kubernetes/pki/ca.crt    - --cluster-cidr=172.17.0.1/16    - --cluster-name=kubernetes    - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt    - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key    - --controllers=*,bootstrapsigner,tokencleaner    - --kubeconfig=/etc/kubernetes/controller-manager.conf    - --leader-elect=true#    - --port=0 #将此行注释掉    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt...\n再次查看发现组件已经正常\n[root@master ~]# kubectl get csWarning: v1 ComponentStatus is deprecated in v1.19+NAME                 STATUS    MESSAGE             ERRORcontroller-manager   Healthy   okscheduler            Healthy   oketcd-0               Healthy   &#123;&quot;health&quot;:&quot;true&quot;&#125;\n\nkubeadm证书续期kubeadm默认证书为一年，一年过期后，会导致api service不可用，使用过程中会出现：x509: certificate has expired or is not yet valid.\n证书默认存放目录：/etc/kubernetes/pki\n[root@master kubernetes]# kubeadm certs check-expiration[check-expiration] Reading configuration from the cluster...[check-expiration] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -o yaml&#x27;CERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGEDadmin.conf                 Mar 29, 2023 09:25 UTC   363d                                    noapiserver                  Mar 29, 2023 09:24 UTC   363d            ca                      noapiserver-etcd-client      Mar 29, 2023 09:25 UTC   363d            etcd-ca                 noapiserver-kubelet-client   Mar 29, 2023 09:24 UTC   363d            ca                      nocontroller-manager.conf    Mar 29, 2023 09:25 UTC   363d                                    noetcd-healthcheck-client    Mar 29, 2023 09:25 UTC   363d            etcd-ca                 noetcd-peer                  Mar 29, 2023 09:25 UTC   363d            etcd-ca                 noetcd-server                Mar 29, 2023 09:24 UTC   363d            etcd-ca                 nofront-proxy-client         Mar 29, 2023 09:24 UTC   363d            front-proxy-ca          noscheduler.conf             Mar 29, 2023 09:25 UTC   363d                                    noCERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGEDca                      Mar 26, 2032 09:24 UTC   9y              noetcd-ca                 Mar 26, 2032 09:24 UTC   9y              nofront-proxy-ca          Mar 26, 2032 09:24 UTC   9y              no\n\n也可以直接查看证书\n[root@master pki]# for i in `ll /etc/kubernetes/pki | grep crt | awk &#x27;&#123;print $9&#125;&#x27;`;do echo $i &amp;&amp; openssl x509 -in $i -noout -text |grep Not;doneapiserver.crt            Not Before: Mar 29 09:24:59 2022 GMT            Not After : Mar 29 09:24:59 2023 GMTapiserver-etcd-client.crt            Not Before: Mar 29 09:24:59 2022 GMT            Not After : Mar 29 09:25:00 2023 GMTapiserver-kubelet-client.crt            Not Before: Mar 29 09:24:59 2022 GMT            Not After : Mar 29 09:24:59 2023 GMTca.crt            Not Before: Mar 29 09:24:59 2022 GMT            Not After : Mar 26 09:24:59 2032 GMTfront-proxy-ca.crt            Not Before: Mar 29 09:24:59 2022 GMT            Not After : Mar 26 09:24:59 2032 GMTfront-proxy-client.crt            Not Before: Mar 29 09:24:59 2022 GMT            Not After : Mar 29 09:24:59 2023 GMT\n\n安装完K8S后发现flannel无法正常启动[root@localhost ~]# kubectl get pod -ANAMESPACE     NAME                                            READY   STATUS              RESTARTS   AGEkube-system   coredns-59d64cd4d4-fnmnr                        0/1     ContainerCreating   0          125mkube-system   coredns-59d64cd4d4-t5k8h                        0/1     ContainerCreating   0          125mkube-system   etcd-localhost.localdomain                      1/1     Running             1          125mkube-system   kube-apiserver-localhost.localdomain            1/1     Running             1          125mkube-system   kube-controller-manager-localhost.localdomain   1/1     Running             1          125mkube-system   kube-flannel-ds-5n42z                           0/1     CrashLoopBackOff    11         13mkube-system   kube-proxy-xbl8g                                1/1     Running             1          108mkube-system   kube-scheduler-localhost.localdomain            1/1     Running             1          125m[root@localhost ~]# kubectl logs kube-flannel-ds-5n42z --namespace=kube-systemI0527 08:17:09.842024       1 main.go:207] CLI flags config: &#123;etcdEndpoints:http://127.0.0.1:4001,http://127.0.0.1:2379 etcdPrefix:/coreos.com/network etcdKeyfile: etcdCertfile: etcdCAFile: etcdUsername: etcdPassword: version:false kubeSubnetMgr:true kubeApiUrl: kubeAnnotationPrefix:flannel.alpha.coreos.com kubeConfigFile: iface:[] ifaceRegex:[] ipMasq:true ifaceCanReach: subnetFile:/run/flannel/subnet.env publicIP: publicIPv6: subnetLeaseRenewMargin:60 healthzIP:0.0.0.0 healthzPort:0 iptablesResyncSeconds:5 iptablesForwardRules:true netConfPath:/etc/kube-flannel/net-conf.json setNodeNetworkUnavailable:true&#125;W0527 08:17:09.947820       1 client_config.go:614] Neither --kubeconfig nor --master was specified.  Using the inClusterConfig.  This might not work.I0527 08:17:10.433515       1 kube.go:121] Waiting 10m0s for node controller to syncI0527 08:17:10.433611       1 kube.go:398] Starting kube subnet managerI0527 08:17:11.434343       1 kube.go:128] Node controller sync successfulI0527 08:17:11.434437       1 main.go:227] Created subnet manager: Kubernetes Subnet Manager - localhost.localdomainI0527 08:17:11.434453       1 main.go:230] Installing signal handlersI0527 08:17:11.435783       1 main.go:463] Found network config - Backend type: vxlanI0527 08:17:11.435882       1 match.go:195] Determining IP address of default interfaceI0527 08:17:11.438439       1 match.go:248] Using interface with name enp0s3 and address 10.0.2.15I0527 08:17:11.440261       1 match.go:270] Defaulting external address to interface address (10.0.2.15)I0527 08:17:11.440412       1 vxlan.go:138] VXLAN config: VNI=1 Port=0 GBP=false Learning=false DirectRouting=falseI0527 08:17:11.442592       1 kube.go:351] Setting NodeNetworkUnavailableE0527 08:17:11.720252       1 main.go:326] Error registering network: failed to acquire lease: subnet &quot;10.244.0.0/16&quot; specified in the flannel net config doesn&#x27;t contain &quot;172.17.0.0/24&quot; PodCIDR of the &quot;localhost.localdomain&quot; node.W0527 08:17:11.720481       1 reflector.go:436] github.com/flannel-io/flannel/subnet/kube/kube.go:399: watch of *v1.Node ended with: an error on the server (&quot;unable to decode an event from the watch stream: context canceled&quot;) has prevented the request from succeedingI0527 08:17:11.720578       1 main.go:443] Stopping shutdownHandler...\n\n集群初始化时参数--pod-network-cidr=172.17.0.1/16，未修改kube-flannel.yml中Network键值\n[root@localhost kubeConfig]# cat kube-flannel.yml|grep -E &quot;^\\s*\\&quot;Network&quot;      &quot;Network&quot;: &quot;10.244.0.0/16&quot;,\n\n将kube-flannel.yml中的配置进行修改\n...metadata:  name: kube-flannel-cfg  namespace: kube-system  labels:    tier: node    app: flanneldata:  cni-conf.json: |    &#123;      &quot;name&quot;: &quot;cbr0&quot;,      &quot;cniVersion&quot;: &quot;0.3.1&quot;,      &quot;plugins&quot;: [        &#123;          &quot;type&quot;: &quot;flannel&quot;,          &quot;delegate&quot;: &#123;            &quot;hairpinMode&quot;: true,            &quot;isDefaultGateway&quot;: true          &#125;        &#125;,        &#123;          &quot;type&quot;: &quot;portmap&quot;,          &quot;capabilities&quot;: &#123;            &quot;portMappings&quot;: true          &#125;        &#125;      ]    &#125;  net-conf.json: |    &#123;      &quot;Network&quot;: &quot;172.17.0.0/16&quot;,#此项修改为初始化时pod-network-cidr指定的值      &quot;Backend&quot;: &#123;        &quot;Type&quot;: &quot;vxlan&quot;      &#125;    &#125;...\n\n[root@localhost kubeConfig]# kubectl apply -f kube-flannel.yml[root@localhost kubeConfig]# kubectl get pod -ANAMESPACE     NAME                                            READY   STATUS    RESTARTS   AGEkube-system   coredns-59d64cd4d4-fnmnr                        1/1     Running   0          172mkube-system   coredns-59d64cd4d4-t5k8h                        1/1     Running   0          172mkube-system   etcd-localhost.localdomain                      1/1     Running   1          172mkube-system   kube-apiserver-localhost.localdomain            1/1     Running   1          172mkube-system   kube-controller-manager-localhost.localdomain   1/1     Running   1          172mkube-system   kube-flannel-ds-f5zcs                           1/1     Running   0          7m22skube-system   kube-proxy-xbl8g                                1/1     Running   1          154mkube-system   kube-scheduler-localhost.localdomain            1/1     Running   1          172m\n\n如果flannel重启较慢，可以将此pod手动删除kubectl delete pod kube-flannel-ds-5n42z --namespace=kube-system\ncore dns 无限重启安装完k8s后，过几天发现coredns无限重启，并报错，突然想到是不是因为未修改flannel导致的，虽然flannel看着是正常的，还是按照安装完K8S后发现flannel无法正常启动进行了修改，然后删除coredns pod后，发现dns恢复正常\n[root@master ~]# k get podsNAME                             READY   STATUS             RESTARTS   AGEcoredns-59d64cd4d4-2nqw9         0/1     CrashLoopBackOff   1277       64dcoredns-59d64cd4d4-glgcv         0/1     Running            1271       64detcd-master                      1/1     Running            17         64dkube-apiserver-master            1/1     Running            17         64dkube-controller-manager-master   1/1     Running            17         64dkube-flannel-ds-kp42d            1/1     Running            0          19mkube-flannel-ds-l95xj            1/1     Running            0          19mkube-flannel-ds-p7dtg            1/1     Running            0          19mkube-proxy-2v62k                 1/1     Running            8          63dkube-proxy-rdxvn                 1/1     Running            17         64dkube-proxy-x94l2                 1/1     Running            8          63dkube-scheduler-master            1/1     Running            17         64d[root@master conf]# k logs coredns-59d64cd4d4-glgcv -n=kube-systemE0602 02:13:06.387925       1 reflector.go:127] pkg/mod/k8s.io/client-go@v0.19.2/tools/cache/reflector.go:156: Failed to watch *v1.Endpoints: failed to list *v1.Endpoints: Get &quot;https://172.18.0.1:443/api/v1/endpoints?limit=500&amp;resourceVersion=0&quot;: dial tcp 172.18.0.1:443: connect: no route to hostE0602 02:13:06.387945       1 reflector.go:127] pkg/mod/k8s.io/client-go@v0.19.2/tools/cache/reflector.go:156: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get &quot;https://172.18.0.1:443/api/v1/namespaces?limit=500&amp;resourceVersion=0&quot;: dial tcp 172.18.0.1:443: connect: no route to hostE0602 02:13:06.388047       1 reflector.go:127] pkg/mod/k8s.io/client-go@v0.19.2/tools/cache/reflector.go:156: Failed to watch *v1.Service: failed to list *v1.Service: Get &quot;https://172.18.0.1:443/api/v1/services?limit=500&amp;resourceVersion=0&quot;: dial tcp 172.18.0.1:443: connect: no route to host\n\n[root@master ~]# k get pod -ANAMESPACE     NAME                             READY   STATUS    RESTARTS   AGEkube-system   coredns-59d64cd4d4-fphkz         1/1     Running   0          66mkube-system   coredns-59d64cd4d4-q4692         1/1     Running   0          66mkube-system   etcd-master                      1/1     Running   17         64dkube-system   kube-apiserver-master            1/1     Running   17         64dkube-system   kube-controller-manager-master   1/1     Running   17         64dkube-system   kube-flannel-ds-kp42d            1/1     Running   0          86mkube-system   kube-flannel-ds-l95xj            1/1     Running   0          86mkube-system   kube-flannel-ds-p7dtg            1/1     Running   0          86mkube-system   kube-proxy-2v62k                 1/1     Running   8          63dkube-system   kube-proxy-rdxvn                 1/1     Running   17         64dkube-system   kube-proxy-x94l2                 1/1     Running   8          63dkube-system   kube-scheduler-master            1/1     Running   17         64d\n\n节点状态notReadyK8S node节点kubeadm join命令后，已成功添加到集群，但是执行kubectl get nodes命令看到node状态依旧是NotReady\n查看报错信息\n➜  net.d systemctl status kubelet -l● kubelet.service - kubelet: The Kubernetes Node Agent   Loaded: loaded (/usr/lib/systemd/system/kubelet.service; enabled; vendor preset: disabled)  Drop-In: /usr/lib/systemd/system/kubelet.service.d           └─10-kubeadm.conf   Active: active (running) since Sat 2022-12-17 13:16:12 CST; 6min ago     Docs: https://kubernetes.io/docs/ Main PID: 29732 (kubelet)    Tasks: 14   Memory: 33.4M   CGroup: /system.slice/kubelet.service           └─29732 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml --network-plugin=cni --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.4.1Dec 17 13:22:01 victor kubelet[29732]: E1217 13:22:01.343133   29732 kubelet.go:2211] &quot;Container runtime network not ready&quot; networkReady=&quot;NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized&quot;Dec 17 13:22:03 victor kubelet[29732]: I1217 13:22:03.373089   29732 cni.go:204] &quot;Error validating CNI config list&quot; configList=&quot;&#123;\\n  \\&quot;name\\&quot;: \\&quot;cbr0\\&quot;,\\n  \\&quot;cniVersion\\&quot;: \\&quot;0.3.1\\&quot;,\\n  \\&quot;plugins\\&quot;: [\\n    &#123;\\n      \\&quot;type\\&quot;: \\&quot;flannel\\&quot;,\\n      \\&quot;delegate\\&quot;: &#123;\\n        \\&quot;hairpinMode\\&quot;: true,\\n        \\&quot;isDefaultGateway\\&quot;: true\\n      &#125;\\n    &#125;,\\n    &#123;\\n      \\&quot;type\\&quot;: \\&quot;portmap\\&quot;,\\n      \\&quot;capabilities\\&quot;: &#123;\\n        \\&quot;portMappings\\&quot;: true\\n      &#125;\\n    &#125;\\n  ]\\n&#125;\\n&quot; err=&quot;[failed to find plugin \\&quot;flannel\\&quot; in path [/opt/cni/bin]]&quot;Dec 17 13:22:03 victor kubelet[29732]: I1217 13:22:03.373159   29732 cni.go:239] &quot;Unable to update cni config&quot; err=&quot;no valid networks found in /etc/cni/net.d&quot;Dec 17 13:22:06 victor kubelet[29732]: E1217 13:22:06.366103   29732 kubelet.go:2211] &quot;Container runtime network not ready&quot; networkReady=&quot;NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized&quot;Dec 17 13:22:08 victor kubelet[29732]: I1217 13:22:08.378997   29732 cni.go:204] &quot;Error validating CNI config list&quot; configList=&quot;&#123;\\n  \\&quot;name\\&quot;: \\&quot;cbr0\\&quot;,\\n  \\&quot;cniVersion\\&quot;: \\&quot;0.3.1\\&quot;,\\n  \\&quot;plugins\\&quot;: [\\n    &#123;\\n      \\&quot;type\\&quot;: \\&quot;flannel\\&quot;,\\n      \\&quot;delegate\\&quot;: &#123;\\n        \\&quot;hairpinMode\\&quot;: true,\\n        \\&quot;isDefaultGateway\\&quot;: true\\n      &#125;\\n    &#125;,\\n    &#123;\\n      \\&quot;type\\&quot;: \\&quot;portmap\\&quot;,\\n      \\&quot;capabilities\\&quot;: &#123;\\n        \\&quot;portMappings\\&quot;: true\\n      &#125;\\n    &#125;\\n  ]\\n&#125;\\n&quot; err=&quot;[failed to find plugin \\&quot;flannel\\&quot; in path [/opt/cni/bin]]&quot;Dec 17 13:22:08 victor kubelet[29732]: I1217 13:22:08.379065   29732 cni.go:239] &quot;Unable to update cni config&quot; err=&quot;no valid networks found in /etc/cni/net.d&quot;Dec 17 13:22:11 victor kubelet[29732]: E1217 13:22:11.388666   29732 kubelet.go:2211] &quot;Container runtime network not ready&quot; networkReady=&quot;NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized&quot;Dec 17 13:22:13 victor kubelet[29732]: I1217 13:22:13.384406   29732 cni.go:204] &quot;Error validating CNI config list&quot; configList=&quot;&#123;\\n  \\&quot;name\\&quot;: \\&quot;cbr0\\&quot;,\\n  \\&quot;cniVersion\\&quot;: \\&quot;0.3.1\\&quot;,\\n  \\&quot;plugins\\&quot;: [\\n    &#123;\\n      \\&quot;type\\&quot;: \\&quot;flannel\\&quot;,\\n      \\&quot;delegate\\&quot;: &#123;\\n        \\&quot;hairpinMode\\&quot;: true,\\n        \\&quot;isDefaultGateway\\&quot;: true\\n      &#125;\\n    &#125;,\\n    &#123;\\n      \\&quot;type\\&quot;: \\&quot;portmap\\&quot;,\\n      \\&quot;capabilities\\&quot;: &#123;\\n        \\&quot;portMappings\\&quot;: true\\n      &#125;\\n    &#125;\\n  ]\\n&#125;\\n&quot; err=&quot;[failed to find plugin \\&quot;flannel\\&quot; in path [/opt/cni/bin]]&quot;Dec 17 13:22:13 victor kubelet[29732]: I1217 13:22:13.384479   29732 cni.go:239] &quot;Unable to update cni config&quot; err=&quot;no valid networks found in /etc/cni/net.d&quot;Dec 17 13:22:16 victor kubelet[29732]: E1217 13:22:16.418715   29732 kubelet.go:2211] &quot;Container runtime network not ready&quot; networkReady=&quot;NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized&quot;\n\n发现有问题的节点上缺少flannel文件\n➜  system cd /opt/cni/bin➜  bin lsbandwidth  bridge  dhcp  firewall  host-device  host-local  ipvlan  loopback  macvlan  portmap  ptp  sbr  static  tuning  vlan  vrf\n\n查看master节点\n➜  system cd /opt/cni/bin➜  bin lsbandwidth  bridge  dhcp  firewall  flannel  host-device  host-local  ipvlan  loopback  macvlan  portmap  ptp  sbr  static  tuning  vlan  vrf\n\n将master节点上的flannel文件copy到slave节点上，node状态转为正常\n➜  bin kubectl get nodesNAME     STATUS   ROLES                  AGE   VERSIONchay     Ready    control-plane,master   13h   v1.21.5victor   Ready    node                   9h    v1.21.5\n\n无法访问某个节点pod的日志通过kubectl logs kubernetes-dashboard-5bdbb67675-wcj26 -f去查看日志时，发现此pod被调度到了一个节点上，\n","categories":["K8S"],"tags":["K8S"]},{"title":"Kubectl介绍","url":"/2022/03/14/K8S/Kubectl%E4%BB%8B%E7%BB%8D/","content":"kubectl概要kubectl控制Kubernetes集群管理器，使用Kubernetes命令行工具kubectl在Kubernetes上部署和管理应用程序。使用kubectl，您可以检查群集资源;创建，删除和更新组件;看看你的新集群;并提出示例应用程序。\nkubectl安装[root@master ~]# cat &gt;&gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; E[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgE[root@master ~]# yum install kubectl-&lt;VERSION&gt; -y\n\nkubectl配置在开启了TLS的集群中，当与集群交互的时候少不了的是身份认证，使用kubeconfig(即证书)和token两种认证方式是最简单也最通用的认证方式。kubectl只是个go编写的可执行程序，只要为kubectl配置合适的kubeconfig，就可以在集群中的任意节点使用。kubectl默认会从$HOME/.kube目录下查找文件名为config的文件，也可以通过设置环境变量KUBECONFIG或者通过设置kubeconfig去指定其它kubeconfig文件。kubeconfig就是为访问集群所作的配置。\n\n设置集群参数\nkubectl config set-cluster kubernetes \\\t--certificate-authority=/etc/kubernetes/ssl/ca.pem \\\t--embed-certs=true \\\t--server=$&#123;KUBE_APISERVER&#125;\n\n本段设置了所需要访问的集群的信息。使用set-cluster设置了需要访问的集群，如上为kubernetes ，这只是个名称\n\n--server 指向apiserver\n--certificate-authority设置该集群的公钥\n--embed-certs为true表示将--certificate-authority写入到kubeconfig中\n\n\n设置客户端认证参数\nkubectl config set-credentials admin \\\t--client-certificate=/etc/kubernetes/ssl/admin.pem \\\t--embed-certs=true \\\t--client-key=/etc/kubernetes/ssl/admin-key.pem\n\n本段主要设置用户的相关信息，主要是用户证书。如上的用户名为admin，证书为/etc/kubernetes/ssl/admin.pem，私钥为：/etc/kubernetes/ssl/admin key.pem。注意客户端的证书首先要经过集群CA的签署，否则不会被集群认可。此处使用的是ca认证方式，也可以使用token认证，如kubelet的TLS Boostrap机制下的bootstrapping使用的就是token认证方式。上述kubectl使用的是ca认证，不需要token字段。\n\n设置上下文参数\nkubectl config set-context kubernetes \\\t--cluster=kubernetes \\\t--user=admin\n\ncontext定义了一个命名的cluster、user、namespace元组，用于使用提供的认证信息和命名空间将请求发送到指定的集群。三个都是可选的，仅使用cluster、user、namespace之一指定上下文，或指定none。\n也可以修改默认的namespace名字kubectl config set-context --current --namespace=kube-system\n\n设置默认上下文\nkubectl config use-context\n\n使用kubectl config use-context kubernetes来使用名为kubenetes的环境项来作为配置。如果配置了多个环境项，可以通过切换不同的环境项名字来访问到不同的集群环境。\n\n\n生成的kubeconfig被保存到~/.kube/config文件，配置文件描述了集群、用户和上下文，可以通过kubectl config view查看相应配置参数\n\n使用kubeconfig还需要注意用户已经经过授权（如RBAC授权），上述例子中用户的证书中OU字段为system:masters，kube-apiserver预定义的RoleBinding cluster-admin将Groupsystem:masters与Rolecluster-admin绑定，该Role授予了调用kube-apiserver相关的API权限。\n\nkubectl自动补全在使用kubectl命令工具，有些复杂，使用时记不住那么多api，可以使用命令补全工具\n\n安装bash-completion\n[root@localhost kubeConfig]# yum install bash-completion -y[root@localhost kubeConfig]# source /usr/share/bash-completion/bash_completion\n应用kubectl的completion到系统环境\n[root@localhost kubeConfig]# source &lt;(kubectl completion bash)[root@localhost kubeConfig]# echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc\n简化kubectl命令,设置别名\n[root@localhost kubeConfig]# echo &quot;alias k=&#x27;kubectl&#x27;&quot; &gt;&gt; ~/.bashrc[root@localhost kubeConfig]# source ~/.bashrc\n别名自动补全命令\n[root@localhost kubeConfig]# echo &quot;complete -F __start_kubectl k&quot; &gt;&gt; ~/.bashrc[root@localhost kubeConfig]# source ~/.bashrc\n设置切换名称空间别名\n[root@localhost kubeConfig]# echo &quot;alias kns=&#x27;kubectl config set-context --current --namespace&#x27;&quot; &gt;&gt; ~/.bashrc\n\nkubectl命令简介Basic Commands(Beginner)基础命令(初级)\nkubectl create 通过yaml/json文件或者标准输入创建一个资源对象，支持很多子命令，例如namespace pod deployment service等\nkubectl expose 将yaml/json文件中定义的资源对象的端口暴露给新的service资源对象\nkubectl run 创建并运行一个或多个容器镜像\nkubectl set 配置资9源对象设置特定功能\n\nBasic Commands (Intermediate)基础命令(中级)\nkubectl explain 查看资源对象的详细信息(编写yaml的时候做一个提示kubectl explain deployment会出现deployment下面可以写的字段以及字段属性还有可以逐级使用)\nkubectl get 获取一个或多个资源对象的信息\nkubectl edit 使用默认编辑器编辑服务器上定义的资源对象\nkubectl delete 通过yaml/json文件、标准输入、资源名称或标签选择器来删除资源\n\nDeployCommands部署命令\nkubectl rollout 资源管理对象的部署\nkubectl rollout-update 使用rc(replication controller)来做滚动升级\nkubectl scale 扩容或者缩容deployment,replicaset,replication,controller等\nkubectl autoscale 自动设置在k8s系统中运行的pod数量(水平自动伸缩)\n\nCluster Manager Commands集群管理命令\nkubectl cetificate 修改证书资源对象\nkubectl cluster-info 查看集群信息\nkubectl top 显示资源cpu内存存储使用情况\nkubectl cordon 标记节点为不可调度\nkubectl uncordon 指定节点为可调度\nkubectl drain 安全的驱逐节点的所有pod\nkubectl taint 将一个或多个节点设置为污点\n\nTroubleshooting and Debugging Commands 故障排查和调试命令\nkubectl describe 显示一个或多个资源对象的详细信息\nkubectl logs 输出pod资源对象中一个容器的日志\nkubectl attach 连接到一个运行的容器\nkubectl exec 在指定容器内执行命令\nkubectl port-forward 将本机指定端口映射到pod资源对象的端口\nkubectl proxy 将本机指定端口映射到kube-apiserver\nkubectl cp 用于pod与主机交换文件\nkubectl auth 检查验证\n\nAdvanced Commands高级命令\nkubectl diff 对比本地yaml/json文件与kube-apiserver中运行的配置文件是否有差异\nkubectl apply 通过yaml/json文件 标准输入对资源进行配置更新或者创建\nkubectl patch 通过patch方式修改资源对象字段（补丁式）\nkubectl replace 通过yaml/json文件或者标准输入来替换资源对象\nkubectl wait 在一个或者多个资源上等待条件达成\nkubectl convert 转换yaml/json文件为不同的资源版本\nkubectl kustomize 定制kubernetes配置\n\nSettings Commands 设置命令\nkubectl label 增删改资源的标签\nkubectl annotate 更新一个或者多个资源对象的注释(annotaion)信息\nkubectl completion 命令自动补全\n\nOther Commands 其他命令\nkubectl config 管理kubeconfig配置文件\nkubectl plugin 运行命令行插件功能\nkubectl version 查看客户端服务端的系统版本信息\nkubectl api-versions 列出当前kubernetes系统支持的资源组和资源版本表现形式为”group/version”\nkubectl api-resources 列出当前kubernetes系统支持的resource资源列表\nkubectl options 查看支持的参数列表\nkubectl explain 列出支持的资源字段\n\n\n\nkubectl小抄传送门\n\n\nkubectl常用命令\n切换名称空间kubectl config set-context --current --namespace=&lt;NAMESPACE&gt;\n\n查看deployment各字段含义kubectl explain deployment\n\n查看所有的命令及命令简写kubectl api-resources\n\n查看当前kubectl上下文kubectl config view\n\n查看deployment滚动升级版本\nkubectl rollout history  deployment &lt;DEPLOYMENT_NAME&gt;\n\n查看deployment滚动升级某个版本详细信息kubectl rollout history deployment &lt;DEPLOYMENT_NAME&gt; --revision=&lt;REVISION_ID&gt;\n\ndeployment部署回滚\nkubectl rollout undo deployment &lt;DEPLOYMENT_NAME&gt; --revision=&lt;REVISION_ID&gt;\n\n给某个节点打标签kubectl label nodes &lt;YOUR_NODE_NAME&gt; &lt;LABEL_NAME&gt;=&lt;LABEL_VALUE&gt;\n\n\n","categories":["K8S"],"tags":["K8S"]},{"title":"Pod介绍","url":"/2022/08/22/K8S/Pod%E4%BB%8B%E7%BB%8D/","content":"Kubernetes Pod介绍Pod直译是豆荚，可以把容器想像成豆荚里的豆子，把一个或多个关系紧密的豆子包在一起就是豆荚(一个Pod)。在k8s中我们不会直接操作容器，而是把容器包装成Pod再进行管理。\nPod介绍与原理讲解Pod是Kubernetes项目中最小的API对象。如果换一个更专业的说法，我们可以这样描述:Pod，是Kubernetes项目的原子调度单位。\nPod是运行服务的基础，基础容器是pause。每启动一个Pod都会附加启动这样一个容器，它的作用就只是简单的等待，回收僵尸进程。\n一个 Pod 中的应用容器共享同一组资源:\n\nPID命名空间: Pod中的不同应用程序可以看见其他应用程序的进程ID\n网络命名空间: Pod中的多个容器能访问同一个IP和端口范围\nIPC命名空间: Pod中的多个容器能够使用SystemV IPC或POSIX消息队列进行通信\nUTS命名空间: Pod中的多个容器共享一个主机名\nVolumes(共享存储卷): Pod中的各个容器可以访问在Pod级别定义的Volumes\n\n每个 pod 中容器的镜像应该不同(不同的应用)，避免端口重复\n\nKubernetes 集群中的 Pod 主要有两种用法：\n\n运行单个容器的 Pod。”每个 Pod 一个容器” 模型是最常见的 Kubernetes 用例； 在这种情况下，可以将 Pod 看作单个容器的包装器，并且 Kubernetes 直接管理 Pod，而不是容器。\n运行多个协同工作的容器的 Pod。 Pod 可能封装由多个紧密耦合且需要共享资源的共处容器组成的应用程序。 这些位于同一位置的容器可能形成单个内聚的服务单元 —— 一个容器将文件从共享卷提供给公众， 而另一个单独的 “边车”（sidecar）容器则刷新或更新这些文件。 Pod 将这些容器和存储资源打包为一个可管理的实体。\n\n\n将多个并置、同管的容器组织到一个 Pod 中是一种相对高级的使用场景。 只有在一些场景中，容器之间紧密关联时才应该使用这种模式。\n\n每个 Pod 都旨在运行给定应用程序的单个实例。如果希望横向扩展应用程序 （例如，运行多个实例以提供更多的资源），则应该使用多个 Pod，每个实例使用一个 Pod。 在 Kubernetes 中，这通常被称为副本（Replication）。 通常使用一种工作负载资源及其控制器 来创建和管理一组 Pod 副本。\nPod创建Pod 通常不是直接创建的，而是使用工作负载资源创建的。\n创建单个Pod可以使用命令kubectl run nginx --image=nginx:1.14.2 --port=80 --dry-run=client -o yaml&gt;nginx.yaml来生成pod的yaml文件，这不会真正去创建pod。\napiVersion: v1kind: Podmetadata:  creationTimestamp: null  labels:    run: nginx  name: nginxspec:  containers:  - image: nginx:1.14.2    name: nginx    ports:    - containerPort: 80    resources: &#123;&#125;  dnsPolicy: ClusterFirst  restartPolicy: Alwaysstatus: &#123;&#125;\n\n使用kubectl apply -f nginx.yaml命令来真正创建Pod。\n创建多容器Pod创建文件multi-container.yaml，并将以下信息复制到文件中。使用命令kubectl apply -f multi-container.yaml来创建Pod。\napiVersion: v1kind: Podmetadata:  creationTimestamp: null  labels:    run: nginx  name: multi-containerspec:  containers:  - image: nginx:1.14.2    name: nginx    ports:    - containerPort: 80    resources: &#123;&#125;  - image: tomcat    name: tomcat    ports:    - containerPort: 8080  dnsPolicy: ClusterFirst  restartPolicy: Alwaysstatus: &#123;&#125;\n\n使用Pod正常情况下很少在 Kubernetes 中直接创建一个个的 Pod，甚至是单实例（Singleton）的 Pod。 这是因为 Pod 被设计成了相对临时性的、用后即抛的一次性实体。 当 Pod 由你或者间接地由控制器 创建时，它被调度在集群中的节点上运行。 Pod 会保持在该节点上运行，直到 Pod 结束执行、Pod 对象被删除、Pod 因资源不足而被驱逐或者节点失效为止。\n可以使用工作负载资源来创建和管理多个 Pod。 资源的控制器能够处理副本的管理、上线，并在 Pod 失效时提供自愈能力。 例如，如果一个节点失败，控制器注意到该节点上的 Pod 已经停止工作， 就可以创建替换性的 Pod。调度器会将替身 Pod 调度到一个健康的节点执行。\n下面是一些管理一个或者多个 Pod 的工作负载资源的示例：\n\nDeployment\nStatefulSet\nDaemonSet\n\nPod生命周期Pod 的 status 字段是一个 PodStatus 对象，其中包含一个 phase 字段。\nPod 的阶段（Phase）是 Pod 在其生命周期中所处位置的简单宏观概述。 该阶段并不是对容器或 Pod 状态的综合汇总，也不是为了成为完整的状态机。\nPod 阶段的数量和含义是严格定义的。 除了本文档中列举的内容外，不应该再假定 Pod 有其他的 phase 值。\n下面是 phase 可能的值：\n\n\n\n取值\n描述\n\n\n\nPending（悬决）\nPod 已被 Kubernetes 系统接受，但有一个或者多个容器尚未创建亦未运行。此阶段包括等待 Pod 被调度的时间和通过网络下载镜像的时间。\n\n\nRunning（运行中）\nPod 已经绑定到了某个节点，Pod 中所有的容器都已被创建。至少有一个容器仍在运行，或者正处于启动或重启状态。\n\n\nSucceeded（成功）\nPod 中的所有容器都已成功终止，并且不会再重启。\n\n\nFailed（失败）\nPod 中的所有容器都已终止，并且至少有一个容器是因为失败终止。也就是说，容器以非 0 状态退出或者被系统终止。\n\n\nUnknown（未知）\n因为某些原因无法取得 Pod 的状态。这种情况通常是因为与 Pod 所在主机通信失败。\n\n\n如果某节点死掉或者与集群中其他节点失联，Kubernetes 会实施一种策略，将失去的节点上运行的所有 Pod 的 phase 设置为 Failed。\n更进一步地，Pod 对象的 Status 字段，还可以再细分出一组 Conditions。这些细分状 态的值包括:PodScheduled、Ready、Initialized，以及 Unschedulable。它们主要用于描述 造成当前 Status 的具体原因是什么。\nPod的资源和配额以下 Pod 有两个容器。每个容器的请求为 0.25 CPU 和 64MiB（226 字节）内存， 每个容器的资源约束为 0.5 CPU 和 128MiB 内存。 你可以认为该 Pod 的资源请求为 0.5 CPU 和 128 MiB 内存，资源限制为 1 CPU 和 256MiB 内存。\napiVersion: v1kind: Podmetadata:  name: frontendspec:  containers:  - name: app    image: images.my-company.example/app:v4    resources:      requests:        memory: &quot;64Mi&quot;        cpu: &quot;250m&quot;      limits:        memory: &quot;128Mi&quot;        cpu: &quot;500m&quot;  - name: log-aggregator    image: images.my-company.example/log-aggregator:v6    resources:      requests:        memory: &quot;64Mi&quot;        cpu: &quot;250m&quot;      limits:        memory: &quot;128Mi&quot;        cpu: &quot;500m&quot;\n\n静态Pod静态 Pod（Static Pod）直接由特定节点上的 kubelet 守护进程管理， 不需要 API 服务器看到它们。 尽管大多数 Pod 都是通过控制面（例如，Deployment） 来管理的，对于静态 Pod 而言，kubelet 直接监控每个 Pod，并在其失效时重启之。\n静态 Pod 通常绑定到某个节点上的 kubelet。 其主要用途是运行自托管的控制面。 在自托管场景中，使用 kubelet 来管理各个独立的 控制面组件。\nkubelet 自动尝试为每个静态 Pod 在 Kubernetes API 服务器上创建一个 镜像 Pod。 这意味着在节点上运行的 Pod 在 API 服务器上是可见的，但不可以通过 API 服务器来控制。\n创建静态pod以通过配置文件为例，来创建静态Pod。\n在master节点的目录 /etc/kubernetes/manifests 写入 static.yaml 文件，内容:\napiVersion: v1kind: Podmetadata:  creationTimestamp: null  labels:    run: nginx  name: static-nginxspec:  containers:  - image: nginx:1.14.2    name: nginx    ports:    - containerPort: 80    resources: &#123;&#125;  dnsPolicy: ClusterFirst  restartPolicy: Alwaysstatus: &#123;&#125;\n\n等待一会儿后，会发现pod已经自动被创建了\n[root@master manifests]# kubectl get podNAME                  READY   STATUS    RESTARTS   AGEmulti-container       2/2     Running   0          89mnginx                 1/1     Running   0          97mstatic-nginx-master   1/1     Running   0          5m57s\n\n由于静态 Pod 无法通过 API Server 直接管理，所以在 Master 节点尝试删除这个 Pod，将会 使其标为 Pending 状态，且不会被删除。\n[root@master manifests]# kubectl delete pod static-nginx-masterpod &quot;static-nginx-master&quot; deleted[root@master manifests]# kubectl get podNAME                  READY   STATUS    RESTARTS   AGEmulti-container       2/2     Running   0          94mnginx                 1/1     Running   0          102mstatic-nginx-master   0/1     Pending   0          4s\n\n删除该 Pod 的操作只能是到其所在 Node 上，将其自定义文件 static.yaml 从 /etc/kubernetes/manifests 目录下删除。rm -f /etc/kubernetes/manifests/static.yaml\n初始化容器初始化容器，顾名思义容器启动的时候，会先启动可一个或多个容器，如果有多个，那么这 几个 Init Container 按照定义的顺序依次执行，只有所有的 Init Container 执行完后，主容器 才会启动。由于一个 Pod 里的存储卷是共享的，所以 Init Container 里产生的数据可以被主 容器使用到。\nInit Container 可以在多种 K8S 资源里被使用到如 Deployment、Daemon Set, Pet Set, Job 等， 但归根结底都是在 Pod 启动时，在主容器启动前执行，做初始化工作。应用场景:\n第一种场景:等待其它模块 Ready，比如我们有一个应用里面有两个容器化的服务，一个是 Web Server，另一个是数据库。其中 Web Server 需要访问数据库。但是当我们启动这个应 用的时候，并不能保证数据库服务先启动起来，所以可能出现在一段时间内 Web Server 有 数据库连接错误。为了解决这个问题，我们可以在运行 Web Server 服务的 Pod 里使用一个 InitContainer，去检查数据库是否准备好，直到数据库可以连接，Init Container 才结束退出， 然后 Web Server 容器被启动，发起正式的数据库连接请求。\n第二种场景:初始化配置，比如集群里检测所有已经存在的成员节点，为主容器准备好集群 的配置信息，这样主容器起来后就能用这个配置信息加入集群。\n其它使用场景:如将 pod 注册到一个中央数据库、下载应用依赖等。\nPod的健康检查探针是由 kubelet 对容器执行的定期诊断。要执行诊断，kubelet 调用由容器实现的 Handler。有三种类型的探针:\n\nExec 探针:执行进程的地方，容器的状态由进程的退出状态代码确认。\nHttp get 探针:向容器发送 HTTP GET 请求，通过响应的 HTTP 状态代码判断容器是否准备 好;如果响应的状态码大于等于 200 且小于 400，则诊断被认为是成功的。\nTcp socket 探针:它打开一个 TCP 连接到容器的指定端口，如果连接己建立，则认为容器己 准备就绪。\n\nkubernetes 会周期性地调用探针，并根据就绪探针的结果采取行动。如果某个 pod 报告它 尚未准备就绪，则会从该服务中删除该 pod。如果 pod 再次准备就绪，则重新添加 pod; 每次探测都将获得以下三种结果之一:\n\n成功:容器通过了诊断。\n失败:容器未通过诊断。\n未知:诊断失败，因此不会采取任何行动 。\n\nlivenessProbe(存活探针):指示容器是否正在运行。如果存活探测失败，则 kubelet 会杀死容器，并且 容器将受到其 重启策略 的影响。如果容器不提供存活探针，则默认状态为 Success 。\nreadinessProbe(就绪探针):指示容器是否准备好服务请求。如果就绪探测失败，端点控制器将从与 Pod 匹配的所有 Service 的端点中删除该 Pod 的 IP 地址。初始延迟之前的就绪状态默认为Failure。如果容器不提供就绪探针，则默认状态为 Success。\n只要 pod 的标签和服务的 pod 选择器匹配，pod 就可以作为服务的后端，但是如果 pod 没有准备好，是不能处理请求的，这时候就需要就绪探针了，用来检查 pod 是否已经准备好 了，如果检查成功就可以作为服务的后端处理消息了。\n添加存活探针apiVersion: v1kind: Podmetadata:  labels:    test: liveness  name: liveness-execspec:  containers:  - name: liveness    image: k8s.gcr.io/busybox    args:    - /bin/sh    - -c    - touch /tmp/healthy; sleep 30; rm -f /tmp/healthy; sleep 600    livenessProbe:      exec:        command:        - cat        - /tmp/healthy      initialDelaySeconds: 5      periodSeconds: 5\n\n在这个配置文件中，可以看到 Pod 中只有一个 Container。 periodSeconds 字段指定了 kubelet 应该每 5 秒执行一次存活探测。 initialDelaySeconds 字段告诉 kubelet 在执行第一次探测前应该等待 5 秒。 kubelet 在容器内执行命令 cat /tmp/healthy 来进行探测。 如果命令执行成功并且返回值为 0，kubelet 就会认为这个容器是健康存活的。 如果这个命令返回非 0 值，kubelet 会杀死这个容器并重新启动它。\n添加就绪探针apiVersion: v1kind: Podmetadata:  labels:    test: liveness  name: liveness-execspec:  containers:  - name: liveness    image: k8s.gcr.io/busybox    args:    - /bin/sh    - -c    - touch /tmp/healthy; sleep 30; rm -f /tmp/healthy; sleep 600    readinessProbe:      exec:        command:        - cat        - /tmp/healthy      initialDelaySeconds: 5      periodSeconds: 5\n\n\n\n探针参数Probe 有很多配置字段，可以使用这些字段精确地控制活跃和就绪检测的行为：\n\ninitialDelaySeconds：容器启动后要等待多少秒后才启动存活和就绪探测器， 默认是 0 秒，最小值是 0。\nperiodSeconds：执行探测的时间间隔（单位是秒）。默认是 10 秒。最小值是 1。\ntimeoutSeconds：探测的超时后等待多少秒。默认值是 1 秒。最小值是 1。\nsuccessThreshold：探测器在失败后，被视为成功的最小连续成功数。默认值是 1。 存活和启动探测的这个值必须是 1。最小值是 1。\nfailureThreshold：当探测失败时，Kubernetes 的重试次数。 对存活探测而言，放弃就意味着重新启动容器。 对就绪探测而言，放弃意味着 Pod 会被打上未就绪的标签。默认值是 3。最小值是 1。\n\nPod调度调度 是指将 Pod 放置到合适的节点上，以便对应节点上的 Kubelet 能够运行这些 Pod。\nPod的调度流程如下\n\n用户提交 pod，APIServer 记录到 etcd 中;\n\nscheduler 周期性查询 APIServer，以获取未绑定的 pod，尝试为 pod 分配节点;\n\nscheduler调度:首先过滤不符合pod资源要求的主机。然后考虑整体优化策略对主机打分，比如使用最低负载，使用分散主机等。最后选择最高分的主机存储绑定信息到 etcd 中;\n\nkubelet 周期查询绑定对象，获取需要在本机启动的 pod 并通过 docker 启动。\n\n\n\nkube-schedulerkube-scheduler 是 Kubernetes 集群的默认调度器，并且是集群 控制面 的一部分。 如果你真得希望或者有这方面的需求，kube-scheduler 在设计上允许你自己编写一个调度组件并替换原有的 kube-scheduler。\n对每一个新创建的 Pod 或者是未被调度的 Pod，kube-scheduler 会选择一个最优的节点去运行这个 Pod。 然而，Pod 内的每一个容器对资源都有不同的需求， 而且 Pod 本身也有不同的需求。因此，Pod 在被调度到节点上之前， 根据这些特定的调度需求，需要对集群中的节点进行一次过滤。\n在一个集群中，满足一个 Pod 调度请求的所有节点称之为 可调度节点。 如果没有任何一个节点能满足 Pod 的资源请求， 那么这个 Pod 将一直停留在未调度状态直到调度器能够找到合适的 Node。\n调度器先在集群中找到一个 Pod 的所有可调度节点，然后根据一系列函数对这些可调度节点打分， 选出其中得分最高的节点来运行 Pod。之后，调度器将这个调度决定通知给 kube-apiserver，这个过程叫做 绑定。\n在做调度决定时需要考虑的因素包括：单独和整体的资源请求、硬件/软件/策略限制、 亲和以及反亲和要求、数据局部性、负载间的干扰等等。\nkube-scheduler 调度流程kube-scheduler 给一个 Pod 做调度选择时包含两个步骤：\n\n过滤\n打分\n\n过滤阶段会将所有满足 Pod 调度需求的节点选出来。 例如，PodFitsResources 过滤函数会检查候选节点的可用资源能否满足 Pod 的资源请求。 在过滤之后，得出一个节点列表，里面包含了所有可调度节点；通常情况下， 这个节点列表包含不止一个节点。如果这个列表是空的，代表这个 Pod 不可调度。\n在打分阶段，调度器会为 Pod 从所有可调度节点中选取一个最合适的节点。 根据当前启用的打分规则，调度器会给每一个可调度节点进行打分。\n最后，kube-scheduler 会将 Pod 调度到得分最高的节点上。 如果存在多个得分最高的节点，kube-scheduler 会从中随机选取一个。\n支持以下两种方式配置调度器的过滤和打分行为：\n\n调度策略 允许你配置过滤所用的 断言（Predicates） 和打分所用的 优先级（Priorities）。\n调度配置 允许你配置实现不同调度阶段的插件， 包括：QueueSort、Filter、Score、Bind、Reserve、Permit 等等。 你也可以配置 kube-scheduler 运行不同的配置文件。\n\n将pod调度到节点节点选择器给某个node添加 disktype=ssd 标签：kubectl label nodes &lt;your-node-name&gt; disktype=ssd\n此 Pod 配置文件描述了一个拥有节点选择器 disktype: ssd 的 Pod。这表明该 Pod 将被调度到有 disktype=ssd 标签的节点。如果没有节点包含disktype=ssd 标签，Pod则处于Pending状态，直到找到包含disktype=ssd 标签的节点。\napiVersion: v1kind: Podmetadata:  name: nginx  labels:    env: testspec:  containers:  - name: nginx    image: nginx    imagePullPolicy: IfNotPresent  nodeSelector:    disktype: ssd\n\n节点名称可以通过设置 nodeName 将某个 Pod 调度到特定的节点。如果节点名称不存在的话，Pod无法被调度，不会被创建。\n使用 nodeName 来选择节点的一些限制:\n\n如果指定的节点不存在，则Pod调度失败。\n如果指定的节点没有资源来容纳 Pod，Pod 将会调度失败并且其原因将显示 OutOfmemory 或 OutOfcpu。\n云环境中的节点名称并非总是可预测或稳定的。\n\n如果 nodeName 在 PodSpec 中指定了，则它优先于节点选择方法。\napiVersion: v1kind: Podmetadata:  name: nginxspec:  nodeName: foo-node # 调度 Pod 到特定的节点  containers:  - name: nginx    image: nginx    imagePullPolicy: IfNotPresent\n\n\n\n亲和性与反亲和性nodeSelector 提供了一种最简单的方法来将 Pod 约束到具有特定标签的节点上。 亲和性和反亲和性扩展了你可以定义的约束类型。使用亲和性与反亲和性的一些好处有：\n\n亲和性、反亲和性语言的表达能力更强。nodeSelector 只能选择拥有所有指定标签的节点。 亲和性、反亲和性为你提供对选择逻辑的更强控制能力。\n你可以标明某规则是“软需求”或者“偏好”，这样调度器在无法找到匹配节点时仍然调度该 Pod。\n你可以使用节点上（或其他拓扑域中）运行的其他 Pod 的标签来实施调度约束， 而不是只能使用节点本身的标签。这个能力让你能够定义规则允许哪些 Pod 可以被放置在一起。\n\n亲和性功能由两种类型的亲和性组成：\n\n节点亲和性功能类似于 nodeSelector 字段，但它的表达能力更强，并且允许你指定软规则。\nPod 间亲和性/反亲和性允许你根据其他 Pod 的标签来约束 Pod。\n\n节点亲和性节点亲和性概念上类似于 nodeSelector， 它使你可以根据节点上的标签来约束 Pod 可以调度到哪些节点上。 节点亲和性有两种：\n\nrequiredDuringSchedulingIgnoredDuringExecution： 调度器只有在规则被满足的时候才能执行调度。此功能类似于 nodeSelector， 但其语法表达能力更强。\npreferredDuringSchedulingIgnoredDuringExecution： 调度器会尝试寻找满足对应规则的节点。如果找不到匹配的节点，调度器仍然会调度该 Pod。\n\n\n在上述类型中，IgnoredDuringExecution 意味着如果节点标签在 Kubernetes 调度 Pod 时发生了变更，Pod 仍将继续运行。\n\napiVersion: v1kind: Podmetadata:  name: with-node-affinityspec:  affinity:    nodeAffinity:      requiredDuringSchedulingIgnoredDuringExecution:        nodeSelectorTerms:        - matchExpressions:          - key: topology.kubernetes.io/zone            operator: In            values:            - antarctica-east1            - antarctica-west1      preferredDuringSchedulingIgnoredDuringExecution:      - weight: 1        preference:          matchExpressions:          - key: another-node-label-key            operator: In            values:            - another-node-label-value  containers:  - name: with-node-affinity    image: k8s.gcr.io/pause:2.0\n\n在这一示例中，所应用的规则如下：\n\n节点必须包含一个键名为 topology.kubernetes.io/zone 的标签， 并且该标签的取值必须为 antarctica-east1 或 antarctica-west1。\n节点最好具有一个键名为 another-node-label-key 且取值为 another-node-label-value 的标签。\n\n你可以使用 operator 字段来为 Kubernetes 设置在解释规则时要使用的逻辑操作符。 你可以使用 In、NotIn、Exists、DoesNotExist、Gt 和 Lt 之一作为操作符。\nNotIn 和 DoesNotExist 可用来实现节点反亲和性行为。 你也可以使用节点污点 将 Pod 从特定节点上驱逐。\n\n如果同时指定了 nodeSelector 和 nodeAffinity，两者 必须都要满足， 才能将 Pod 调度到候选节点上。\n如果指定了多个与 nodeAffinity 类型关联的 nodeSelectorTerms， 只要其中一个 nodeSelectorTerms 满足的话，Pod 就可以被调度到节点上。\n如果指定了多个与同一 nodeSelectorTerms 关联的 matchExpressions， 则只有当所有 matchExpressions 都满足时 Pod 才可以被调度到节点上。\n\n污点和容忍度节点亲和性 是 Pod 的一种属性，它使 Pod 被吸引到一类特定的节点 （这可能出于一种偏好，也可能是硬性要求）。 污点（Taint） 则相反——它使节点能够排斥一类特定的 Pod。\n容忍度（Toleration） 是应用于 Pod 上的。容忍度允许调度器调度带有对应污点的 Pod。 容忍度允许调度但并不保证调度：作为其功能的一部分， 调度器也会评估其他参数。\n污点和容忍度（Toleration）相互配合，可以用来避免 Pod 被分配到不合适的节点上。 每个节点上都可以应用一个或多个污点，这表示对于那些不能容忍这些污点的 Pod， 是不会被该节点接受的。\n给节点增加一个污点。比如，\nkubectl taint nodes node1 key1=value1:NoSchedule\n\n给节点 node1 增加一个污点，它的键名是 key1，键值是 value1，效果是 NoSchedule。 这表示只有拥有和这个污点相匹配的容忍度的 Pod 才能够被分配到 node1 这个节点。\n可以在 Pod 规约中为 Pod 设置容忍度。 下面的Pod配置的容忍度，则能够被调度到 node1 ：\napiVersion: v1kind: Podmetadata:  name: nginx  labels:    env: testspec:  containers:  - name: nginx    image: nginx    imagePullPolicy: IfNotPresent  tolerations:  - key: &quot;key1&quot;    operator: &quot;Equal&quot;    value: &quot;value1&quot;    effect: &quot;NoSchedule&quot;\n\n给节点删除一个污点\nkubectl taint nodes master node-role.kubernetes.io/master-\n\n\n\nPod间亲和性与反亲和性Pod 间亲和性与反亲和性使你可以基于已经在节点上运行的 Pod 的标签来约束 Pod 可以调度到的节点，而不是基于节点上的标签。\nPod 间亲和性与反亲和性的规则格式为“如果 X 上已经运行了一个或多个满足规则 Y 的 Pod， 则这个 Pod 应该（或者在反亲和性的情况下不应该）运行在 X 上”。 这里的 X 可以是节点、机架、云提供商可用区或地理区域或类似的拓扑域， Y 则是 Kubernetes 尝试满足的规则。\n你通过标签选择算符 的形式来表达规则（Y），并可根据需要指定选关联的名字空间列表。 Pod 在 Kubernetes 中是名字空间作用域的对象，因此 Pod 的标签也隐式地具有名字空间属性。 针对 Pod 标签的所有标签选择算符都要指定名字空间，Kubernetes 会在指定的名字空间内寻找标签。\n你会通过 topologyKey 来表达拓扑域（X）的概念，其取值是系统用来标示域的节点标签键。 相关示例可参见常用标签、注解和污点。\n\nPod 反亲和性需要节点上存在一致性的标签。换言之， 集群中每个节点都必须拥有与 topologyKey 匹配的标签。 如果某些或者所有节点上不存在所指定的 topologyKey 标签，调度行为可能与预期的不同。\n\nkind: Podmetadata:  name: with-pod-affinityspec:  affinity:    podAffinity:      requiredDuringSchedulingIgnoredDuringExecution:      - labelSelector:          matchExpressions:          - key: security            operator: In            values:            - S1        topologyKey: topology.kubernetes.io/zone    podAntiAffinity:      preferredDuringSchedulingIgnoredDuringExecution:      - weight: 100        podAffinityTerm:          labelSelector:            matchExpressions:            - key: security              operator: In              values:              - S2          topologyKey: topology.kubernetes.io/zone  containers:  - name: with-pod-affinity    image: k8s.gcr.io/pause:2.0\n\n本示例定义了一条 Pod 亲和性规则和一条 Pod 反亲和性规则。Pod 亲和性规则配置为 requiredDuringSchedulingIgnoredDuringExecution，而 Pod 反亲和性配置为 preferredDuringSchedulingIgnoredDuringExecution。\n亲和性规则表示，仅当节点和至少一个已运行且有 security=S1 的标签的 Pod 处于同一区域时，才可以将该 Pod 调度到节点上。 更确切的说，调度器必须将 Pod 调度到具有 topology.kubernetes.io/zone=V 标签的节点上，并且集群中至少有一个位于该可用区的节点上运行着带有 security=S1 标签的 Pod。\n反亲和性规则表示，如果节点处于 Pod 所在的同一可用区且至少一个 Pod 具有 security=S2 标签，则该 Pod 不应被调度到该节点上。 更确切地说， 如果同一可用区中存在其他运行着带有 security=S2 标签的 Pod 节点， 并且节点具有标签 topology.kubernetes.io/zone=R，Pod 不能被调度到该节点上。\n查阅设计文档 以进一步熟悉 Pod 亲和性与反亲和性的示例。\n你可以针对 Pod 间亲和性与反亲和性为其 operator 字段使用 In、NotIn、Exists、 DoesNotExist 等值。\n原则上，topologyKey 可以是任何合法的标签键。出于性能和安全原因，topologyKey 有一些限制：\n\n对于 Pod 亲和性而言，在 requiredDuringSchedulingIgnoredDuringExecution 和 preferredDuringSchedulingIgnoredDuringExecution 中，topologyKey 不允许为空。\n对于 requiredDuringSchedulingIgnoredDuringExecution 要求的 Pod 反亲和性， 准入控制器 LimitPodHardAntiAffinityTopology 要求 topologyKey 只能是 kubernetes.io/hostname。如果你希望使用其他定制拓扑逻辑， 你可以更改准入控制器或者禁用之。\n\n除了 labelSelector 和 topologyKey，你也可以指定 labelSelector 要匹配的命名空间列表，方法是在 labelSelector 和 topologyKey 所在层同一层次上设置 namespaces。 如果 namespaces 被忽略或者为空，则默认为 Pod 亲和性/反亲和性的定义所在的命名空间。\n","categories":["K8S"],"tags":["K8S"]},{"title":"Prometheus&Grafana安装及使用","url":"/2022/06/13/K8S/Prometheus&Grafana%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/","content":"之前通过docker的方式安装过Prometheus和Grafana，用于监控web服务及linux资源信息。后续想通过K8S来进行管理，并且不想通过operator的形式安装高可用模式。\n不再介绍Prometheus和Grafana，主要介绍单机版安装及安装过程中遇到的坑及怎样去解决。\n前置条件Prometheus需要进行信息的抓取，所以需要提供前置的metrics。Prometheus提供了非常多的exporter，用来抓取各种第三方信息，其中node exporter是Prometheus官方公布的exporter，用于抓取服务器内存，磁盘等信息。而kube state metrics则是由kubernetes社区提供的用于抓取K8S集群信息的exporter。所以需要先在K8S上部署node exporter和kube state metrics，用以监控K8S node节点信息及集群信息。\n需要创建monitoring命名空间，所有的pod均在此命名空间下\n安装node exporter编写yaml文件nodeExporterServiceDeployment.yaml\napiVersion: apps/v1kind: DaemonSetmetadata:  name: node-exporter  namespace: monitoring  labels:    app: node-exporterspec:  selector:   matchLabels:    app: node-exporter  template:    metadata:      labels:        app: node-exporter    spec:      containers:      - image: prom/node-exporter        name: node-exporter        ports:        - containerPort: 9100          protocol: TCP          name: http---apiVersion: v1kind: Servicemetadata:  labels:    app: node-exporter  name: node-exporter  namespace: monitoringspec:  ports:  - name: http    port: 9100    protocol: TCP  type: NodePort  selector:    app: node-exporter\n\n创建deployment和servicekubectl apply -f nodeExporterServiceDeployment.yaml\n查看暴露端口为30206，访问http://&lt;domain&gt;:30206/metrics,显示抓取信息，则表明安装成功\n[root@localhost node-exporter]# k get svcNAME                 TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGEgrafana              NodePort    172.22.234.69    &lt;none&gt;        3000:30009/TCP   3d21hkube-state-metrics   ClusterIP   172.22.244.239   &lt;none&gt;        8080/TCP         2d23hnode-exporter        NodePort    172.22.53.67     &lt;none&gt;        9100:30206/TCP   2d22hprometheus           NodePort    172.22.47.43     &lt;none&gt;        9090:30909/TCP   3d21h\n\n\n安装kube state metrics官方单独部署的yaml文件\n进行了些许的改动，namespace修改了下。改动后的文件列表\n\ncluster-role.yaml\ncluster-role-binding.yaml\ndeployment.yaml\nservice-account.yaml\nservice.yaml\n\nkubectl apply -f &lt;filename&gt;.yaml来使上述文件生效\n安装Prometheus和Grafana由于Prometheus是基于时序数据库TSDB，生成的数据如果在pod中，在pod删除重建后抓取的数据就没了（相当于docker的container）,所以需要将数据通过PV/PVC挂载到外面。\n部署文件列表\n\nprometheus.yaml\nprometheus-pv.yaml\nprometheus-pvc.yaml\nprometheusServiceDeployment.yaml\ngrafanaServiceDeployment.yaml\n\nkubectl apply -f &lt;filename&gt;.yaml来使上述文件生效\n修改Prometheus和Grafana的service，可以通过IP进行外网访问[root@localhost data]# k edit service prometheus...  ports:  - name: http    nodePort: 30909    port: 9090    protocol: TCP    targetPort: 9090  selector:    app: prometheus  sessionAffinity: None  type: NodePort #此项修改为NodePort...\n\n[root@localhost data]# k edit service grafana...spec:  clusterIP: 172.22.234.69  clusterIPs:  - 172.22.234.69  externalTrafficPolicy: Cluster  ipFamilies:  - IPv4  ipFamilyPolicy: SingleStack  ports:  - name: http    nodePort: 30009    port: 3000    protocol: TCP    targetPort: 3000  selector:    app: grafana  sessionAffinity: None  type: NodePort #此项修改为NodePort...\n\n查看monitoring名称空间下的所有信息如下\n[root@localhost data]# k get allNAME                                     READY   STATUS    RESTARTS   AGEpod/grafana-9579494df-l2hzc              1/1     Running   0          3d23hpod/kube-state-metrics-dcf4dbb9b-g96dm   1/1     Running   0          3d3hpod/node-exporter-hr2zv                  1/1     Running   0          3d1hpod/prometheus-749bdc7fb5-z6m4d          1/1     Running   0          3d2hNAME                         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGEservice/grafana              NodePort    172.22.234.69    &lt;none&gt;        3000:30009/TCP   3d23hservice/kube-state-metrics   ClusterIP   172.22.244.239   &lt;none&gt;        8080/TCP         3d2hservice/node-exporter        NodePort    172.22.53.67     &lt;none&gt;        9100:30206/TCP   3d1hservice/prometheus           NodePort    172.22.47.43     &lt;none&gt;        9090:30909/TCP   3d23hNAME                           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGEdaemonset.apps/node-exporter   1         1         1       1            1           &lt;none&gt;          3d1hNAME                                 READY   UP-TO-DATE   AVAILABLE   AGEdeployment.apps/grafana              1/1     1            1           3d23hdeployment.apps/kube-state-metrics   1/1     1            1           3d3hdeployment.apps/prometheus           1/1     1            1           3d23hNAME                                            DESIRED   CURRENT   READY   AGEreplicaset.apps/grafana-9579494df               1         1         1       3d23hreplicaset.apps/kube-state-metrics-67d4fc6999   0         0         0       3d3hreplicaset.apps/kube-state-metrics-dcf4dbb9b    1         1         1       3d3hreplicaset.apps/prometheus-554dccf664           0         0         0       3d23hreplicaset.apps/prometheus-58cd99776b           0         0         0       3d23hreplicaset.apps/prometheus-749bdc7fb5           1         1         1       3d9hreplicaset.apps/prometheus-78f7c6c9d5           0         0         0       3d23hreplicaset.apps/prometheus-dc566c756            0         0         0       3d23h\n\n","categories":["K8S"],"tags":["K8S"]},{"title":"k8s简介","url":"/2022/03/14/K8S/k8s%E7%AE%80%E4%BB%8B/","content":"Kubernetes是什么\n\n传统部署时代\n早期，各个组织机构在物理服务器上运行应用程序。无法为物理服务器中的应用程序定义资源边界，这会导致资源分配问题。例如，如果在物理服务器上运行多个应用程序，则可能会出现一个应用程序占用大部分资源的情况，结果可能导致其他应用程序的性能下降。 一种解决方案是在不同的物理服务器上运行每个应用程序，但是由于资源利用不足而无法扩展，并且维护许多物理服务器的成本很高。\n\n虚拟化部署时代\n作为解决方案，引入了虚拟化。虚拟化技术允许你在单个物理服务器的CPU上运行多个虚拟机（VM）。虚拟化允许应用程序在VM之间隔离，并提供一定程度的安全，因为一个应用程序的信息不能被另一应用程序随意访问。虚拟化技术能够更好地利用物理服务器上的资源，并且因为可轻松地添加或更新应用程序而可以实现更好的可伸缩性，降低硬件成本等等。每个VM是一台完整的计算机，在虚拟化硬件之上运行所有组件，包括其自己的操作系统。\n\n容器部署时代\n容器类似于VM，但是它们具有被放宽的隔离属性，可以在应用程序之间共享操作系统（OS）。因此，容器被认为是轻量级的。容器与VM类似，具有自己的文件系统、CPU、内存、进程空间等。由于它们与基础架构分离，因此可以跨云和OS发行版本进行移植。容器因具有许多优势而变得流行起来。下面列出的是容器的一些好处：\n\n敏捷应用程序的创建和部署：与使用VM镜像相比，提高了容器镜像创建的简便性和效率。\n持续开发、集成和部署：通过快速简单的回滚（由于镜像不可变性），支持可靠且频繁的容器镜像构建和部署。\n关注开发与运维的分离：在构建发布时而不是在部署时创建应用程序容器镜像，从而将应用程序与基础架构分离。\n可观察性：不仅可以显示操作系统级别的信息和指标，还可以显示应用程序的运行状况和其他指标信号。\n跨开发、测试和生产的环境一致性：在便携式计算机上与在云中相同地运行。\n跨云和操作系统发行版本的可移植性：可在Ubuntu、RHEL、CoreOS、本地、Google Kubernetes engine和其他任何地方运行。\n以应用程序为中心的管理：提高抽象级别，从在虚拟硬件上运行OS到使用逻辑资源在OS上运行应用程序。\n松散耦合、分布式、弹性、解放的微服务：应用程序被分解成较小的独立部分，并且可以动态部署和管理 而不是在一台大型单机上整体运行。\n资源隔离：可预测的应用程序性能。\n资源利用：高效率和高密度。\n\n\n\n容器是捆绑和运行应用程序的好方法。在生产环境中，您需要管理运行应用程序的容器并确保没有停机时间。例如，如果一个容器发生故障，则另一个容器需要启动。如果这种行为由系统处理会不会更容易？\n为什么需要Kubernetes，它能做什么\n服务发现和负载均衡Kubernetes可以使用DNS名称或自己的IP地址公开容器，如果进入容器的流量很大，Kubernetes可以负载均衡并分配网络流量，从而使部署稳定。\n自动部署和回滚你可以使用Kubernetes描述已部署容器的所需状态，它可以以受控的速率将实际状态 更改为期望状态。例如，你可以自动化Kubernetes来为你的部署创建新容器，删除现有容器并将它们的所有资源用于新容器。\n自动完成装箱计算Kubernetes允许你指定每个容器所需CPU和内存（RAM）。当容器指定了资源请求时，Kubernetes可以做出更好的决策来管理容器的资源。\n自我修复Kubernetes重新启动失败的容器、替换容器、杀死不响应用户定义的运行状况检查的容器，并且在准备好服务之前不将其通告给客户端。\n密钥与配置管理Kubernetes允许你存储和管理敏感信息，例如密码、OAuth令牌和ssh密钥。你可以在不重建容器镜像的情况下部署和更新密钥和应用程序配置，也无需在堆栈配置中暴露密钥。\n弹性扩展定义期待的容器状态与资源，K8S自动检测、创建、删除实例和配置以满足要求。\n存储编排Kubernetes允许你自动挂载你选择的存储系统，例如本地存储、公共云提供商等。允许你自动挂载你选择的存储系统，例如本地存储、公共云提供商等。\n\nK8s容器生态系统及容器编排技术对比\n容器编排对比\n\nKubernetes版本进化\n2014年6月：谷歌宣布kubernetes开源\n2014年7月：Mircrosoft、Red Hat、IBM、Docker、CoreOS、Mesosphere和Saltstack加入kubernetes。\n2014年8月：2014年8月Mesosphere宣布将kubernetes作为frame整合到mesosphere生态系统中，用于Docker容器集群的调度、部署和管理\n2014年8月：VMware加入kubernetes社区\n2014年11月HP加入kubernetes社区\n2014年11月：Google容器引擎Alpha启动，谷歌宣布GCE中支持容器及服务，并以kubernetes为构架\n2015年1月：Google和 Mirantis及伙伴将kubernetes引入OpenStack开发者可以在openstack上部署运行kubernetes应用\n2015年4月： Google和CoreOs联合发布Tectonic它将kubernetes和CoreOS软件栈整合在了一起\n2015年5月： Intel加入kubernetes社区，宣布将合作加速Tectonic软件栈的发展进度\n2015年6月：Google容器引擎进入beta版\n2015年7月：Google正式加入OpenStack基金会，Kubernetes的产品经理宣称将把它容器计算的专家技术带入OpenStack\n2015年7月：Kuberentes v1.0正式发布\n2017年9月：Kuberentes v1. 8正式发布\n2017年12月：Kuberentes v1. 9正式发布\n2022年3月：Kuberentes 1.22\n\nKubernetes概念\n\n\n控制平面组件（Control Plane Components）\napi server：作为kubernetes系统的入口，封装了核心对象的增删改查操作，以RESTFUL接口方式提供给外部客户和内部组件调用。它维护的REST对象将持久化到etcd（一个分布式强一致性的 key/value 存储）\nscheduler：负责集群的资源调度，为新建的pod分配机器。这部分工作分出来变成一个组件，意味着可以很方便地替换成其他的调度器\ncontroller manager：负责执行各种控制器，目前有两类\nendpoint controller：定期关联service 和pod( 关联信息由endpoint 对象维护)，保证service到pod的映射总是最新的\nreplication controller：定期关联replicationController和pod，保证replicationController定义的复制数量与实际运行pod的数量总是一致的\n\n\n\n\nNode组件\nkubelet：负责管控docker容器，如启动停止、监控运行状态等。它会定期从etcd获取分配到本机的pod，并根据pod信息启动或停止相应的容器。同时，它也会接收apiserver的HTTP请求，汇报pod的运行状态。\nproxy：负责为pod提供代理。它会定期从etcd获取所有的service，并根据service信息创建代理。当某个客户pod要访问其他pod时，访问请求会经过本机proxy做代理。\nContainer Runtime： Docker engine\n\n\n插件（Addons）\nCore DNS：kube-DNS,CoreDNS\nNetwork plugin：Flannel, calico\nWeb界面（仪表盘）：Dashboard是Kubernetes集群的通用的、基于Web的用户界面。它使用户可以管理集群中运行的应用程序以及集群本身并进行故障排除。\n容器资源监控：Heapster, Metrics server\n\n\n\nKubernetes HA集群\nKubernetes中三个重要概念\nPod：是Kubernetes最基本的部署调度单元，可以包含Container，逻辑上表示某种应用的一个实例。比如一个web站点应用由前端、后端及数据库构建而成，这三个组件将运行在各自的容器中，那么我们可以创建包含三个Container的Pod。\nService：也是Kubernetes的基本操作单元，是真实应用服务的抽象，每一个服务后面都有很多对应的容器来支持，通过Proxy的port和服务selector决定服务请求传递给后端提供服务的容器，对外表现为一个单一访问接口，外部不需要了解后端如何运行，这给扩展或维护后端带来很大的好处。\nReplicationController：是Pod的复制抽象，用于解决Pod的扩容缩容问题。通常，分布式应用为了性能或高可用性的考虑，需要复制多份资源，并且根据负载情况动态伸缩。通过ReplicationController，我们可以指定一个应用需要几份复制Kubernetes将为每份复制创建一个Pod，并且保证实际运行Pod数量总是与该复制数量相等。例如，当前某个Pod宕机时，自动创建新的Pod来替换。\n\n\nKubernetes编排调度框架\n\n\n中文社区\n官方网址\n\n\n","categories":["K8S"],"tags":["K8S"]},{"title":"工作负载","url":"/2022/09/01/K8S/%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD/","content":"","categories":["K8S"],"tags":["K8S"]},{"title":"centos8 基本操作","url":"/2022/03/14/Linux/Centos8%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/","content":"网络相关网卡配置文件：/etc/sysconfig/network-scripts/ifcfg-ens33\nnmcli\n查看网卡设备详细信息nmcli device show [deviceName]\n查看网卡设备状态nmcli device status\n启动网卡nmcli connection up [deviceName]\n停止网卡nmcli connection down [deviceName]\n重启网卡nmcli connection reload [deviceName]\n\n修改为静态ip[root@slave1 ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens33TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=static #修改为staticDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens33UUID=df81f434-c8f4-4b8c-a586-e0e7bac35b5bDEVICE=ens33ONBOOT=yes #修改为yesIPADDR=192.168.8.3 #本机地址PREFIX=24 #子网掩码GATEWAY=192.168.8.5 #网关地址IPV6_PRIVACY=onDNS1=114.114.114.114 #DNSd\n\n\n\n主机相关域名解析文件：/etc/hosts\nhostnamectlhostname有三种类型：static,pretty,和transient\n\nstatic:传统主机名。它存储在/etc/hostname文件中，并且可以被用户设置\npretty:一个自由形态的 UTF8 主机名，用来代表用户。例如： Chay’s desktop。\ntransient:由 kernel 维护的动态主机名。 在运行过程中，DHCP 或者 mDNS 服务器可以改变 transient 主机名。默认情况下，它和 static 主机名一模一样\n\n\n修改主机名\n\n​        hostnamectl set-hostname &lt;your hostname&gt; --static\npasswd\n修改用户密码sudo passwd root\n\n命令别名\n修改/etc/profile文件，在最后进行追加命令alias vi=&#39;vim&#39;\n\n授权chmod  [-cfvR] [--help] [--version] [ugoa...][[+-=][rwxX]...][,...] \n\nu 表示该文件的拥有者，g 表示与该文件的拥有者属于同一个群体(group)者，o 表示其他以外的人，a 表示这三者皆是。\n+ 表示增加权限、- 表示取消权限、= 表示唯一设定权限。\nr 表示可读取，w 表示可写入，x 表示可执行，X 表示只有当该文件是个子目录或者该文件已经被设定过为可执行。\n其他参数说明：\n-c : 若该文件权限确实已经更改，才显示其更改动作\n-f : 若该文件权限无法被更改也不要显示错误讯息\n-v : 显示权限变更的详细资料\n-R : 对目前目录下的所有文件与子目录进行相同的权限变更(即以递回的方式逐个变更)\n–help : 显示辅助说明\n–version : 显示版本\n\n\n\ntroubleshooting无法远程SSH登录前置条件：\n\n两台机器可以互相ping通，但是无法ssh登录\n\n可能原因及解决方式：\n\n未安装openssh-servernetstat -ntlp | grep 22 发现没有程序在监听22端口，即未安装openssh-server解决方式：apt install openssh-server -y\n\n无法远程SSH到ROOT用户前置条件：\n\n两台机器可以互相ping通\n\n可能原因及解决方式：\n\n未开启root用户远程登录权限chay@chay:~# su - rootroot@chay:~# vim /etc/ssh/sshd_config...# Logging#SyslogFacility AUTH#LogLevel INFO# Authentication:#LoginGraceTime 2mPermitRootLogin yes  #将此行注释去掉，并修改为yes#StrictModes yes#MaxAuthTries 6#MaxSessions 10...root@chay:~# systemctl restart ssh\n\n","categories":["Linux"],"tags":["centos8"]},{"title":"Docker命令","url":"/2021/03/03/Linux/Docker%E5%91%BD%E4%BB%A4/","content":"Docker rundocker run [OPTIONS] IMAGE [COMMAND] [ARG...]\n","categories":["Linux"],"tags":["DevOps"]},{"title":"Docker安装","url":"/2021/03/03/Linux/Docker%E5%AE%89%E8%A3%85/","content":"删除旧版本docker如果是yum安装的话，需要通过yum删除sudo yum remove docker \\                  docker-client \\                  docker-client-latest \\                  docker-common \\                  docker-latest \\                  docker-latest-logrotate \\                  docker-logrotate \\                  docker-selinux \\                  docker-engine-selinux \\                  docker-engine\n删除yum源[chay@localhost ~]$ yum repolist已加载插件：fastestmirror, langpacks, product-id, search-disabled-repos, subscription-managerLoading mirror speeds from cached hostfile * base: mirrors.huaweicloud.com * extras: mirrors.huaweicloud.com * updates: mirrors.huaweicloud.com源标识                           源名称                                      状态base/7/x86_64                   CentOS-7 - Base                            10,070docker-ce-stable/x86_64         Docker CE Stable - x86_64                  79extras/7/x86_64                 CentOS-7 - Extras                          413updates/7/x86_64               CentOS-7 - Updates                          1,134repolist: 11,696[chay@localhost ~]$ cd /etc/yum.repos.d/[chay@localhost yum.repos.d]$ ll总用量 40-rw-r--r--. 1 root root 1664 4月   8 06:01 CentOS-Base.repo-rw-r--r--. 1 root root 1309 4月   8 06:01 CentOS-CR.repo-rw-r--r--. 1 root root  649 4月   8 06:01 CentOS-Debuginfo.repo-rw-r--r--. 1 root root  314 4月   8 06:01 CentOS-fasttrack.repo-rw-r--r--. 1 root root  630 4月   8 06:01 CentOS-Media.repo-rw-r--r--. 1 root root 1331 4月   8 06:01 CentOS-Sources.repo-rw-r--r--. 1 root root 7577 4月   8 06:01 CentOS-Vault.repo-rw-r--r--. 1 root root  616 4月   8 06:01 CentOS-x86_64-kernel.repo-rw-r--r--. 1 root root 2424 7月  28 19:08 docker-ce.repo[chay@localhost yum.repos.d]$ sudo rm -f docker-ce.repo [chay@localhost yum.repos.d]$ yum clean all\n删除文件夹sudo rm -rf /etc/systemd/system/docker.service.d &amp;&amp; rm -rf /etc/systemd/system/docker.service.d &amp;&amp; rm -rf /etc/systemd/system/docker.service.d &amp;&amp; rm -rf /etc/systemd/system/docker.service.d &amp;&amp; rm -rf /etc/systemd/system/docker.service.d\n安装docker安装yum工具包sudo yum -y install yum-utils device-mapper-persistent-data lvm2\n添加阿里docker镜像源sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n更新 yum 缓存sudo yum makecache fast\n安装 Docker-cesudo yum -y install docker-ce\n\n查看当前所有docker版本yum list docker-ce.x86_64 --showduplicates | sort -r\n\n启动 Docker 后台服务sudo systemctl start docker\n开启自启sudo systemctl enable docker\n验证docker是否安装成功[root@localhost chay]# docker run hello-worldUnable to find image &#x27;hello-world:latest&#x27; locallylatest: Pulling from library/hello-world0e03bdcc26d7: Pull complete Digest: sha256:4cf9c47f86df71d48364001ede3a4fcd85ae80ce02ebad74156906caff5378bcStatus: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub.    (amd64) 3. The Docker daemon created a new container from that image which runs the    executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it    to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/[root@localhost chay]# docker image lsREPOSITORY          TAG                 IMAGE ID            CREATED             SIZEhello-world         latest              bf756fb1ae65        8 months ago        13.3kB\n设置dockerHub国内镜像源创建或修改 /etc/docker/daemon.json 文件# vi /etc/docker/daemon.json&#123;&quot;registry-mirrors&quot;: [&quot;http://hub-mirror.c.163.com&quot;]&#125;\n重启docker容器：\nsystemctl restart docker.service\nDocker中国区官方镜像https://registry.docker-cn.com\n网易http://hub-mirror.c.163.com\n中国科技大学https://docker.mirrors.ustc.edu.cn\n阿里云容器服务https://cr.console.aliyun.com/首页点击“创建我的容器镜像”得到一个专属的镜像加速地址\n安装docker-compose[root@localhost ~]# curl -L https://get.daocloud.io/docker/compose/releases/download/v2.4.1/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current                                 Dload  Upload   Total   Spent    Left  Speed100   423  100   423    0     0    407      0  0:00:01  0:00:01 --:--:--   407100 25.2M  100 25.2M    0     0  5251k      0  0:00:04  0:00:04 --:--:-- 6707k[root@localhost ~]# sudo chmod +x /usr/local/bin/docker-compose[root@localhost ~]# ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose[root@localhost ~]# docker-compose --versionDocker Compose version v2.4.1\n\n\n\n遇到问题1.Got permission denied while trying to connect to the Docker daemon socket现象[chay@localhost ~]$ docker run hello-worlddocker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/create: dial unix /var/run/docker.sock: connect: permission denied.See &#x27;docker run --help&#x27;.\n原因来自docker manual：\n\nManage Docker as a non-root user\nThe docker daemon binds to a Unix socket instead of a TCP port. By default that Unix socket is owned by the user root and other users can only access it using sudo. The docker daemon always runs as the root user.\nIf you don’t want to use sudo when you use the docker command, create a Unix group called docker and add users to it. When the docker daemon starts, it makes the ownership of the Unix socket read/writable by the docker group.\n\n docker进程使用 Unix Socket 而不是 TCP 端口。而默认情况下，Unix socket 属于 root 用户，因此需要 root权限 才能访问。\n解决方法[chay@localhost ~]$ sudo groupadd docker groupadd：“docker”组已存在[chay@localhost ~]$ sudo gpasswd -a chay docker正在将用户“chay”加入到“docker”组中[chay@localhost ~]$ sudo newgrp docker[root@localhost chay]# groupsdocker root\n","categories":["Linux"],"tags":["DevOps"]},{"title":"Linux使用DenyHosts防止ssh暴力破解","url":"/2020/01/03/Linux/Linux%E4%BD%BF%E7%94%A8DenyHosts%E9%98%B2%E6%AD%A2ssh%E6%9A%B4%E5%8A%9B%E7%A0%B4%E8%A7%A3/","content":"背景在自己部署的服务器上，查看日志发现被疯狂扫描22端口，并且伴随着暴力登录，为了防止服务器被暴力破解，故而寻找解决方法。\nDenyHosts介绍DenyHosts是Python语言写的一个程序，它会分析sshd的日志文件（/var/log/secure），当发现重复的攻击时就会记录IP到/etc/hosts.deny文件，从而达到自动屏IP的功能。\n\nDenyHosts官方网站为：http://denyhosts.sourceforge.net\n\n安装DenyHostswget &quot;downloads.sourceforge.net/project/denyhosts/denyhosts/2.6/DenyHosts-2.6.tar.gz&quot;tar -xzf DenyHosts-2.6.tar.gz cd DenyHosts-2.6python setup.py install\n\nDenyHosts默认安装到/usr/share/denyhosts目录\n\n配置DenyHostscd /usr/share/denyhosts/cp denyhosts.cfg-dist denyhosts.cfgvim denyhosts.cfg\n\n修改如下：PURGE_DENY = 50m               #过多久后清除已阻止IPHOSTS_DENY = /etc/hosts.deny   #将阻止IP写入到hosts.denyBLOCK_SERVICE = sshd           #阻止服务名PURGE_THRESHOLD =              #定义了某一IP最多被解封多少次。某IP暴力破解SSH密码被阻止/解封达到了PURGE_THRESHOLD次，则会被永久禁止；DENY_THRESHOLD_INVALID = 1     #允许无效用户登录失败的次数DENY_THRESHOLD_VALID = 10      #允许普通用户登录失败的次数DENY_THRESHOLD_ROOT = 5        #允许root登录失败的次数WORK_DIR = /usr/local/share/denyhosts/data #将deny的host或ip纪录到Work_dir中DENY_THRESHOLD_RESTRICTED = 1 #设定 deny host 写入到该资料夹LOCK_FILE = /var/lock/subsys/denyhosts #将DenyHOts启动的pid纪录到LOCK_FILE中，已确保服务正确启动，防止同时启动多个服务。HOSTNAME_LOOKUP=NO            #是否做域名反解ADMIN_EMAIL =                 #设置管理员邮件地址DAEMON_LOG = /var/log/denyhosts #DenyHosts日志位置\n\n设置启动脚本使DenyHosts每次重起后自动启动:\ncp daemon-control-dist daemon-controlln -s /usr/share/denyhosts/daemon-control /etc/init.d/denyhostschkconfig --add denyhostschkconfig denyhosts onservice denyhosts start\n\n查看屏蔽IP[root@localhost ~]# cat /etc/hosts.deny## hosts.deny    This file contains access rules which are used to#        deny connections to network services that either use#        the tcp_wrappers library or that have been#        started through a tcp_wrappers-enabled xinetd.##        The rules in this file can also be set up in#        /etc/hosts.allow with a &#x27;deny&#x27; option instead.##        See &#x27;man 5 hosts_options&#x27; and &#x27;man 5 hosts_access&#x27;#        for information on rule syntax.#        See &#x27;man tcpd&#x27; for information on tcp_wrappers## DenyHosts: Mon Mar  7 16:04:00 2016 | sshd: 123.30.135.177sshd: 123.30.135.177# DenyHosts: Mon Mar  7 16:25:31 2016 | sshd: 125.88.177.95sshd: 125.88.177.95\n","categories":["Linux"],"tags":["DenyHosts"]},{"title":"性能监控系统Prometheus&Grafana","url":"/2020/01/03/Linux/Prometheus&Grafana/","content":"Prometheus 算是一个全能型选手，原生支持容器监控，当然监控传统应用也不是吃干饭的，所以就是容器和非容器他都支持，所有的监控系统都具备这个流程，数据采集→数据处理→数据存储→数据展示→告警\nPrometheus中文名普罗米修斯，最初在 SoundCloud 上构建的监控系统，自 2012 年成为社区开源项目，用户非常活跃的开发人员和用户社区，2016 年加入 CNCF，成为继 kubernetes 之后的第二个托管项目。\nPrometheus 特点\n多维数据模型：由度量名称和键值对标识的时间序列数据\nPromSQL: — 种灵活的查询语言，可以利用多维数据完成复杂的查询\n不依赖分布式存储，单个服务器节点可直接工作\n基于 HTTP 的 pull 方式釆集时间序列数据\n推送时间序列数据通过PushGateway组件支持\n通过服务发现或静态配罝发现目标\n多种图形模式及仪表盘支持 (Grafana)\n\nPrometheus 组成与架构\n\n\n\n名称\n说明\n\n\n\nPrometheus Server\n收集指标和存储时间序列数据，并提供查询接口\n\n\nPush Gateway\n短期存储指标数据，主要用于临时性任务\n\n\nExporters\n采集已有的三方服务监控指标并暴露 metrics\n\n\nAlert manager\n告警\n\n\nWeb UI\n简单的 WEB 控制台\n\n\n集成了数据的采集，处理，存储，展示，告警一系列流程都已经具备了\n数据模型Prometheus 将所有数据存储为时间序列，具有相同度量名称以及标签属于同个指标，也就是说 Prometheus 从数据源拿到数据之后都会存到内置的 TSDB 中，这里存储的就是时间序列数据，它存储的数据会有一个度量名称，譬如你现在监控一个nginx，首先你要给他起个名字，这个名称也就是度量名，还会有 N 个标签，你可以理解名称为表名，标签为字段，所以，每个时间序列都由度量标准名称和一组键值对 (也称为标签) 唯一标识。\n时间序列的格式是这样的，&lt;metricename&gt; &#123;&lt;labelname&gt;=&lt;labelvalue&gt;,...&#125;\nmetric name指的就是度量标准名称，label name也就是标签名，这个标签可以有多个，例如jvm_memory_max_bytes&#123;area=&quot;heap&quot;,id=&quot;Eden Space&quot;,&#125;\n这个度量名称为jvm_memory_max_bytes，后面是两个标签，和他们各对应的值，当然你还可以继续指定标签，你指定的标签越多查询的维度就越多。\n指标类型\n\n\n类型名称\n说明\n\n\n\nCounter\n递增计数器，适合收集接口请求次数\n\n\nGuage\n可以任意变化的数值，适用 CPU 使用率\n\n\nHistogram\n对一段时间内数据进行采集，并对有所数值求和于统计数量\n\n\nSummary\n与 Histogram 类型类似\n\n\n任务和实例实例指的就是你可以抓取的目标target，这个会在 Prometheus 配置文件中体现，任务是具有相同目标的实例集合，你可以理解为是一个组(比如，订单服务多台实例机器，可以放入一个任务里，分多个实例target抓取)，一会写配置文件的时候会详细解析，下面开始安装 Prometheus。\nPrometheus&amp;Grafana 部署我们借助docker来安装，新建目录docker-monitor，并创建对应的目录结构\n[root@localhost ~]# tree docker-monitordocker-monitor├── grafana│   ├── config│   │   └── grafana.ini│   ├── config.monitoring│   └── provisioning│       └── datasources│           └── datasource.yml├── prometheus│   └── prometheus.yml└── docker-compose.yml\n\n在里面创建文件docker-compose.yml，内容如下：\nversion: &quot;3&quot;services:  prometheus:    image: prom/prometheus:v2.4.3    container_name: &#x27;prometheus&#x27;    volumes:      - ./prometheus/:/etc/prometheus/    #映射prometheus的配置文件      - /etc/localtime:/etc/localtime:ro  #同步容器与宿主机的时间，这个非常重要，如果时间不一致，会导致prometheus抓不到数据      - ./prometheus_data:/prometheus    ports:      - &#x27;9090:9090&#x27;  grafana:    image: grafana/grafana:5.2.4    container_name: &#x27;grafana&#x27;    ports:      - &#x27;3000:3000&#x27;    volumes:#      - ./grafana/config/grafana.ini:/etc/grafana/grafana.ini  #grafana报警邮件配置,如果需要报警则需要解开此注释      - ./grafana/provisioning/:/etc/grafana/provisioning/  #配置grafana的prometheus数据源      - /etc/localtime:/etc/localtime:ro      - ./grafana_data:/var/lib/grafana    env_file:      - ./grafana/config.monitoring  #grafana登录配置    depends_on:      - prometheus  #grafana需要在prometheus之后启动\n\n在prometheus.yml中添加以下信息,用来监控spring-boot web项目及Prometheus本身的信息\nglobal:  #全局配置  scrape_interval:   15s  #全局定时任务抓取性能数据间隔scrape_configs:  #抓取性能数据任务配置- job_name: &#x27;prometheus&#x27;  #抓取prometheus自身性能指标数据任务  scrape_interval: 5s  static_configs:    - targets: [&#x27;localhost:9090&#x27;]\n\n在config.monitoring文件中添加以下内容：\nGF_SECURITY_ADMIN_PASSWORD=password  #grafana管理界面的登录用户密码，用户名是adminGF_USERS_ALLOW_SIGN_UP=false  #grafana管理界面是否允许注册，默认不允许\n\n在datasource.yml文件中添加以下内容：\n# config file versionapiVersion: 1deleteDatasources:  #如果之前存在name为Prometheus，orgId为1的数据源先删除- name: Prometheus  orgId: 1datasources:  #配置Prometheus的数据源- name: Prometheus  type: prometheus  access: proxy  orgId: 1  url: http://prometheus:9090  #在相同的docker compose下，可以直接用prometheus服务名直接访问  basicAuth: false  isDefault: true  version: 1  editable: true\n\n在grafana.ini文件中添加以下内容：\n#################################### SMTP / Emailing ########################### 配置邮件服务器[smtp]enabled = true# 发件服务器host = smtp.qq.com:465# smtp账号user = &lt;QQ_NUMBER&gt;@qq.com# smtp 授权码password = xxx# 发信邮箱from_address = &lt;QQ_NUMBER&gt;@qq.com# 发信人from_name = &lt;USER_NAME&gt;\n\n在docker-monitor目录下执行如下命令 docker-compose -f docker-compose.yml up -d  \nPrometheus访问地址：http://localhost:9090\nGrafana访问地址：http://localhost:3000\nGrafana大盘可以在官网中找到\n配置监控信息监控spring web项目\n项目中添加以下依赖\n&lt;!-- 开启springboot的应用监控 --&gt;&lt;dependency&gt;   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;   &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 增加prometheus整合 --&gt;&lt;dependency&gt;   &lt;groupId&gt;io.micrometer&lt;/groupId&gt;   &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;&lt;/dependency&gt;\n项目中添加配置\nmanagement.endpoints.web.exposure.include=*management.endpoint.health.show-details= always\n访问项目地址：http:///actuator/prometheus,会打开服务对外暴露的性能指标数据\n\n修改prometheus的配置文件，在prometheus.yml中添加如下信息\n- job_name: &#x27;api&#x27;  #抓取订单服务性能指标数据任务，一个job下可以配置多个抓紧的targets，比如订单服务多个实例机器  scrape_interval: 10s  #每10s抓取一次  metrics_path: &#x27;/actuator/prometheus&#x27;  #抓取的数据url， 组装后的监控访问路径http://&lt;YOUR_HOST&gt;/actuator/prometheus  static_configs:    - targets: [&#x27;&lt;YOUR_HOST&gt;&#x27;]  #抓取的服务地址      labels:        application: &#x27;api&#x27;  #抓取任务标签\n\n监控Linux服务器性能指标\n通过docker创建监控服务\ndocker pull prom/node-exporter\n启动时创建端口映射\ndocker run -d -p 9100:9100 prom/node-exporter\n在prometheus.yml中添加如下信息\n- job_name: &#x27;linux&#x27;  scrape_interval: 5s  static_configs:    - targets: [&#x27;&lt;HOST&gt;:9100&#x27;]      labels:        instance: &#x27;linux-1&#x27;    - targets: [&#x27;&lt;HOST&gt;:9100&#x27;]      labels:        instance: &#x27;linux-2&#x27;\n\n监控Mysql服务器性能指标\n通过docker创建监控服务\ndocker pull prom/mysqld-exporter\n启动监控连接，容器创建的时候需要指定\ndocker run -d -p 9104:9104 -e DATA_SOURCE_NAME=&quot;root:password@(&lt;mysql服务器ip&gt;:3306)/&lt;databaseName&gt;&quot; prom/mysqld-exporter\n在prometheus.yml中添加如下信息\n- job_name: &#x27;mysql&#x27;  scrape_interval: 5s  static_configs:  - targets: [&#x27;&lt;HOST&gt;:9104&#x27;]    labels:      instance: &#x27;mysql&#x27;\n\n监控Redis性能指标\n通过docker创建监控服务\ndocker pull oliver006/redis_exporter\n启动监控\ndocker run -d -p 9121:9121 oliver006/redis_exporter --redis.addr redis://&lt;redis连接IP&gt;:6379\n在prometheus.yml中添加如下信息\n- job_name: &#x27;redis&#x27;  scrape_interval: 5s  static_configs:  - targets: [&#x27;&lt;HOST&gt;:9121&#x27;]    labels:      instance: &#x27;redis&#x27;\n\n","categories":["Linux"],"tags":["Prometheus","Grafana"]},{"title":"Putty注册表","url":"/2022/03/28/Linux/Putty%E6%B3%A8%E5%86%8C%E8%A1%A8/","content":"默认下的putty配色，太毁眼睛了，putty的配置信息均存在于windows注册表中，将下列信息copy到reg为结尾的文件中，并双击进行修改，可以修改默认putty配色。\nWindows Registry Editor Version 5.00[HKEY_CURRENT_USER\\SOFTWARE\\SimonTatham\\PuTTY\\Sessions\\Default%20Settings]&quot;Present&quot;=dword:00000001&quot;HostName&quot;=&quot;&quot;&quot;LogFileName&quot;=&quot;putty.log&quot;&quot;LogType&quot;=dword:00000000&quot;LogFileClash&quot;=dword:ffffffff&quot;LogFlush&quot;=dword:00000001&quot;LogHeader&quot;=dword:00000001&quot;SSHLogOmitPasswords&quot;=dword:00000001&quot;SSHLogOmitData&quot;=dword:00000000&quot;Protocol&quot;=&quot;ssh&quot;&quot;PortNumber&quot;=dword:00000016&quot;CloseOnExit&quot;=dword:00000001&quot;WarnOnClose&quot;=dword:00000001&quot;PingInterval&quot;=dword:00000000&quot;PingIntervalSecs&quot;=dword:00000000&quot;TCPNoDelay&quot;=dword:00000001&quot;TCPKeepalives&quot;=dword:00000000&quot;TerminalType&quot;=&quot;xterm&quot;&quot;TerminalSpeed&quot;=&quot;38400,38400&quot;&quot;TerminalModes&quot;=&quot;CS7=A,CS8=A,DISCARD=A,DSUSP=A,ECHO=A,ECHOCTL=A,ECHOE=A,ECHOK=A,ECHOKE=A,ECHONL=A,EOF=A,EOL=A,EOL2=A,ERASE=A,FLUSH=A,ICANON=A,ICRNL=A,IEXTEN=A,IGNCR=A,IGNPAR=A,IMAXBEL=A,INLCR=A,INPCK=A,INTR=A,ISIG=A,ISTRIP=A,IUCLC=A,IUTF8=A,IXANY=A,IXOFF=A,IXON=A,KILL=A,LNEXT=A,NOFLSH=A,OCRNL=A,OLCUC=A,ONLCR=A,ONLRET=A,ONOCR=A,OPOST=A,PARENB=A,PARMRK=A,PARODD=A,PENDIN=A,QUIT=A,REPRINT=A,START=A,STATUS=A,STOP=A,SUSP=A,SWTCH=A,TOSTOP=A,WERASE=A,XCASE=A&quot;&quot;AddressFamily&quot;=dword:00000000&quot;ProxyExcludeList&quot;=&quot;&quot;&quot;ProxyDNS&quot;=dword:00000001&quot;ProxyLocalhost&quot;=dword:00000000&quot;ProxyMethod&quot;=dword:00000000&quot;ProxyHost&quot;=&quot;proxy&quot;&quot;ProxyPort&quot;=dword:00000050&quot;ProxyUsername&quot;=&quot;&quot;&quot;ProxyPassword&quot;=&quot;&quot;&quot;ProxyTelnetCommand&quot;=&quot;connect %host %port\\\\n&quot;&quot;ProxyLogToTerm&quot;=dword:00000001&quot;Environment&quot;=&quot;&quot;&quot;UserName&quot;=&quot;&quot;&quot;UserNameFromEnvironment&quot;=dword:00000000&quot;LocalUserName&quot;=&quot;&quot;&quot;NoPTY&quot;=dword:00000000&quot;Compression&quot;=dword:00000000&quot;TryAgent&quot;=dword:00000001&quot;AgentFwd&quot;=dword:00000000&quot;GssapiFwd&quot;=dword:00000000&quot;ChangeUsername&quot;=dword:00000000&quot;Cipher&quot;=&quot;aes,chacha20,3des,WARN,des,blowfish,arcfour&quot;&quot;KEX&quot;=&quot;ecdh,dh-gex-sha1,dh-group14-sha1,rsa,WARN,dh-group1-sha1&quot;&quot;HostKey&quot;=&quot;ed448,ed25519,ecdsa,rsa,dsa,WARN&quot;&quot;PreferKnownHostKeys&quot;=dword:00000001&quot;RekeyTime&quot;=dword:0000003c&quot;GssapiRekey&quot;=dword:00000002&quot;RekeyBytes&quot;=&quot;1G&quot;&quot;SshNoAuth&quot;=dword:00000000&quot;SshBanner&quot;=dword:00000001&quot;AuthTIS&quot;=dword:00000000&quot;AuthKI&quot;=dword:00000001&quot;AuthGSSAPI&quot;=dword:00000001&quot;AuthGSSAPIKEX&quot;=dword:00000001&quot;GSSLibs&quot;=&quot;gssapi32,sspi,custom&quot;&quot;GSSCustom&quot;=&quot;&quot;&quot;SshNoShell&quot;=dword:00000000&quot;SshProt&quot;=dword:00000003&quot;LogHost&quot;=&quot;&quot;&quot;SSH2DES&quot;=dword:00000000&quot;PublicKeyFile&quot;=&quot;&quot;&quot;RemoteCommand&quot;=&quot;&quot;&quot;RFCEnviron&quot;=dword:00000000&quot;PassiveTelnet&quot;=dword:00000000&quot;BackspaceIsDelete&quot;=dword:00000001&quot;RXVTHomeEnd&quot;=dword:00000000&quot;LinuxFunctionKeys&quot;=dword:00000000&quot;NoApplicationKeys&quot;=dword:00000000&quot;NoApplicationCursors&quot;=dword:00000000&quot;NoMouseReporting&quot;=dword:00000000&quot;NoRemoteResize&quot;=dword:00000000&quot;NoAltScreen&quot;=dword:00000000&quot;NoRemoteWinTitle&quot;=dword:00000000&quot;NoRemoteClearScroll&quot;=dword:00000000&quot;RemoteQTitleAction&quot;=dword:00000001&quot;NoDBackspace&quot;=dword:00000000&quot;NoRemoteCharset&quot;=dword:00000000&quot;ApplicationCursorKeys&quot;=dword:00000000&quot;ApplicationKeypad&quot;=dword:00000000&quot;NetHackKeypad&quot;=dword:00000000&quot;AltF4&quot;=dword:00000001&quot;AltSpace&quot;=dword:00000000&quot;AltOnly&quot;=dword:00000000&quot;ComposeKey&quot;=dword:00000000&quot;CtrlAltKeys&quot;=dword:00000001&quot;TelnetKey&quot;=dword:00000000&quot;TelnetRet&quot;=dword:00000001&quot;LocalEcho&quot;=dword:00000002&quot;LocalEdit&quot;=dword:00000002&quot;Answerback&quot;=&quot;PuTTY&quot;&quot;AlwaysOnTop&quot;=dword:00000000&quot;FullScreenOnAltEnter&quot;=dword:00000000&quot;HideMousePtr&quot;=dword:00000000&quot;SunkenEdge&quot;=dword:00000000&quot;WindowBorder&quot;=dword:00000001&quot;CurType&quot;=dword:00000000&quot;BlinkCur&quot;=dword:00000000&quot;Beep&quot;=dword:00000001&quot;BeepInd&quot;=dword:00000000&quot;BellWaveFile&quot;=&quot;&quot;&quot;BellOverload&quot;=dword:00000001&quot;BellOverloadN&quot;=dword:00000005&quot;BellOverloadT&quot;=dword:000007d0&quot;BellOverloadS&quot;=dword:00001388&quot;ScrollbackLines&quot;=dword:000007d0&quot;DECOriginMode&quot;=dword:00000000&quot;AutoWrapMode&quot;=dword:00000001&quot;LFImpliesCR&quot;=dword:00000000&quot;CRImpliesLF&quot;=dword:00000000&quot;DisableArabicShaping&quot;=dword:00000000&quot;DisableBidi&quot;=dword:00000000&quot;WinNameAlways&quot;=dword:00000001&quot;WinTitle&quot;=&quot;&quot;&quot;TermWidth&quot;=dword:00000050&quot;TermHeight&quot;=dword:00000018&quot;Font&quot;=&quot;Courier New&quot;&quot;FontIsBold&quot;=dword:00000000&quot;FontCharSet&quot;=dword:00000000&quot;FontHeight&quot;=dword:0000000a&quot;FontQuality&quot;=dword:00000000&quot;FontVTMode&quot;=dword:00000004&quot;UseSystemColours&quot;=dword:00000000&quot;TryPalette&quot;=dword:00000000&quot;ANSIColour&quot;=dword:00000001&quot;Xterm256Colour&quot;=dword:00000001&quot;TrueColour&quot;=dword:00000001&quot;BoldAsColour&quot;=dword:00000001&quot;Colour0&quot;=&quot;255,255,255&quot;&quot;Colour1&quot;=&quot;255,255,255&quot;&quot;Colour2&quot;=&quot;51,51,51&quot;&quot;Colour3&quot;=&quot;85,85,85&quot;&quot;Colour4&quot;=&quot;0,0,0&quot;&quot;Colour5&quot;=&quot;0,255,0&quot;&quot;Colour6&quot;=&quot;77,77,77&quot;&quot;Colour7&quot;=&quot;85,85,85&quot;&quot;Colour8&quot;=&quot;187,0,0&quot;&quot;Colour9&quot;=&quot;255,85,85&quot;&quot;Colour10&quot;=&quot;152,251,152&quot;&quot;Colour11&quot;=&quot;85,255,85&quot;&quot;Colour12&quot;=&quot;240,230,140&quot;&quot;Colour13&quot;=&quot;255,255,85&quot;&quot;Colour14&quot;=&quot;205,133,63&quot;&quot;Colour15&quot;=&quot;135,206,235&quot;&quot;Colour16&quot;=&quot;255,222,173&quot;&quot;Colour17&quot;=&quot;255,85,255&quot;&quot;Colour18&quot;=&quot;255,160,160&quot;&quot;Colour19&quot;=&quot;255,125,0&quot;&quot;Colour20&quot;=&quot;245,222,179&quot;&quot;Colour21&quot;=&quot;255,255,255&quot;&quot;RawCNP&quot;=dword:00000000&quot;UTF8linedraw&quot;=dword:00000000&quot;PasteRTF&quot;=dword:00000000&quot;MouseIsXterm&quot;=dword:00000000&quot;RectSelect&quot;=dword:00000000&quot;PasteControls&quot;=dword:00000000&quot;MouseOverride&quot;=dword:00000001&quot;Wordness0&quot;=&quot;0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0&quot;&quot;Wordness32&quot;=&quot;0,1,2,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1&quot;&quot;Wordness64&quot;=&quot;1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,2&quot;&quot;Wordness96&quot;=&quot;1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1&quot;&quot;Wordness128&quot;=&quot;1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1&quot;&quot;Wordness160&quot;=&quot;1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1&quot;&quot;Wordness192&quot;=&quot;2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,2,2,2,2,2,2,2,2&quot;&quot;Wordness224&quot;=&quot;2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,2,2,2,2,2,2,2,2&quot;&quot;MouseAutocopy&quot;=dword:00000001&quot;MousePaste&quot;=&quot;explicit&quot;&quot;CtrlShiftIns&quot;=&quot;explicit&quot;&quot;CtrlShiftCV&quot;=&quot;none&quot;&quot;LineCodePage&quot;=&quot;UTF-8&quot;&quot;CJKAmbigWide&quot;=dword:00000000&quot;UTF8Override&quot;=dword:00000001&quot;Printer&quot;=&quot;&quot;&quot;CapsLockCyr&quot;=dword:00000000&quot;ScrollBar&quot;=dword:00000001&quot;ScrollBarFullScreen&quot;=dword:00000000&quot;ScrollOnKey&quot;=dword:00000000&quot;ScrollOnDisp&quot;=dword:00000001&quot;EraseToScrollback&quot;=dword:00000001&quot;LockSize&quot;=dword:00000000&quot;BCE&quot;=dword:00000001&quot;BlinkText&quot;=dword:00000000&quot;X11Forward&quot;=dword:00000000&quot;X11Display&quot;=&quot;&quot;&quot;X11AuthType&quot;=dword:00000001&quot;X11AuthFile&quot;=&quot;&quot;&quot;LocalPortAcceptAll&quot;=dword:00000000&quot;RemotePortAcceptAll&quot;=dword:00000000&quot;PortForwardings&quot;=&quot;&quot;&quot;BugIgnore1&quot;=dword:00000000&quot;BugPlainPW1&quot;=dword:00000000&quot;BugRSA1&quot;=dword:00000000&quot;BugIgnore2&quot;=dword:00000000&quot;BugHMAC2&quot;=dword:00000000&quot;BugDeriveKey2&quot;=dword:00000000&quot;BugRSAPad2&quot;=dword:00000000&quot;BugPKSessID2&quot;=dword:00000000&quot;BugRekey2&quot;=dword:00000000&quot;BugMaxPkt2&quot;=dword:00000000&quot;BugOldGex2&quot;=dword:00000000&quot;BugWinadj&quot;=dword:00000000&quot;BugChanReq&quot;=dword:00000000&quot;StampUtmp&quot;=dword:00000001&quot;LoginShell&quot;=dword:00000001&quot;ScrollbarOnLeft&quot;=dword:00000000&quot;BoldFont&quot;=&quot;&quot;&quot;BoldFontIsBold&quot;=dword:00000000&quot;BoldFontCharSet&quot;=dword:00000000&quot;BoldFontHeight&quot;=dword:00000000&quot;WideFont&quot;=&quot;&quot;&quot;WideFontIsBold&quot;=dword:00000000&quot;WideFontCharSet&quot;=dword:00000000&quot;WideFontHeight&quot;=dword:00000000&quot;WideBoldFont&quot;=&quot;&quot;&quot;WideBoldFontIsBold&quot;=dword:00000000&quot;WideBoldFontCharSet&quot;=dword:00000000&quot;WideBoldFontHeight&quot;=dword:00000000&quot;ShadowBold&quot;=dword:00000000&quot;ShadowBoldOffset&quot;=dword:00000001&quot;SerialLine&quot;=&quot;COM1&quot;&quot;SerialSpeed&quot;=dword:00002580&quot;SerialDataBits&quot;=dword:00000008&quot;SerialStopHalfbits&quot;=dword:00000002&quot;SerialParity&quot;=dword:00000000&quot;SerialFlowControl&quot;=dword:00000001&quot;WindowClass&quot;=&quot;&quot;&quot;ConnectionSharing&quot;=dword:00000000&quot;ConnectionSharingUpstream&quot;=dword:00000001&quot;ConnectionSharingDownstream&quot;=dword:00000001&quot;SSHManualHostKeys&quot;=&quot;&quot;&quot;SUPDUPLocation&quot;=&quot;The Internet&quot;&quot;SUPDUPCharset&quot;=dword:00000000&quot;SUPDUPMoreProcessing&quot;=dword:00000000&quot;SUPDUPScrolling&quot;=dword:00000000\n\n","categories":["Linux"],"tags":["Putty"]},{"title":"配置Jenkins通过HTTPS访问","url":"/2020/07/12/Linux/%E9%85%8D%E7%BD%AEJenkins%E9%80%9A%E8%BF%87HTTPS%E8%AE%BF%E9%97%AE/","content":"通过.pfx文件来生成.jks文件keytool -importkeystore -srckeystore &lt;pfx文件路径&gt; -srcstoretype pkcs12 -destkeystore jenkins.&lt;网址&gt;.jks -deststoretype JKS\n\n在生成的过程中，需要输入pfx-password，这个一般在颁发证书的时候就直接将这个密码给你了。\n\n[root@vultr ~]# ls -altotal 56dr-xr-x---.  5 root root 4096 May 29 08:24 .dr-xr-xr-x. 18 root root 4096 May 15 22:06 ..-rw-r--r--   1 root root 4554 May 29 07:58 2266529_www.dancingmonkey.cn.pfx-rw-------   1 root root 1399 May 24 12:22 .bash_history-rw-r--r--.  1 root root   18 Dec 29  2013 .bash_logout-rw-r--r--.  1 root root  176 Dec 29  2013 .bash_profile-rw-r--r--.  1 root root  176 Dec 29  2013 .bashrcdrwx------   3 root root 4096 May 21 03:26 .cache-rw-r--r--.  1 root root  100 Dec 29  2013 .cshrcdrwxr-----   3 root root 4096 May 15 22:10 .pkidrwx------   2 root root 4096 May 27 06:48 .ssh-rw-r--r--.  1 root root  129 Dec 29  2013 .tcshrc-rw-------   1 root root 1032 May 29 08:09 .viminfo[root@vultr ~]# keytool -importkeystore -srckeystore /root/2266529_www.dancingmonkey.cn.pfx -srcstoretype pkcs12 -destkeystore jenkins.dancingmonkey.cn.jks -deststoretype JKSImporting keystore /root/2266529_www.dancingmonkey.cn.pfx to jenkins.dancingmonkey.cn.jks...Enter destination keystore password:Re-enter new password:Enter source keystore password:Entry for alias alias successfully imported.Import command completed:  1 entries successfully imported, 0 entries failed or cancelledWarning:The JKS keystore uses a proprietary format. It is recommended to migrate to PKCS12 which is an industry standard format using &quot;keytool -importkeystore -srckeystore jenkins.dancingmonkey.cn.jks -destkeystore jenkins.dancingmonkey.cn.jks -deststoretype pkcs12&quot;.[root@vultr ~]# ls -altotal 60drwx------.  5 jenkins jenkins 4096 May 29 08:24 .dr-xr-xr-x. 18 root    root    4096 May 15 22:06 ..-rw-r--r--   1 jenkins jenkins 4554 May 29 07:58 2266529_www.dancingmonkey.cn.pfx-rw-------   1 jenkins jenkins 1399 May 24 12:22 .bash_history-rw-r--r--.  1 jenkins jenkins   18 Dec 29  2013 .bash_logout-rw-r--r--.  1 jenkins jenkins  176 Dec 29  2013 .bash_profile-rw-r--r--.  1 jenkins jenkins  176 Dec 29  2013 .bashrcdrwx------   3 jenkins jenkins 4096 May 21 03:26 .cache-rw-r--r--.  1 jenkins jenkins  100 Dec 29  2013 .cshrc-rw-r--r--   1 jenkins jenkins 4003 May 29 08:24 jenkins.dancingmonkey.cn.jksdrwxr-----   3 jenkins jenkins 4096 May 15 22:10 .pkidrwx------   2 jenkins jenkins 4096 May 27 06:48 .ssh-rw-r--r--.  1 jenkins jenkins  129 Dec 29  2013 .tcshrc-rw-------   1 jenkins jenkins 1032 May 29 08:09 .viminfo\n备份/etc/sysconfig/jenkinscp /etc/sysconfig/jenkins /etc/sysconfig/jenkins.bak\n停止jenkins 服务service jenkins stop\n更改配置文件将 /etc/sysconfig/jenkins 的最后一行JENKINS_ARGS=&quot;&quot;更新为：JENKINS_ARGS=&quot; --httpsPort=8443 --httpsKeyStore=/var/lib/jenkins/jenkins-1.jks --httpsKeyStorePassword=xxx --httpsPrivateKeyPassword=xxx --httpPort=-1&quot;\n启动Jenkins并访问service jenkins start启动jenkins后通过https (8443) 访问公网jenkins:https://&lt;hostname&gt;:8443/发现无法访问，查看jenkins日志发现：\njava.io.IOException: Failed to start a listener: winstone.HttpsConnectorFactory\tat winstone.Launcher.spawnListener(Launcher.java:217)\tat winstone.Launcher.&lt;init&gt;(Launcher.java:177)\tat winstone.Launcher.main(Launcher.java:362)\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\tat java.lang.reflect.Method.invoke(Method.java:498)\tat Main._main(Main.java:375)\tat Main.main(Main.java:151)Caused by: winstone.WinstoneException: No SSL key store found at /root/jenkins.dancingmonkey.cn.jks\tat winstone.AbstractSecuredConnectorFactory.configureSsl(AbstractSecuredConnectorFactory.java:66)\tat winstone.HttpsConnectorFactory.start(HttpsConnectorFactory.java:39)\tat winstone.Launcher.spawnListener(Launcher.java:215)\t... 8 more\n后查找原因发现是因为jenkins.dancingmonkey.cn.jks权限不足导致的，因为jenkins如果不进行修改配置文件的话，默认jenkins会创建一个jenkins用户来执行相关命令,而jks文件是通过root用户创建出来的，jenkins没有权限来操作。\n给jks文件赋权[root@vultr ~]# chown -R jenkins.jenkins /root/jenkins.dancingmonkey.cn.jks[root@vultr ~]# chmod 700 /root/jenkins.dancingmonkey.cn.jks[root@vultr ~]# service jenkins restartRestarting jenkins (via systemctl):                        [  OK  ]\n赋完权限后发现还是无法访问，但是jenkins日志中正常启动，没有报错。防火墙端口未暴露…\n防火墙开放8443端口[root@vultr ~]# firewall-cmd --zone=public --add-port=8443/tcp --permanentsuccess[root@vultr ~]# firewall-cmd --reloadsuccess\n","categories":["Linux"],"tags":["DevOps"]},{"title":"JVM相关面试题","url":"/2021/08/31/%E9%9D%A2%E8%AF%95%E9%A2%98/JVM%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/","content":"什么情况下，minorGC对象会直接进入老年代？\nCMS执行过程？\nCMS执行过程中如果浮动垃圾过多会导致什么？怎样避免？\nTLAB是什么？\n三色标记法流程是什么？\n颜色指针是什么？\n类加载过程是什么？\n为什么要设计双亲委派机制？\n怎样打破双亲委派机制？\njava内存模型描述下？\n类加载的每个过程都干了什么？\n元空间Class对象怎样判断是需要卸载的类？\n如果说系统中内存突然飙升，怎么办？\n如果系统中cpu飙升，怎么办？怎么定位问题？\nfull gc 比minor gc 频繁可能是因为什么情况导致的？\n对象创建的流程是什么？\nGC时间多长算正常？\n多长时间触发一次GC算正常？\njmap会不会触发FullGC?jmap -dump:live呢？ 有没有不触发full gc 查看堆内存的方法？\n用户态内核态的切换\n","categories":["Java"],"tags":["面试","Spring"]},{"title":"Netty面试题","url":"/2021/12/17/%E9%9D%A2%E8%AF%95%E9%A2%98/Netty%E9%9D%A2%E8%AF%95%E9%A2%98/","content":"Nio空轮询bug，Netty是怎么解决的netty是边缘触发还是水平触发select和poll都是水平触发，epoll即支持边缘触发也支持水平触发。水平触发即需要查看每个socket的状态，判断是否可读或可写，在数据没有被处理完时，下次还会进行处理。而边缘触发则是有就绪事件时，才会进行触发，每次必须得把数据全部进行处理，因为如果不进行处理的话，下次也不会进行返回。\n"},{"title":"mysql面试题","url":"/2021/09/08/%E9%9D%A2%E8%AF%95%E9%A2%98/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/","content":"为什么要有redolog\nmysql锁，间隙锁是怎么锁的，还有行锁\n查询一条数据，加了什么锁 select a from table where a &gt; 5 a为索引\n事务隔离级别都有什么\n可重复读事务隔离级别下，插入和查询都是怎么实现的\nMYsql底层索引用的数据结构是什么？为什么用B+TREE，而不是Btree\n事务是什么？\n事务隔离级别是什么？有哪些隔离级别？每种隔离级别分别会出现什么现象？\n锁是什么，mysql中有哪些锁，有什么用？\n聚集索引与非聚集索引的区别?在单纯查找数据来讲，哪个快一些？\n非聚集索引需要回表，聚集索引快一些\n为什么建议InnoDB存储引擎表必须创建主键，并且推荐使用整型的自增主键?\n主键默认带索引，会构建B+Tree。如果不创建主键，会扫描所有列，找到没有重复的列去构建B+Tree,如果没有找到的话，Mysql会自己创建一个隐藏列去构建B+Tree。\n数据页默认大小是16KB，bigint大小为8K，如果用UUID,大小大于8K，生成B+Tree的每个节点可以放的数据少？\n二级索引与主键索引有什么区别？\n一张表只有一个聚集索引，便是主键，二级索引的叶子节点存储的是主键值。\n为什么非主键索引存放的是主键值？\n\n节省存储空间\n数据的一致性，如果每个索引存储的都是行数据，那么进行插入和删除的时候，会增加复杂度，更新索引的时候每个索引的叶子结点都需要插入整条数据。\n\n联合索引的底层存储结构什么样？\n联合索引为什么是最左匹配？\n因为生成B+Tree的时候，是按照创建的字段从左到右进行排序的。\n更新如果没走索引，那么是行锁还是表锁？\nundolog redolog binlog 缓冲区 内存 数据页的写入顺序 为什么这么设计？\n如何确认mysql的数据是完整的 未丢失的？\nmysql二级索引叶子节点为什么不存数据？\nmysql二级索引叶子节点为什么不存数据地址的映射？\n2000万数据分表怎么分？ 分库分表之后，表关联查询咋办？\nlike’%字符串%’不走索引怎么优化？\n","categories":["Mysql"],"tags":["面试","Mysql"]},{"title":"redis面试题","url":"/2021/09/06/%E9%9D%A2%E8%AF%95%E9%A2%98/redis%E9%9D%A2%E8%AF%95%E9%A2%98/","content":"redis数据存储结构与使用场景redis有五种数据结构\nhash结构的缺点\n在集群模式下不适合，集群模式下，会进行分片存储 key%16384,hash的可以会打到一个机器上，如果这个key太大的话，会造成流量都打到一个机器上。\nlist实现消息订阅如果订阅量较大的话，怎么办？  给在线人发，如果是大V呢？在线人也很多，可以用pull方式进行消息拉去，push与pull两种方式的优缺点\npush的话，已经按照时间维度将消息进行排序，发送到指定人，但是消息订阅的人比较多的话，可能较慢。pull的话如果订阅了很多大V的话，需要将每个人的消息都拉取到本地并进行排序。\nset关注模型哨兵模式下，主下线的过程？重新选举的过程？\nredis看门狗怎么实现？\n看门狗是单线程实现的吗？不是的话当前实例要是获取一万个锁的话，需要创建一万个子线程去监听？是的话如果当前实例获取一万个锁的话，一次循环要判断一万次？（时间轮）\nredis单机节点内存一般配置多大？ 为什么？\n一般配置不会大于10G，在开启RDB或者AOP整理的过程中以及主从架构赋值过程中，会导致主节点压力太大，影响性能。\n为什么redis没用一致性hash而使用了哈希槽如果使用一致性hash，当其中一个master节点挂掉后，此节点的请求全部转移到顺时针的下一个节点，可能会导致下一个节点流量增大而宕机，最终全部节点宕机。并且节点数少，对节点hash会分布不均。当数据过多的时候，节点的增删需要对部分数据进行迁移，其他节点会受影响。redis使用哈希槽，当master节点宕机，会选举出一个slave节点成为master节点继续提供服务，不会对其他节点造成影响。并且可以灵活的控制数据的分布，可以对slot进行多机分布，防止流量严重倾斜。\n如果使用一致性hash，在主新增/删除的时候，需要进行数据的迁移，而redis的哈希槽则不需要数据的迁移，数据还是在每个槽位中，只是将槽位挂在不同的节点去管理，影响较小。\nredis集群从节点支持读吗?  redis主从架构呢？\nredis总共有多少个DB16个\n亿级日活系统，怎么做日活统计？通过bitmap来记录，key可以是login:2021:09:13,即登录日期，而value中存储的0|1可以用来区分是否登录，offset与userId(userId是long类型)进行映射，setbit login:2021:09:13 userId 1，并通过bitcount login:2021:09:13来获取日活量\nhash与string有什么优缺点？公司进行数据存储的时候是怎么选型的？比如在存储用户信息的时候，如果用string来进行存储，会频繁的进行set值的操作，比如set user:userId:name set user:userId:age set user:userId:sex等，在数据量较大时，会进行频繁的rehash,如果通过hash来进行存储的话，则只是在对同一个user:userId进行操作，hset user:userId name v1 age v2 sex v3,会避免频繁的rehash\n在涉及到过期时间的时候，只可以对key来设置过期时间，无法对hash中的key里面的key来设置过期时间。\nsave和bgsave会阻塞其他客户端吗？save会阻塞，因为客户端的命令执行是串行的，当前线程执行save操作会阻塞其他的客户端。当redis内存太大的时候，bgsave会在fork子线程的时候阻塞客户端，因为fork子线程时，会将redis内存中的数据copy一份给子线程，在此过程中，操作系统会阻塞，间接性的阻塞了redis客户端。\n","categories":["Redis"],"tags":["面试"]},{"title":"spring面试题","url":"/2021/08/09/%E9%9D%A2%E8%AF%95%E9%A2%98/spring%E9%9D%A2%E8%AF%95%E9%A2%98/","content":"BeanFactory与ApplicationContext有什么区别？他们都有生产bean的能力，ApplicationContext实现了BeanFactory,BeanFactory只能一个一个的注册beanDefinition，ApplicationContext在BeanFactory的基础上，可以进行包的扫描，配置的扫描等，可以整体转换为BeanDefinition.\n\n\n\nFeature\nBeanFactory\nApplicationContext\n\n\n\nBean Bean实例化/装配\nYes\nYes\n\n\n集成的生命周期管理\nNo\nYes\n\n\n自动注册 BeanPostProcessor\nNo\nYes\n\n\n自动注册 BeanFactoryPostProcessor\nNo\nYes\n\n\n便利的 MessageSource 访问 (国际化)\nNo\nYes\n\n\n内置ApplicationEvent 发布机制\nNo\nYes\n\n\n\n参考：https://github.com/DocsHome/spring-docs/blob/master/pages/core/IoC-container.md#context-introduction-ctx-vs-beanfactory\n\nspring IOC与DI有什么区别？IOC是一种思想，将对象的创建与依赖进行解耦，DI是一种具体的实现。\nspring IOC的加载流程？bean的生命周期\n通过beanDefinition反射进行实例化，将对象创建出来\n\n填充属性\n\n初始化，执行 initMethod方法，这个过程会执行很多aware方法\n\n将bean放入单例池\n\n\nspring怎么解决的循环依赖bean实例化的方式bean实例化有两种方式，一种为反射，一种为bean工厂，比如添加@component注解，这种为通过反射来生成的，而添加@bean则允许自己进行创建bean。\nspring的扩展点Bean工厂相关\n\nbeanFactoryPostProcessor 可以修改定义的beanDefinition\nbeanDefinitionRegistryPostProcessor 用来自定义注册beanDefinition\n\nBean生命周期相关\n​    调用9个\nspring Bean加载流程？   类生产成一个bean，先将类加载成bean定义\n\n读取到配置类\n通过配置类扫描所有的@Component等注解，并注册成beanDefinition\napplicationContext可以调用BeanFactoryPostProcessor去修改bean定义，可以调用BeanDefinitionRegistryPostProcessor来注册类\n\nspring是怎样解决拿到的bean是不完整的？beanDefinition转换为bean并放入单例池中的过程为：\n\n获取BD \n通过BD实例化\n属性赋值\n执行初始化方法\n放入单例池中\n\n这样的过程有个问题，就是无法解决循环依赖，如果在实例化后就将bean放入单例池的话，因为属性还没进行赋值，其他线程在获取bean的时候可能获取到的是不完整的bean，spring解决这个问题的方式是添加了二级缓存，当bean实例化之后将其放入二级缓存中，最后当执行完初始化方法后再从二级缓存中删除并移动到一级缓存。\nspring Bean创建过程中，在哪儿创建的代理？\n初始化之后\n出现循环依赖时，实例化的时候\n\n二级缓存就可以解决循环依赖了，spring为什么还要用三级缓存？AOP什么情况下走JDK动态代理，什么情况下走CGLIB动态代理？JDK动态代理与CGLIB动态代理有什么区别？AOP动态代理 执行顺序是什么？ 为什么要排序？异常通知-&gt;返回通知-&gt;后置通知-&gt;前置通知-&gt;目标方法\nAOP的原理是什么？spring容器中可以注入springMvc容器的bean吗？springMVC运行流程是什么？mybatis mapper可以有几种设置方式？装饰器与代理模式都是增强，有什么区别？代理注重将被代理的类隐藏，装饰器注重增强\nmybatis一二级缓存的原理二级缓存：装饰器+责任链，最外面的为synchonizedCache-&gt;loggingCache-&gt;serualizedCache-&gt;perpetualCache\nmybatis设计模式mybatis动态sql是怎么解析的将sql解析成一个月给的sqlNode,通过责任链的方式，调用每种类型的sqlNode的解析方式，最后拼接成一个可执行sql\nmybatis插件mybatis执行器有几种spring整合mybatis原理mybatis怎么继承spring声明式事务的？mybatis实际上就是拿到的spring的事务，spring在开始事务的时候，会创建一个connection放在事务同步管理器的resource里，在构建sqlSSessionFactoryBean的时候，会创建一个mybatis的适配类springManagedTransactionFactory,当mybatis获取Connection就会调用springManagedTransactionFactory.getconnect方法，而这个connection就是事务管理器中的connection\nmybatis的mapper底层是什么？动态代理啊\nmapper是怎么注入到ioc容器中得？","categories":["Java"],"tags":["面试","JVM"]},{"title":"分布式面试题","url":"/2021/09/08/%E9%9D%A2%E8%AF%95%E9%A2%98/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9D%A2%E8%AF%95%E9%A2%98/","content":"分布式系统，当配置中心更新后，会通知客户端获取通知，为什么配置更新后不直接把配置给客户端？\n","categories":["分布式"],"tags":["面试","分布式"]},{"title":"并发面试题","url":"/2021/08/31/%E9%9D%A2%E8%AF%95%E9%A2%98/%E5%B9%B6%E5%8F%91%E9%9D%A2%E8%AF%95%E9%A2%98/","content":"future 会不会阻塞主线程？reentrantlock和synchornized使用场景掉一个接口 这个接口同时请求三个接口，有一个接口返回你就返回hashMap负载因子为什么是0.75hashMap扩容为什么必须是2的倍数在jdk1.8中，在\nhashMap为什么链表长度为8之后转为红黑树jdk1.8中hashMap扩容与jdk1.7有什么不同？jdk1.7中采用头插法，在多线程环境下，扩容时容易产生链表环，导致死循环。jdk1.8中采用的是将链表中的Node.hash&amp;老的数组长度，分成等于0和等于原数组长度的两个链表，将等于0的链表放入新的数组下角标与老下角标相同的桶中，将等于原数组长度的链表放入新数组的数组下角标为老下角标+老数组长度的桶中。\nsynchronized锁的升级过程\n压测http_load和jmeters\ncopyOnWrite使用场景\nAQS condition是怎么实现的，实现过程\nCAS怎么保证不会并发，原理\nsynchronized放到静态方法上锁的是什么？synchronized放到普通方法上锁的是什么？Synchronized(this)锁的是什么？\n总线风暴?伪共享?\n令牌桶和漏桶都是为了干什么用的\n怎么解决hash冲突？四种方式","categories":["Java"],"tags":["面试","并发"]},{"title":"消息队列面试题","url":"/2021/09/30/%E9%9D%A2%E8%AF%95%E9%A2%98/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%9D%A2%E8%AF%95%E9%A2%98/","content":"说一说kafka的索引？稀疏索引\nkafka的常用参数都有哪些？ACK都可以设置为多少？代表的含义是什么？"},{"title":"Explain详解与索引最佳实践","url":"/2021/11/03/Database/Mysql/Explain%E8%AF%A6%E8%A7%A3%E4%B8%8E%E7%B4%A2%E5%BC%95%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/","content":"Explain工具介绍使用EXPLAIN关键字可以模拟优化器执行SQL语句，分析你的查询语句或是结构的性能瓶颈，在select语句之前增加explain关键字，MySQL会在查询上设置一个标记，执行查询会返回执行计划的信息，而不是执行这条SQL。5.7官方文档\n\n注意：如果 from 中包含子查询，仍会执行该子查询，将结果放入临时表中 \n\nExplain分析示例DROP TABLE IF EXISTS `actor`;CREATE TABLE `actor` (`id` int(11) NOT NULL,`name` varchar(45) DEFAULT NULL,`update_time` datetime DEFAULT NULL,PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;  INSERT INTO `actor` (`id`, `name`, `update_time`) VALUES (1,&#x27;a&#x27;,&#x27;2017‐12‐22:27:18&#x27;), (2,&#x27;b&#x27;,&#x27;2017‐12‐22 15:27:18&#x27;), (3,&#x27;c&#x27;,&#x27;2017‐12‐22 15:27:18&#x27;);  DROP TABLE IF EXISTS `film`;  CREATE TABLE `film` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `name` varchar(10) DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `idx_name` (`name`)  ) ENGINE=InnoDB DEFAULT CHARSET=utf8;  INSERT INTO `film` (`id`, `name`) VALUES (3,&#x27;film0&#x27;),(1,&#x27;film1&#x27;),(2,&#x27;film2&#x27;);  DROP TABLE IF EXISTS `film_actor`;  CREATE TABLE `film_actor` (  `id` int(11) NOT NULL,  `film_id` int(11) NOT NULL,  `actor_id` int(11) NOT NULL,  `remark` varchar(255) DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `idx_film_actor_id` (`film_id`,`actor_id`)  ) ENGINE=InnoDB DEFAULT CHARSET=utf8;  INSERT INTO `film_actor` (`id`, `film_id`, `actor_id`) VALUES (1,1,1),(2,1,2),(3,2,1);\n\nmysql&gt; explain select * from actor;\n\n\n在查询中的每个表会输出一行，如果有两个表通过join连接查询，那么会输出两行\nexplain 两个变种\nexplain extended\n会在explain的基础上额外提供一些查询优化的信息。紧随其后通过show warnings命令可以得到优化后的查询语句，从而看出优化器优化了什么。额外还有filtered列，是一个半分比的值，rows * filtered/100可以估算出将要和explain中前一个表进行连接的行数（前一个表指explain中的id值比当前表id值小的表）。\nmysql&gt; explain extended select * from film where id = 1;\n\n\nmysql&gt; show warnings;\n\n\n\nexplain partitions相比 explain 多了个 partitions 字段，如果查询是基于分区表的话，会显示查询将访问的分区。\n\n\nexplain中的列id列id列的编号是 select 的序列号，有几个 select 就有几个id，并且id的顺序是按 select 出现的顺序增长的。id列越大执行优先级越高，id相同则从上往下执行，id为NULL最后执行。\nselect_type列select_type 表示对应行是简单还是复杂的查询。\n\nSimple简单查询。查询不包含子查询和union\nmysql&gt; explain select * from film where id = 2;\n\n\n\nPrimary复杂查询中最外层的select\n\nSubquery包含在 select 中的子查询（不在 from 子句中）\n\nderived包含在 from 子句中的子查询。MySQL会将结果存放在一个临时表中，也称为派生表（derived的英文含义）\n\nUnion在 union 中的第二个和随后的 select\nmysql&gt; explain select 1 union all select 1;\n\n\n\n\n用这个例子来了解 primary、subquery 和 derived 类型\nmysql&gt; set session optimizer_switch=&#x27;derived_merge=off&#x27;; #关闭mysql5.7新特性对衍生表的合并优化mysql&gt; explain select (select 1 from actor where id = 1) from (select * from film where id = 1) der;\n\n\nmysql&gt; set session optimizer_switch=&#x27;derived_merge=on&#x27;; #还原默认配置\n\ntable列这一列表示 explain 的一行正在访问哪个表。当 from 子句中有子查询时，table列是 &lt;derivenN&gt; 格式，表示当前查询依赖 id=N 的查询，于是先执行 id=N 的查询。当有 union 时，UNION RESULT 的 table 列的值为&lt;union1,2&gt;，1和2表示参与 union 的 select 行id。\ntype列这一列表示关联类型或访问类型，即MySQL决定如何查找表中的行，查找数据行记录的大概范围。依次从最优到最差分别为：system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL一般来说，得保证查询达到range级别，最好达到ref\n\nNULLmysql能够在优化阶段分解查询语句，在执行阶段用不着再访问表或索引。例如：在索引列中选取最小值，可以单独查找索引来完成，不需要在执行时访问表\nmysql&gt; explain select min(id) from film;\n\n\n\nconst、systemmysql能对查询的某部分进行优化并将其转化成一个常量（可以看show warnings 的结果）。用于primary key 或 unique key 的所有列与常数比较时，所以表最多有一个匹配行，读取1次，速度比较快。system是const的特例，表里只有一条元组匹配时为system\nmysql&gt; explain extended select * from (select * from film where id = 1) tmp;\n\n\nmysql&gt; show warnings;\n\n\n\neq_refprimary key或unique key索引的所有部分被连接使用，最多只会返回一条符合条件的记录。这可能是在const之外最好的联接类型了，简单的select查询不会出现这种type。\nmysql&gt; explain select * from film_actor left join film on film_actor.film_id = film.id;\n\n\n\nref相比 eq_ref，不使用唯一索引，而是使用普通索引或者唯一性索引的部分前缀，索引要和某个值相比较，可能会找到多个符合条件的行。\n\n简单 select 查询，name是普通索引（非唯一索引）\nmysql&gt; explain select * from film where name = &#x27;film1&#x27;;\n\n\n\n关联表查询，idx_film_actor_id是film_id和actor_id的联合索引，这里使用到了film_actor的左边前缀film_id部分\nmysql&gt; explain select film_id from film left join film_actor on film.id = film_actor.film_id;\n\n\n\n\n\nrange范围扫描通常出现在 in(), between ,&gt; ,&lt;, &gt;= 等操作中。使用一个索引来检索给定范围的行。\nmysql&gt; explain select * from actor where id &gt; 1;\n\n\n\nIndex\n扫描全索引就能拿到结果，一般是扫描某个二级索引，这种扫描不会从索引树根节点开始快速查找，而是直接对二级索引的叶子节点遍历和扫描，速度还是比较慢的，这种查询一般为使用覆盖索引，二级索引一般比较小，所以这种通常比ALL快一些。\nmysql&gt; explain select * from film;\n\n\n\nALL即全表扫描，扫描你的聚簇索引的所有叶子节点。通常情况下这需要增加索引来进行优化了。\nmysql&gt; explain select * from actor;\n\n\n\n\npossible_keys列这一列显示查询可能使用哪些索引来查找。explain 时可能出现 possible_keys列有值，而 key 显示 NULL 的情况，这种情况是因为表中数据不多，mysql认为索引对此查询帮助不大，选择了全表查询。如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查 where 子句看是否可以创造一个适当的索引来提高查询性能，然后用 explain 查看效果。\nkey列这一列显示mysql实际采用哪个索引来优化对该表的访问。如果没有使用索引，则该列是 NULL。如果想强制mysql使用或忽视possible_keys列中的索引，在查询中使用 force index、ignore index。\nkey_len列这一列显示了mysql在索引里使用的字节数，通过这个值可以算出具体使用了索引中的哪些列。举例来说，film_actor的联合索引 idx_film_actor_id 由 film_id 和 actor_id 两个int列组成，并且每个int是4字节。通过结果中的key_len=4可推断出查询使用了第一个列：film_id列来执行索引查找。\nmysql&gt; explain select * from film_actor where film_id = 2;\n\n\nkey_len计算规则如下：\n\n字符串：\nchar(n)和varchar(n)，5.0.3以后版本中，n均代表字符数，而不是字节数，如果是utf-8，一个数字或字母占1个字节，一个汉字占3个字节\n\nchar(n)：如果存汉字长度就是 3n 字节\nvarchar(n)：如果存汉字则长度是 3n + 2     字节，加的2字节用来存储字符串长度，因为varchar是变长字符串\n\n\n数值类型：\n\ntinyint：1字节\nsmallint：2字节\nint：4字节\nbigint：8字节\n\n\n时间类型：\n\ndate：3字节\n\ntimestamp：4字节\n\ndatetime：8字节\n\n\n\n\n如果字段允许为 NULL，需要1字节记录是否为 NULL索引最大长度是768字节，当字符串过长时，mysql会做一个类似左前缀索引的处理，将前半部分的字符提取出来做索引\nref列这一列显示了在key列记录的索引中，表查找值所用到的列或常量，常见的有：const（常量），字段名（例：film.id）\nrows列这一列是mysql估计要读取并检测的行数，注意这个不是结果集里的行数\nExtra列这一列展示的是额外信息。常见的重要值如下：\n\nUsing index：\n使用覆盖索引\n覆盖索引定义：mysql执行计划explain结果里的key有使用索引，如果select后面查询的字段都可以从这个索引的树中获取，\n这种情况一般可以说是用到了覆盖索引，extra里一般都有using index；覆盖索引一般针对的是辅助索引，整个查询结果只通过辅助索引就能拿到结果，\n不需要通过辅助索引树找到主键，再通过主键去主键索引树里获取其它字段值。\nmysql&gt; explain select film_id from film_actor where film_id = 1;\n\n\n\nUsing where：\n使用 where 语句来处理结果，并且查询的列未被索引覆盖\nmysql&gt; explain select * from actor where name = &#x27;a&#x27;;\n\n\n\nUsing index condition：查询的列不完全被索引覆盖，where条件中是一个前导列的范围；\nmysql&gt; explain select * from film_actor where film_id &gt; 1;\n\n\n\nUsing temporary：mysql需要创建一张临时表来处理查询。出现这种情况一般是要进行优化的，首先是想到用索引来优化。\n\nactor.name没有索引，此时创建了张临时表来distinct\nmysql&gt; explain select distinct name from actor;\n\n\n\nfilm.name建立了idx_name索引，此时查询时extra是using index,没有用临时表\nmysql&gt; explain select distinct name from film;\n\n\n\n\n\nUsing filesort：将用外部排序而不是索引排序，数据较小时从内存排序，否则需要在磁盘完成排序。这种情况下一般也是要考虑使用索引来优化的。\n\nactor.name未创建索引，会浏览actor整个表，保存排序关键字name和对应的id，然后排序name并检索行记录\nmysql&gt; explain select * from actor order by name;\n\n\n\nfilm.name建立了idx_name索引,此时查询时extra是using index\nmysql&gt; explain select * from film order by name;\n\n\n\n\n\nSelect tables optimized away：使用某些聚合函数（比如 max、min）来访问存在索引的某个字段是\nmysql&gt; explain select min(id) from film;\n\n\n\n\n索引最佳实践示例表\nCREATE TABLE `employees` (`id` int(11) NOT NULL AUTO_INCREMENT,`name` varchar(24) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;姓名&#x27;,`age` int(11) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;年龄&#x27;,`position` varchar(20) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;职位&#x27;,`hire_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;入职时间&#x27;,PRIMARY KEY (`id`),KEY `idx_name_age_position` (`name`,`age`,`position`) USING BTREE  ) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8 COMMENT=&#x27;员工记录表&#x27;;  INSERT INTO employees(name,age,position,hire_time) VALUES(&#x27;LiLei&#x27;,22,&#x27;manager&#x27;,NOW());  INSERT INTO employees(name,age,position,hire_time) VALUES(&#x27;HanMeimei&#x27;,23,&#x27;dev&#x27;,NOW());  INSERT INTO employees(name,age,position,hire_time) VALUES(&#x27;Lucy&#x27;,23,&#x27;dev&#x27;,NOW());\n\n全值匹配EXPLAIN SELECT * FROM employees WHERE name= &#x27;LiLei&#x27;;\n\n\nEXPLAIN SELECT * FROM employees WHERE name= &#x27;LiLei&#x27; AND age = 22;\n\n\nEXPLAIN SELECT * FROM employees WHERE name= &#x27;LiLei&#x27; AND age = 22 AND position =&#x27;manager&#x27;;\n\n\n最左前缀法则如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始并且不跳过索引中的列\nEXPLAIN SELECT * FROM employees WHERE name = &#x27;Bill&#x27; and age = 31;EXPLAIN SELECT * FROM employees WHERE age = 30 AND position = &#x27;dev&#x27;;EXPLAIN SELECT * FROM employees WHERE position = &#x27;manager&#x27;;\n\n\n不在索引列上做任何操作如果在索引列上做计算、函数、（自动or手动）类型转换，会导致索引失效而转向全表扫描\nEXPLAIN SELECT * FROM employees WHERE name = &#x27;LiLei&#x27;;EXPLAIN SELECT * FROM employees WHERE left(name,3) = &#x27;LiLei&#x27;;\n\n\n给hire_time增加一个普通索引：\nALTER TABLE `employees` ADD INDEX `idx_hire_time` (`hire_time`) USING BTREE ;EXPLAIN select * from employees where date(hire_time) =&#x27;2018‐09‐30&#x27;;\n\n\n转化为日期范围查询，有可能会走索引：\nEXPLAIN select * from employees where hire_time &gt;=&#x27;2018‐09‐30 00:00:00&#x27; and hire_time &lt;=&#x27;2018‐09‐30 23:59:59&#x27;;\n\n\n但是实际结果并没走索引，mysql会计算cost成本，发现数据量不大，而走索引的话还有回表操作，不如走全表扫描了。\n还原最初索引状态\nALTER TABLE `employees` DROP INDEX `idx_hire_time`;\n\n存储引擎不能使用索引中范围条件右边的列EXPLAIN SELECT * FROM employees WHERE name= &#x27;LiLei&#x27; AND age = 22 AND position =&#x27;manager&#x27;;EXPLAIN SELECT * FROM employees WHERE name= &#x27;LiLei&#x27; AND age &gt; 22 AND position =&#x27;manager&#x27;;\n\n\n尽量使用覆盖索引尽量使用覆盖索引（只访问索引的查询（索引列包含查询列）），减少 select * 语句\nEXPLAIN SELECT name,age FROM employees WHERE name= &#x27;LiLei&#x27; AND age = 23 AND position=&#x27;manager&#x27;;\n\n\nEXPLAIN SELECT * FROM employees WHERE name= &#x27;LiLei&#x27; AND age = 23 AND position =&#x27;manager&#x27;;\n\n\n不走索引mysql在使用不等于（！=或者&lt;&gt;），not in ，not exists 的时候无法使用索引会导致全表扫描&lt; 、 &gt; 、 &lt;=、&gt;= 这些，mysql内部优化器会根据检索比例、表大小等多个因素整体评估是否使用索引\nEXPLAIN SELECT * FROM employees WHERE name != &#x27;LiLei&#x27;;\n\n\nis null,is not null 一般情况下也无法使用索引EXPLAIN SELECT * FROM employees WHERE name is null;\n\n\nlike以通配符开头（’$abc…’）mysql索引失效会变成全表扫描操作EXPLAIN SELECT * FROM employees WHERE name like &#x27;%Lei&#x27;;\n\n\nEXPLAIN SELECT * FROM employees WHERE name like &#x27;Lei%&#x27;;\n\n\n问题：解决like’%字符串%’索引不被使用的方法？\n使用覆盖索引，查询字段必须是建立覆盖索引字段\nEXPLAIN SELECT name,age,position FROM employees WHERE name like &#x27;%Lei%&#x27;;\n\n\n\n如果不能使用覆盖索引则可能需要借助搜索引擎\n\n\n字符串不加单引号索引失效EXPLAIN SELECT * FROM employees WHERE name = &#x27;1000&#x27;;EXPLAIN SELECT * FROM employees WHERE name = 1000;\n\n\n少用or或in用它查询时，mysql不一定使用索引，mysql内部优化器会根据检索比例、表大小等多个因素整体评估是否使用索引，详见范围查询优化\nEXPLAIN SELECT * FROM employees WHERE name = &#x27;LiLei&#x27; or name = &#x27;HanMeimei&#x27;;\n\n\n范围查询优化给年龄添加单值索引\nALTER TABLE `employees` ADD INDEX `idx_age` (`age`) USING BTREE ;explain select * from employees where age &gt;=1 and age &lt;=2000;\n\n\n没走索引原因：mysql内部优化器会根据检索比例、表大小等多个因素整体评估是否使用索引。比如这个例子，可能是由于单次数据量查询过大导致优化器最终选择不走索引优化方法：可以将大的范围拆分成多个小范围\nexplain select * from employees where age &gt;=1 and age &lt;=1000;explain select * from employees where age &gt;=1001 and age &lt;=2000;\n\n\n还原最初索引状态\nALTER TABLE `employees` DROP INDEX `idx_age`;\n索引使用总结\nlike KK%相当于=常量，%KK和%KK% 相当于范围\n\nmysql5.7关闭ONLY_FULL_GROUP_BY报错select version(), @@sql_mode;SET sql_mode=(SELECT REPLACE(@@sql_mode,&#39;ONLY_FULL_GROUP_BY&#39;,&#39;&#39;));\n\n","categories":["Database"],"tags":["Mysql"]},{"title":"MVCC多版本并发控制机制","url":"/2021/11/18/Database/Mysql/MVCC%E5%A4%9A%E7%89%88%E6%9C%AC%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/","content":"Mysql在可重复读隔离级别下如何保证事务较高的隔离性，我们上节课给大家演示过，同样的sql查询语句在一个事务里多次执行查询结果相同，就算其它事务对数据有修改也不会影响当前事务sql语句的查询结果。\n这个隔离性就是靠MVCC(Multi-Version Concurrency Control)机制来保证的，对一行数据的读和写两个操作默认是不会通过加锁互斥来保证隔离性，避免了频繁加锁互斥，而在串行化隔离级别为了保证较高的隔离性是通过将所有操作加锁互斥来实现的。\nMysql在读已提交和可重复读隔离级别下都实现了MVCC机制。\nundo日志版本链与read view机制详解undo日志版本链是指一行数据被多个事务依次修改过后，在每个事务修改完后，Mysql会保留修改前的数据undo回滚日志，并且用两个隐藏字段trx_id和roll_pointer把这些undo日志串联起来形成一个历史记录版本链\n\n在可重复读隔离级别，当事务开启，执行任何查询sql时会生成当前事务的一致性视图read-view，该视图在事务结束之前都不会变化(如果是读已提交隔离级别在每次执行查询sql时都会重新生成)，这个视图由执行查询时所有未提交事务id数组（数组里最小的id为min_id）和已创建的最大事务id（max_id）组成，事务里的任何sql查询结果需要从对应版本链里的最新数据开始逐条跟read-view做比对从而得到最终的快照结果。\n版本链比对规则：\n\n如果 row 的 trx_id 落在绿色部分( trx_id&lt;min_id )，表示这个版本是已提交的事务生成的，这个数据是可见的\n如果 row 的 trx_id 落在红色部分( trx_id&gt;max_id )，表示这个版本是由将来启动的事务生成的，是不可见的(若 row 的 trx_id 就是当前自己的事务是可见的）\n如果 row 的 trx_id 落在黄色部分(min_id &lt;=trx_id&lt;= max_id)，那就包括两种情况\n若 row 的 trx_id 在视图数组中，表示这个版本是由还没提交的事务生成的，不可见(若 row 的 trx_id 就是当前自己的事务是可见的)\n若 row 的 trx_id 不在视图数组中，表示这个版本是已经提交了的事务生成的，可见\n\n\n\n对于删除的情况可以认为是update的特殊情况，会将版本链上最新的数据复制一份，然后将trx_id修改成删除操作的trx_id，同时在该条记录的头信息（record header）里的（deleted_flag）标记位写上true，来表示当前记录已经被删除，在查询时按照上面的规则查到对应的记录如果delete_flag标记位为true，意味着记录已被删除，则不返回数据\n注意：begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个修改操作InnoDB表的语句，事务才真正启动，才会向mysql申请事务id，mysql内部是严格按照事务的启动顺序来分配事务id的\n\nMVCC机制的实现就是通过read-view机制与undo版本链比对机制，使得不同的事务会根据数据版本链对比规则读取同一条数据在版本链上的不同版本数据\n\nMVCC例子讲解\n说明：\n\n时间节点一select1在开启事务后的首次查询时，生成一致性视图readView：[100,200],300account表中id=1所对应的name刚开始为lilei，版本链记录中记录了trx_id=300的更新记录版本链第一个是由trx_id=80的事务进行修改的，80小于未提交事务的最小ID100，说明数据可见，第二个是由trx_id=300的事务进行修改的，300没在未提交事务的数组中，说明数据可见，所以查询出的数据为lilei300\n\n时间节点二select1在时间节点一生成一致性视图readView，此试图在事务未结束时不会进行更改，所以一致性视图readView：[100,200],300\n版本链第一个是由trx_id=80的事务进行修改的，80小于未提交事务的最小ID100，说明数据可见，第二个是由trx_id=300的事务进行修改的，300没在未提交事务的数组中，说明数据可见，第三个是由trx_id=100的事务进行修改的，100在未提交事务的数组中，说明数据不可见，第四个是由trx_id=100的事务进行修改的，100在未提交事务的数组中，说明数据不可见，\n所以查询出来的数据为lilei300\n\n时间节点三select1在时间节点一生成一致性视图readView，此试图在事务未结束时不会进行更改，所以一致性视图readView：[100,200],300\n版本链第一个是由trx_id=80的事务进行修改的，80小于未提交事务的最小ID100，说明数据可见，第二个是由trx_id=300的事务进行修改的，300没在未提交事务的数组中，说明数据可见，第三个是由trx_id=100的事务进行修改的，100在未提交事务的数组中，说明数据不可见，第四个是由trx_id=100的事务进行修改的，100在未提交事务的数组中，说明数据不可见，第五个是由trx_id=200的事务进行修改的，200在未提交事务的数组中，说明数据不可见，第六个是由trx_id=200的事务进行修改的，200在未提交事务的数组中，说明数据不可见，\n所以查询出来的数据为lilei300\nselect2在开启事务后的首次查询时，生成一致性视图readView：[200],300版本链第一个是由trx_id=80的事务进行修改的，80小于未提交事务的最小ID200，说明数据可见，第二个是由trx_id=300的事务进行修改的，300没在未提交事务的数组中，说明数据可见，第三个是由trx_id=100的事务进行修改的，100没在未提交事务的数组中，说明数据可见，第四个是由trx_id=100的事务进行修改的，100没在未提交事务的数组中，说明数据可见，第五个是由trx_id=200的事务进行修改的，200在未提交事务的数组中，说明数据不可见，第六个是由trx_id=200的事务进行修改的，200在未提交事务的数组中，说明数据不可见，所以查询出来的数据为lilei2\n\n\n","categories":["Database"],"tags":["Mysql"]},{"title":"Mysql索引优化一","url":"/2021/11/16/Database/Mysql/MySql%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96%E4%B8%80/","content":"CREATE TABLE `employees` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `name` varchar(24) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;姓名&#x27;,  `age` int(11) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;年龄&#x27;,  `position` varchar(20) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;职位&#x27;,  `hire_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;入职时间&#x27;,  PRIMARY KEY (`id`),  KEY `idx_name_age_position` (`name`,`age`,`position`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT=&#x27;员工记录表&#x27;;INSERT INTO employees(name,age,position,hire_time) VALUES(&#x27;LiLei&#x27;,22,&#x27;manager&#x27;,NOW());INSERT INTO employees(name,age,position,hire_time) VALUES(&#x27;HanMeimei&#x27;, 23,&#x27;dev&#x27;,NOW());INSERT INTO employees(name,age,position,hire_time) VALUES(&#x27;Lucy&#x27;,23,&#x27;dev&#x27;,NOW());-- 插入一些示例数据drop procedure if exists insert_emp; delimiter ;;create procedure insert_emp()        begin  declare i int;                      set i=1;                            while(i&lt;=100000)do                     insert into employees(name,age,position) values(CONCAT(&#x27;zhuge&#x27;,i),i,&#x27;dev&#x27;);      set i=i+1;                         end while;end;;delimiter ;call insert_emp();\n\n联合索引示例联合索引第一个字段用范围不会走索引EXPLAIN SELECT * FROM employees WHERE name &gt; &#x27;LiLei&#x27; AND age = 22 AND position =&#x27;manager&#x27;;\n\n\n联合索引第一个字段就用范围查找不会走索引，mysql内部可能觉得第一个字段就用范围，结果集应该很大，回表效率不高，还不如就全表扫描\n强制走索引EXPLAIN SELECT * FROM employees force index(idx_name_age_position) WHERE name &gt; &#x27;LiLei&#x27; AND age = 22 AND position =&#x27;manager&#x27;;\n\n\n虽然使用了强制走索引让联合索引第一个字段范围查找也走索引，扫描的行rows看上去也少了点，但是最终查找效率不一定比全表扫描高，因为回表效率不高\n-- 关闭查询缓存set global query_cache_size=0;  set global query_cache_type=0;-- 执行时间0.333sSELECT * FROM employees WHERE name &gt; &#x27;LiLei&#x27;;-- 执行时间0.444sSELECT * FROM employees force index(idx_name_age_position) WHERE name &gt; &#x27;LiLei&#x27;;\n\n覆盖索引优化EXPLAIN SELECT name,age,position FROM employees WHERE name &gt; &#x27;LiLei&#x27; AND age = 22 AND position =&#x27;manager&#x27;;\n\n\nin和or在表数据量比较大的情况会走索引，在表记录不多的情况下会选择全表扫描EXPLAIN SELECT * FROM employees WHERE name in (&#x27;LiLei&#x27;,&#x27;HanMeimei&#x27;,&#x27;Lucy&#x27;) AND age = 22 AND position =&#x27;manager&#x27;;\n\n\nEXPLAIN SELECT * FROM employees WHERE (name = &#x27;LiLei&#x27; or name = &#x27;HanMeimei&#x27;) AND age = 22 AND position =&#x27;manager&#x27;;\n\n\n将employees 表复制一张employees_copy的表，里面保留两三条记录\nEXPLAIN SELECT * FROM employees_copy WHERE name in (&#x27;LiLei&#x27;,&#x27;HanMeimei&#x27;,&#x27;Lucy&#x27;) AND age = 22 AND position =&#x27;manager&#x27;;\n\n\nEXPLAIN SELECT * FROM employees_copy WHERE (name = &#x27;LiLei&#x27; or name = &#x27;HanMeimei&#x27;) AND age = 22 AND position =&#x27;manager&#x27;;\n\n\nlike KK% 一般情况都会走索引EXPLAIN SELECT * FROM employees WHERE name like &#x27;LiLei%&#x27; AND age = 22 AND position =&#x27;manager&#x27;;\n\n\nEXPLAIN SELECT * FROM employees_copy WHERE name like &#x27;LiLei%&#x27; AND age = 22 AND position =&#x27;manager&#x27;;\n\n\n索引下推（Index Condition Pushdown，ICP）like KK%其实就是用到了索引下推优化\n什么是索引下推？\n对于辅助的联合索引(name,age,position)，正常情况按照最左前缀原则，SELECT * FROM employees WHERE name like &#39;LiLei%&#39; AND age = 22 AND position =&#39;manager&#39;  这种情况只会走name字段索引，因为根据name字段过滤完，得到的索引行里的age和position是无序的，无法很好的利用索引。\n在MySQL5.6之前的版本，这个查询只能在联合索引里匹配到名字是 ‘LiLei’ 开头的索引，然后拿这些索引对应的主键逐个回表，到主键索引上找出相应的记录，再比对age和position这两个字段的值是否符合。\nMySQL 5.6引入了索引下推优化，可以在索引遍历过程中，对索引中包含的所有字段先做判断，过滤掉不符合条件的记录之后再回表，可以有效的减少回表次数。使用了索引下推优化后，上面那个查询在联合索引里匹配到名字是 ‘LiLei’ 开头的索引之后，同时还会在索引里过滤age和position这两个字段，拿着过滤完剩下的索引对应的主键id再回表查整行数据。\n索引下推会减少回表次数，对于innodb引擎的表索引下推只能用于二级索引，innodb的主键索引（聚簇索引）树叶子节点上保存的是全行数据，所以这个时候索引下推并不会起到减少查询全行数据的效果。\n为什么范围查找Mysql没有用索引下推优化？\n估计应该是Mysql认为范围查找过滤的结果集过大，like KK% 在绝大多数情况来看，过滤后的结果集比较小，所以这里Mysql选择给 like KK% 用了索引下推优化，当然这也不是绝对的，有时like KK% 也不一定就会走索引下推。\nMysql如何选择合适的索引mysql&gt; EXPLAIN select * from employees where name &gt; &#x27;a&#x27;;\n\n\n如果用name索引需要遍历name字段联合索引树，然后还需要根据遍历出来的主键值去主键索引树里再去查出最终数据，成本比全表扫描还高，可以用覆盖索引优化，这样只需要遍历name字段的联合索引树就能拿到所有结果，如下：\nmysql&gt; EXPLAIN select name,age,position from employees where name &gt; &#x27;a&#x27; ;\n\n\nmysql&gt; EXPLAIN select * from employees where name &gt; &#x27;zzz&#x27; ;\n\n\n对于上面这两种 name&gt;’a’ 和 name&gt;’zzz’ 的执行结果，mysql最终是否选择走索引或者一张表涉及多个索引，mysql最终如何选择索引，我们可以用trace工具来一查究竟，开启trace工具会影响mysql性能，所以只能临时分析sql使用，用完之后立即关闭\ntrace工具用法：\nmysql&gt; set session optimizer_trace=&quot;enabled=on&quot;,end_markers_in_json=on;  --开启tracemysql&gt; select * from employees where name &gt; &#x27;a&#x27; order by position;mysql&gt; SELECT * FROM information_schema.OPTIMIZER_TRACE;查看trace字段：&#123;  &quot;steps&quot;: [    &#123;      &quot;join_preparation&quot;: &#123;    --第一阶段：SQL准备阶段，格式化sql        &quot;select#&quot;: 1,        &quot;steps&quot;: [          &#123;            &quot;expanded_query&quot;: &quot;/* select#1 */ select `employees`.`id` AS `id`,`employees`.`name` AS `name`,            `employees`.`age` AS `age`,`employees`.`position` AS `position`,            `employees`.`hire_time` AS `hire_time` from `employees`            where (`employees`.`name` &gt; &#x27;a&#x27;)             order by employees`.`position`&quot;          &#125;        ] /* steps */      &#125; /* join_preparation */    &#125;,    &#123;      &quot;join_optimization&quot;: &#123;    --第二阶段：SQL优化阶段        &quot;select#&quot;: 1,        &quot;steps&quot;: [          &#123;            &quot;condition_processing&quot;: &#123;    --条件处理              &quot;condition&quot;: &quot;WHERE&quot;,              &quot;original_condition&quot;: &quot;(`employees`.`name` &gt; &#x27;a&#x27;)&quot;,              &quot;steps&quot;: [                &#123;                  &quot;transformation&quot;: &quot;equality_propagation&quot;,                  &quot;resulting_condition&quot;: &quot;(`employees`.`name` &gt; &#x27;a&#x27;)&quot;                &#125;,                &#123;                  &quot;transformation&quot;: &quot;constant_propagation&quot;,                  &quot;resulting_condition&quot;: &quot;(`employees`.`name` &gt; &#x27;a&#x27;)&quot;                &#125;,                &#123;                  &quot;transformation&quot;: &quot;trivial_condition_removal&quot;,                  &quot;resulting_condition&quot;: &quot;(`employees`.`name` &gt; &#x27;a&#x27;)&quot;                &#125;              ] /* steps */            &#125; /* condition_processing */          &#125;,          &#123;            &quot;substitute_generated_columns&quot;: &#123;            &#125; /* substitute_generated_columns */          &#125;,          &#123;            &quot;table_dependencies&quot;: [    --表依赖详情              &#123;                &quot;table&quot;: &quot;`employees`&quot;,                &quot;row_may_be_null&quot;: false,                &quot;map_bit&quot;: 0,                &quot;depends_on_map_bits&quot;: [                ] /* depends_on_map_bits */              &#125;            ] /* table_dependencies */          &#125;,          &#123;            &quot;ref_optimizer_key_uses&quot;: [            ] /* ref_optimizer_key_uses */          &#125;,          &#123;            &quot;rows_estimation&quot;: [    --预估表的访问成本              &#123;                &quot;table&quot;: &quot;`employees`&quot;,                &quot;range_analysis&quot;: &#123;                  &quot;table_scan&quot;: &#123;     --全表扫描情况                    &quot;rows&quot;: 10123,    --扫描行数                    &quot;cost&quot;: 2054.7    --查询成本                  &#125; /* table_scan */,                  &quot;potential_range_indexes&quot;: [    --查询可能使用的索引                    &#123;                      &quot;index&quot;: &quot;PRIMARY&quot;,    --主键索引                      &quot;usable&quot;: false,                      &quot;cause&quot;: &quot;not_applicable&quot;                    &#125;,                    &#123;                      &quot;index&quot;: &quot;idx_name_age_position&quot;,    --辅助索引                      &quot;usable&quot;: true,                      &quot;key_parts&quot;: [                        &quot;name&quot;,                        &quot;age&quot;,                        &quot;position&quot;,                        &quot;id&quot;                      ] /* key_parts */                    &#125;                  ] /* potential_range_indexes */,                  &quot;setup_range_conditions&quot;: [                  ] /* setup_range_conditions */,                  &quot;group_index_range&quot;: &#123;                    &quot;chosen&quot;: false,                    &quot;cause&quot;: &quot;not_group_by_or_distinct&quot;                  &#125; /* group_index_range */,                  &quot;analyzing_range_alternatives&quot;: &#123;    --分析各个索引使用成本                    &quot;range_scan_alternatives&quot;: [                      &#123;                        &quot;index&quot;: &quot;idx_name_age_position&quot;,                        &quot;ranges&quot;: [                          &quot;a &lt; name&quot;      --索引使用范围                        ] /* ranges */,                        &quot;index_dives_for_eq_ranges&quot;: true,                        &quot;rowid_ordered&quot;: false,    --使用该索引获取的记录是否按照主键排序                        &quot;using_mrr&quot;: false,                        &quot;index_only&quot;: false,       --是否使用覆盖索引                        &quot;rows&quot;: 5061,              --索引扫描行数                        &quot;cost&quot;: 6074.2,            --索引使用成本                        &quot;chosen&quot;: false,           --是否选择该索引                        &quot;cause&quot;: &quot;cost&quot;                      &#125;                    ] /* range_scan_alternatives */,                    &quot;analyzing_roworder_intersect&quot;: &#123;                      &quot;usable&quot;: false,                      &quot;cause&quot;: &quot;too_few_roworder_scans&quot;                    &#125; /* analyzing_roworder_intersect */                  &#125; /* analyzing_range_alternatives */                &#125; /* range_analysis */              &#125;            ] /* rows_estimation */          &#125;,          &#123;            &quot;considered_execution_plans&quot;: [              &#123;                &quot;plan_prefix&quot;: [                ] /* plan_prefix */,                &quot;table&quot;: &quot;`employees`&quot;,                &quot;best_access_path&quot;: &#123;    --最优访问路径                  &quot;considered_access_paths&quot;: [   --最终选择的访问路径                    &#123;                      &quot;rows_to_scan&quot;: 10123,                      &quot;access_type&quot;: &quot;scan&quot;,     --访问类型：为scan，全表扫描                      &quot;resulting_rows&quot;: 10123,                      &quot;cost&quot;: 2052.6,                      &quot;chosen&quot;: true,            --确定选择                      &quot;use_tmp_table&quot;: true                    &#125;                  ] /* considered_access_paths */                &#125; /* best_access_path */,                &quot;condition_filtering_pct&quot;: 100,                &quot;rows_for_plan&quot;: 10123,                &quot;cost_for_plan&quot;: 2052.6,                &quot;sort_cost&quot;: 10123,                &quot;new_cost_for_plan&quot;: 12176,                &quot;chosen&quot;: true              &#125;            ] /* considered_execution_plans */          &#125;,          &#123;            &quot;attaching_conditions_to_tables&quot;: &#123;              &quot;original_condition&quot;: &quot;(`employees`.`name` &gt; &#x27;a&#x27;)&quot;,              &quot;attached_conditions_computation&quot;: [              ] /* attached_conditions_computation */,              &quot;attached_conditions_summary&quot;: [                &#123;                  &quot;table&quot;: &quot;`employees`&quot;,                  &quot;attached&quot;: &quot;(`employees`.`name` &gt; &#x27;a&#x27;)&quot;                &#125;              ] /* attached_conditions_summary */            &#125; /* attaching_conditions_to_tables */          &#125;,          &#123;            &quot;clause_processing&quot;: &#123;              &quot;clause&quot;: &quot;ORDER BY&quot;,              &quot;original_clause&quot;: &quot;`employees`.`position`&quot;,              &quot;items&quot;: [                &#123;                  &quot;item&quot;: &quot;`employees`.`position`&quot;                &#125;              ] /* items */,              &quot;resulting_clause_is_simple&quot;: true,              &quot;resulting_clause&quot;: &quot;`employees`.`position`&quot;            &#125; /* clause_processing */          &#125;,          &#123;            &quot;reconsidering_access_paths_for_index_ordering&quot;: &#123;              &quot;clause&quot;: &quot;ORDER BY&quot;,              &quot;steps&quot;: [              ] /* steps */,              &quot;index_order_summary&quot;: &#123;                &quot;table&quot;: &quot;`employees`&quot;,                &quot;index_provides_order&quot;: false,                &quot;order_direction&quot;: &quot;undefined&quot;,                &quot;index&quot;: &quot;unknown&quot;,                &quot;plan_changed&quot;: false              &#125; /* index_order_summary */            &#125; /* reconsidering_access_paths_for_index_ordering */          &#125;,          &#123;            &quot;refine_plan&quot;: [              &#123;                &quot;table&quot;: &quot;`employees`&quot;              &#125;            ] /* refine_plan */          &#125;        ] /* steps */      &#125; /* join_optimization */    &#125;,    &#123;      &quot;join_execution&quot;: &#123;    --第三阶段：SQL执行阶段        &quot;select#&quot;: 1,        &quot;steps&quot;: [        ] /* steps */      &#125; /* join_execution */    &#125;  ] /* steps */&#125;结论：全表扫描的成本低于索引扫描，所以mysql最终选择全表扫描mysql&gt; select * from employees where name &gt; &#x27;zzz&#x27; order by position;mysql&gt; SELECT * FROM information_schema.OPTIMIZER_TRACE;查看trace字段可知索引扫描的成本低于全表扫描，所以mysql最终选择索引扫描mysql&gt; set session optimizer_trace=&quot;enabled=off&quot;;    --关闭trace\n\n常见sql深入优化Order by与Group by优化\nCase1\n分析：\n利用最左前缀法则：中间字段不能断，因此查询用到了name索引，从key_len=74也能看出，age索引列用在排序过程中，因为Extra字段里没有using filesort\n\nCase 2\n分析：\n从explain的执行结果来看：key_len=74，查询使用了name索引，由于用了position进行排序，跳过了age，出现了Using filesort\n\nCase 3\n分析：\n查找只用到索引name，age和position用于排序，无Using filesort\n\nCase 4\n分析：\n和Case 3中explain的执行结果一样，但是出现了Using filesort，因为索引的创建顺序为name,age,position，但是排序的时候age和position颠倒位置了\n\nCase 5\n分析：\n与Case 4对比，在Extra中并未出现Using filesort，因为age为常量，在排序中被优化，所以索引未颠倒，不会出现Using filesort\n\nCase 6\n分析：\n虽然排序的字段列与索引顺序一样，且order by默认升序，这里position desc变成了降序，导致与索引的排序方式不同，从而产生Using filesort。Mysql8以上版本有降序索引可以支持该种查询方式\n\nCase 7\n分析：\n对于排序来说，多个相等条件也是范围查询\n\nCase 8可以用覆盖索引优化\n\n\nUsing filesort文件排序原理详解filesort文件排序方式\n单路排序：是一次性取出满足条件行的所有字段，然后在sort buffer中进行排序；用trace工具可以看到sort_mode信息里显示&lt; sort_key, additional_fields &gt;或者&lt; sort_key, packed_additional_fields &gt;\n双路排序（又叫回表排序模式）：是首先根据相应的条件取出相应的排序字段和可以直接定位行数据的行 ID，然后在 sort buffer 中进行排序，排序完后需要再次取回其它需要的字段；用trace工具可以看到sort_mode信息里显示&lt; sort_key, rowid &gt;\n\nMySQL 通过比较系统变量 max_length_for_sort_data(默认1024字节) 的大小和需要查询的字段总大小来判断使用哪种排序模式。\n\n如果 字段的总长度小于max_length_for_sort_data ，那么使用 单路排序模式\n如果 字段的总长度大于max_length_for_sort_data ，那么使用 双路排序模·式\n\n验证下各种排序方式\nmysql&gt; set session optimizer_trace=&quot;enabled=on&quot;,end_markers_in_json=on;  --开启tracemysql&gt; select * from employees where name = &#x27;zhuge&#x27; order by position;mysql&gt; select * from information_schema.OPTIMIZER_TRACE;trace排序部分结果：&quot;join_execution&quot;: &#123;    --Sql执行阶段        &quot;select#&quot;: 1,        &quot;steps&quot;: [          &#123;            &quot;filesort_information&quot;: [              &#123;                &quot;direction&quot;: &quot;asc&quot;,                &quot;table&quot;: &quot;`employees`&quot;,                &quot;field&quot;: &quot;position&quot;              &#125;            ] /* filesort_information */,            &quot;filesort_priority_queue_optimization&quot;: &#123;              &quot;usable&quot;: false,              &quot;cause&quot;: &quot;not applicable (no LIMIT)&quot;            &#125; /* filesort_priority_queue_optimization */,            &quot;filesort_execution&quot;: [            ] /* filesort_execution */,            &quot;filesort_summary&quot;: &#123;                      --文件排序信息              &quot;rows&quot;: 10000,                           --预计扫描行数              &quot;examined_rows&quot;: 10000,                  --参与排序的行              &quot;number_of_tmp_files&quot;: 3,                --使用临时文件的个数，这个值如果为0代表全部使用的sort_buffer内存排序，否则使用的磁盘文件排序              &quot;sort_buffer_size&quot;: 262056,              --排序缓存的大小，单位Byte              &quot;sort_mode&quot;: &quot;&lt;sort_key, packed_additional_fields&gt;&quot;       --排序方式，这里用的单路排序            &#125; /* filesort_summary */          &#125;        ] /* steps */      &#125; /* join_execution */            mysql&gt; set max_length_for_sort_data = 10;    --employees表所有字段长度总和肯定大于10字节mysql&gt; select * from employees where name = &#x27;zhuge&#x27; order by position;mysql&gt; select * from information_schema.OPTIMIZER_TRACE;trace排序部分结果：&quot;join_execution&quot;: &#123;        &quot;select#&quot;: 1,        &quot;steps&quot;: [          &#123;            &quot;filesort_information&quot;: [              &#123;                &quot;direction&quot;: &quot;asc&quot;,                &quot;table&quot;: &quot;`employees`&quot;,                &quot;field&quot;: &quot;position&quot;              &#125;            ] /* filesort_information */,            &quot;filesort_priority_queue_optimization&quot;: &#123;              &quot;usable&quot;: false,              &quot;cause&quot;: &quot;not applicable (no LIMIT)&quot;            &#125; /* filesort_priority_queue_optimization */,            &quot;filesort_execution&quot;: [            ] /* filesort_execution */,            &quot;filesort_summary&quot;: &#123;              &quot;rows&quot;: 10000,              &quot;examined_rows&quot;: 10000,              &quot;number_of_tmp_files&quot;: 2,              &quot;sort_buffer_size&quot;: 262136,                 &quot;sort_mode&quot;: &quot;&lt;sort_key, rowid&gt;&quot;         --排序方式，这里用的双路排序            &#125; /* filesort_summary */          &#125;        ] /* steps */      &#125; /* join_execution */mysql&gt; set session optimizer_trace=&quot;enabled=off&quot;;    --关闭trace\n\n单路排序的详细过程\n从索引name找到第一个满足 name = ‘zhuge’ 条件的主键 id\n根据主键 id 取出整行，取出所有字段的值，存入 sort_buffer 中\n从索引name找到下一个满足 name = ‘zhuge’ 条件的主键 id\n重复步骤 2、3 直到不满足 name = ‘zhuge’ \n对 sort_buffer 中的数据按照字段 position 进行排序\n返回结果给客户端\n\n双路排序的详细过程\n从索引 name 找到第一个满足 name = ‘zhuge’  的主键id\n根据主键 id 取出整行，把排序字段 position 和主键 id 这两个字段放到 sort buffer 中\n从索引 name 取下一个满足 name = ‘zhuge’  记录的主键 id\n重复 3、4 直到不满足 name = ‘zhuge’ \n对 sort_buffer 中的字段 position 和主键 id 按照字段 position 进行排序\n遍历排序好的 id 和字段 position，按照 id 的值回到原表中取出 所有字段的值返回给客户端\n\n其实对比两个排序模式，单路排序会把所有需要查询的字段都放到 sort buffer 中，而双路排序只会把主键和需要排序的字段放到 sort buffer 中进行排序，然后再通过主键回到原表查询需要的字段。\n如果 MySQL 排序内存 sort_buffer 配置的比较小并且没有条件继续增加了，可以适当把 max_length_for_sort_data 配置小点，让优化器选择使用双路排序算法，可以在sort_buffer 中一次排序更多的行，只是需要再根据主键回到原表取数据。\n如果 MySQL 排序内存有条件可以配置比较大，可以适当增大 max_length_for_sort_data 的值，让优化器优先选择全字段排序(单路排序)，把需要的字段放到 sort_buffer 中，这样排序后就会直接从内存里返回查询结果了。\n所以，MySQL通过 max_length_for_sort_data 这个参数来控制排序，在不同场景使用不同的排序模式，从而提升排序效率。\n注意，如果全部使用sort_buffer内存排序一般情况下效率会高于磁盘文件排序，但不能因为这个就随便增大sort_buffer(默认1M)，mysql很多参数设置都是做过优化的，不要轻易调整。\n优化总结\nMySQL支持两种方式的排序filesort和index，Using index是指MySQL扫描索引本身完成排序。index效率高，filesort效率低\n\norder by满足两种情况会使用Using index\n\norder by语句使用索引最左前列\n使用where子句与order by子句条件列组合满足索引最左前列\n\n\n尽量在索引列上完成排序，遵循索引建立（索引创建的顺序）时的最左前缀法则\n\n如果order by的条件不在索引列上，就会产生Using filesort\n\n能用覆盖索引尽量用覆盖索引\n\ngroup by与order by很类似，其实质是先排序后分组，遵照索引创建顺序的最左前缀法则。对于group by的优化如果不需要排序的可以加上order by null禁止排序。注意，where高于having，能写在where中的限定条件就不要去having限定了。    \n\n\n索引设计原则代码先行，索引后上不知大家一般是怎么给数据表建立索引的，是建完表马上就建立索引吗？\n这其实是不对的，一般应该等到主体业务功能开发完毕，把涉及到该表相关sql都要拿出来分析之后再建立索引。\n联合索引尽量覆盖条件比如可以设计一个或者两三个联合索引(尽量少建单值索引)，让每一个联合索引都尽量去包含sql语句里的where、order by、group by的字段，还要确保这些联合索引的字段顺序尽量满足sql查询的最左前缀原则。\n不要在小基数字段上建立索引索引基数是指这个字段在表里总共有多少个不同的值，比如一张表总共100万行记录，其中有个性别字段，其值不是男就是女，那么该字段的基数就是2。\n如果对这种小基数字段建立索引的话，还不如全表扫描了，因为你的索引树里就包含男和女两种值，根本没法进行快速的二分查找，那用索引就没有太大的意义了。\n一般建立索引，尽量使用那些基数比较大的字段，就是值比较多的字段，那么才能发挥出B+树快速二分查找的优势来。\n长字符串我们可以采用前缀索引尽量对字段类型较小的列设计索引，比如说什么tinyint之类的，因为字段类型较小的话，占用磁盘空间也会比较小，此时你在搜索的时候性能也会比较好一点。\n当然，这个所谓的字段类型小一点的列，也不是绝对的，很多时候你就是要针对varchar(255)这种字段建立索引，哪怕多占用一些磁盘空间也是有必要的。\n对于这种varchar(255)的大字段可能会比较占用磁盘空间，可以稍微优化下，比如针对这个字段的前20个字符建立索引，就是说，对这个字段里的每个值的前20个字符放在索引树里，类似于 KEY index(name(20),age,position)。\n此时你在where条件里搜索的时候，如果是根据name字段来搜索，那么此时就会先到索引树里根据name字段的前20个字符去搜索，定位到之后前20个字符的前缀匹配的部分数据之后，再回到聚簇索引提取出来完整的name字段值进行比对。\n但是假如你要是order by name，那么此时你的name因为在索引树里仅仅包含了前20个字符，所以这个排序是没法用上索引的， group by也是同理。所以这里大家要对前缀索引有一个了解。\nwhere与order by冲突时优先where在where和order by出现索引设计冲突时，到底是针对where去设计索引，还是针对order by设计索引？到底是让where去用上索引，还是让order by用上索引?\n一般这种时候往往都是让where条件去使用索引来快速筛选出来一部分指定的数据，接着再进行排序。\n因为大多数情况基于索引进行where筛选往往可以最快速度筛选出你要的少部分数据，然后做排序的成本可能会小很多。\n基于慢sql查询做优化可以根据监控后台的一些慢sql，针对这些慢sql查询做特定的索引优化。关于慢sql查询不清楚的可以参考这篇文章。\n索引设计实战以社交场景APP来举例，我们一般会去搜索一些好友，这里面就涉及到对用户信息的筛选，这里肯定就是对用户user表搜索了，这个表一般来说数据量会比较大，我们先不考虑分库分表的情况，比如，我们一般会筛选地区(省市)，性别，年龄，身高，爱好之类的，有的APP可能用户还有评分，比如用户的受欢迎程度评分，我们可能还会根据评分来排序等等。\n对于后台程序来说除了过滤用户的各种条件，还需要分页之类的处理，可能会生成类似sql语句执行：\nselect xx from user where xx=xx and xx=xx order by xx limit xx,xx\n对于这种情况如何合理设计索引了，比如用户可能经常会根据省市优先筛选同城的用户，还有根据性别去筛选，那我们是否应该设计一个联合索引 (province,city,sex) 了？这些字段好像基数都不大，其实是应该的，因为这些字段查询太频繁了。\n假设又有用户根据年龄范围去筛选了，比如 where  province=xx and city=xx and age&gt;=xx and age&lt;=xx，我们尝试着把age字段加入联合索引 (province,city,sex,age)，注意，一般这种范围查找的条件都要放在最后，之前讲过联合索引范围之后条件的是不能用索引的，但是对于当前这种情况依然用不到age这个索引字段，因为用户没有筛选sex字段，那怎么优化了？其实我们可以这么来优化下sql的写法：\nwhere  province=xx and city=xx and sex in (&#39;female&#39;,&#39;male&#39;) and age&gt;=xx and age&lt;=xx\n对于爱好之类的字段也可以类似sex字段处理，所以可以把爱好字段也加入索引 (province,city,sex,hobby,age) \n假设可能还有一个筛选条件，比如要筛选最近一周登录过的用户，一般大家肯定希望跟活跃用户交友了，这样能尽快收到反馈，对应后台sql可能是这样：\nwhere  province=xx and city=xx and sex in (&#39;female&#39;,&#39;male&#39;) and age&gt;=xx and age&lt;=xx and latest_login_time&gt;= xx\n那我们是否能把 latest_login_time 字段也加入索引了？比如  (province,city,sex,hobby,age,latest_login_time) ，显然是不行的，那怎么来优化这种情况了？其实我们可以试着再设计一个字段is_login_in_latest_7_days，用户如果一周内有登录值就为1，否则为0，那么我们就可以把索引设计成 (province,city,sex,hobby,is_login_in_latest_7_days,age)  来满足上面那种场景了！\n一般来说，通过这么一个多字段的索引是能够过滤掉绝大部分数据的，就保留小部分数据下来基于磁盘文件进行order by语句的排序，最后基于limit进行分页，那么一般性能还是比较高的。\n不过有时可能用户会这么来查询，就查下受欢迎度较高的女性，比如sql：where  sex = ‘female’  order by score limit xx,xx，那么上面那个索引是很难用上的，不能把太多的字段以及太多的值都用 in 语句拼接到sql里的，那怎么办了？其实我们可以再设计一个辅助的联合索引，比如 (sex,score)，这样就能满足查询要求了。\n以上就是给大家讲的一些索引设计的思路了，核心思想就是，尽量利用一两个复杂的多字段联合索引，抗下你80%以上的查询，然后用一两个辅助索引尽量抗下剩余的一些非典型查询，保证这种大数据量表的查询尽可能多的都能充分利用索引，这样就能保证你的查询速度和性能了！\n","categories":["Database"],"tags":["Mysql"]},{"title":"MYSQL中WAL策略与checkpoint技术","url":"/2021/09/06/Database/Mysql/Mysql%E4%B8%ADWAL%E7%AD%96%E7%95%A5%E4%B8%8Echeckpoint%E6%8A%80%E6%9C%AF/","content":"InnoDB 体系架构在说 WAL 之前，有必要简单介绍下 InnoDB 存储引擎的体系架构，方便我们理解下文，并且 redo log 也是 InnoDB 存储引擎所特有的。\n如下图，InnoDB 存储引擎由内存池和一些后台线程组成：\n\n内存池先来解释下内存池。\n首先，我们需要知道，InnoDB 存储引擎是基于磁盘存储的，并将其中的记录按照页的方式进行管理。因此可将其视为基于磁盘的数据库系统（Disk-base Database），在这样的系统中，众所周知，由于 CPU 速度与磁盘速度之间的不匹配，通常会使用缓冲池技术来提高数据库的整体性能。\n所以这里的内存池也被称为缓冲池（简单理解为缓存就好了）。\n具体来说，缓冲池其实就是一块内存区域，在 CPU 与磁盘之间加入内存访问，通过内存的速度来弥补磁盘速度较慢对数据库性能的影响。\n拥有了缓冲池后，“读取页” 操作的具体步骤就是这样的：\n\n首先将从磁盘读到的页存放在缓冲池中\n下一次再读相同的页时，首先判断该页是否在缓冲池中。若在缓冲池中，称该页在缓冲池中被命中，直接读取该页。否则，读取磁盘上的页。\n\n“修改页” 操作的具体步骤就是这样的：\n\n首先修改在缓冲池中的页；然后再以一定的频率刷新到磁盘上。\n\n所谓 ”脏页“ 就发生在修改这个操作中，如果缓冲池中的页已经被修改了，但是还没有刷新到磁盘上，那么我们就称缓冲池中的这页是 ”脏页“，即缓冲池中的页的版本要比磁盘的新。\n至此，综上所述，我们可以得出这样的结论：缓冲池的大小直接影响着数据库的整体性能。\n后台线程后台线程其实最大的作用就是用来完成 “将从磁盘读到的页存放在缓冲池中” 以及 “将缓冲池中的数据以一定的频率刷新到磁盘上” 这俩个操作的，当然了，还有其他的作用。以下是《MySQL 技术内幕：InnoDB 存储引擎 - 第 2 版》对于后台线程的描述：\n\n后台线程的主要作用就是刷新内存池中的数据，保证内存池中缓存的是最近的数据；此外将已修改的数据文件刷新到磁盘文件，同时保证在数据库发生异常的情况下 InnoDB 能恢复到正常运行状态。\n\n另外，InnoDB 存储引擎是多线程的模型，也就是说它拥有多个不同的后台线程，负责处理不同的任务。这里简单列举下几种不同的后台线程：\n\nMaster Thread：主要负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性\nIO Thread：在 InnoDB 存储引擎中大量使用了 AIO（Async IO）来处理写 IO 请求，这样可以极大提高数据库的性能。IO Thread 的工作主要是负责这些 IO 请求的回调（call back）处理\nPurge Thread：回收已经使用并分配的 undo 页\nPage Cleaner Thread：将之前版本中脏页的刷新操作都放入到单独的线程中来完成。其目的是为了减轻原 Master Thread 的工作及对于用户查询线程的阻塞，进一步提高 InnoDB 存储引擎的性能\n\nredo log 与 WAL 策略上文我们提到，当缓冲池中的某页数据被修改后，该页就被标记为 ”脏页“，脏页的数据会被定期刷新到磁盘上。\n倘若每次一个页发生变化，就将新页的版本刷新到磁盘，那么这个开销是非常大的。并且，如果热点数据都集中在某几个页中，那么数据库的性能将变得非常差。另外，如果在从缓冲池将页的新版本刷新到磁盘时发生了宕机，那么这个数据就不能恢复了。\n所以，为了避免发生数据丢失的问题，当前事务数据库系统（并非 MySQL 所独有）普遍都采用了 WAL（Write Ahead Log，预写日志）策略：即当事务提交时，先写重做日志（redo log），再修改页（先修改缓冲池，再刷新到磁盘）；当由于发生宕机而导致数据丢失时，通过 redo log 来完成数据的恢复。这也是事务 ACID 中 D（Durability 持久性）的要求。\n有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。\n举个简单的例子，假设你非常热心且 rich 的，借出去了很多钱，但是你非常 old school，不会使用电子设备并且记性不太好，所以你用一个小本本记下了所有欠你钱的人的名字和具体金额。这样，别人还你钱的时候，你就翻出你的小本本，一页页地找到他的名字然后把这次还的钱扣除掉。\n但是呢，其实你平常是非常忙碌的，没办法随时随地翻小本本做记录，因此你就想出了一个主意：每当有人还你钱的时候，你就在一张白纸上记下来，然后挑个时间对照小本本把白纸上的账目都给清了。\n这就是 WAL。白纸就是 redo log，小本本就是磁盘。\n当然了，redo log 可不是白纸这么简单，一张用完了换一张就行了，这里有必要详细解释下。\n每个 InnoDB 存储引擎至少有 1 个重做日志文件组（ redo log group），每个文件组下至少有 2 个重做日志文件（redo log file），默认的话是一个 redo log group，其中包含 2 个 redo log file：ib_logfile0 和 ib_logfile1 。\n一般来说，为了得到更高的可靠性，用户可以设置多个镜像日志组（mirrored log groups），将不同的文件组放在不同的磁盘上，以此提高 redo log 的高可用性。在日志组中每个 redo log file 的大小一致，并以循环写入的方式运行。\n所谓循环写入，也就是为啥我们说 redo log 不像白纸那样用完一张换一张就行，举个例子，如下图，一个 redo log group，包含 3 个 redo log file：\n\nInnoDB 存储引擎会先写 redo log file 0，当 file 0 被写满的时候，会切换至 redo log file 1，当 file 1 也被写满时，会切换到 redo log file 2 中，而当 file 2 也被写满时，会再切换到  file 0 中。\n可以看出，redo log file 的大小设置对于 InnoDB 存储引擎的性能有着非常大的影响：\n\nredo log file 不能设置得太大，如果设置得很大，在恢复时可能需要很长的时间\nredo log file 又不能设置得太小了，否则可能导致一个事务的日志需要多次切换重做日志文件\n\nCheckPoint 技术有了 redo log 就可以高枕无忧了吗？显然不是这么简单，我们仍然面临这样 3 个问题：\n1）缓冲池不是无限大的，也就是说不能没完没了的存储我们的数据等待一起刷新到磁盘\n2）redo log 是循环使用而不是无限大的（也许可以，但是成本太高，同时不便于运维），那么当所有的 redo log file 都写满了怎么办？\n3）当数据库运行了几个月甚至几年时，这时如果发生宕机，重新应用 redo log 的时间会非常久，此时恢复的代价将会非常大。\n因此 Checkpoint 技术的目的就是解决上述问题：\n\n缓冲池不够用时，将脏页刷新到磁盘\nredo log 不可用时，将脏页刷新到磁盘\n缩短数据库的恢复时间\n\n所谓 CheckPoint 技术简单来说其实就是在 redo log file 中找到一个位置，将这个位置前的页都刷新到磁盘中去，这个位置就称为 CheckPoint（检查点）。\n针对上面这三点我们依次来解释下：\n1）缩短数据库的恢复时间：当数据库发生宕机时，数据库不需要重做所有的日志，因为 Checkpoint 之前的页都已经刷新回磁盘。故数据库只需对 Checkpoint 后的 redo log 进行恢复就行了。这显然大大缩短了恢复的时间。\n2）缓冲池不够用时，将脏页刷新到磁盘：所谓缓冲池不够用的意思就是缓冲池的空间无法存放新读取到的页，这个时候 InnoDB 引擎会怎么办呢？LRU 算法。InnoDB 存储引擎对传统的 LRU 算法做了一些优化，用其来管理缓冲池这块空间。\n总的思路还是传统 LRU 那套，具体的优化细节这里就不再赘述了：即最频繁使用的页在 LRU 列表（LRU List）的前端，最少使用的页在 LRU 列表的尾端；当缓冲池的空间无法存放新读取到的页时，将首先释放 LRU 列表中尾端的页。这个被释放出来（溢出）的页，如果是脏页，那么就需要强制执行 CheckPoint，将脏页刷新到磁盘中去。\n3）redo log 不可用时，将脏页刷新到磁盘：\n所谓 redo log 不可用就是所有的 redo log file 都写满了。但事实上，其实 redo log 中的数据并不是时时刻刻都是有用的，那些已经不再需要的部分就称为 ”可以被重用的部分“，即当数据库发生宕机时，数据库恢复操作不需要这部分的 redo log，因此这部分就可以被覆盖重用（或者说被擦除）。\n举个例子来具体解释下：一组 4 个文件，每个文件的大小是 1GB，那么总共就有 4GB 的 redo log file 空间。write pos 是当前 redo log 记录的位置，随着不断地写入磁盘，write pos 也不断地往后移，就像我们上文说的，写到 file 3 末尾后就回到 file 0 开头。CheckPoint 是当前要擦除的位置（将 Checkpoint 之前的页刷新回磁盘），也是往后推移并且循环的：\n\nwrite pos 和 CheckPoint 之间的就是 redo log file 上还空着的部分，可以用来记录新的操作。如果 write pos 追上 CheckPoint，就表示 redo log file 满了，这时候不能再执行新的更新，得停下来先覆盖（擦掉）一些 redo log，把 CheckPoint 推进一下。\n综上所述，Checkpoint 所做的事情无外乎是将缓冲池中的脏页刷新到磁盘。不同之处在于每次刷新多少页到磁盘，每次从哪里取脏页，以及什么时间触发 Checkpoint。在 InnoDB 存储引擎内部，有两种 Checkpoint，分别为：\n\nSharp Checkpoint：发生在数据库关闭时将所有的脏页都刷新回磁盘，这是默认的工作方式，参数 innodb_fast_shutdown=1\nFuzzy Checkpoin：InnoDB 存储引擎内部使用这种模式，只刷新一部分脏页，而不是刷新所有的脏页回磁盘。关于 Fuzzy CheckPoint 具体的情况这里就不再赘述了。\n\n有了 bin log 为什么还需要 redo log？前文我们讲过，MySQL 架构可以分成俩层，一层是 Server 层，它主要做的是 MySQL 功能层面的事情；另一层就是存储引擎，负责存储与提取相关的具体事宜。\nredo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，包括错误日志（error log）、二进制日志（binlog）、慢查询日志（slow query log）、查询日志（log）。\n其他三个日志顾明思意都挺好理解的，需要解释的就是 binlog（二进制日志，binary log），它记录了对 MySQL 数据库执行更改的所有操作，但是不包括 SELECT 和 SHOW 这类操作，因为这类操作对数据本身并没有修改。也就是说，binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如 “给 ID=1 这一行的 a 字段加 1”。\n可以看出来，binlog 日志只能用于归档，因此 binlog 也被称为归档日志，显然如果 MySQL 只依靠 binlog 等这四种日志是没有 crash-safe 能力的，所以为了弥补这种先天的不足，得益于 MySQL 可插拔的存储引擎架构，InnoDB 开发了另外一套日志系统 — 也就是 redo log 来实现 crash-safe 能力。\n这就是为什么有了 bin log 为什么还需要 redo log 的答案。\n回顾下 redo log 存储的东西，可以发现 redo log 是物理日志，记录的是 “在某个数据页上做了什么修改”。\n另外，还有一点不同的是：binlog 是追加写入的，就是说 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志；而 redo log 是循环写入的。\n","categories":["Database"],"tags":["Mysql"]},{"title":"Mysql索引优化二","url":"/2021/11/18/Database/Mysql/Mysql%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96%E4%BA%8C/","content":"分页查询优化CREATE TABLE `employees` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `name` varchar(24) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;姓名&#x27;,  `age` int(11) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;年龄&#x27;,  `position` varchar(20) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;职位&#x27;,  `hire_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;入职时间&#x27;,  PRIMARY KEY (`id`),  KEY `idx_name_age_position` (`name`,`age`,`position`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT=&#x27;员工记录表&#x27;;\n\n很多时候我们业务系统实现分页功能可能会用如下sql实现\nmysql&gt; select * from employees limit 10000,10;\n\n表示从表 employees 中取出从 10001 行开始的 10 行记录。看似只查询了 10 条记录，实际这条 SQL 是先读取 10010 条记录，然后抛弃前 10000 条记录，然后读到后面 10 条想要的数据。因此要查询一张大表比较靠后的数据，执行效率是非常低的。\n根据自增且连续的主键排序的分页查询首先来看一个根据自增且连续主键排序的分页查询的例子：\nmysql&gt; select * from employees limit 90000,5;\n\n\n该 SQL 表示查询从第 90001开始的五行数据，没添加单独 order by，表示通过主键排序。我们再看表 employees ，因为主键是自增并且连续的，所以可以改写成按照主键去查询从第 90001开始的五行数据，如下：\nmysql&gt; select * from employees where id &gt; 90000 limit 5;\n\n\n查询的结果是一致的。我们再对比一下执行计划：\nmysql&gt; EXPLAIN select * from employees limit 90000,5;\n\n\nmysql&gt; EXPLAIN select * from employees where id &gt; 90000 limit 5;\n\n\n显然改写后的 SQL 走了索引，而且扫描的行数大大减少，执行效率更高。 \n但是，这条改写的SQL 在很多场景并不实用，因为表中可能某些记录被删后，主键空缺，导致结果不一致。如果主键不连续，不能使用上面描述的优化方法。\n另外如果原 SQL 是 order by 非主键的字段，按照上面说的方法改写会导致两条 SQL 的结果不一致。所以这种改写得满足以下两个条件：\n\n主键自增且连续\n结果是按照主键排序的\n\n根据非主键字段排序的分页查询再看一个根据非主键字段排序的分页查询，SQL 如下：\nmysql&gt;  select * from employees ORDER BY name limit 90000,5;\n\n\nmysql&gt; EXPLAIN select * from employees ORDER BY name limit 90000,5;\n\n\n发现并没有使用 name 字段的索引（key 字段对应的值为 null），具体原因上节课讲过：扫描整个索引并查找到没索引的行(可能要遍历多个索引树)的成本比扫描全表的成本更高，所以优化器放弃使用索引。知道不走索引的原因，那么怎么优化呢？其实关键是让排序时返回的字段尽可能少，所以可以让排序和分页操作先查出主键，然后根据主键查到对应的记录，SQL改写如下:\nmysql&gt; select * from employees e inner join (select id from employees order by name limit 90000,5) ed on e.id = ed.id;\n\n\n需要的结果与原 SQL 一致，执行时间减少了一半以上，我们再对比优化前后sql的执行计划：\n\n原 SQL 使用的是 filesort 排序，而优化后的 SQL 使用的是索引排序。\nJoin关联查询优化-- 示例表：CREATE TABLE `t1` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `a` int(11) DEFAULT NULL,  `b` int(11) DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `idx_a` (`a`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;create table t2 like t1;-- 插入一些示例数据-- 往t1表插入1万行记录drop procedure if exists insert_t1; delimiter ;;create procedure insert_t1()        begin  declare i int;                      set i=1;                            while(i&lt;=10000)do                     insert into t1(a,b) values(i,i);      set i=i+1;                         end while;end;;delimiter ;call insert_t1();-- 往t2表插入100行记录drop procedure if exists insert_t2; delimiter ;;create procedure insert_t2()        begin  declare i int;                      set i=1;                            while(i&lt;=100)do                     insert into t2(a,b) values(i,i);      set i=i+1;                         end while;end;;delimiter ;call insert_t2();\n\nmysql的表关联常见有两种算法\n\nNested-Loop Join 算法\n\nBlock Nested-Loop Join 算法\n\n\n嵌套循环连接 Nested-Loop Join(NLJ) 算法一次一行循环地从第一张表（称为驱动表）中读取行，在这行数据中取到关联字段，根据关联字段在另一张表（被驱动表）里取出满足条件的行，然后取出两张表的结果合集。\nmysql&gt; EXPLAIN select * from t1 inner join t2 on t1.a= t2.a;\n\n\n从执行计划中可以看到这些信息：\n\n驱动表是 t2，被驱动表是 t1。先执行的就是驱动表(执行计划结果的id如果一样则按从上到下顺序执行sql)；优化器一般会优先选择小表做驱动表，用where条件过滤完驱动表，然后再跟被驱动表做关联查询。所以使用 inner join 时，排在前面的表并不一定就是驱动表。\n\n当使用left join时，左表是驱动表，右表是被驱动表，当使用right join时，右表时驱动表，左表是被驱动表，当使用join时，mysql会选择数据量比较小的表作为驱动表，大表作为被驱动表。\n\n使用了 NLJ算法。一般 join 语句中，如果执行计划 Extra 中未出现 Using join buffer 则表示使用的 join 算法是 NLJ。\n\n上面sql的大致流程如下：\n\n从表 t2 中读取一行数据（如果t2表有查询过滤条件的，用先用条件过滤完，再从过滤结果里取出一行数据）；\n从第 1 步的数据中，取出关联字段 a，到表 t1 中查找；\n取出表 t1 中满足条件的行，跟 t2 中获取到的结果合并，作为结果返回给客户端；\n重复上面 3 步。\n\n整个过程会读取 t2 表的所有数据(扫描100行)，然后遍历这每行数据中字段 a 的值，根据 t2 表中 a 的值索引扫描 t1 表中的对应行(扫描100次 t1 表的索引，1次扫描可以认为最终只扫描 t1 表一行完整数据，也就是总共 t1 表也扫描了100行)。因此整个过程扫描了 200 行。\n如果被驱动表的关联字段没索引，**使用NLJ算法性能会比较低(下面有详细解释)**，mysql会选择Block Nested-Loop Join算法。\n基于块的嵌套循环连接 Block Nested-Loop Join(BNL)算法把驱动表的数据读入到 join_buffer 中，然后扫描被驱动表，把被驱动表每一行取出来跟 join_buffer 中的数据做对比。\nmysql&gt;EXPLAIN select * from t1 inner join t2 on t1.b= t2.b;\n\n\nExtra 中 的Using join buffer (Block Nested Loop)说明该关联查询使用的是 BNL 算法。\n上面sql的大致流程如下：\n\n把 t2 的所有数据放入到 join_buffer 中\n把表 t1 中每一行取出来，跟 join_buffer 中的数据做对比\n返回满足 join 条件的数据\n\n整个过程对表 t1 和 t2 都做了一次全表扫描，因此扫描的总行数为10000(表 t1 的数据总量) + 100(表 t2 的数据总量) = 10100。并且 join_buffer 里的数据是无序的，因此对表 t1 中的每一行，都要做 100 次判断，所以内存中的判断次数是 100 * 10000= 100 万次。\n这个例子里表 t2 才 100 行，要是表 t2 是一个大表，join_buffer 放不下怎么办呢？·\njoin_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。如果放不下表 t2 的所有数据话，策略很简单，就是分段放。\n比如 t2 表有1000行记录， join_buffer 一次只能放800行数据，那么执行过程就是先往 join_buffer 里放800行记录，然后从 t1 表里取数据跟 join_buffer 中数据对比得到部分结果，然后清空  join_buffer ，再放入 t2 表剩余200行记录，再次从 t1 表里取数据跟 join_buffer 中数据对比。所以就多扫了一次 t1 表。\n被驱动表的关联字段没索引为什么要选择使用 BNL 算法而不使用 Nested-Loop Join 呢？\n如果上面第二条sql使用 Nested-Loop Join，那么扫描行数为 100 * 10000 = 100万次，这个是磁盘扫描。很显然，用BNL磁盘扫描次数少很多，相比于磁盘扫描，BNL的内存计算会快得多。因此MySQL对于被驱动表的关联字段没索引的关联查询，一般都会使用 BNL 算法。如果有索引一般选择 NLJ 算法，有索引的情况下 NLJ 算法比 BNL算法性能更高\n\n\n对于关联sql的优化\n关联字段加索引：让mysql做join操作时尽量选择NLJ算法，驱动表因为需要全部查询出来，所以过滤的条件也尽量要走索引，避免全表扫描，总之，能走索引的过滤条件尽量都走索引\n小表驱动大表：写多表连接sql时如果明确知道哪张表是小表可以用straight_join写法固定连接驱动方式，省去mysql优化器自己判断的时间\n\nstraight_join解释：straight_join功能同join类似，但能让左边的表来驱动右边的表，能改表优化器对于联表查询的执行顺序。比如：select * from t2 straight_join t1 on t2.a = t1.a; 代表指定mysql选着 t2 表作为驱动表。\n\nstraight_join只适用于inner join，并不适用于left join，right join。（因为left join，right join已经代表指定了表的执行顺序）\n尽可能让优化器去判断，因为大部分情况下mysql优化器是比人要聪明的。使用straight_join一定要慎重，因为部分情况下人为指定的执行顺序并不一定会比优化引擎要靠谱\n\n\n对于小表定义的明确:在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。\n\nin和exsits优化原则：小表驱动大表，即小的数据集驱动大的数据集\n\nin当B表的数据集小于A表的数据集时，in优于exists \nselect * from A where id in (select id from B)  #等价于：for(select id from B)&#123;\tselect * from A where A.id = B.id&#125;\nexists当A表的数据集小于B表的数据集时，exists优于in将主查询A的数据，放到子查询B中做条件验证，根据验证结果（true或false）来决定主查询的数据是否保留\nselect * from A where exists (select 1 from B where B.id = A.id)#等价于:for(select * from A)&#123;\tselect * from B where B.id = A.id&#125;   #A表与B表的ID字段应建立索引\n\n\nEXISTS (subquery)只返回TRUE或FALSE,因此子查询中的SELECT * 也可以用SELECT 1替换,官方说法是实际执行时会忽略SELECT清单,因此没有区别\nEXISTS子查询的实际执行过程可能经过了优化而不是我们理解上的逐条对比\nEXISTS子查询往往也可以用JOIN来代替，何种最优需要具体问题具体分析\n\ncount(*)查询优化-- 临时关闭mysql查询缓存，为了查看sql多次执行的真实时间mysql&gt; set global query_cache_size=0;mysql&gt; set global query_cache_type=0;mysql&gt; EXPLAIN select count(1) from employees;mysql&gt; EXPLAIN select count(id) from employees;mysql&gt; EXPLAIN select count(name) from employees;mysql&gt; EXPLAIN select count(*) from employees;\n\n注意：以上4条sql只有根据某个字段count不会统计字段为null值的数据行\n\n四个sql的执行计划一样，说明这四个sql执行效率应该差不多\n\n字段有索引count(*)≈count(1)&gt;count(字段)&gt;count(主键 id)字段有索引，count(字段)统计走二级索引，二级索引存储数据比主键索引少，所以count(字段)&gt;count(主键 id)\n\n字段无索引count(*)≈count(1)&gt;count(主键 id)&gt;count(字段)字段没有索引count(字段)统计走不了索引，count(主键 id)还可以走主键索引，所以count(主键 id)&gt;count(字段)\n\n\n\ncount(1)跟count(字段)执行过程类似，不过count(1)不需要取出字段统计，就用常量1做统计，count(字段)还需要取出字段，所以理论上count(1)比count(字段)会快一点\ncount() 是例外，mysql并不会把全部字段取出来，而是专门做了优化，不取值，按行累加，效率很高，所以不需要用count(列名)或count(常量)来替代 count()\n为什么对于count(id)，mysql最终选择辅助索引而不是主键聚集索引？因为二级索引相对主键索引存储数据更少，检索性能应该更高，mysql内部做了点优化(应该是在5.7版本才优化)\n\n查询mysql自己维护的总行数对于myisam存储引擎的表做不带where条件的count查询性能是很高的，因为myisam存储引擎的表的总行数会被mysql存储在磁盘上，查询不需要计算\n\n对于innodb存储引擎的表mysql不会存储表的总记录行数(因为有MVCC机制，后面会讲)，查询count需要实时计算\nshow table status如果只需要知道表总行数的估计值可以用如下sql查询，性能很高\n\n将总数维护到Redis里插入或删除表数据行的时候同时维护redis里的表总行数key的计数值(用incr或decr命令)，但是这种方式可能不准，很难保证表操作和redis操作的事务一致性\n增加数据库计数表插入或删除表数据行的时候同时维护计数表，让他们在同一个事务里操作\nMySQL数据类型选择在MySQL中，选择正确的数据类型，对于性能至关重要。一般应该遵循下面两步：\n\n确定合适的大类型：数字、字符串、时间、二进制\n确定具体的类型：有无符号、取值范围、变长定长等\n\n在MySQL数据类型设置方面，尽量用更小的数据类型，因为它们通常有更好的性能，花费更少的硬件资源。并且，尽量把字段定义为NOT NULL，避免使用NULL\n数值类型\n\n\n类型\n大小\n范围（有符号）\n范围（无符号）\n用途\n\n\n\nTINYINT\n1 字节\n(-128, 127)\n(0, 255)\n小整数值\n\n\nSMALLINT\n2 字节\n(-32 768, 32 767)\n(0, 65 535)\n大整数值\n\n\nMEDIUMINT\n3 字节\n(-8 388 608, 8 388 607)\n(0, 16 777 215)\n大整数值\n\n\nINT或INTEGER\n4 字节\n(-2 147 483 648, 2 147 483 647)\n(0, 4 294 967 295)\n大整数值\n\n\nBIGINT\n8 字节\n(-9 233 372 036 854 775 808, 9 223 372 036 854 775 807)\n(0, 18 446 744 073 709 551 615)\n极大整数值\n\n\nFLOAT\n4 字节\n(-3.402 823 466 E+38, 1.175 494 351 E-38)，0，(1.175 494 351 E-38，3.402 823 466 351 E+38)\n0, (1.175 494 351 E-38, 3.402 823 466 E+38)\n单精度浮点数值\n\n\nDOUBLE\n8 字节\n(1.797 693 134 862 315 7 E+308, 2.225 073 858 507 201 4 E-308), 0, (2.225 073 858 507 201 4 E-308, 1.797 693 134 862 315 7 E+308)\n0, (2.225 073 858 507 201 4 E-308, 1.797 693 134 862 315 7 E+308)\n双精度浮点数值\n\n\nDECIMAL\n对DECIMAL(M,D) ，如果M&gt;D，为M+2否则为D+2\n依赖于M和D的值\n依赖于M和D的值\n小数值\n\n\n优化建议\n\n如果整形数据没有负数，如ID号，建议指定为UNSIGNED无符号类型，容量可以扩大一倍\n建议使用TINYINT代替ENUM、BITENUM、SET\n避免使用整数的显示宽度(参看文档最后)，也就是说，不要用INT(10)类似的方法指定字段显示宽度，直接用INT\nDECIMAL最适合保存准确度要求高，而且用于计算的数据，比如价格。但是在使用DECIMAL类型的时候，注意长度设置\n建议使用整形类型来运算和存储实数，方法是，实数乘以相应的倍数后再操作\n整数通常是最佳的数据类型，因为它速度快，并且能使用AUTO_INCREMENT\n\n日期和时间\n\n\n类型\n大小(字节)\n范围\n格式\n用途\n\n\n\nDATE\n3\n1000-01-01 到 9999-12-31\nYYYY-MM-DD\n日期值\n\n\nTIME\n3\n‘-838:59:59’ 到 ‘838:59:59’\nHH:MM:SS\n时间值或持续时间\n\n\nYEAR\n1\n1901 到 2155\nYYYY\n年份值\n\n\nDATETIME\n8\n1000-01-01 00:00:00 到 9999-12-31 23:59:59\nYYYY-MM-DD HH:MM:SS\n混合日期和时间值\n\n\nTIMESTAMP\n4\n1970-01-01 00:00:00 到 2038-01-19 03:14:07\nYYYYMMDDhhmmss\n混合日期和时间值，时间戳\n\n\n优化建议\n\nMySQL能存储的最小时间粒度为秒\n建议用DATE数据类型来保存日期。MySQL中默认的日期格式是yyyy-mm-dd\n用MySQL的内建类型DATE、TIME、DATETIME来存储时间，而不是使用字符串\n当数据格式为TIMESTAMP和DATETIME时，可以用CURRENT_TIMESTAMP作为默认（MySQL5.6以后），MySQL会自动返回记录插入的确切时间\nTIMESTAMP是UTC时间戳，与时区相关\nDATETIME的存储格式是一个YYYYMMDD HH:MM:SS的整数，与时区无关，你存了什么，读出来就是什么\n除非有特殊需求，一般的公司建议使用TIMESTAMP，它比DATETIME更节约空间，但是像阿里这样的公司一般会用DATETIME，因为不用考虑TIMESTAMP将来的时间上限问题\n有时人们把Unix的时间戳保存为整数值，但是这通常没有任何好处，这种格式处理起来不太方便，并不推荐它\n\n字符串\n\n\n类型\n大小\n用途\n\n\n\nCHAR\n0-255字节\n定长字符串，char(n)当插入的字符数不足n时(n代表字符数)，插入空格进行补充保存。在进行检索时，尾部的空格会被去掉。\n\n\nVARCHAR\n0-65535 字节\n变长字符串，varchar(n)中的n代表最大字符数，插入的字符数不足n时不会补充空格\n\n\nTINYBLOB\n0-255字节\n不超过 255 个字符的二进制字符串\n\n\nTINYTEXT\n0-255字节\n短文本字符串\n\n\nBLOB\n0-65 535字节\n二进制形式的长文本数据\n\n\nTEXT\n0-65 535字节\n长文本数据\n\n\nMEDIUMBLOB\n0-16 777 215字节\n二进制形式的中等长度文本数据\n\n\nMEDIUMTEXT\n0-16 777 215字节\n中等长度文本数据\n\n\nLONGBLOB\n0-4 294 967 295字节\n二进制形式的极大文本数据\n\n\nLONGTEXT\n0-4 294 967 295字节\n极大文本数据\n\n\n优化建议\n\n\n\n\n\n字符串的长度相差较大用VARCHAR；字符串短，且所有值都接近一个长度用CHAR\nCHAR和VARCHAR适用于包括人名、邮政编码、电话号码和不超过255个字符长度的任意字母数字组合。那些要用来计算的数字不要用VARCHAR类型保存，因为可能会导致一些与计算相关的问题。换句话说，可能影响到计算的准确性和完整性\n尽量少用BLOB和TEXT，如果实在要用可以考虑将BLOB和TEXT字段单独存一张表，用id关联\nBLOB系列存储二进制字符串，与字符集无关。TEXT系列存储非二进制字符串，与字符集相关\nBLOB和TEXT都不能有默认值\n\nINT显示宽度我们经常会使用命令来创建数据表，而且同时会指定一个长度，如下。但是，这里的长度并非是TINYINT类型存储的最大长度，而是显示的最大长度。\nCREATE TABLE `user`(\t`id` TINYINT(2) UNSIGNED);\n\n这里表示user表的id字段的类型是TINYINT，可以存储的最大数值是255。所以，在存储数据时，如果存入值小于等于255，如200，虽然超过2位，但是没有超出TINYINT类型长度，所以可以正常保存；如果存入值大于255，如500，那么MySQL会自动保存为TINYINT类型的最大值255。\n在查询数据时，不管查询结果为何值，都按实际输出。这里TINYINT(2)中2的作用就是，当需要在查询结果前填充0时，命令中加上ZEROFILL就可以实现。\n","categories":["Database"],"tags":["Mysql"]},{"title":"Mysql索引底层数据结构与算法","url":"/2021/11/03/Database/Mysql/Mysql%E7%B4%A2%E5%BC%95%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/","content":"局部性原理在InnoDB中，数据会存储到磁盘上，在真正处理数据时需要先将数据加载到内存，表中读取某些记录时，InnoDB存储引擎不需要一条一条的把记录从磁盘上读出来，InnoDB采取的方式是：将数据划分为若干个页，以页作为磁盘和内存之间交互的基本单位，InnoDB中页的大小一般为 16 KB，也就是说，当需要从磁盘中读数据时每一次最少将从磁盘中读取16KB的内容到内存中，每一次最少也会把内存中的16KB内容写到磁盘中。\nInnoDB数据页结构页是InnoDB管理存储空间的基本单位，一个页的大小默认是16KB。\nSHOW GLOBAL STATUS like &#x27;Innodb_page_size&#x27;;\n\n\n页结构：\n\n\n\n名称\n中文名\n占用空间\n简单描述\n\n\n\nFile  Header\n文件头部\n38字节\n页的一些通用信息\n\n\nPage  Header\n页面头部\n56字节\n数据页专有的一些信息\n\n\nInfimum +  Supremum\n最小记录和最大记录\n26字节\n两个虚拟的行记录\n\n\nUser  Records\n用户记录\n不确定\n实际存储的行记录内容\n\n\nFree  Space\n空闲空间\n不确定\n页中尚未使用的空间\n\n\nPage  Directory\n页面目录\n不确定\n页中的某些记录的相对位置\n\n\nFile  Trailer\n文件尾部\n8字节\n校验页是否完整\n\n\n\n\nInnoDB行格式一行记录可以以不同的格式存在InnoDB中，行格式分别是Compact、Redundant、Dynamic和Compressed行格式。我们可以在创建或修改表的语句中指定行格式：\nCREATE TABLE 表名 (列的信息) ROW_FORMAT=行格式名称;ALTER TABLE 表名 ROW_FORMAT=行格式名称;\n\nCOMPACT行格式\n这部分信息是服务器为了描述这条记录而不得不额外添加的一些信息，这些额外信息分为3类，分别是：\n\n变长字段长度列表\nNULL值列表\n记录头信息\n\n变长字段长度列表MySQL支持一些变长的数据类型，比如VARCHAR(M)、VARBINARY(M)、TEXT类型，BLOB类型，这些数据类型修饰列称为变长字段，变长字段中存储多少字节的数据不是固定的，所以我们在存储真实数据的时候需要顺便把这些数据占用的字节数也存起来。在Compact行格式中，把所有变长字段的真实数据占用的字节长度都存放在记录的开头部位，从而形成一个变长字段长度列表。\nNULL值列表Compact行格式会把可以为NULL的列统一管理起来，存一个标记为在NULL值列表中，如果表中没有允许存储 NULL 的列，则 NULL值列表也不存在了。\n\n二进制位的值为1时，代表该列的值为NULL。\n二进制位的值为0时，代表该列的值不为NULL。\n\n记录头信息除了变长字段长度列表、NULL值列表之外，还有一个用于描述记录的记录头信息，它是由固定的5个字节组成。5个字节也就是40个二进制位，不同的位代表不同的意思\n\n\n\n名称\n大小（单位：bit）\n描述\n\n\n\n预留位1\n1\n没有使用\n\n\n预留位2\n1\n没有使用\n\n\ndelete_mask\n1\n标记该记录是否被删除\n\n\nmin_rec_mask\n1\nB+树的每层非叶子节点中的最小记录都会添加该标记\n\n\nn_owned\n4\n表示当前记录拥有的记录数\n\n\nheap_no\n13\n表示当前记录在记录堆的位置信息\n\n\nrecord_type\n3\n表示当前记录的类型，0表示普通记录，1表示B+树非叶子节点记录，2表示最小记录，3表示最大记录\n\n\nnext_record\n16\n表示下一条记录的相对位置\n\n\n记录的真实数据记录的真实数据除了我们自己定义的列的数据以外，还会有三个隐藏列\n\n\n\n列名\n是否必须\n占用空间\n描述\n\n\n\nrow_id\n否\n6字节\n行ID，唯一标识一条记录\n\n\ntransaction_id\n是\n6字节\n事务ID\n\n\nroll_pointer\n是\n7字节\n回滚指针\n\n\n\n实际上这几个列的真正名称其实是：DB_ROW_ID、DB_TRX_ID、DB_ROLL_PTR。一个表没有手动定义主键，则会选取一个Unique键作为主键，如果连Unique键都没有定义的话，则会为表默认添加一个名为row_id的隐藏列作为主键。所以row_id是在没有自定义主键以及Unique键的情况下才会存在的。\n\n行溢出数据VARCHAR(M)类型的列最多可以占用65535个字节。其中的M代表该类型最多存储的字符数量，如果我们使用ascii字符集的话，一个字符就代表一个字节，我们看看VARCHAR(65535)是否可用：\nmysql&gt; CREATE TABLE varchar_size_demo(        -&gt;     c VARCHAR(65535)        -&gt; ) CHARSET=ascii ROW_FORMAT=Compact;ERROR 1118 (42000): Row size too large. The maximum row size for the used table type, not counting BLOBs, is 65535. This includes storage overhead, check the manual. You have to change some columns to TEXT or BLOBsmysql&gt;\n\n报错信息表达的意思是：MySQL对一条记录占用的最大存储空间是有限制的，除BLOB或者TEXT类型的列之外，其他所有的列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过65535个字节。\n这个65535个字节除了列本身的数据之外，还包括一些其他的数据，比如说我们为了存储一个VARCHAR(M)类型的列，其实需要占用3部分存储空间：\n\n真实数据\n变长字段真实数据的长度\nNULL值标识\n\n如果该VARCHAR类型的列没有NOT NULL属性，那最多只能存储65532个字节的数据，因为变长字段的长度占用2个字节，NULL值标识需要占用1个字节。\nmysql&gt; CREATE TABLE varchar_size_demo(        -&gt;      c VARCHAR(65532)        -&gt; ) CHARSET=ascii ROW_FORMAT=Compact;Query OK, 0 rows affected (0.02 sec)\n\nCREATE TABLE varchar_size_demo(        c VARCHAR(65533) not null) CHARSET=ascii ROW_FORMAT=Compact;Query OK, 0 rows affected (0.02 sec)\n\n记录中的数据太多产生的溢出一个页的大小一般是16KB，也就是16384字节，而一个VARCHAR(M)类型的列就最多可以存储65533个字节，这样就可能出现一个页存放不了一条记录。在Compact和Reduntant行格式中，对于占用存储空间非常大的列，在记录的真实数据处只会存储该列的一部分数据，把剩余的数据分散存储在几个其他的页中，然后记录的真实数据处用20个字节存储指向这些页的地址（当然这20个字节中还包括这些分散在其他页面中的数据的占用的字节数），从而可以找到剩余数据所在的页。\nDynamic和Compressed行格式这两种行格式类似于COMPACT行格式，只不过在处理行溢出数据时有点儿分歧，它们不会在记录的真实数据处存储一部分数据，而是把所有的数据都存储到其他页面中，只在记录的真实数据处存储其他页面的地址。另外，Compressed行格式会采用压缩算法对页面进行压缩。\n索引的本质索引是帮助MySQL高效获取数据的排好序的数据结构\n索引数据结构\n\n二叉树\n红黑树\nHash表\nB-Tree\n\n二叉树一棵空树，或者是具有下列性质的二叉树：（1）若左子树不空，则左子树上所有结点的值均小于它的根结点的值；（2）若右子树不空，则右子树上所有结点的值均大于它的根结点的值；（3）左、右子树也分别为二叉排序树；（4）没有键值相等的结点\n为什么Mysql索引底层未通过二叉查找树实现？\n当数据依次递增的时候，二叉查找树会变成链表。\n\n红黑树红黑树的特性:（1）每个节点或者是黑色，或者是红色。（2）根节点是黑色。（3）每个叶子节点（NIL）是黑色。 [注意：这里叶子节点，是指为空(NIL或NULL)的叶子节点！]（4）如果一个节点是红色的，则它的子节点必须是黑色的。（5）从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。\n为什么Mysql索引底层未通过红黑树实现？当数据量较大，上百万乃至千万的时候，树的深度较深。\n\nHash表对索引的key进行一次hash计算就可以定位出数据存储所在的位置，很多时候hash索引比B+Tree索引效率高。\n为什么Mysql索引底层未通过Hash表实现？\n\n仅能满足“=”和“in”不支持范围查询，范围查询时，只能走全表扫描。\nhash冲突问题\n\n\nB-Tree回到红黑树的问题，之所以不选中红黑树，最大的原因是没有解决高度问题。（尽管高度相对无索引或普通二叉树已经降低很多，但数据量大时，仍然要多次磁盘IO）而BTree索引能很好解决高度问题。B-Tree是一种平衡的多路查找（又称排序）树，在文件系统中和数据库系统有所应用，主要用作文件的索引。其中的B就表示平衡（Balance）。BTree 的特性：为了描述BTree，首先定义一条数据记录为一个二元组[key, data]，key为记录的键值，对于不同数据记录，key是互不相同的；data为数据记录除以key外的数据。那么BTree是满足下列条件的数据结构：\n\n叶节点具有相同的深度,叶节点的指针为空\n所有索引元素不重复\n节点的数据索引从左到右递增排列\n\n\n为什么Mysql索引底层未通过B-Tree实现？\n\nBTree各个元素是由[key,     data]来实现，key为索引值，data为所对应的行数据，Mysql默认数据页大小为16KB，那么每个节点所存储的数据由于包含了行数据，所以存储数据较少。\n在进行范围查找时，由于各个叶子节点之间没有关联，需要多次遍历叶子节点。比如说查询&gt;20的值，不止需要叶子节点&gt;20的值，还需要非叶子节点56，56与77之间的叶子节点，77非叶子节点。。。\n\nB+TreeB+Tree特性:\n\n非叶子节点不存储data，只存储索引(冗余)，可以放更多的索引\n叶子节点包含所有索引字段\n叶子节点用指针连接，提高区间访问的性能\n\n\nMySQL 官方对非叶子节点(如最上层 h = 1的节点，B+Tree高度为3) 的大小是有限制的，通过执行SHOW GLOBAL STATUS like &#39;InnoDB_page_size&#39;;可以得到大小为 16384，即 16k大小。那么第二层也是16k大小。假如：B+Tree的表都存满了。索引的节点的类型为BigInt，大小为8B，指针为6B。最后一层，假如存放的数据data为1k大小，那么第一层最大节点数为：16k / (8B + 6B) = 1170 (个)；第二层最大节点数也应为：1170个；第三层最大节点数为：16k / 1k = 16 (个)。则，一张B+Tree的表最多存放 1170 * 1170 * 16 ≈ 2千万。所以，通过分析，我们可以得出，B+Tree结构的表可以容纳千万数据量的查询。而且一般来说，MySQL会把B+Tree根节点放在内存中，那只需要两次磁盘IO就行。\nB+Tree解决范围查找B+Tree的叶子节点是双向链表，在进行范围查找时，可以不通过非叶子节点直接找到下一个叶子节点,B+Tree可以通过该指针把20后面的直接找到，非常方便。\nselect *from t where col1 &gt;= 20;\n\nMyISAM和InnoDB存储引擎和索引MyISAM\n我们知道，**MyISAM索引文件和数据文件是分开的(非聚集)**，存储引擎在磁盘中文件有三个：\n\n.frm 文件(数据表定义)\n.MYI(索引)\n.MYD(实际数据，存储的是一整行的数据，包括索引值)\n\n比如查找 49，那么再 .MYI 中找到 49对应的磁盘指针 0x49，根据 0x49 去 .MYD找到实际的行数据数据内容data\nInnoDBInnoDB结构我们知道InnoDB存储引擎的主键索引是聚集索引。它的表数据文件本身就是按B+Tree组织的一个索引文件。不同于MyISAM存储引擎是，数据不分离。如下图，找到49的索引之后，数据就在该节点，不必像MyISAM存储引擎那样，需要根据磁盘指针到另一个文件中取数据。性能比MyISAM高。\n\nInnoDB必须要有主键，并且推荐使用整型自增主键要有主键：mysql底层就是用B+Tree维护的，而B+Tree的结构就决定了必须有主键才能构建B+Tree树这个结构。每个表在磁盘上，是单独的一个文件。索引和数据都在其中，文件是按照主键索引组织的一个B+TREE结构。假如没有定义主键，MySQL会在挑选能唯一标识的字段作为索引；假如找不到，会生成一个默认的隐藏列作为主键列。\n整型主键：假如使用类似 UUID 的字符串作为主键，那么在查找时，需要比较两个主键是否相同，这是一个相比整型比较 非常耗时的过程。需要一个字符，一个字符的比较，自然比较慢。\n自增主键：在添加的过程中，因为是自增的，每次添加都是在后面插入，树分裂的机会小；而UUID大小不确定，分裂机会大，性能损耗大。\n为什么非主键索引结构叶子节点存储的是主键值？非主键的 data存储的是 主键值的好处：\n\n节省空间：指向主键的节点，不用再存储一份相同的数据；\n数据一致性：如果修改索引15 的数据，那只要修改主键的     data，而如果非主键的data也存一份的话，那得修改两份。\n\n\n联合索引的底层结构\n先第一个排序，然后第二个字段排序，然后第三个字段排序\n","categories":["Database"],"tags":["Mysql"]},{"title":"Mysql锁与事务隔离级别","url":"/2021/11/18/Database/Mysql/Mysql%E9%94%81%E4%B8%8E%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/","content":"我们的数据库一般都会并发执行多个事务，多个事务可能会并发的对相同的一批数据进行增删改查操作，可能就会导致我们说的脏写、脏读、不可重复读、幻读这些问题。这些问题的本质都是数据库的多事务并发问题，为了解决多事务并发问题，数据库设计了事务隔离机制、锁机制、MVCC多版本并发控制隔离机制，用一整套机制来解决多事务并发问题。\n事务及其ACID属性事务是由一组SQL语句组成的逻辑处理单元,事务具有以下4个属性,通常简称为事务的ACID属性。\n\n原子性(Atomicity) ：事务是一个原子操作单元,其对数据的修改,要么全都执行,要么全都不执行。\n一致性(Consistent) ：在事务开始和完成时,数据都必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改,以保持数据的完整性。\n隔离性(Isolation) ：数据库系统提供一定的隔离机制,保证事务在不受外部并发操作影响的“独立”环境执行。这意味着事务处理过程中的中间状态对外部是不可见的,反之亦然。\n持久性(Durable) ：事务完成之后,它对于数据的修改是永久性的,即使出现系统故障也能够保持。\n\n并发事务处理带来的问题\n更新丢失(Lost Update)或脏写当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题–最后的更新覆盖了由其他事务所做的更新。\n脏读（Dirty Reads）一个事务正在对一条记录做修改，在这个事务完成并提交前，这条记录的数据就处于不一致的状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”数据，并据此作进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象的叫做“脏读”。事务A读取到了事务B已经修改但尚未提交的数据，还在这个数据基础上做了操作。此时，如果B事务回滚，A读取的数据无效，不符合一致性要求。\n不可重读（Non-Repeatable Reads）一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了！这种现象就叫做“不可重复读”。事务A内部的相同查询语句在不同时刻读出的结果不一致，不符合隔离性\n幻读（Phantom Reads）一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。事务A读取到了事务B提交的新增数据，不符合隔离性\n\n事务隔离级别“脏读”、“不可重复读”和“幻读”,其实都是数据库读一致性问题,必须由数据库提供一定的事务隔离机制来解决。\n\n数据库的事务隔离越严格,并发副作用越小,但付出的代价也就越大,因为事务隔离实质上就是使事务在一定程度上“串行化”进行,这显然与“并发”是矛盾的。\n同时,不同的应用对读一致性和事务隔离程度的要求也是不同的,比如许多应用对“不可重复读”和“幻读”并不敏感,可能更关心数据并发访问的能力。\n常看当前数据库的事务隔离级别: show variables like &#39;tx_isolation&#39;;\n设置事务隔离级别：set tx_isolation=&#39;REPEATABLE-READ&#39;;\nMysql默认的事务隔离级别是可重复读，用Spring开发程序时，如果不设置隔离级别默认用Mysql设置的隔离级别，如果Spring设置了就用已经设置的隔离级别\n锁详解锁是计算机协调多个进程或线程并发访问某一资源的机制。\n在数据库中，除了传统的计算资源（如CPU、RAM、I/O等）的争用以外，数据也是一种供需要用户共享的资源。如何保证数据并发访问的一致性、有效性是所有数据库必须解决的一个问题，锁冲突也是影响数据库并发访问性能的一个重要因素。\n锁分类\n从性能上分为乐观锁(用版本对比来实现)和悲观锁\n\n从对数据库操作的类型分，分为读锁和写锁(都属于悲观锁)\n\n读锁（共享锁，S锁(Shared)）：针对同一份数据，多个读操作可以同时进行而不会互相影响\n写锁（排它锁，X锁(eXclusive)）：当前写操作没有完成前，它会阻断其他写锁和读锁\n\n\n从对数据操作的粒度分，分为表锁和行锁\n\n\n表锁每次操作锁住整张表。开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低；一般用在整表数据迁移的场景。\n--建表SQLCREATE TABLE `mylock` (\t`id` INT (11) NOT NULL AUTO_INCREMENT,\t`NAME` VARCHAR (20) DEFAULT NULL,\tPRIMARY KEY (`id`)) ENGINE = MyISAM DEFAULT CHARSET = utf8;--插入数据INSERT INTO`test`.`mylock` (`id`, `NAME`) VALUES (&#x27;1&#x27;, &#x27;a&#x27;);INSERT INTO`test`.`mylock` (`id`, `NAME`) VALUES (&#x27;2&#x27;, &#x27;b&#x27;);INSERT INTO`test`.`mylock` (`id`, `NAME`) VALUES (&#x27;3&#x27;, &#x27;c&#x27;);INSERT INTO`test`.`mylock` (`id`, `NAME`) VALUES (&#x27;4&#x27;, &#x27;d&#x27;);\n\n\n手动增加表锁lock table &lt;tableName&gt; read(write),&lt;tableName&gt; read(write);\n\n查看表上加过的锁\n\n\nshow open tables;\n\n删除表锁\n\nunlock tables;\n加读锁\n当前session和其他session都可以读该表\n当前session中插入或者更新锁定的表都会报错，其他session插入或更新则会等待\n加写锁\n当前session对该表的增删改查都没有问题，其他session对该表的所有操作被阻塞\n结论\n对MyISAM表的读操作(加读锁) ,不会阻塞其他进程对同一表的读请求,但会阻塞对同一表的写请求。只有当读锁释放后,才会执行其它进程的写操作。\n对MylSAM表的写操作(加写锁) ,会阻塞其他进程对同一表的读和写操作,只有当写锁释放后,才会执行其它进程的读写操作\n\n行锁每次操作锁住一行数据。开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度最高。\nInnoDB与MYISAM的最大不同有两点：\n\nInnoDB支持事务（TRANSACTION）\nInnoDB支持行级锁\n\nMyISAM在执行查询语句SELECT前，会自动给涉及的所有表加读锁,在执行update、insert、delete操作会自动给涉及的表加写锁。\nInnoDB在执行查询语句SELECT时(非串行隔离级别)，不会加锁。但是update、insert、delete操作会加行锁。\n简而言之，就是读锁会阻塞写，但是不会阻塞读。而写锁则会把读和写都阻塞。\n行锁与事务隔离级别案例分析CREATE TABLE `account` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `name` varchar(255) DEFAULT NULL,  `balance` int(11) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;INSERT INTO `test`.`account` (`name`, `balance`) VALUES (&#x27;lilei&#x27;, &#x27;450&#x27;);INSERT INTO `test`.`account` (`name`, `balance`) VALUES (&#x27;hanmei&#x27;, &#x27;16000&#x27;);INSERT INTO `test`.`account` (`name`, `balance`) VALUES (&#x27;lucy&#x27;, &#x27;2400&#x27;);\n\n读未提交打开一个客户端A，并设置当前事务模式为read uncommitted（未提交读），查询表account的初始值\nset tx_isolation=&#x27;read-uncommitted&#x27;;\n\n\n在客户端A的事务提交之前，打开另一个客户端B，更新表account\n\n这时，虽然客户端B的事务还没提交，但是客户端A就可以查询到B已经更新的数据\n\n一旦客户端B的事务因为某种原因回滚，所有的操作都将会被撤销，那客户端A查询到的数据其实就是脏数据\n\n在客户端A执行更新语句update account set balance = balance - 50 where id =1，lilei的balance没有变成350，居然是400，是不是很奇怪，数据不一致啊，如果你这么想就太天真 了，在应用程序中，我们会用400-50=350，并不知道其他会话回滚了，要想解决这个问题可以采用读已提交的隔离级别\n\n读已提交打开一个客户端A，并设置当前事务模式为read committed（未提交读），查询表account的所有记录\nset tx_isolation=&#x27;read-committed&#x27;;\n\n\n在客户端A的事务提交之前，打开另一个客户端B，更新表account\n\n这时，客户端B的事务还没提交，客户端A不能查询到B已经更新的数据，解决了脏读问题\n\n客户端B的事务提交\n\n客户端A执行与上一步相同的查询，结果 与上一步不一致，即产生了不可重复读的问题\n\n可重复读打开一个客户端A，并设置当前事务模式为repeatable read，查询表account的所有记录\nset tx_isolation=&#x27;repeatable-read&#x27;;\n\n\n在客户端A的事务提交之前，打开另一个客户端B，更新表account并提交\n\n在客户端A查询表account的所有记录，与步骤（1）查询结果一致，没有出现不可重复读的问题\n\n在客户端A，接着执行update account set balance = balance - 50 where id = 1，balance没有变成400-50=350，lilei的balance值用的是步骤2中的350来算的，所以是300，数据的一致性倒是没有被破坏。可重复读的隔离级别下使用了MVCC(multi-version concurrency control)机制，select操作不会更新版本号，是快照读（历史版本）；insert、update和delete会更新版本号，是当前读（当前版本）\n\n重新打开客户端B，插入一条新数据后提交\n\n在客户端A查询表account的所有记录，没有查出新增数据，所以没有出现幻读\n\n验证幻读\n在客户端A执行update account set balance=888 where id = 4;能更新成功，再次查询能查到客户端B新增的数据\n\n串行化打开一个客户端A，并设置当前事务模式为serializable，查询表account的初始值\nset tx_isolation=&#x27;serializable&#x27;;\n\n\n打开一个客户端B，并设置当前事务模式为serializable，更新相同的id为1的记录会被阻塞等待，更新id为2的记录可以成功，说明在串行模式下innodb的查询也会被加上行锁\n如果客户端A执行的是一个范围查询，那么该范围内的所有行包括每行记录所在的间隙区间范围(就算该行数据还未被插入也会加锁，这种是间隙锁)都会被加锁。此时如果客户端B在该范围内插入数据都会被阻塞，所以就避免了幻读\n这种隔离级别并发性极低，开发中很少会用到\n\n间隙锁(Gap Lock)间隙锁，锁的就是两个值之间的空隙。Mysql默认级别是repeatable-read，有办法解决幻读问题吗？间隙锁在某些情况下可以解决幻读问题。\n假设account表里数据如下\n\n那么间隙就有 id 为 (3,10)，(10,20)，(20,正无穷) 这三个区间，\n在Session_1下面执行 update account set name = ‘zhuge’ where id &gt; 8 and id &lt;18;，则其他Session没法在这个范围所包含的所有行记录(包括间隙行记录)以及行记录所在的间隙里插入或修改任何数据，即id在(3,20]区间都无法修改数据，注意最后那个20也是包含在内的。\n间隙锁是在可重复读隔离级别下才会生效。\n临键锁(Next-key Locks)Next-Key Locks是行锁与间隙锁的组合。像上面那个例子里的这个(3,20]的整个区间可以叫做临键锁。\n无索引行锁会升级为表锁(RR级别会升级为表锁，RC级别不会升级为表锁)\n锁主要是加在索引上，如果对非索引字段更新，行锁可能会变表锁\n\nsession1 执行：update account set balance = 800 where name = ‘lilei’;\n\nsession2 对该表任一行操作都会阻塞住\n\n\nInnoDB的行锁是针对索引加的锁，不是针对记录加的锁。并且该索引不能失效，否则都会从行锁升级为表锁。\n锁定某一行还可以用lock in share mode(共享锁) 和for update(排它锁)，例如：select * from test_innodb_lock where a = 2 for update; 这样其他session只能读这行数据，修改则会被阻塞，直到锁定行的session提交\n结论Innodb存储引擎由于实现了行级锁定，虽然在锁定机制的实现方面所带来的性能损耗可能比表级锁定会要更高一下，但是在整体并发处理能力方面要远远优于MYISAM的表级锁定的。当系统并发量高的时候，Innodb的整体性能和MYISAM相比就会有比较明显的优势了。\n但是，Innodb的行级锁定同样也有其脆弱的一面，当我们使用不当的时候，可能会让Innodb的整体性能表现不仅不能比MYISAM高，甚至可能会更差。\n查看INFORMATION_SCHEMA系统库锁相关数据表-- 查看事务select * from INFORMATION_SCHEMA.INNODB_TRX;-- 查看锁select * from INFORMATION_SCHEMA.INNODB_LOCKS;-- 查看锁等待select * from INFORMATION_SCHEMA.INNODB_LOCK_WAITS;-- 释放锁，trx_mysql_thread_id可以从INNODB_TRX表里查看到kill trx_mysql_thread_id-- 查看锁等待详细信息show engine innodb status; \n\n查看行锁信息通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况\nshow status like &#x27;innodb_row_lock%&#x27;;\n\n对各个状态量的说明如下：\n\nInnodb_row_lock_current_waits：当前正在等待锁定的数量\n\nInnodb_row_lock_time：从系统启动到现在锁定总时间长度\n\nInnodb_row_lock_time_avg：每次等待所花平均时间\n\nInnodb_row_lock_time_max：从系统启动到现在等待最长的一次所花时间\n\nInnodb_row_lock_waits：系统启动后到现在总共等待的次数\n\n\n\n对于这5个状态变量，比较重要的主要是：Innodb_row_lock_time_avg（等待平均时长）Innodb_row_lock_waits（等待总次数）Innodb_row_lock_time（等待总时长）尤其是当等待次数很高，而且每次等待时长也不小的时候，我们就需要分析系统中为什么会有如此多的等待，然后根据分析结果着手制定优化计划\n\n死锁set tx_isolation=&#39;repeatable-read&#39;;\nSession_1执行：select * from account where id=1 for update;\nSession_2执行：select * from account where id=2 for update;\nSession_1执行：select * from account where id=2 for update;\nSession_2执行：select * from account where id=1 for update;\n查看近期死锁日志信息：show engine innodb status; \n大多数情况mysql可以自动检测死锁并回滚产生死锁的那个事务，但是有些情况mysql没法自动检测死锁\n锁优化建议\n尽可能让所有数据检索都通过索引来完成，避免无索引行锁升级为表锁\n合理设计索引，尽量缩小锁的范围\n尽可能减少检索条件范围，避免间隙锁\n尽量控制事务大小，减少锁定资源量和时间长度，涉及事务加锁的sql尽量放在事务最后执行\n尽可能低级别事务隔离\n\n","categories":["Database"],"tags":["Mysql"]},{"title":"一条SQL在Mysql中是如何执行的","url":"/2021/11/15/Database/Mysql/%E4%B8%80%E6%9D%A1SQL%E5%9C%A8MySql%E4%B8%AD%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/","content":"MySQL的内部组件结构大体来说，MySQL 可以分为 Server 层和存储引擎层两部分\n\nServer层主要包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。\n连接器由于MySQL是开源的，他有非常多种类的客户端：navicat,mysql front,jdbc,SQLyog等非常丰富的客户端,这些客户端要向mysql发起通信都必须先跟Server端建立通信连接，而建立连接的工作就是有连接器完成的。\n第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令一般是这么写的：\n[root@192 ~]# mysql -h host[数据库地址] -u root[用户] -p root[密码] -P 3306\n\n连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。\n\n1、如果用户名或密码不对，你就会收到一个”Access denied for user”的错误，然后客户端程序结束执行。\n2、如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。\n\n这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。用户的权限表在系统表空间的mysql的user表中。\n\n修改user密码\nmysql&gt; CREATE USER &#x27;username&#x27;@&#x27;host&#x27; IDENTIFIED BY &#x27;password&#x27;; //创建新用户mysql&gt; grant all privileges on *.* to &#x27;username&#x27;@&#x27;%&#x27;; //赋权限,%表示所有(host)mysql&gt; flush privileges //刷新数据库mysql&gt; update user set password=password(”123456″) where user=’root’;(设置用户名密码)mysql&gt; show grants for root@&quot;%&quot;; 查看当前用户的权限\n\n连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist 命令中看到它。文本中这个图是 show processlist 的结果，其中的 Command 列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接，关闭连接 kill  。\n\n客户端如果长时间不发送command到Server端，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。\n查看wait_timeout\nmysql&gt; show global variables like &quot;wait_timeout&quot;;mysql&gt;set global wait_timeout=28800; 设置全局服务器关闭非交互连接之前等待活动的秒数\n\n\n如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。这时候如果你要继续，就需要重连，然后再执行请求了。\n数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。\n开发当中我们大多数时候用的都是长连接,把连接放在Pool内进行管理，但是长连接有些时候会导致 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。\n怎么解决这类问题呢？\n\n1、定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。\n2、如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。\n\n查询缓存mysql&gt;show databases; 显示所有数据库mysql&gt;use dbname； 打开数据库：mysql&gt;show tables; 显示数据库mysql中所有的表；mysql&gt;describe user; 显示表mysql数据库中user表的列信息）；\n\n连接建立完成后，你就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。\nMySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。\n如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。\n大多数情况查询缓存就是个鸡肋，为什么呢？\n因为查询缓存往往弊大于利。查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。\n一般建议大家在静态表里使用查询缓存，什么叫静态表呢？就是一般我们极少更新的表。比如，一个系统配置表、字典表，那这张表上的查询才适合使用查询缓存。好在 MySQL 也提供了这种“按需使用”的方式。你可以将my.cnf参数 query_cache_type 设置成 DEMAND。\nmy.cnf#query_cache_type有3个值 0代表关闭查询缓存OFF，1代表开启ON，2（DEMAND）代表当sql语句中有SQL_CACHE关键词时才缓存query_cache_type=2\n\n这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，像下面这个语句一样：\nmysql&gt; select SQL_CACHE * from test where ID=5；\n\n查看当前mysql实例是否开启缓存机制\nmysql&gt; show global variables like &quot;%query_cache_type%&quot;;\n\n监控查询缓存的命中率:\nmysql&gt; show status like&#x27;%Qcache%&#x27;; //查看运行的缓存信息\n\n\n\nQcache_free_blocks:表示查询缓存中目前还有多少剩余的blocks，如果该值显示较大，则说明查询缓存中的内存碎片过多了，可能在一定的时间进行整理。\nQcache_free_memory:查询缓存的内存大小，通过这个参数可以很清晰的知道当前系统的查询内存是否够用，是多了，还是不够用，DBA可以根据实际情况做出调整。\nQcache_hits:表示有多少次命中缓存。我们主要可以通过该值来验证我们的查询缓存的效果。数字越大，缓存效果越理想。\nQcache_inserts: 表示多少次未命中然后插入，意思是新来的SQL请求在缓存中未找到，不得不执行查询处理，执行查询处理后把结果insert到查询缓存中。这样的情况的次数，次数越多，表示查询缓存应用到的比较少，效果也就不理想。当然系统刚启动后，查询缓存是空的，这很正常。\nQcache_lowmem_prunes:该参数记录有多少条查询因为内存不足而被移除出查询缓存。通过这个值，用户可以适当的调整缓存大小。\nQcache_not_cached: 表示因为query_cache_type的设置而没有被缓存的查询数量。\nQcache_queries_in_cache:当前缓存中缓存的查询数量。\nQcache_total_blocks:当前缓存的block数量。\n\nmysql8.0已经移除了查询缓存功能\n分析器如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。MySQL 从你输入的”select”这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，比如下面这个语句 from 写成了 “rom”。\nmysql&gt; select * fro test where id=1;ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#x27;fro test where id=1&#x27; at line 1\n\n词法分析器原理词法分析器分成6个主要步骤完成对sql语句的分析\n1、词法分析\n2、语法分析\n3、语义分析\n4、构造执行树\n5、生成执行计划\n6、计划的执行\n\nSQL语句的分析分为词法分析与语法分析，mysql的词法分析由MySQLLex[MySQL自己实现的]完成，语法分析由Bison生成。关于语法树大家如果想要深入研究可以参考这篇wiki文章：https://en.wikipedia.org/wiki/LR_parser。那么除了Bison外，Java当中也有开源的词法结构分析工具例如Antlr4，ANTLR从语法生成一个解析器，可以构建和遍历解析树，可以在IDEA工具当中安装插件：**antlr v4 grammar plugin**\n经过bison语法分析之后，会生成一个这样的语法树\n\n优化器经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。\n优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的 join：\nmysql&gt; select * from test1 join test2 using(ID) where test1.name=name1 and test2.name=name2;\n\n既可以先从表 test1 里面取出 name=yangguo的记录的 ID 值，再根据 ID 值关联到表 test2，再判断 test2 里面 name的值是否等于 yangguo。\n也可以先从表 test2 里面取出 name=xiaolongnv 的记录的 ID 值，再根据 ID 值关联到 test1，再判断 test1 里面 name 的值是否等于 yangguo。\n这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。如果你还有一些疑问，比如优化器是怎么选择索引的，有没有可能选择错等等。\n执行器开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。\nmysql&gt; select * from test where id=1;\n\n如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。\n比如我们这个例子中的表 test 中，ID 字段没有索引，那么执行器的执行流程是这样的：\n\n调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；\n调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。\n执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。\n\n至此，这个语句就执行完成了。对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。\nbinlogbinlog,即二进制日志,它记录了数据库上的所有改变，并以二进制的形式保存在磁盘中；它可以用来查看数据库的变更历史、数据库增量备份和恢复、Mysql的复制（主从数据库的复制）。\nbinlog有三种格式：\n\nstatement:基于SQL语句的复制(statement-based replication,SBR)\nrow:基于行的复制(row-based replication,RBR)\nmixed:混合模式复制(mixed-based replication,MBR)\n\nStatement每一条会修改数据的sql都会记录在binlog中。\n优点：不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。\n缺点：由于记录的只是执行语句，为了这些语句能在slave上正确运行，因此还必须记录每条语句在执行的时候的一些相关信息，以保证所有语句能在slave得到和在master端执行时候相同 的结果。另外mysql 的复制,像一些特定函数功能，slave可与master上要保持一致会有很多相关问题\n\n相比row能节约多少性能与日志量，这个取决于应用的SQL情况，正常同一条记录修改或者插入row格式所产生的日志量还小于Statement产生的日志量，但是考虑到如果带条件的update操作，以及整表删除，alter表等操作，ROW格式会产生大量日志，因此在考虑是否使用ROW格式日志时应该跟据应用的实际情况，其所产生的日志量会增加多少，以及带来的IO性能问题。\n\nRow5.1.5版本的MySQL才开始支持row level的复制,它不记录sql语句上下文相关信息，仅保存哪条记录被修改。\n优点：binlog中可以不记录执行的sql语句的上下文相关的信息，仅需要记录那一条记录被修改成什么了。所以rowlevel的日志内容会非常清楚的记录下每一行数据修改的细节。而且不会出现某些特定情况下的存储过程，或function，以及trigger的调用和触发无法被正确复制的问题.\n缺点：所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生大量的日志内容。\n\n新版本的MySQL中对row level模式也被做了优化，并不是所有的修改都会以row level来记录，像遇到表结构变更的时候就会以statement模式来记录，如果sql语句确实就是update或者delete等修改数据的语句，那么还是会记录所有行的变更。\n\nMixed从5.1.8版本开始，MySQL提供了Mixed格式，实际上就是Statement与Row的结合。\n在Mixed模式下，一般的语句修改使用statment格式保存binlog，如一些函数，statement无法完成主从复制的操作，则采用row格式保存binlog，MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志形式，也就是在Statement和Row之间选择一种。\nStore层存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。也就是说如果我们在create table时不指定表的存储引擎类型,默认会给你设置存储引擎为InnoDB。 \n一条SQL在MySql中是如何执行的\n为什么Mysql不能直接更新磁盘上的数据而且设置这么一套复杂的机制来执行SQL了？\n因为来一个请求就直接对磁盘文件进行随机读写，然后更新磁盘文件里的数据性能可能相当差。\n因为磁盘随机读写的性能是非常差的，所以直接更新磁盘文件是不能让数据库抗住很高并发的。\nMysql这套机制看起来复杂，但它可以保证每个更新请求都是更新内存BufferPool，然后顺序写日志文件，同时还能保证各种异常情况下的数据一致性。\n更新内存的性能是极高的，然后顺序写磁盘上的日志文件的性能也是非常高的，要远高于随机读写磁盘文件。\n正是通过这套机制，才能让我们的MySQL数据库在较高配置的机器上每秒可以抗下几干甚至上万的读写请求。\n","categories":["Database"],"tags":["Mysql"]},{"title":"Centos7静默安装Oracle11g","url":"/2020/08/03/Database/Oracle/Centos7%E9%9D%99%E9%BB%98%E5%AE%89%E8%A3%85Oracle11g/","content":"\n环境准备\nCentos7.3.64  64位   这里使用的是阿里云 轻量应用服务器（1核，1G内存，20G硬盘）\nOracle 11g R2 64位\nlinux.x64_11gR2_database_1of2.zip　　　　linux.x64_11gR2_database_2of2.zip\n\n\n\n系统要求\n 64位操作系统\n 内存1G\n 交换空间为内存的1.5~2倍安装前准备查看交换空间free -h[root@izbp14kztkmxnrzha007zkz ~]# free -h            total        used         free       shared  buff/cache   availableMem:           992M       90M         67M        6.5M        834M        742MSwap:            0B     0B            0B\n\n发现交换空间大小是0，需要手动添加交换空间，调整为内存大小的2倍。dd if=/dev/zero of=/swap bs=1024 count=2048000mkswap /swapchmod 600 /swapswapon /swap\n\n[root@izbp14kztkmxnrzha007zkz ~]# dd if=/dev/zero of=/swap bs=1024 count=20480002048000+0 records in2048000+0 records out2097152000 bytes (2.1 GB) copied, 14.9063 s, 141 MB/s[root@izbp14kztkmxnrzha007zkz ~]# mkswap /swapSetting up swapspace version 1, size = 2047996 KiBno label, UUID=d25a6621-b6f6-4537-8924-eda4630635fd[root@izbp14kztkmxnrzha007zkz ~]# chmod 600 /swap[root@izbp14kztkmxnrzha007zkz ~]# swapon /swap[root@izbp14kztkmxnrzha007zkz ~]# free -h              total        used        free      shared  buff/cache   availableMem:           992M         92M         59M        6.5M        841M        738MSwap:          2.0G          0B        2.0G\n\n为防止重启后swap分区变为0,设置开机自动挂载,在文件的末尾添加vi /etc/fstab/swap swap swap default 0 0 \n\n[root@izbp14kztkmxnrzha007zkz ~]#  vi /etc/fstab## /etc/fstab# Created by anaconda on Fri Aug 18 03:51:14 2017## Accessible filesystems, by reference, are maintained under &#x27;/dev/disk&#x27;# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#UUID=59d9ca7b-4f39-4c0c-9334-c56c182076b5 /                       ext4    defaults        1 1/swap swap swap default 0 0~~~~~~\n修改主机名hostnamectl set-hostname oracledbecho &quot;127.0.0.1     oracledb&quot; &gt;&gt;/etc/hosts\n\n[root@izbp14kztkmxnrzha007zkz ~]# hostnamectl set-hostname oracledb[root@izbp14kztkmxnrzha007zkz ~]# echo &quot;127.0.0.1     oracledb&quot; &gt;&gt;/etc/hosts\n关闭selinuxsed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/&quot; /etc/selinux/configsetenforce 0\n[root@oracledb ~]# sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/&quot; /etc/selinux/config[root@oracledb ~]# setenforce 0setenforce: SELinux is disabled\n安装oracle依赖包以及环境配置通过安装Oracle YUM 来安装所依赖的包cd /etc/yum.repos.dwget http://public-yum.oracle.com/public-yum-ol7.repo\n[root@oracledb ~]# cd /etc/yum.repos.d[root@oracledb yum.repos.d]# wget http://public-yum.oracle.com/public-yum-ol7.repo--2019-10-18 15:28:31--  http://public-yum.oracle.com/public-yum-ol7.repoResolving public-yum.oracle.com (public-yum.oracle.com)... 104.127.192.72Connecting to public-yum.oracle.com (public-yum.oracle.com)|104.127.192.72|:80... connected.HTTP request sent, awaiting response... 200 OKLength: 16402 (16K) [text/plain]Saving to: ‘public-yum-ol7.repo’100%[===================================================================================================================================================================================================&gt;] 16,402      --.-K/s   in 0s2019-10-18 15:28:32 (219 MB/s) - ‘public-yum-ol7.repo’ saved [16402/16402]\n导入RPM-GPG-KEY-oraclewget http://public-yum.oracle.com/RPM-GPG-KEY-oracle-ol7 -O /etc/pki/rpm-gpg/RPM-GPG-KEY-oracle\n[root@oracledb yum.repos.d]# wget http://public-yum.oracle.com/RPM-GPG-KEY-oracle-ol7 -O /etc/pki/rpm-gpg/RPM-GPG-KEY-oracle--2019-10-18 15:30:25--  http://public-yum.oracle.com/RPM-GPG-KEY-oracle-ol7Resolving public-yum.oracle.com (public-yum.oracle.com)... 104.127.192.72Connecting to public-yum.oracle.com (public-yum.oracle.com)|104.127.192.72|:80... connected.HTTP request sent, awaiting response... 200 OKLength: 1011 [text/plain]Saving to: ‘/etc/pki/rpm-gpg/RPM-GPG-KEY-oracle’100%[===================================================================================================================================================================================================&gt;] 1,011       --.-K/s   in 0s2019-10-18 15:30:26 (212 MB/s) - ‘/etc/pki/rpm-gpg/RPM-GPG-KEY-oracle’ saved [1011/1011]\n\n安装oracle-rdbms-server-11gR2-preinstall快速配置Oracle安装环境（采用这种方式的目的是为了快捷、方便）\n\nyum install oracle-rdbms-server-11gR2-preinstall -y\n[root@oracledb yum.repos.d]# yum install oracle-rdbms-server-11gR2-preinstall -y\n\n查看preinstall日志more /var/log/oracle-rdbms-server-11gR2-preinstall/results/orakernel.logoracle-rdbms-server-11gR2-preinstall包所干的事情　　　　（1）自动安装oracle所需的RPM包　　　　（2）自动创建oracle用户和group组　　　　（3）自动配置/etc/sysctl.conf内核参数　　　　（4）自动配置/etc/security/limits.conf参数　　　　（5）关闭NUMA=OFF （关闭非一致内存访问）\n\n安装目录以及环境变量的配置创建安装目录及权限mkdir -p /data/oracle/product/11.2.0/db_1chown oracle:oinstall -R /datachmod 755 -R /data/oracle/\n[root@oracledb yum.repos.d]# mkdir -p /data/oracle/product/11.2.0/db_1[root@oracledb yum.repos.d]# chown oracle:oinstall -R /data[root@oracledb yum.repos.d]# chmod 755 -R /data/oracle/\n设置Oracle环境变量\n切换到Oracle用户su oracle\n[root@oracledb yum.repos.d]# su oracle\n修改环境变量cd ~ls -alvi .bash_profile\n[oracle@oracledb yum.repos.d]$ cd ~[oracle@oracledb ~]$ ls -altotal 24drwx------  2 oracle oinstall 4096 Oct 18 15:36 .drwxr-xr-x. 4 root   root     4096 Oct 18 15:36 ..-rw-r--r--  1 oracle oinstall   18 Dec  7  2016 .bash_logout-rw-r--r--  1 oracle oinstall  193 Dec  7  2016 .bash_profile-rw-r--r--  1 oracle oinstall  231 Dec  7  2016 .bashrc-rw-r--r--  1 oracle oinstall  172 Aug 31  2018 .kshrc[oracle@oracledb ~]$ vi .bash_profile\n# .bash_profile# Get the aliases and functionsif [ -f ~/.bashrc ]; then        . ~/.bashrcfi# User specific environment and startup programsPATH=$PATH:$HOME/.local/bin:$HOME/binexport PATHexport TMP=/tmp      #安装oracle软件过程中使用的临时文件目录export TMPDIR=$TMP  #安装oracle软件过程中使用的临时文件目录export ORACLE_BASE=/data/oracle  #Oracle 的 base 目录，所有的oracle文件全部存放在这个目录export ORACLE_HOME=/data/oracle/product/11.2.0/db_1  #oracle软件存放目录export ORACLE_SID=orcl  #实例名称export ORACLE_TERM=xtermexport PATH=/usr/sbin:$PATHexport PATH=$ORACLE_HOME/bin:$PATH   #SHELL可执行文件的搜索路径export LD_LIBRARY_PATH=$ORACLE_HOME/lib:/lib:/usr/lib  #库文件搜索路径export CLASSPATH=$ORACLE_HOME/jre:$ORACLE_HOME/jlib:$ORACLE_HOME/rdbms/jlibexport EDITOR=vimexport NLS_LANG=AMERICAN_AMERICA.UTF8export NLS_DATE_FORMAT=&#x27;YYYY-MM-DD HH24:MI:SS&#x27;\n\n在文件的末尾追加export TMP=/tmp      #安装oracle软件过程中使用的临时文件目录export TMPDIR=$TMP  #安装oracle软件过程中使用的临时文件目录export ORACLE_BASE=/data/oracle  #Oracle 的 base 目录，所有的oracle文件全部存放在这个目录export ORACLE_HOME=/data/oracle/product/11.2.0/db_1  #oracle软件存放目录export ORACLE_SID=orcl  #实例名称export ORACLE_TERM=xtermexport PATH=/usr/sbin:$PATHexport PATH=$ORACLE_HOME/bin:$PATH   #SHELL可执行文件的搜索路径export LD_LIBRARY_PATH=$ORACLE_HOME/lib:/lib:/usr/lib  #库文件搜索路径export CLASSPATH=$ORACLE_HOME/jre:$ORACLE_HOME/jlib:$ORACLE_HOME/rdbms/jlibexport EDITOR=vimexport NLS_LANG=AMERICAN_AMERICA.UTF8export NLS_DATE_FORMAT=&#39;YYYY-MM-DD HH24:MI:SS&#39;\n\n\n使配置文件生效source .bash_profile\n[oracle@oracledb ~]$ source .bash_profile\n解压缩\n在root用户下安装unzip命令yum install -y zip unzip\n[root@oracledb data]# yum install -y zip unzipLoaded plugins: fastestmirrorLoading mirror speeds from cached hostfileResolving Dependencies--&gt; Running transaction check---&gt; Package unzip.x86_64 0:6.0-20.el7 will be installed---&gt; Package zip.x86_64 0:3.0-11.el7 will be installed--&gt; Finished Dependency ResolutionDependencies Resolved============================================================================================================================================================================================================================================= Package                                                 Arch                                                     Version                                                       Repository                                              Size=============================================================================================================================================================================================================================================Installing: unzip                                                   x86_64                                                   6.0-20.el7                                                    base                                                   170 k zip                                                     x86_64                                                   3.0-11.el7                                                    base                                                   260 kTransaction Summary=============================================================================================================================================================================================================================================Install  2 PackagesTotal download size: 430 kInstalled size: 1.1 MDownloading packages:(1/2): unzip-6.0-20.el7.x86_64.rpm                                                                                                                                                                                    | 170 kB  00:00:00(2/2): zip-3.0-11.el7.x86_64.rpm                                                                                                                                                                                      | 260 kB  00:00:00---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------Total                                                                                                                                                                                                        2.9 MB/s | 430 kB  00:00:00Running transaction checkRunning transaction testTransaction test succeededRunning transaction  Installing : zip-3.0-11.el7.x86_64                                                                                                                                                                                                     1/2  Installing : unzip-6.0-20.el7.x86_64                                                                                                                                                                                                   2/2  Verifying  : unzip-6.0-20.el7.x86_64                                                                                                                                                                                                   1/2  Verifying  : zip-3.0-11.el7.x86_64                                                                                                                                                                                                     2/2Installed:  unzip.x86_64 0:6.0-20.el7                                                                                              zip.x86_64 0:3.0-11.el7Complete!\n将下载的安装包上传到服务器之后修改权限ls -alchown oracle:oinstall -R linux.x64_11gR2_database_1of2.zipchown oracle:oinstall -R linux.x64_11gR2_database_2of2.zip\n[root@oracledb data]# ls -altotal 2295612drwxr-xr-x   3 oracle oinstall       4096 Oct 18 15:58 .dr-xr-xr-x. 19 root   root           4096 Oct 18 15:44 ..-rw-r--r--   1 root   root     1239269270 Oct 18 15:58 linux.x64_11gR2_database_1of2.zip-rw-r--r--   1 root   root     1111416131 Oct 18 15:58 linux.x64_11gR2_database_2of2.zipdrwxr-xr-x   3 oracle oinstall       4096 Oct 18 15:44 oracle[root@oracledb data]# chown oracle:oinstall -R linux.x64_11gR2_database_1of2.zip[root@oracledb data]# chown oracle:oinstall -R linux.x64_11gR2_database_2of2.zip[root@oracledb data]# ls -altotal 2295612drwxr-xr-x   3 oracle oinstall       4096 Oct 18 15:58 .dr-xr-xr-x. 19 root   root           4096 Oct 18 15:44 ..-rwxr-xr-x   1 oracle oinstall 1239269270 Oct 18 15:58 linux.x64_11gR2_database_1of2.zip-rwxr-xr-x   1 oracle oinstall 1111416131 Oct 18 15:58 linux.x64_11gR2_database_2of2.zipdrwxr-xr-x   3 oracle oinstall       4096 Oct 18 15:44 oracle\n切换到 oralce用户解压缩oracle文件unzip linux.x64_11gR2_database_1of2.zipunzip linux.x64_11gR2_database_2of2.zip\n[oracle@oracledb data]$ unzip linux.x64_11gR2_database_1of2.zip[oracle@oracledb data]$ unzip linux.x64_11gR2_database_2of2.zip[oracle@oracledb data]$ ls -altotal 2295616drwxr-xr-x   4 oracle oinstall       4096 Oct 18 16:25 .dr-xr-xr-x. 19 root   root           4096 Oct 18 15:44 ..drwxr-xr-x   8 oracle oinstall       4096 Aug 21  2009 database-rwxr-xr-x   1 oracle oinstall 1239269270 Oct 18 15:58 linux.x64_11gR2_database_1of2.zip-rwxr-xr-x   1 oracle oinstall 1111416131 Oct 18 15:58 linux.x64_11gR2_database_2of2.zipdrwxr-xr-x   3 oracle oinstall       4096 Oct 18 15:44 oracle\n安装数据库软件修改应答文件[oracle@oracledb data]$ vi /data/database/response/db_install.rsp\n\n按下列值进行比较修改oracle.install.responseFileVersion=/oracle/install/rspfmt_dbinstall_response_schema_v11_2_0oracle.install.option=INSTALL_DB_SWONLYORACLE_HOSTNAME=oradbUNIX_GROUP_NAME=oinstallINVENTORY_LOCATION=/data/oracle/oraInventorySELECTED_LANGUAGES=en,zh_CNORACLE_HOME=/data/oracle/product/11.2.0/db_1ORACLE_BASE=/data/oracleoracle.install.db.InstallEdition=EEoracle.install.db.isCustomInstall=falseoracle.install.db.customComponents=oracle.server:11.2.0.1.0,oracle.sysman.ccr:10.2.7.0.0,oracle.xdk:11.2.0.1.0,oracle.rdbms.oci:11.2.0.1.0,oracle.network:11.2.0.1.0,oracle.network.listener:11.2.0.1.0,oracle.rdbms:11.2.0.1.0,oracle.options:11.2.0.1.0,oracle.rdbms.partitioning:11.2.0.1.0,oracle.oraolap:11.2.0.1.0,oracle.rdbms.dm:11.2.0.1.0,oracle.rdbms.dv:11.2.0.1.0,orcle.rdbms.lbac:11.2.0.1.0,oracle.rdbms.rat:11.2.0.1.0oracle.install.db.DBA_GROUP=dbaoracle.install.db.OPER_GROUP=oinstalloracle.install.db.CLUSTER_NODES=oracle.install.db.config.starterdb.type=GENERAL_PURPOSEoracle.install.db.config.starterdb.globalDBName=ora11goracle.install.db.config.starterdb.SID=ORCLoracle.install.db.config.starterdb.characterSet=AL32UTF8oracle.install.db.config.starterdb.memoryOption=trueoracle.install.db.config.starterdb.memoryLimit=512oracle.install.db.config.starterdb.installExampleSchemas=falseoracle.install.db.config.starterdb.enableSecuritySettings=trueoracle.install.db.config.starterdb.password.ALL=oracle    #所有用户的密码oracle.install.db.config.starterdb.password.SYS=oracle.install.db.config.starterdb.password.SYSTEM=oracle.install.db.config.starterdb.password.SYSMAN=oracle.install.db.config.starterdb.password.DBSNMP=oracle.install.db.config.starterdb.control=DB_CONTROLoracle.install.db.config.starterdb.gridcontrol.gridControlServiceURL=oracle.install.db.config.starterdb.dbcontrol.enableEmailNotification=falseoracle.install.db.config.starterdb.dbcontrol.emailAddress=oracle.install.db.config.starterdb.dbcontrol.SMTPServer=oracle.install.db.config.starterdb.automatedBackup.enable=falseoracle.install.db.config.starterdb.automatedBackup.osuid=oracle.install.db.config.starterdb.automatedBackup.ospwd=oracle.install.db.config.starterdb.storageType=FILE_SYSTEM_STORAGEoracle.install.db.config.starterdb.fileSystemStorage.dataLocation=oracle.install.db.config.starterdb.fileSystemStorage.recoveryLocation=oracle.install.db.config.asm.diskGroup=oracle.install.db.config.asm.ASMSNMPPassword=MYORACLESUPPORT_USERNAME=MYORACLESUPPORT_PASSWORD=SECURITY_UPDATES_VIA_MYORACLESUPPORT=DECLINE_SECURITY_UPDATES=truePROXY_HOST=PROXY_PORT=PROXY_USER=PROXY_PWD=\n\n\n\n静默安装数据库软件/data/database/runInstaller -silent -force -ignorePrereq -responseFile  /data/database/response/db_install.rsp\n[oracle@oracledb data]$ /data/database/runInstaller -silent -force -ignorePrereq -responseFile  /data/database/response/db_install.rspStarting Oracle Universal Installer...Checking Temp space: must be greater than 120 MB.   Actual 8269 MB    PassedChecking swap space: must be greater than 150 MB.   Actual 1999 MB    PassedPreparing to launch Oracle Universal Installer from /tmp/OraInstall2019-10-18_04-43-37PM. Please wait ...[oracle@oracledb data]$ [WARNING] [INS-32055] The Central Inventory is located in the Oracle base.   CAUSE: The Central Inventory is located in the Oracle base.   ACTION: Oracle recommends placing this Central Inventory in a location outside the Oracle base directory.[WARNING] [INS-32055] The Central Inventory is located in the Oracle base.   CAUSE: The Central Inventory is located in the Oracle base.   ACTION: Oracle recommends placing this Central Inventory in a location outside the Oracle base directory.You can find the log of this install session at: /data/oracle/oraInventory/logs/installActions2019-10-18_04-43-37PM.log\n约五分钟后会出现\nThe following configuration scripts need to be executed as the &quot;root&quot; user. #!/bin/sh #Root scripts to run/data/oracle/oraInventory/orainstRoot.sh/data/oracle/product/11.2.0/db_1/root.shTo execute the configuration scripts:         1. Open a terminal window         2. Log in as &quot;root&quot;         3. Run the scripts         4. Return to this window and hit &quot;Enter&quot; key to continueSuccessfully Setup Software.\n切换到root用户执行脚本/data/oracle/oraInventory/orainstRoot.sh/data/oracle/product/11.2.0/db_1/root.sh\n[oracle@oracledb data]$ exitlogout[root@oracledb data]# /data/oracle/oraInventory/orainstRoot.shChanging permissions of /data/oracle/oraInventory.Adding read,write permissions for group.Removing read,write,execute permissions for world.Changing groupname of /data/oracle/oraInventory to oinstall.The execution of the script is complete.[root@oracledb data]# /data/oracle/product/11.2.0/db_1/root.shCheck /data/oracle/product/11.2.0/db_1/install/root_oracledb_2019-10-18_16-50-42.log for the output of root script\n配置监听切换到oracle用户 su - oracle\n[root@oracledb data]# su - oracleLast login: Fri Oct 18 16:51:19 CST 2019 on pts/0\n创建监听netca /silent /responseFile /data/database/response/netca.rsp\n[oracle@oracledb ~]$ netca /silent /responseFile /data/database/response/netca.rspParsing command line arguments:    Parameter &quot;silent&quot; = true    Parameter &quot;responsefile&quot; = /data/database/response/netca.rspDone parsing command line arguments.Oracle Net Services Configuration:Profile configuration complete.Oracle Net Listener Startup:    Running Listener Control:      /data/oracle/product/11.2.0/db_1/bin/lsnrctl start LISTENER    Listener Control complete.    Listener started successfully.Listener configuration complete.Oracle Net Services configuration successful. The exit code is 0\n启动监听lsnrctl start\n[oracle@oracledb ~]$ lsnrctl startLSNRCTL for Linux: Version 11.2.0.1.0 - Production on 18-OCT-2019 16:55:24Copyright (c) 1991, 2009, Oracle.  All rights reserved.TNS-01106: Listener using listener name LISTENER has already been started\n查看监听状态lsnrctl status\n[oracle@oracledb ~]$ lsnrctl statusLSNRCTL for Linux: Version 11.2.0.1.0 - Production on 18-OCT-2019 16:56:02Copyright (c) 1991, 2009, Oracle.  All rights reserved.Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1521)))STATUS of the LISTENER------------------------Alias                     LISTENERVersion                   TNSLSNR for Linux: Version 11.2.0.1.0 - ProductionStart Date                18-OCT-2019 16:54:25Uptime                    0 days 0 hr. 1 min. 37 secTrace Level               offSecurity                  ON: Local OS AuthenticationSNMP                      OFFListener Parameter File   /data/oracle/product/11.2.0/db_1/network/admin/listener.oraListener Log File         /data/oracle/diag/tnslsnr/oracledb/listener/alert/log.xmlListening Endpoints Summary...  (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC1521)))  (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=oracledb)(PORT=1521)))The listener supports no servicesThe command completed successfully\n安装数据库修改建库应答文件vi /data/database/response/dbca.rsp\n\nGDBNAME = &quot;orcl.oracle&quot; #78行 全局数据库名字　　SID = &quot;orcl&quot; #149行　　CHARACTERSET = &quot;AL32UTF8&quot; #415行，编码　　NATIONALCHARACTERSET= &quot;UTF8&quot; #425行\n\n静默建库dbca -silent -responseFile /data/database/response/dbca.rsp在执行完这个命令后，会清屏，这时候需要输入密码（有可能不会有提示），输入密码后，会进行数据库的创建,密码是在数据软件应答文件中设置的。oracle.install.db.config.starterdb.password.ALL=oracle #所有用户的密码\nCopying database fileso1% complete                                                                                                                     3% complete11% complete18% complete26% complete37% completeCreating and starting Oracle instance40% complete45% complete50% complete55% complete56% complete60% complete62% completeCompleting Database Creation66% complete70% complete73% complete85% complete96% complete100% completeLook at the log file &quot;/data/oracle/cfgtoollogs/dbca/orcl/orcl.log&quot; for further details.\n","categories":["Database"],"tags":["Oracle"]},{"title":"ORACLE创建表空间、用户及授权","url":"/2020/10/03/Database/Oracle/ORACLE%E5%88%9B%E5%BB%BA%E8%A1%A8%E7%A9%BA%E9%97%B4%E3%80%81%E7%94%A8%E6%88%B7%E5%8F%8A%E6%8E%88%E6%9D%83/","content":"创建临时表空间CREATE TEMPORARY TABLESPACE BUILDINGAPITEMPTEMPFILE &#x27;/data/oracle/oradata/orcl/buildingapitemptbs01.dbf&#x27;SIZE 100MAUTOEXTEND ONNEXT 100M MAXSIZE UNLIMITED;\n\n\nBUILDINGAPITEMP:临时表空间名称/data/oracle/oradata/orcl/buildingapitemptbs01.dbf:创建的临时表空间文件SIZE 100M:初始大小AUTOEXTEND ON :自动扩容NEXT 100M: 每次自动扩容大小MAXSIZE UNLIMITED:文件最大无限制\n\n创建数据表空间CREATE TABLESPACE BUILDINGAPIDATAFILE &#x27;/data/oracle/oradata/orcl/buildingapitbs01.dbf&#x27;SIZE 100MAUTOEXTEND ONNEXT 100M MAXSIZE UNLIMITED;\n\n\nBUILDINGAPI:表空间名称/data/oracle/oradata/orcl/buildingapitbs01.dbf&#39;:创建的表空间文件SIZE 100M:初始大小AUTOEXTEND ON :自动扩容NEXT 100M: 每次自动扩容大小MAXSIZE UNLIMITED:文件最大无限制\n\n创建用户CREATE USER buildingapi IDENTIFIED BY passwordACCOUNT UNLOCKDEFAULT TABLESPACE BUILDINGAPITEMPORARY TABLESPACE BUILDINGAPITEMP;\n\n\nbuildingapi:用户名password:密码BUILDINGAPI:指定用户的表空间BUILDINGAPITEMP:指定用户的临时表空间\n\n用户授权grant CONNECT to username;grant RESOURCE to username;\n\n\nCONNECT角色： 是授予最终用户的典型权利，最基本的权力，能够连接到&gt;ORACLE数据库中，并在对其他用户的表有访问权限时，做SELECT、UPDATE、&gt;INSERTT等操作。\n\nALTER SESSION –修改会话\nCREATE CLUSTER –建立聚簇\nCREATE DATABASE LINK –建立数据库链接\nCREATE SEQUENCE –建立序列\nCREATE SESSION –建立会话\nCREATE SYNONYM –建立同义词\nCREATE VIEW –建立视图\n\nRESOURCE角色： 是授予开发人员的，能在自己的方案中创建表、序列、视图等。\n\nCREATE CLUSTER –建立聚簇\nCREATE PROCEDURE –建立过程\nCREATE SEQUENCE –建立序列\nCREATE TABLE –建表\nCREATE TRIGGER –建立触发器\nCREATE TYPE –建立类型　　\n\nDBA角色:是授予系统管理员的，拥有该角色&gt;的用户就能成为系统管理员了，它拥有所有的系统权限\n\n删除表空间drop tablespace BUILDINGAPI including contents and datafiles;\n\n\n删除表空间包括数据文件\n\n","categories":["Database"],"tags":["Oracle"]},{"title":"RMAN简介与配置","url":"/2020/11/03/Database/Oracle/RMAN%E7%AE%80%E4%BB%8B%E4%B8%8E%E9%85%8D%E7%BD%AE/","content":"RMAN简介与配置RMAN是自动管理的备份恢复。它功能强大，使用起来虽然比手动管理的备份恢复有些繁琐，但当你全部掌握RMAN的功能后就会发现，它其实是比手动管理的备份恢复要简单的。还有值得称道的一点是，RMAN的操作性能要好于手动管理的备份恢复。\nRMAN动态视图可以使用以下视图获取在控制文件中存储的RMAN 信息：V$ARCHIVED_LOG 显示在数据库中已经创建、备份或清除的归档文件V$BACKUP_CORRUPTION 显示在备份集的备份过程中找到损坏块V$COPY_CORRUPTION 显示映像复制过程中找到的损坏块V$BACKUP_DATAFILE 用于通过确定各数据文件中的块数来创建大小相同的备份集。通过它也可找出数据文件中已损坏的块数V$BACKUP_REDOLOG 显示在备份集中存储的归档日志V$BACKUP_SET 显示已经创建的备份集V$BACKUP_PIECE 显示为备份集创建的备份片\nRMAN备份恢复简介RMAN 提供了一种灵活的方式来备份数据库、表空间、数据文件、控制文件和归档日志，因为灵活，所以有些繁琐。RMAN有对坏块进行恢复的功能，这是手动管理的恢复所不具备的。RMAN可以只恢复数据文件中损毁的块。 \nRMAN的常用组件服务器会话、目标数据库、RMAN 资料档案库、通道、介质管理库 …….服务器会话：由RMAN 调用的服务器进程(UNIX) 或线程(Windows NT) 与目标数据库连接，通过PL/SQL 接口执行备份、还原和恢复功能。目标数据库：正在使用RMAN 对其进行备份和恢复操作的数据库称作目标数据库。目标数据库的控制文件包含其物理结构的有关信息，例如，数据文件的大小和位置、联机和归档重做日志文件以及控制文件。在备份和恢复操作过程中，由RMAN 调用的服务器会话将使用这些信息。RMAN 资料档案库：RMAN 在执行备份、还原和恢复操作时使用的数据称为RMAN 元数据。这些元数据存储在目标数据库的控制文件和可选的恢复目录数据库中。尽管不是必须创建恢复目录才可以使用RMAN，但使用恢复目录却是有益的。恢复目录应放在目标数据库之外的另一数据库中。通道：要执行并记录备份和恢复操作，RMAN 需要链接至目标数据库。该链接称为通道。可以手动分配通道，也可以使用自动通道分配功能预先配置通道。介质管理库：介质管理库(MML) 由RMAN 在写入磁带或从磁带读取时使用。使用磁带介质所需的附加介质管理软件由介质和存储系统供应商提供。\nRMAN配置RMAN恢复目录和控制文件RMAN 在RMAN 资料档案库中存储有关目标数据库及其备份和恢复操作的信息。目标数据库控制文件可用作专门存储该信息的位置。存储的信息量会根据备份频率、生成的归档重做日志文件的数量以及RMAN 记录的保留时间而增长。CONTROL_FILE_RECORD_KEEP_TIME 参数指定RMAN 信息至少要在控制文件中存储多少天后才会被覆盖。该值越小，信息就会越频繁地被覆盖，从而尽可能减少控制文件的增长。如果使用恢复目录，则应选择较小的数值。缺省值为7 天。\n\n如果控制文件太小，不能存储由CONTROL_FILE_RECORD_KEEP_TIME 指定的时间段内的所有信息，那么控制文件将会增长。在控制文件增长之前，将执行以下的特定步骤： \n\n\n使用控制文件中的空闲空间。\n覆盖早于CONTROL_FILE_RECORD_KEEP_TIME 的条目。\n如果没有更多空间可用，控制文件将按需增长，直到达到操作文件大小的系统限制。通道分配每个通道代表通向某一类型设备的一个数据流。在执行备份和恢复命令前，必须先分配通道。每个已分配的通道建立从RMAN 可执行文件到目标或辅助数据库（通过复制命令建立的数据库或TSPITR 中使用的临时数据库）例程的连接，方法是在例程上启动服务器会话。该服务器会话执行备份和恢复操作。只有一个RMAN 会话可与已分配的服务器会话通信。每个通道通常对应一个输出设备.可以以手动分配通道，也可以使用自动通道分配功能预先配置要在所有RMAN 会话中使用的通道。 手动分配通道时，可在RMAN 提示符下，将ALLOCATE CHANNEL 作为RUN 命令的子命令发出，也可使用ALLOCATE CHANNEL FOR MAINTENANCE 命令。手动通道分配将覆盖自动通道分配。恢复管理器使用通道进程在Oracle 服务器与操作系统之间进行通信。系统将为每个分配的通道创建目标数据库的一个Oracle 服务器进程。从恢复管理器发出的每个BACKUP、COPY、RESTORE 或RECOVER 命令至少需要一个通道。分配的通道数将是备份、还原或恢复期间使用的最大并行度。所需的介质类型确定了分配的通道类型。查询V$BACKUP_DEVICE 视图可以确定支持哪些设备类型。可以通过在ALLOCATE CHANNEL 命令中指定参数来对COPY 和BACKUP 命令施加限制：Read rate：限制每个文件每秒读取的缓冲区数，防止过多的磁盘I/O 降低联机性能。allocate channel … rate = integer Kbytes：限制通道创建的备份片文件大小。这在操作系统或设备类型有最大的文件大小限制时非常有用。allocate channel … maxpiecesize = integerMAXOPENFILE：限制大型备份时同时打开的文件数（缺省值为16）。该参数可以防止打开的文件过多。ALLOCATE CHANNEL … MAXOPENFILE = integer 分配通道示例：ALLOCATE CHANNEL FOR MAINTENANCE DEVICE TYPE disk; 此命令为DELETE 命令分配通道，因为将从磁盘删除一个文件。维护通道不能用于任何其它I/O 操作，如备份或复制。RMAN&gt; RUN &#123;  ALLOCATE CHANNEL d1 DEVICE TYPE disk  FORMAT = &#39;/db01/BACKUP/%U’;  BACKUP DATAFILE ’/…/u03/users01.dbf&#39;;&#125; 第二个示例分配一个名为d1 的通道，由该通道创建的所有文件都具有格式’/db01/BACKUP/%U’。该通道备份一个数据文件/db01/ORADATA/u03/users01.dbf。在Oracle9i 中，可以使用自动通道分配功能预先配置要在所有RMAN 会话中使用的通道。RMAN 提供一个预先配置的DISK 通道，可以将该通道用于备份数据和将数据复制到磁盘。此外，您还可以配置一组永久的自动通道。可通过CONFIGURE CHANNEL 命令将自动通道指定给磁盘或磁带。可在RMAN 资料档案库中保存永久配置信息，如通道参数、并行性和缺省设备类型。可配置自动通道用于备份、还原、恢复和维护作业。如果通道是由RMAN 自动分配的，其名称格式为ora_devicetype_n（ora_sbt_tape_n 或ora_disk_n）。如果未指定名称格式，在缺省情况下，RMAN 将使用%U 格式，该格式可保证标识符唯一。%U 指定%u_%p_%c 的简写方式，可保证生成的备份文件名的唯一性。%u 指定一个8 个字符长的名称，该名称由备份集号和备份集创建时间的缩写形式构成。%p 指定备份集中的备份片号。%c 指定一组双重备份片中备份片的副本数。可通过ALLOCATE CHANNEL 命令手动分配通道来覆盖自动通道。自动分配通道功能与手动分配通道功能是互斥的，即：对于每个作业，RMAN 要么使用自动分配，要么使用手动分配。缺省情况下，RMAN 已预先配置了一个磁盘通道，这样可以以备份到磁盘而无需进行任何手动配置。因此，如果要备份到磁盘而不是介质管理器，现在就可以开始备份到磁盘。介质管理器要使用磁带存储数据库备份，RMAN 需要使用介质管理器。介质管理器是加载、标记和卸载顺序介质的实用程序，如用于备份、还原和恢复数据的磁带机。Oracle 服务器调用MML 软件例行程序将数据文件备份到由介质管理器控制的介质或从介质中还原数据文件。有些介质管理产品可以管理Oracle 数据文件与备份设备之间的整个数据移动。有些产品在存储设备与介质子系统之间使用高速连接，从而大大降低主数据库服务器的备份负载。注：如果是备份到磁盘，Oracle 服务器无需连接到介质管理库(MML) 软件。Oracle 备份解决方案(Oracle Backup Solutions Program, BSP) 提供一系列符合Oracle的MML 规范的介质管理产品。使用与MML 界面相兼容的软件，Oracle 服务器会话可备份到介质管理器并请求介质管理器还原备份。请与介质供应商联系以确定其是否为Oracle BSP 的成员。在开始将RMAN 用于介质管理器之前，必须先安装介质管理器并确保RMAN 可与其进行通信。有关该过程的具体说明，请参见介质管理器供应商的软件文档。根据要安装的产品，相应执行以下基本步骤： \n在目标主机或产品网络上安装并配置介质管理软件。此阶段无需集成RMAN。\n确保可在目标数据库主机上创建操作系统文件的非RMAN 备份。此步骤将使以后排除故障更为容易。请参阅介质管理文档以了解如何将文件备份到介质管理器。 \n获取并安装要与Oracle 服务器集成的第三方介质管理模块。该模块必须包含Oracle要在访问介质管理器时加载的库。安装介质管理软件后，介质管理库应已与Oracle 服务器集成在一起。下面的恢复管理器脚本可以将数据文件备份到由介质管理器控制的磁带机上：run &#123;  Allocating a channel of type &#39;sbt&#39; for serial device ; ALLOCATE CHANNEL ch1 DEVICE TYPE &#39;sbt&#39;;  BACKUP DATAFILE 3;  &#125;恢复管理器执行该命令时，将向执行该备份操作的Oracle 服务器会话发送备份请求。Oracle 服务器会话将输出通道标识为介质管理设备，然后请求介质管理器装载磁带并将输出写入磁带。介质管理器会标记并记录磁带以及磁带上每个文件的名称。介质管理器可处理还原和备份操作。还原文件时，将执行以下步骤： \nOracle 服务器请求还原某一特定文件。\n介质管理器标识包含该文件的磁带，并读取磁带。\n介质管理器将信息传回到Oracle 服务器会话。\nOracle 会话将文件写入磁盘。与RMAN连接的类型使用恢复管理器，可连接到下列类型的数据库：目标数据库：使用SYSDBA 权限连接到目标数据库。您必须具有该权限才能连接成功。恢复目录数据库：这是一种为RMAN 资料档案库配置的可选数据库。辅助数据库：辅助数据库是使用RMAN DUPLICATE 命令创建的数据库。它也可能是在表空间时间点恢复(TSPITR) 过程中使用的临时数据库。备用数据库是生产数据库的副本，可用于灾难恢复。恢复管理器模式恢复管理器是一个具有自己的命令语言的命令行解释程序(CLI)。RMAN 有两种操作模式：交互模式和批处理模式。交互模式：要交互运行RMAN 命令，请启动RMAN，然后在命令行界面中键入命令。例如，可以从UNIX 命令shell 启动RMAN，然后执行以下交互命令： $ rman target sys/sys_pwd@db1 RMAN&gt; BACKUP DATABASE; \n批处理模式：可以以将RMAN 命令输入到一个文件中，然后通过在命令行中指定该文件的名称来运行该命令文件。命令文件的内容应与命令行中输入的命令完全相同。以批处理模式运行时，RMAN 从命令文件中读取输入内容，然后将输出消息写入日志文件（如果已指定）。RMAN 在编译或执行任何命令前先对整个命令文件进行语法分析。无需在文件中添加退出命令，因为RMAN 将在到达文件末尾时终止执行。批处理模式最适合于通过操作系统作业控制设备来执行安排好的定期备份操作。$ rman target / @tbsbk.rcv log tbs.log \n在该示例中，用户已经创建了文件tbsbk.rcv，该文件包含用户本要交互使用的命令。RMAN 会将消息输出到文件tbs.log。使用“运行RMAN 脚本” 任务，所有可从RMAN 命令行调用的命令或脚本都可以通过Oracle Enterprise Manager 发出。在“参数” (Parameters) 页上，指定“运行RMAN 脚本” 任务的参数设置。RMAN命令、参数RMAN 具有两种基本类型的命令：独立命令和作业命令。独立命令在RMAN 提示符下执行，通常是自包含的。下列是部分独立命令：CHANGE、CONNECT、CREATE CATALOG, RESYNC CATALOG、CREATE SCRIPT, DELETE SCRIPT, REPLACE SCRIPT。作业命令通常被分成几组，由RMAN 在RUN 命令块内按顺序执行。如果块内任何一个命令失败，RMAN 将停止处理；而不再继续执行块内的其它命令。\n将RMAN 输出写入到一个日志文件：$ rman target sys/oracle  log $HOME/ORADATA/u03/rman.log append 调用RMAN 时执行命令文件：$ rman target sys/oracle  log $HOME/ORADATA/u03/rman.log append  @&#39;$HOME/STUDENT/LABS/my_rman_script.rcv&#39; LOG = ‘filename’ 参数指定用于记录RMAN 输出的文件。如果未指定该参数，RMAN 将把其消息日志文件写入到标准输出。如果无法打开指定的文件，RMAN 不会中止，而是将输出内容写入到标准输出设备。APPEND 关键字指定新的输出应附加在消息日志文件的末尾。如果未指定该参数，一旦存在与消息日志文件同名的文件，RMAN 将覆盖该文件。可使用CMDFILE = ‘filename’ 运行包含RMAN 命令的文件。如果文件名的第一个字符是字母，则可不必将文件名放在引号内。RMAN 将在运行命令文件后终止。有一些命令既可在提示符下发出也可在RUN 命令中发出。如果在RMAN 提示符下执行独立命令，可利用自动分配通道的功能。可以按交互模式或批处理模式执行命令。独立命令示例： \n\n--装载目标数据库 --发出启动命令，如下所示： RMAN&gt; STARTUP MOUNT --关闭目标数据库 --发出关闭命令，如下所示： RMAN&gt; SHUTDOWN IMMEDIATE--列出目标数据库的当前配置 --使用REPORT 命令获取数据库的配置信息，如下所示： RMAN&gt; REPORT SCHEMA; RMAN-03022: compiling command: report Report of database schema File K-bytes Tablespace RB Name ---- -------- ---------- --- ----------------- 1 117760 SYSTEM *** …/ORADATA/u01/system_01.dbf 2 30720 UNDO1 *** …/ORADATA/u02/undotbs.dbf 3 5120 USERS *** …/ORADATA/u04/users_01.dbf 4 5120 INDX *** …/ORADATA/u03/indx_01.dbf 5 5120 SAMPLE *** …/ORADATA/u02/sample_01.dbf 6 1024 QUERY_DATA *** …/ORADATA/u01/query_01.dbf 作业命令示例： RMAN&gt; RUN &#123; backup incremental level 0 format ‘/u01/db01/backup/%d_%s_%p’ fileperset 5 (database include current controlfile); sql ‘alter database archive log current’; &#125;\n与独立命令不同，作业命令必须包含在RUN 命令的括号中。下面是作业命令的示例：ALLOCATE CHANNEL、SWITCHRMAN 按顺序执行RUN 命令块内的作业命令。如果块内的任何命令失败，RMAN 将停止处理；不再继续执行块内的其它命令。实际上，RUN 命令定义了一个命令执行单位。当RUN 命令块内的最后一个命令执行完毕后，Oracle 将释放为该命令块分配的所有服务器端资源，如I/O 缓冲区或I/O 从属进程。RMAN环境配置RMAN 预设为使用适用于所有RMAN 会话的缺省配置设置。可以使用CONFIGURE 命令配置RMAN 备份、还原、复制和维护作业的永久设置。这些设置将对所有RMAN 会话有效，除非清除或更改该配置。使用Oracle Enterprise Manager，可以使用“创建备份配置” 向导来设置备份和恢复的缺省值。可通过“Oracle EnterpriseManager 控制台” (Oracle Enterprise Manager Console) 来访问该向导。在“常规” (General)页上，指定用于备份、恢复和目录维护操作的一组缺省值的名称和说明。在“通道”(Channels) 页上，指定是要将该配置用于映像副本还是备份集，并提供该通道的附加说明。在“备份参数” (Backup Parameters) 页上，设置备份集的存储参数。使用CONFIGURE 命令可以：配置自动通道、指定备份保留策略、指定要创建的备份副本数、限制备份集的大小、使表空间从备份中脱离、启用和禁用备份优化。CONFIGURE 命令示例：配置自动通道，使用CONFIGURE CHANNEL 命令可指定缺省备份位置和文件命名约定。RMAN&gt; CONFIGURE CHANNEL DEVICE TYPE DISK FORMAT &#39;/db01/BACKUP/%U&#39;; 配置备份保留策略，使用CONFIGURE RETENTION POLICY 命令可创建永久和自动的备份保留策略。RMAN 将根据您用CONFIGURE 命令指定的标准来确定数据文件和控制文件的备份和副本何时过期；即，何时介质恢复不再需要使用这些备份和副本。可以发出REPORT OBSOLETE 命令查看已过期的文件，并使用DELETE OBSOLETE 命令将它们删除。发出CONFIGURE RETENTION POLICY CLEAR 命令可将该设置恢复为缺省值。RMAN&gt; CONFIGURE RETENTION POLICY TO RECOVERY WINDOW OF 7 days; 可以使用以下两种互斥方法中的任意一种来实施保留策略：指定一个恢复期，该恢复期是从当前时间回溯到可恢复时间点的时间段。在以上示例中，使用CONFIGURE 命令可确保对每个数据文件都保留一份早于可恢复点（七天）的备份。指定一个冗余值，该值指示备份或副本一旦超过某一指定数目，将不再予以保留。缺省情况下，RETENTION POLICY 配置为REDUNDANCY 1。RMAN&gt; CONFIGURE RETENTION POLICY TO REDUNDANCY 2; 配置双重备份集：对于使用自动通道的所有备份命令，可在一个备份集中为每个备份片最多创建四个副本。这仅适用于数据文件和归档重做日志文件。RMAN&gt; CONFIGURE DATAFILE BACKUP COPIES FOR DEVICE TYPE disk TO 2; 配置备份优化：设置备份优化的目的是：如果相同的文件已备份到某一设备类型，BACKUP 命令不再将文件备份到该设备类型。两个文件相同，指的是其内容必须完全相同。备份优化的缺省值是OFF。可以通过使用BACKUP 命令的FORCE 选项覆盖备份优化设置。RMAN&gt; CONFIGURE BACKUP OPTIMIZATION ON; 使用CLEAR 选项恢复为缺省值RMAN&gt; CONFIGURE RETENTION POLICY CLEAR;  RMAN&gt; CONFIGURE CHANNEL DEVICE TYPE sbt CLEAR; SHOW 命令用于显示使用CONFIGURE 命令指定的永久配置设置。配置的这些设置将用于任意RMAN 会话。可以使用SHOW 命令显示下列信息：自动通道配置设置：SHOW CHANNEL;  SHOW DEVICE TYPE;  SHOW DEFAULT DEVICE TYPE; RMAN 保留策略配置设置：SHOW RETENTION POLICY; 备份副本数：SHOW DATAFILE BACKUP COPIES; 备份集的最大大小：SHOW MAXSETSIZE; 不包括在整个数据库备份中的表空间：SHOW EXCLUDE; 备份优化的状态：SHOW BACKUP OPTIMIZATION; LIST 命令用于生成详细报告，列出下各项的所有信息：包含指定的一系列数据文件的备份的备份集，指定的一系列数据文件的副本，包含属于指定表空间列表的任何数据文件的备份的备份集，属于指定表空间列表的任何数据文件的副本，包含任何具有指定名称或范围的归档日志的备份的备份集，任何具有指定名称或范围的归档日志的副本。使用此命令时必须连接至目标数据库。如果在NOCATALOG 模式下进行连接，则必须装载数据库。如果使用恢复目录进行连接，则必须启动目标例程（但无需装载）。列出数据库备份，可以使用此命令生成数据库中所有文件的备份的列表：RMAN&gt; LIST BACKUP OF DATABASE; 列出备份集，上面的示例使用LIST 命令列出数据文件“/db01 /ORADATA/ u03/ users01.dbf”的所有已知备份。RMAN&gt; LIST BACKUP OF DATAFILE“/db01/ORADATA/u03/users01.dbf”; 列出数据文件副本，上面的示例使用LIST 命令列出SYSTEM 表空间的数据文件副本。RMAN&gt; LIST COPY OF TABLESPACE “SYSTEM”; REPORT 命令，该命令有助于更详细地分析RMAN 资料档案库中的信息。可以针对各种问题生成报告，该数据库的结构是怎样的？RMAN&gt; REPORT SCHEMA; 哪些文件需要备份？RMAN&gt; REPORT NEED BACKUP ...; 哪些备份可以删除（即已过期）？RMAN&gt; REPORT OBSOLETE; 哪些文件由于不可恢复的操作而不可恢复？RMAN&gt; REPORT UNRECOVERABLE ...; REPORT NEED BACKUP 命令用于标识所有需要备份的数据文件。该报告假定在还原时使用最新的备份。该命令有三个选项：增量(Incremental)：是一个整数值，指定应在恢复过程中还原的增量备份的最大数目。如果需要该数目或更多的增量备份，则需要对数据文件执行新的完全备份。例如，要报告需要三个或更多增量备份才能进行恢复的文件：RMAN &gt; REPORT NEED BACKUP incremental 3 database; 天数(Days)：是一个整数值，指定距文件上一次完全或增量备份操作的最大天数。如果最近一次备份到当前的天数等于或超过该数字，则需要对该文件进行备份。例如，报告三天未备份的系统文件：RMAN &gt; REPORT NEED BACKUP days 3 tablespace system; 冗余(Redundancy)：一个整数值，指定必要的最低冗余级别。例如，如果没有两个或更多备份，则冗余级别2 将要求进行备份。\n\n","categories":["Database"],"tags":["Oracle"]},{"title":"jvisualvm安装Visual GC插件","url":"/2021/08/31/Java/JVM/JIT/","content":"解释执行分层编译","categories":["Java"],"tags":["JVM"]},{"title":"JVM内存模型深度剖析与优化","url":"/2020/06/30/Java/JVM/JVM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E6%B7%B1%E5%BA%A6%E5%89%96%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96/","content":"JDK体系结构\nJava语言的跨平台特性\nJVM整体结构及内存模型\n在minor gc过程中对象挪动后，引用如何修改?\n\n对象在堆内部挪动的过程其实是复制，原有区域对象还在，一般不直接清理，JVM内部清理过程只是将对象分配指针移动到区域的头位置即可，比如扫描s0区域，扫到gcroot引用的非垃圾对象是将这些对象复制到s1或老年代，最后扫描完了将s0区域的对象分配指针移动到区域的起始位置即可，s0区域之前对象并不直接清理，当有新对象分配了，原有区域里的对象也就被清除了。\n\nminor gc在根扫描过程中会记录所有被扫描到的对象引用(在年轻代这些引用很少，因为大部分都是垃圾对象不会扫描到)，如果引用的对象被复制到新地址了，最后会一并更新引用指向新地址。\n\n\n\nhttps://www.zhihu.com/question/42181722/answer/145085437\nhttps://hllvm-group.iteye.com/group/topic/39376#post-257329\n\nClass常量池与运行时常量池Class常量池可以理解为是Class文件中的资源仓库。 Class文件中除了包含类的版本、字段、方法、接口等描述信息外，还有一项信息就是常量池(constant pool table)，用于存放编译期生成的各种字面量(Literal)和符号引用(Symbolic References)。\n一个class文件的16进制大体结构如下图：\n\n对应的含义如下，细节可以查下oracle官方文档\n\n当然我们一般不会去人工解析这种16进制的字节码文件，我们一般可以通过javap命令生成更可读的JVM字节码指令文件：javap -v Math.class\n\n红框标出的就是class常量池信息，常量池中主要存放两大类常量：字面量和符号引用。\n字面量字面量就是指由字母、数字等构成的字符串或者数值常量\n字面量只可以右值出现，所谓右值是指等号右边的值，如：int a=1 这里的a为左值，1为右值。在这个例子中1就是字面量。\nint a = 1;int b = 2;int c = &quot;abcdefg&quot;;int d = &quot;abcdefg&quot;;\n\n符号引用符号引用是编译原理中的概念，是相对于直接引用来说的。主要包括了以下三类常量：\n\n类和接口的全限定名 \n字段的名称和描述符 \n方法的名称和描述符\n\n上面的a，b就是字段名称，就是一种符号引用，还有Math类常量池里的 Lcom/jvm/Math 是类的全限定名，main和compute是方法名称，()是一种UTF8格式的描述符，这些都是符号引用。\n这些常量池现在是静态信息，只有到运行时被加载到内存后，这些符号才有对应的内存地址信息，这些常量池一旦被装入内存就变成运行时常量池，对应的符号引用在程序加载或运行时会被转变为被加载到内存区域的代码的直接引用，也就是我们说的动态链接了。例如，compute()这个符号引用在运行时就会被转变为compute()方法具体代码在内存中的地址，主要通过对象头里的类型指针去转换直接引用。\n字符串常量池字符串常量池的设计思想\n字符串的分配，和其他的对象分配一样，耗费高昂的时间与空间代价，作为最基础的数据类型，大量频繁的创建字符串，极大程度地影响程序的性能\n\nJVM为了提高性能和减少内存开销，在实例化字符串常量的时候进行了一些优化\n\n\n为字符串开辟一个字符串常量池，类似于缓存区\n\n创建字符串常量时，首先查询字符串常量池是否存在该字符串\n\n存在该字符串，返回引用实例，不存在，实例化该字符串并放入池中\n\n\n\n\n三种字符串操作(Jdk1.7 及以上版本)\n直接赋值字符串\nString s = &quot;test&quot;;  // s指向常量池中的引用\n\n这种方式创建的字符串对象，只会在常量池中。\n因为有”test”这个字面量，创建对象s的时候，JVM会先去常量池中通过 equals(key) 方法，判断是否有相同的对象\n如果有，则直接返回该对象在常量池中的引用；如果没有，则会在常量池中创建一个新对象，再返回引用\n\nnew String()\nString s1 = new String(&quot;test&quot;);  // s1指向内存中的对象引用\n\n这种方式会保证字符串常量池和堆中都有这个对象，没有就创建，最后返回堆内存中的对象引用。\n步骤大致如下：\n因为有”test”这个字面量，所以会先检查字符串常量池中是否存在字符串”test”\n不存在，先在字符串常量池里创建一个字符串对象；再去内存中创建一个字符串对象”test”；\n存在的话，就直接去堆内存中创建一个字符串对象”test”；\n最后，将内存中的引用返回。\n\nintern方法\nString s1 = new String(&quot;test&quot;);   String s2 = s1.intern();System.out.println(s1 == s2);  //false\n\nString中的intern方法是一个 native 的方法，当调用 intern方法时，如果池已经包含一个等于此String对象的字符串（用equals(oject)方法确定），则返回池中的字符串。否则，将intern返回的引用指向当前字符串 s1(jdk1.6版本需要将 s1 复制到字符串常量池里)。\n\n\n字符串常量池位置Jdk1.6及之前： 有永久代, 运行时常量池在永久代，运行时常量池包含字符串常量池\nJdk1.7：有永久代，但已经逐步“去永久代”，字符串常量池从永久代里的运行时常量池分离到堆里\nJdk1.8及之后： 无永久代，运行时常量池在元空间，字符串常量池里依然在堆里\n用一个程序证明下字符串常量池在哪里：\n/*** jdk6：-Xms6M -Xmx6M -XX:PermSize=6M -XX:MaxPermSize=6M  * jdk8：-Xms6M -Xmx6M -XX:MetaspaceSize=6M -XX:MaxMetaspaceSize=6M*/public class RuntimeConstantPoolOOM&#123;        public static void main(String[] args) &#123;                ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();                for (int i = 0; i &lt; 10000000; i++) &#123;                        String str = String.valueOf(i).intern();                        list.add(str);                &#125;        &#125;&#125;运行结果：jdk7及以上：Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap spacejdk6：Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: PermGen space\n\n字符串常量池设计原理字符串常量池底层是hotspot的C++实现的，底层类似一个 HashTable， 保存的本质上是字符串对象的引用。看一道比较常见的面试题，下面的代码创建了多少个 String 对象？\nString s1 = new String(&quot;he&quot;) + new String(&quot;llo&quot;);String s2 = s1.intern(); System.out.println(s1 == s2);// 在 JDK 1.6 下输出是 false，创建了 6 个对象// 在 JDK 1.7 及以上的版本输出是 true，创建了 5 个对象// 当然我们这里没有考虑GC，但这些对象确实存在或存在过\n\n为什么输出会有这些变化呢？主要还是字符串池从永久代中脱离、移入堆区的原因， intern() 方法也相应发生了变化：\n\n在 JDK 1.6 中\n调用 intern() 首先会在字符串池中寻找 equal() 相等的字符串，假如字符串存在就返回该字符串在字符串池中的引用；假如字符串不存在，\n虚拟机会重新在永久代上创建一个实例，将 StringTable 的一个表项指向这个新创建的实例\n\n\n在 JDK 1.7 (及以上版本)中\n由于字符串池不在永久代了，intern() 做了一些修改，更方便地利用堆中的对象。字符串存在时和 JDK 1.6一样，\n但是字符串不存在时不再需要重新创建实例，字符串常量池存的堆上实例地址，可以直接指向堆上的实例\n\n\n\n由上面两个图，也不难理解为什么 JDK 1.6 字符串池溢出会抛出 OutOfMemoryError: PermGen space ，而在 JDK 1.7 及以上版本抛出 OutOfMemoryError: Java heap space。\nString常量池问题的几个例子\n例1:\nString s0=&quot;test&quot;;String s1=&quot;test&quot;;String s2=&quot;te&quot; + &quot;st&quot;;System.out.println( s0==s1 ); //trueSystem.out.println( s0==s2 ); //true\n\n分析：因为例子中的 s0和s1中的”test”都是字符串常量，它们在编译期就被确定了，所以s0==s1为true；而”te”和”st”也都是字符串常量，当一个字 符串由多个字符串常量连接而成时，它自己肯定也是字符串常量，所以s2也同样在编译期就被优化为一个字符串常量”test”，所以s2也是常量池中”test”的一个引用。所以我们得出s0==s1==s2；\n\n例2：\nString s0=&quot;test&quot;;String s1=new String(&quot;test&quot;);String s2=&quot;te&quot; + new String(&quot;st&quot;);System.out.println( s0==s1 );// falseSystem.out.println( s0==s2 )； // falseSystem.out.println( s1==s2 );// false\n\n分析：用new String() 创建的字符串不是常量，不能在编译期就确定，所以new String() 创建的字符串不放入常量池中，它们有自己的地址空间。s0还是常量池 中”test”的引用，s1因为无法在编译期确定，所以是运行时创建的新对象”test”的引用，s2因为有后半部分 new String(”st”)所以也无法在编译期确定，所以也是一个新创建对象”test”的引用;明白了这些也就知道为何得出此结果了。\n\n例3：\nString a = &quot;a1&quot;;String b = &quot;a&quot; + 1;System.out.println(a == b); // true String a = &quot;atrue&quot;;String b = &quot;a&quot; + &quot;true&quot;;System.out.println(a == b); // true String a = &quot;a3.4&quot;;String b = &quot;a&quot; + 3.4;System.out.println(a == b); // true\n\n分析：JVM对于字符串常量的”+”号连接，将在程序编译期，JVM就将常量字符串的”+”连接优化为连接后的值，拿”a” + 1来说，经编译器优化后在class中就已经是a1。在编译期其字符串常量的值就确定下来，故上面程序最终的结果都为true。\n\n例4:\nString a = &quot;ab&quot;;String bb = &quot;b&quot;;String b = &quot;a&quot; + bb;System.out.println(a == b); // false\n\n分析：JVM对于字符串引用，由于在字符串的”+”连接中，有字符串引用存在，而引用的值在程序编译期是无法确定的，即”a” + bb无法被编译器优化，只有在程序运行期来动态分配并将连接后的新地址赋给b。所以上面程序的结果也就为false。\n\n例5：\nString a = &quot;ab&quot;;final String bb = &quot;b&quot;;String b = &quot;a&quot; + bb;System.out.println(a == b); // true\n\n分析：和示例4中唯一不同的是bb字符串加了final修饰，对于final修饰的变量，它在编译时被解析为常量值的一个本地拷贝存储到自己的常量池中或嵌入到它的字节码流中。所以此时的”a” + bb和”a” + “b”效果是一样的。故上面程序的结果为true。\n\n例6：\nString a = &quot;ab&quot;;final String bb = getBB();String b = &quot;a&quot; + bb;System.out.println(a == b); // falseprivate static String getBB() &#123;      return &quot;b&quot;;  &#125;\n\n分析：JVM对于字符串引用bb，它的值在编译期无法确定，只有在程序运行期调用方法后，将方法的返回值和”a”来动态连接并分配地址为b，故上面 程序的结果为false。\n\n例7：\nString  s  =  &quot;a&quot; + &quot;b&quot; + &quot;c&quot;;  //就等价于String s = &quot;abc&quot;;String  a  =  &quot;a&quot;;String  b  =  &quot;b&quot;;String  c  =  &quot;c&quot;;String  s1  =   a  +  b  +  c;System.out.println(s == s1); // false\n\n s1 这个就不一样了，可以通过观察其JVM指令码发现s1的”+”操作会变成如下操作：\nStringBuilder temp = new StringBuilder();temp.append(a).append(b).append(c);String s = temp.toString();\n最后的例子：\n//字符串常量池：&quot;计算机&quot;和&quot;技术&quot;     堆内存：str1引用的对象&quot;计算机技术&quot;  //堆内存中还有个StringBuilder的对象，但是会被gc回收，StringBuilder的toString方法会new String()，这个String才是真正返回的对象引用String str2 = new StringBuilder(&quot;计算机&quot;).append(&quot;技术&quot;).toString();   //没有出现&quot;计算机技术&quot;字面量，所以不会在常量池里生成&quot;计算机技术&quot;对象System.out.println(str2 == str2.intern());  //true//&quot;计算机技术&quot; 在池中没有，但是在heap中存在，则intern时，会直接返回该heap中的引用//字符串常量池：&quot;ja&quot;和&quot;va&quot;     堆内存：str1引用的对象&quot;java&quot;  //堆内存中还有个StringBuilder的对象，但是会被gc回收，StringBuilder的toString方法会new String()，这个String才是真正返回的对象引用String str1 = new StringBuilder(&quot;ja&quot;).append(&quot;va&quot;).toString();    //没有出现&quot;java&quot;字面量，所以不会在常量池里生成&quot;java&quot;对象System.out.println(str1 == str1.intern());  //false//java是关键字，在JVM初始化的相关类里肯定早就放进字符串常量池了String s1=new String(&quot;test&quot;);  System.out.println(s1==s1.intern());   //false//&quot;test&quot;作为字面量，放入了池中，而new时s1指向的是heap中新生成的string对象，s1.intern()指向的是&quot;test&quot;字面量之前在池中生成的字符串对象String s2=new StringBuilder(&quot;abc&quot;).toString();System.out.println(s2==s2.intern());  //false//同上\n\n八种基本类型的包装类和对象池java中基本类型的包装类的大部分都实现了常量池技术(严格来说应该叫对象池，在堆上)，这些类是Byte,Short,Integer,Long,Character,Boolean,另外两种浮点数类型的包装类则没有实现。另外Byte,Short,Integer,Long,Character这5种整型的包装类也只是在对应值小于等于127时才可使用对象池，也即对象不负责创建和管理大于127的这些类的对象。因为一般这种比较小的数用到的概率相对较大。\npublic class Test &#123;    public static void main(String[] args) &#123;        //5种整形的包装类Byte,Short,Integer,Long,Character的对象，          //在值小于127时可以使用对象池          Integer i1 = 127;  //这种调用底层实际是执行的Integer.valueOf(127)，里面用到了IntegerCache对象池        Integer i2 = 127;        System.out.println(i1 == i2);//输出true          //值大于127时，不会从对象池中取对象          Integer i3 = 128;        Integer i4 = 128;        System.out.println(i3 == i4);//输出false          //用new关键词新生成对象不会使用对象池        Integer i5 = new Integer(127);          Integer i6 = new Integer(127);        System.out.println(i5 == i6);//输出false         //Boolean类也实现了对象池技术          Boolean bool1 = true;        Boolean bool2 = true;        System.out.println(bool1 == bool2);//输出true          //浮点类型的包装类没有实现对象池技术          Double d1 = 1.0;        Double d2 = 1.0;        System.out.println(d1 == d2);//输出false      &#125;&#125; \n\nJVM内存参数设置\nSpring Boot程序的JVM参数设置格式(Tomcat启动直接加在bin目录下catalina.sh文件里)：\njava -Xms2048M -Xmx2048M -Xmn1024M -Xss512K -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M -jar microservice-eureka-server.jar\n\n-Xss：每个线程的栈大小-Xms：初始堆大小，默认物理内存的1/64-Xmx：最大堆大小，默认物理内存的1/4-Xmn：新生代大小-XX:NewSize：设置新生代初始大小-XX:NewRatio：默认2表示新生代占年老代的1/2，占整个堆内存的1/3。-XX:SurvivorRatio：默认8表示一个survivor区占用1/8的Eden内存，即1/10的新生代内存。关于元空间的JVM参数有两个：-XX:MetaspaceSize=N和 -XX:MaxMetaspaceSize=N-XX：MaxMetaspaceSize： 设置元空间最大值， 默认是-1， 即不限制， 或者说只受限于本地内存大小。-XX：MetaspaceSize： 指定元空间触发Fullgc的初始阈值(元空间无固定初始大小)。\n\n\n元空间大小如果不进行设置的话，默认大小是21M左右，达到该值就会触发full  gc进行类型卸载，同时收集器会对该值进行调整：如果释放了大量的空间，就适当降低该值；如果释放了很少的空间，那么在不超过-XX：MaxMetaspaceSize（如果设置了的话）的情况下，适当提高该值。这个跟早期jdk版本的**-XX:PermSize**参数意思不一样，-XX:PermSize代表永久代的初始容量。\n由于调整元空间的大小需要Full GC，这是非常昂贵的操作，如果应用在启动的时候发生大量Full GC，通常都是由于永久代或元空间发生了大小调整，基于这种情况，一般建议在JVM参数中将MetaspaceSize和MaxMetaspaceSize设置成一样的值，并设置得比初始值要大，对于8G物理内存的机器来说，一般我会将这两个值都设置为256M。\n-Xss设置越小count值越小，说明一个线程栈里能分配的栈帧就越少，但是对JVM整体来说能开启的线程数会更多。\n\nJVM内存参数大小该如何设置？\nJVM参数大小设置并没有固定标准，就是尽可能让对象都在新生代里分配和回收，尽量别让太多对象频繁进入老年代，避免频繁对老年代进行垃圾回收，同时给系统充足的内存大小，避免新生代频繁的进行垃圾回收。\n订单交易系统如何设置JVM参数\n结论： \n尽可能让对象都在新生代里分配和回收，尽量别让太多对象频繁进入老年代，避免频繁对老年代进行垃圾回收，同时给系统充足的内存大小，避免新生代频繁的进行垃圾回收。\n","categories":["Java"],"tags":["JVM"]},{"title":"JVM对象创建与内存分配机制深度剖析","url":"/2020/07/04/Java/JVM/JVM%E5%AF%B9%E8%B1%A1%E5%88%9B%E5%BB%BA%E4%B8%8E%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%E6%B7%B1%E5%BA%A6%E5%89%96%E6%9E%90/","content":"对象的创建对象创建的主要流程:\n\n类加载检查虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。new指令对应到语言层面上讲是，new关键词、对象克隆、对象序列化等。\n分配内存在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需内存的大小在类 加载完成后便可完全确定，为对象分配空间的任务等同于把 一块确定大小的内存从Java堆中划分出来。这个步骤有两个问题：\n\n如何划分内存。\n在并发情况下， 可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。\n\n划分内存的方法\n“指针碰撞”（Bump the Pointer）(默认用指针碰撞)\n如果Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离。\n\n“空闲列表”（Free List）\n如果Java堆中的内存并不是规整的，已使用的内存和空 闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记 录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例， 并更新列表上的记录。\n\n\n解决并发问题的方法\nCAS（compare and swap）\n虚拟机采用CAS配上失败重试的方式保证更新操作的原子性来对分配内存空间的动作进行同步处理。\n\n本地线程分配缓冲（Thread Local Allocation Buffer,TLAB）\n把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存。通过-XX:+/-UseTLAB参数来设定虚拟机是否使用TLAB(JVM会默认开启-XX:+UseTLAB)，-XX:TLABSize 指定TLAB大小。\n\n\n初始化零值内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头）， 如果使用TLAB，这一工作过程也可以提前至TLAB分配时进行。这一步操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。\n设置对象头初始化零值之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。这些信息存放在对象的对象头Object Header之中。\n在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：对象头（Header）、 实例数据（Instance Data）和对齐填充（Padding）。 HotSpot虚拟机的对象头包括两部分信息，第一部分用于存储对象自身的运行时数据， 如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时 间戳等。对象头的另外一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。\n\n32位对象头\n\n\n\n64位对象头\n\n\n对象头在hotspot的C++源码markOop.hpp文件里的注释如下：\n// Bit-format of an object header (most significant first, big endian layout below):////  32 bits://  --------//             hash:25 ------------&gt;| age:4    biased_lock:1 lock:2 (normal object)//             JavaThread*:23 epoch:2 age:4    biased_lock:1 lock:2 (biased object)//             size:32 ------------------------------------------&gt;| (CMS free block)//             PromotedObject*:29 ----------&gt;| promo_bits:3 -----&gt;| (CMS promoted object)////  64 bits://  --------//  unused:25 hash:31 --&gt;| unused:1   age:4    biased_lock:1 lock:2 (normal object)//  JavaThread*:54 epoch:2 unused:1   age:4    biased_lock:1 lock:2 (biased object)//  PromotedObject*:61 ---------------------&gt;| promo_bits:3 -----&gt;| (CMS promoted object)//  size:64 -----------------------------------------------------&gt;| (CMS free block)////  unused:25 hash:31 --&gt;| cms_free:1 age:4    biased_lock:1 lock:2 (COOPs &amp;&amp; normal object)//  JavaThread*:54 epoch:2 cms_free:1 age:4    biased_lock:1 lock:2 (COOPs &amp;&amp; biased object)//  narrowOop:32 unused:24 cms_free:1 unused:4 promo_bits:3 -----&gt;| (COOPs &amp;&amp; CMS promoted object)//  unused:21 size:35 --&gt;| cms_free:1 unused:7 ------------------&gt;| (COOPs &amp;&amp; CMS free block)\n\n执行init方法执行方法，即对象按照程序员的意愿进行初始化。对应到语言层面上讲，就是为属性赋值（注意，这与上面的赋零值不同，这是由程序员赋的值），和执行构造方法。\n对象大小与指针压缩对象大小可以用jol-core包查看，引入依赖\n&lt;dependency&gt;    &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt;    &lt;artifactId&gt;jol-core&lt;/artifactId&gt;    &lt;version&gt;0.9&lt;/version&gt;&lt;/dependency&gt;\n\nimport org.openjdk.jol.info.ClassLayout;/*** 计算对象大小*/public class JOLSample &#123;    public static void main(String[] args) &#123;        ClassLayout layout = ClassLayout.parseInstance(new Object());        System.out.println(layout.toPrintable());        System.out.println();        ClassLayout layout1 = ClassLayout.parseInstance(new int[]&#123;&#125;);        System.out.println(layout1.toPrintable());        System.out.println();        ClassLayout layout2 = ClassLayout.parseInstance(new A());        System.out.println(layout2.toPrintable());    &#125;    // -XX:+UseCompressedOops           默认开启的压缩所有指针    // -XX:+UseCompressedClassPointers  默认开启的压缩对象头里的类型指针Klass Pointer    // Oops : Ordinary Object Pointers    public static class A &#123;        //8B mark word        //4B Klass Pointer   如果关闭压缩-XX:-UseCompressedClassPointers或-XX:-UseCompressedOops，则占用8B        int id;        //4B        String name;   //4B  如果关闭压缩-XX:-UseCompressedOops，则占用8B        byte b;        //1B         Object o;      //4B  如果关闭压缩-XX:-UseCompressedOops，则占用8B    &#125;&#125;运行结果：java.lang.Object object internals:OFFSET  SIZE   TYPE DESCRIPTION                          VALUE    0     4        (object header)                       01 00 00 00 (00000001 00000000 00000000 00000000) (1)    //mark word    4     4        (object header)                       00 00 00 00 (00000000 00000000 00000000 00000000) (0)    //mark word         8     4        (object header)                       e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243)    //Klass Pointer    12     4        (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total[I object internals: OFFSET  SIZE   TYPE DESCRIPTION                          VALUE 0     4        (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4     4        (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8     4        (object header)                           6d 01 00 f8 (01101101 00000001 00000000 11111000) (-134217363) 12     4        (object header)                          00 00 00 00 (00000000 00000000 00000000 00000000) (0) 16     0    int [I.&lt;elements&gt;                            N/AInstance size: 16 bytesSpace losses: 0 bytes internal + 0 bytes external = 0 bytes totalcom.tuling.jvm.JOLSample$A object internals:OFFSET  SIZE               TYPE DESCRIPTION                 VALUE  0     4                    (object header)                01 00 00 00 (00000001 00000000 00000000 00000000) (1)  4     4                    (object header)                00 00 00 00 (00000000 00000000 00000000 00000000) (0)  8     4                    (object header)                61 cc 00 f8 (01100001 11001100 00000000 11111000) (-134165407) 12     4                  int A.id                         0 16     1                  byte A.b                         0 17     3                  (alignment/padding gap)                   20     4                  java.lang.String A.name          null 24     4                  java.lang.Object A.o             null 28     4                  (loss due to the next object alignment)Instance size: 32 bytesSpace losses: 3 bytes internal + 4 bytes external = 7 bytes total\n\n什么是java对象的指针压缩？\njdk1.6 update14开始，在64bit操作系统中，JVM支持指针压缩\njvm配置参数:UseCompressedOops，compressed–压缩、oop(ordinary object pointer)–对象指针\n启用指针压缩:-XX:+UseCompressedOops(默认开启)，禁止指针压缩:-XX:-UseCompressedOops\n\n为什么要进行指针压缩？\n在64位平台的HotSpot中使用32位指针(实际存储用64位)，内存使用会多出1.5倍左右，使用较大指针在主内存和缓存之间移动数据，占用较大宽带，同时GC也会承受较大压力。\n为了减少64位平台下内存的消耗，启用指针压缩功能。\n在jvm中，32位地址最大支持4G内存(2的32次方)，可以通过对对象指针的存入堆内存时压缩编码、取出到cpu寄存器后解码方式进行优化(对象指针在堆中是32位，在寄存器中是35位，2的35次方=32G)，使得jvm只用32位地址就可以支持更大的内存配置(小于等于32G)。\n堆内存小于4G时，不需要启用指针压缩，jvm会直接去除高32位地址，即使用低虚拟地址空间。\n堆内存大于32G时，压缩指针会失效，会强制使用64位(即8字节)来对java对象寻址，这就会出现i的问题，所以堆内存不要大于32G为好。\n\n关于对齐填充对于大部分处理器，对象以8字节整数倍来对齐填充都是最高效的存取方式。\n对象内存分配对象内存分配流程图\n对象栈上分配我们通过JVM内存分配可以知道JAVA中的对象都是在堆上进行分配，当对象没有被引用的时候，需要依靠GC进行回收内存，如果对象数量较多的时候，会给GC带来较大压力，也间接影响了应用的性能。为了减少临时对象在堆内分配的数量，JVM通过逃逸分析确定该对象不会被外部访问。如果不会逃逸可以将该对象在栈上分配内存，这样该对象所占用的内存空间就可以随栈帧出栈而销毁，就减轻了垃圾回收的压力。\n对象逃逸分析就是分析对象动态作用域，当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他地方中。\npublic User test1() &#123;      User user = new User();      user.setId(1);      user.setName(&quot;test&quot;);      //TODO 保存到数据库      return user;&#125;public void test2() &#123;      User user = new User();      user.setId(1);      user.setName(&quot;test&quot;);      //TODO 保存到数据库&#125;\n\n很显然test1方法中的user对象被返回了，这个对象的作用域范围不确定，test2方法中的user对象我们可以确定当方法结束这个对象就可以认为是无效对象了，对于这样的对象我们其实可以将其分配在栈内存里，让其在方法结束时跟随栈内存一起被回收掉。\nJVM对于这种情况可以通过开启逃逸分析参数(-XX:+DoEscapeAnalysis)来优化对象内存分配位置，使其通过标量替换优先分配在栈上(栈上分配)，JDK7之后默认开启逃逸分析，如果要关闭使用参数(-XX:-DoEscapeAnalysis)\n标量替换通过逃逸分析确定该对象不会被外部访问，并且对象可以被进一步分解时，JVM不会创建该对象，而是将该对象成员变量分解若干个被这个方法使用的成员变量所代替，这些代替的成员变量在栈帧或寄存器上分配空间，这样就不会因为没有一大块连续空间导致对象内存不够分配。开启标量替换参数(-XX:+EliminateAllocations)，JDK7之后默认开启。\n标量与聚合量标量即不可被进一步分解的量，而JAVA的基本数据类型就是标量（如：int，long等基本数据类型以及reference类型等），标量的对立就是可以被进一步分解的量，而这种量称之为聚合量。而在JAVA中对象就是可以被进一步分解的聚合量。\n/*** 栈上分配，标量替换* 代码调用了1亿次alloc()，如果是分配到堆上，大概需要1GB以上堆空间，如果堆空间小于该值，必然会触发GC。* * 使用如下参数不会发生GC* -Xmx15m -Xms15m -XX:+DoEscapeAnalysis -XX:+PrintGC -XX:+EliminateAllocations* 使用如下参数都会发生大量GC* -Xmx15m -Xms15m -XX:-DoEscapeAnalysis -XX:+PrintGC -XX:+EliminateAllocations* -Xmx15m -Xms15m -XX:+DoEscapeAnalysis -XX:+PrintGC -XX:-EliminateAllocations*/public class AllotOnStack &#123;    public static void main(String[] args) &#123;        long start = System.currentTimeMillis();        for (int i = 0; i &lt; 100000000; i++) &#123;            alloc();        &#125;        long end = System.currentTimeMillis();        System.out.println(end - start);    &#125;    private static void alloc() &#123;        User user = new User();        user.setId(1);        user.setName(&quot;test&quot;);    &#125;&#125;\n\n结论：栈上分配依赖于逃逸分析和标量替换\n对象在Eden区分配大多数情况下，对象在新生代中 Eden 区分配。当 Eden 区没有足够空间进行分配时，虚拟机将发起一次Minor GC。我们来进行实际测试一下。\n在测试之前我们先来看看 Minor GC和Full GC 有什么不同呢？\n\nMinor GC/Young GC：指发生新生代的的垃圾收集动作，Minor GC非常频繁，回收速度一般也比较快。\n\nMajor GC/Full GC：一般会回收老年代 ，年轻代，方法区的垃圾，Major GC的速度一般会比Minor GC的慢10倍以上。\n\n\nEden与Survivor区默认8:1:1\n大量的对象被分配在eden区，eden区满了后会触发minor gc，可能会有99%以上的对象成为垃圾被回收掉，剩余存活的对象会被挪到为空的那块survivor区，下一次eden区满了后又会触发minor gc，把eden区和survivor区垃圾对象回收，把剩余存活的对象一次性挪动到另外一块为空的survivor区，因为新生代的对象都是朝生夕死的，存活时间很短，所以JVM默认的8:1:1的比例是很合适的，让eden区尽量的大，survivor区够用即可，JVM默认有这个参数-XX:+UseAdaptiveSizePolicy(默认开启)，会导致这个8:1:1比例自动变化，如果不想这个比例有变化可以设置参数-XX:-UseAdaptiveSizePolicy。\n//添加运行JVM参数： -XX:+PrintGCDetailspublic class GCTest &#123;    public static void main(String[] args) throws InterruptedException &#123;        byte[] allocation1, allocation2/*, allocation3, allocation4, allocation5, allocation6*/;        allocation1 = new byte[60000*1024];        //allocation2 = new byte[8000*1024];        /*allocation3 = new byte[1000*1024];\t          allocation4 = new byte[1000*1024];\t          allocation5 = new byte[1000*1024];\t          allocation6 = new byte[1000*1024];*/    &#125;&#125;运行结果：Heap  PSYoungGen      total 76288K, used 65536K [0x000000076b400000, 0x0000000770900000, 0x00000007c0000000)    eden space 65536K, 100% used [0x000000076b400000,0x000000076f400000,0x000000076f400000)    from space 10752K, 0% used [0x000000076fe80000,0x000000076fe80000,0x0000000770900000)    to   space 10752K, 0% used [0x000000076f400000,0x000000076f400000,0x000000076fe80000)  ParOldGen       total 175104K, used 0K [0x00000006c1c00000, 0x00000006cc700000, 0x000000076b400000)    object space 175104K, 0% used [0x00000006c1c00000,0x00000006c1c00000,0x00000006cc700000)  Metaspace       used 3342K, capacity 4496K, committed 4864K, reserved 1056768K    class space    used 361K, capacity 388K, committed 512K, reserved 1048576K\n\n我们可以看出eden区内存几乎已经被分配完全（即使程序什么也不做，新生代也会使用至少几M内存）。假如我们再为allocation2分配内存会出现什么情况呢？\n//添加运行JVM参数： -XX:+PrintGCDetailspublic class GCTest &#123;      public static void main(String[] args) throws InterruptedException &#123;            byte[] allocation1, allocation2/*, allocation3, allocation4, allocation5, allocation6*/;            allocation1 = new byte[60000*1024];            allocation2 = new byte[8000*1024];            /*allocation3 = new byte[1000*1024];              allocation4 = new byte[1000*1024];              allocation5 = new byte[1000*1024];              allocation6 = new byte[1000*1024];*/      &#125;&#125;运行结果：[GC (Allocation Failure) [PSYoungGen: 65253K-&gt;936K(76288K)] 65253K-&gt;60944K(251392K), 0.0279083 secs] [Times: user=0.13 sys=0.02, real=0.03 secs] Heap  PSYoungGen      total 76288K, used 9591K [0x000000076b400000, 0x0000000774900000, 0x00000007c0000000)    eden space 65536K, 13% used [0x000000076b400000,0x000000076bc73ef8,0x000000076f400000)    from space 10752K, 8% used [0x000000076f400000,0x000000076f4ea020,0x000000076fe80000)    to   space 10752K, 0% used [0x0000000773e80000,0x0000000773e80000,0x0000000774900000)  ParOldGen       total 175104K, used 60008K [0x00000006c1c00000, 0x00000006cc700000, 0x000000076b400000)    object space 175104K, 34% used [0x00000006c1c00000,0x00000006c569a010,0x00000006cc700000)  Metaspace       used 3342K, capacity 4496K, committed 4864K, reserved 1056768K    class space    used 361K, capacity 388K, committed 512K, reserved 1048576K\n\n解释一下为什么会出现这种情况： 因为给allocation2分配内存的时候eden区内存几乎已经被分配完了，我们刚刚讲了当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC，GC期间虚拟机又发现allocation1无法存入Survior空间，所以只好把新生代的对象提前转移到老年代中去，老年代上的空间足够存放allocation1，所以不会出现Full GC。执行Minor GC后，后面分配的对象如果能够存在eden区的话，还是会在eden区分配内存。\npublic class GCTest &#123;    public static void main(String[] args) throws InterruptedException &#123;        byte[] allocation1, allocation2, allocation3, allocation4, allocation5, allocation6;        allocation1 = new byte[60000*1024];        allocation2 = new byte[8000*1024];        allocation3 = new byte[1000*1024];        allocation4 = new byte[1000*1024];        allocation5 = new byte[1000*1024];        allocation6 = new byte[1000*1024];    &#125;&#125;运行结果：[GC (Allocation Failure) [PSYoungGen: 65253K-&gt;952K(76288K)] 65253K-&gt;60960K(251392K), 0.0311467 secs] [Times: user=0.08 sys=0.02, real=0.03 secs] Heap  PSYoungGen      total 76288K, used 13878K [0x000000076b400000, 0x0000000774900000, 0x00000007c0000000)    eden space 65536K, 19% used [0x000000076b400000,0x000000076c09fb68,0x000000076f400000)    from space 10752K, 8% used [0x000000076f400000,0x000000076f4ee030,0x000000076fe80000)    to   space 10752K, 0% used [0x0000000773e80000,0x0000000773e80000,0x0000000774900000)  ParOldGen       total 175104K, used 60008K [0x00000006c1c00000, 0x00000006cc700000, 0x000000076b400000)    object space 175104K, 34% used [0x00000006c1c00000,0x00000006c569a010,0x00000006cc700000)  Metaspace       used 3343K, capacity 4496K, committed 4864K, reserved 1056768K    class space    used 361K, capacity 388K, committed 512K, reserved 1048576K\n\n大对象直接进入老年代大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。JVM参数 -XX:PretenureSizeThreshold 可以设置大对象的大小，如果对象超过设置大小会直接进入老年代，不会进入年轻代，这个参数只在 Serial 和ParNew两个收集器下有效。比如设置JVM参数：-XX:PretenureSizeThreshold=1000000 (单位是字节) -XX:+UseSerialGC ，再执行下上面的第一个程序会发现大对象直接进了老年代。为什么要这样呢？为了避免为大对象分配内存时的复制操作而降低效率。\n长期存活的对象将进入老年代既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。为了做到这一点，虚拟机给每个对象一个对象年龄（Age）计数器。如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为1。对象在 Survivor 中每熬过一次 MinorGC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁，CMS收集器默认6岁，不同的垃圾收集器会略微有点不同），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。\n对象动态年龄判断当前放对象的Survivor区域里(其中一块区域，放对象的那块s区)，一批对象的总大小大于这块Survivor区域内存大小的50%(-XX:TargetSurvivorRatio可以指定)，那么此时大于等于这批对象年龄最大值的对象，就可以直接进入老年代了，例如Survivor区域里现在有一批对象，年龄1+年龄2+年龄n的多个年龄对象总和超过了Survivor区域的50%，此时就会把年龄n(含)以上的对象都放入老年代。这个规则其实是希望那些可能是长期存活的对象，尽早进入老年代。对象动态年龄判断机制一般是在minor gc之后触发的。\n老年代空间分配担保机制年轻代每次minor gc之前JVM都会计算下老年代剩余可用空间如果这个可用空间小于年轻代里现有的所有对象大小之和(包括垃圾对象)就会看一个-XX:-HandlePromotionFailure(jdk1.8默认就设置了)的参数是否设置了如果有这个参数，就会看看老年代的可用内存大小，是否大于之前每一次minor gc后进入老年代的对象的平均大小。如果上一步结果是小于或者之前说的参数没有设置，那么就会触发一次Full gc，对老年代和年轻代一起回收一次垃圾，如果回收完还是没有足够空间存放新的对象就会发生”OOM”当然，如果minor gc之后剩余存活的需要挪动到老年代的对象大小还是大于老年代可用空间，那么也会触发full gc，full gc完之后如果还是没有空间放minor gc之后的存活对象，则也会发生“OOM”\n\n对象内存回收堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断哪些对象已经死亡（即不能再被任何途径使用的对象）。\n引用计数法给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加1；当引用失效，计数器就减1；任何时候计数器为0的对象就是不可能再被使用的。这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。 所谓对象之间的相互引用问题，如下面代码所示：除了对象objA 和 objB 相互引用着对方之外，这两个对象之间再无任何引用。但是他们因为互相引用对方，导致它们的引用计数器都不为0，于是引用计数算法无法通知 GC 回收器回收他们。\npublic class ReferenceCountingGc &#123;    Object instance = null;    public static void main(String[] args) &#123;        ReferenceCountingGc objA = new ReferenceCountingGc();        ReferenceCountingGc objB = new ReferenceCountingGc();        objA.instance = objB;        objB.instance = objA;        objA = null;        objB = null;    &#125;&#125;\n\n可达性分析算法将“GC Roots” 对象作为起点，从这些节点开始向下搜索引用的对象，找到的对象都标记为非垃圾对象，其余未标记的对象都是垃圾对象GC Roots根节点：线程栈的本地变量、静态变量、本地方法栈的变量等等\n\n常见引用类型java的引用类型一般分为四种：强引用、软引用、弱引用、虚引用\n\n强引用普通的变量引用\npublic static User user = new User();\n软引用将对象用SoftReference软引用类型的对象包裹，正常情况不会被回收，但是GC做完后发现释放不出空间存放新的对象，则会把这些软引用的对象回收掉。软引用可用来实现内存敏感的高速缓存。\npublic static SoftReference&lt;User&gt; user = new SoftReference&lt;User&gt;(new User());\n软引用在实际中有重要的应用，例如浏览器的后退按钮。按后退时，这个后退时显示的网页内容是重新进行请求还是从缓存中取出呢？这就要看具体的实现策略了。\n\n如果一个网页在浏览结束时就进行内容的回收，则按后退查看前面浏览过的页面时，需要重新构建\n如果将浏览过的网页存储到内存中会造成内存的大量浪费，甚至会造成内存溢出\n\n\n弱引用\n将对象用WeakReference软引用类型的对象包裹，弱引用跟没引用差不多，GC会直接回收掉，很少用。\npublic static WeakReference&lt;User&gt; user = new WeakReference&lt;User&gt;(new User());\n\nThreadLocal中定义了ThreadLocalMap,其中ThreadLocalMap中定义的entry的key便是WeakReference\nstatic class ThreadLocalMap &#123;    /**         * The entries in this hash map extend WeakReference, using         * its main ref field as the key (which is always a         * ThreadLocal object).  Note that null keys (i.e. entry.get()         * == null) mean that the key is no longer referenced, so the         * entry can be expunged from table.  Such entries are referred to         * as &quot;stale entries&quot; in the code that follows.         */    static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123;        /** The value associated with this ThreadLocal. */        Object value;        Entry(ThreadLocal&lt;?&gt; k, Object v) &#123;            super(k);            value = v;        &#125;    &#125;\n虚引用\n虚引用也称为幽灵引用或者幻影引用，它是最弱的一种引用关系，几乎不用\n\n\nfinalize()方法最终判定对象是否存活即使在可达性分析算法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历再次标记过程。\n标记的前提是对象在进行可达性分析后发现没有与GC Roots相连接的引用链。\n\n第一次标记并进行一次筛选\n筛选的条件是此对象是否有必要执行finalize()方法。\n当对象没有覆盖finalize方法，对象将直接被回收。\n\n第二次标记如果这个对象覆盖了finalize方法，finalize方法是对象脱逃死亡命运的最后一次机会，如果对象要在finalize()中成功拯救自己，只要重新与引用链上的任何的一个对象建立关联即可，譬如把自己赋值给某个类变量或对象的成员变量，那在第二次标记时它将移除出“即将回收”的集合。如果对象这时候还没逃脱，那基本上它就真的被回收了。注意：一个对象的finalize()方法只会被执行一次，也就是说通过调用finalize方法自我救命的机会就一次。\n\n\npublic class OOMTest &#123;    public static void main(String[] args) &#123;        List&lt;Object&gt; list = new ArrayList&lt;&gt;();        int i = 0;        int j = 0;        while (true) &#123;            list.add(new User(i++, UUID.randomUUID().toString()));            new User(j--, UUID.randomUUID().toString());        &#125;    &#125;&#125;//User类需要重写finalize方法@Overrideprotected void finalize() throws Throwable &#123;        OOMTest.list.add(this);        System.out.println(&quot;关闭资源，userid=&quot; + id + &quot;即将被回收&quot;);&#125;\n\nfinalize()方法的运行代价高昂，不确定性大，无法保证各个对象的调用顺序， 如今已被官方明确声明为不推荐使用的语法。 有些资料描述它适合做“关闭外部资源”之类的清理性工作， 这完全是对finalize()方法用途的一种自我安慰。 finalize()能做的所有工作， 使用try-finally或者其他方式都可以做得更好、更及时，所以建议完全可以忘掉Java语言里面的这个方法。\n如何判断一个类是无用的类方法区主要回收的是无用的类，那么如何判断一个类是无用的类呢？类需要同时满足下面3个条件才能算是 “无用的类” ：\n\n该类所有的对象实例都已经被回收，也就是Java堆中不存在该类的任何实例。\n加载该类的ClassLoader已经被回收。\n该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。\n\n","categories":["Java"],"tags":["JVM"]},{"title":"JVM类加载机制","url":"/2020/06/25/Java/JVM/JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/","content":"类加载运行全过程当我们用java命令运行某个类的main函数启动程序时，首先需要通过类加载器把主类加载到JVM。\npackage com.jvm;public class Math &#123;        public static final int initData = 666;        public static User user = new User();        public int compute() &#123;  //一个方法对应一块栈帧内存区域                int a = 1;                int b = 2;                int c = (a + b) * 10;                return c;        &#125;        public static void main(String[] args) &#123;                Math math = new Math();                math.compute();        &#125;&#125;\n\n通过Java命令执行代码的大体流程如下：\n\n其中loadClass的类加载过程有如下几步：\n加载 &gt;&gt; 验证 &gt;&gt; 准备 &gt;&gt; 解析 &gt;&gt; 初始化 &gt;&gt; 使用 &gt;&gt; 卸载\n\n加载：在硬盘上查找并通过IO读入字节码文件，使用到类时才会加载，例如调用类的main()方法，new对象等等，在加载阶段会在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口\n验证：校验字节码文件的正确性\n准备：给类的静态变量分配内存，并赋予默认值\n解析：将符号引用替换为直接引用，该阶段会把一些静态方法(符号引用，比如main()方法)替换为指向数据所存内存的指针或句柄等(直接引用)，这是所谓的静态链接过程(类加载期间完成)，动态链接是在程序运行期间完成的将符号引用替换为直接引用，下节课会讲到动态链接\n初始化：对类的静态变量初始化为指定的值，执行静态代码块\n\n\n类被加载到方法区中后主要包含 运行时常量池、类型信息、字段信息、方法信息、类加载器的引用、对应class实例的引用等信息。\n类加载器的引用：这个类到类加载器实例的引用\n对应class实例的引用：类加载器在加载类信息放到方法区中后，会创建一个对应的Class 类型的对象实例放到堆(Heap)中, 作为开发人员访问方法区中类定义的入口和切入点。\n注意：主类在运行过程中如果使用到其它类，会逐步加载这些类。jar包或war包里的类不是一次性全部加载的，是使用到时才加载。\npublic class TestDynamicLoad &#123;        static &#123;                System.out.println(&quot;*************load TestDynamicLoad************&quot;);        &#125;        public static void main(String[] args) &#123;                new A();                System.out.println(&quot;*************load test************&quot;);                B b = null;  //B不会加载，除非这里执行 new B()        &#125;&#125;class A &#123;        static &#123;                System.out.println(&quot;*************load A************&quot;);        &#125;        public A() &#123;                System.out.println(&quot;*************initial A************&quot;);        &#125;&#125;class B &#123;        static &#123;                System.out.println(&quot;*************load B************&quot;);        &#125;        public B() &#123;                System.out.println(&quot;*************initial B************&quot;);        &#125;&#125;运行结果：*************load TestDynamicLoad*************************load A*************************initial A*************************load test************\n\n\n\n类加载器和双亲委派机制上面的类加载过程主要是通过类加载器来实现的，Java里有如下几种类加载器\n\n引导类加载器：负责加载支撑JVM运行的位于JRE的lib目录下的核心类库，比如rt.jar、charsets.jar等(C++实现)\n扩展类加载器：负责加载支撑JVM运行的位于JRE的lib目录下的ext扩展目录中的JAR类包\n应用程序类加载器：负责加载ClassPath路径下的类包，主要就是加载你自己写的那些类\n自定义加载器：负责加载用户自定义路径下的类包\n\n看一个类加载器示例：\npublic class TestJDKClassLoader &#123;        public static void main(String[] args) &#123;                System.out.println(String.class.getClassLoader());                System.out.println(com.sun.crypto.provider.DESKeyFactory.class.getClassLoader().getClass().getName());                System.out.println(TestJDKClassLoader.class.getClassLoader().getClass().getName());                System.out.println();                ClassLoader appClassLoader = ClassLoader.getSystemClassLoader();                ClassLoader extClassloader = appClassLoader.getParent();                ClassLoader bootstrapLoader = extClassloader.getParent();                System.out.println(&quot;the bootstrapLoader : &quot; + bootstrapLoader);                System.out.println(&quot;the extClassloader : &quot; + extClassloader);                System.out.println(&quot;the appClassLoader : &quot; + appClassLoader);                System.out.println();                System.out.println(&quot;bootstrapLoader加载以下文件：&quot;);                URL[] urls = Launcher.getBootstrapClassPath().getURLs();                for (int i = 0; i &lt; urls.length; i++) &#123;                        System.out.println(urls[i]);                &#125;                System.out.println();                System.out.println(&quot;extClassloader加载以下文件：&quot;);                System.out.println(System.getProperty(&quot;java.ext.dirs&quot;));                System.out.println();                System.out.println(&quot;appClassLoader加载以下文件：&quot;);                System.out.println(System.getProperty(&quot;java.class.path&quot;));        &#125;&#125;运行结果:nullsun.misc.Launcher$ExtClassLoadersun.misc.Launcher$AppClassLoaderthe bootstrapLoader : nullthe extClassloader : sun.misc.Launcher$ExtClassLoader@238d68ffthe appClassLoader : sun.misc.Launcher$AppClassLoader@6d06d69cbootstrapLoader加载以下文件：file:/D:/jdk1.8/jdk1.8.0_261/jre/lib/resources.jarfile:/D:/jdk1.8/jdk1.8.0_261/jre/lib/rt.jarfile:/D:/jdk1.8/jdk1.8.0_261/jre/lib/sunrsasign.jarfile:/D:/jdk1.8/jdk1.8.0_261/jre/lib/jsse.jarfile:/D:/jdk1.8/jdk1.8.0_261/jre/lib/jce.jarfile:/D:/jdk1.8/jdk1.8.0_261/jre/lib/charsets.jarfile:/D:/jdk1.8/jdk1.8.0_261/jre/lib/jfr.jarfile:/D:/jdk1.8/jdk1.8.0_261/jre/classesextClassloader加载以下文件：D:\\jdk1.8\\jdk1.8.0_261\\jre\\lib\\ext;C:\\WINDOWS\\Sun\\Java\\lib\\extappClassLoader加载以下文件：C:\\Users\\chay\\AppData\\Local\\Temp\\gradle-javaexec-classpath676837739031002977.jar\n\n\n\n类加载器初始化过程参见类运行加载全过程图可知其中会创建JVM启动器实例sun.misc.Launcher。\n在Launcher构造方法内部，其创建了两个类加载器，分别是sun.misc.Launcher.ExtClassLoader(扩展类加载器)和sun.misc.Launcher.AppClassLoader(应用类加载器)。JVM默认使用Launcher的getClassLoader()方法返回的类加载器AppClassLoader的实例加载我们的应用程序。\n//Launcher的构造方法public Launcher() &#123;        Launcher.ExtClassLoader var1;        try &#123;                //构造扩展类加载器，在构造的过程中将其父加载器设置为null                var1 = Launcher.ExtClassLoader.getExtClassLoader();        &#125; catch (IOException var10) &#123;                throw new InternalError(&quot;Could not create extension class loader&quot;, var10);        &#125;        try &#123;                //构造应用类加载器，在构造的过程中将其父加载器设置为ExtClassLoader，                //Launcher的loader属性值是AppClassLoader，我们一般都是用这个类加载器来加载我们自己写的应用程序                this.loader = Launcher.AppClassLoader.getAppClassLoader(var1);        &#125; catch (IOException var9) &#123;                throw new InternalError(&quot;Could not create application class loader&quot;, var9);        &#125;        Thread.currentThread().setContextClassLoader(this.loader);        String var2 = System.getProperty(&quot;java.security.manager&quot;);        。。。 。。。 //省略一些不需关注代码&#125;\n\n\n\n双亲委派机制\n这里类加载其实就有一个双亲委派机制，加载某个类时会先委托父加载器寻找目标类，找不到再委托上层父加载器加载，如果所有父加载器在自己的加载类路径下都找不到目标类，则在自己的类加载路径中查找并载入目标类。\n比如我们的Math类，最先会找应用程序类加载器加载，应用程序类加载器会先委托扩展类加载器加载，扩展类加载器再委托引导类加载器，顶层引导类加载器在自己的类加载路径里找了半天没找到Math类，则向下退回加载Math类的请求，扩展类加载器收到回复就自己加载，在自己的类加载路径里找了半天也没找到Math类，又向下退回Math类的加载请求给应用程序类加载器，应用程序类加载器于是在自己的类加载路径里找Math类，结果找到了就自己加载了。。\n双亲委派机制说简单点就是，先找父亲加载，不行再由儿子自己加载\n我们来看下应用程序类加载器AppClassLoader加载类的双亲委派机制源码，AppClassLoader的loadClass方法最终会调用其父类ClassLoader的loadClass方法，该方法的大体逻辑如下：\n\n首先，检查一下指定名称的类是否已经加载过，如果加载过了，就不需要再加载，直接返回。\n如果此类没有加载过，那么，再判断一下是否有父加载器；如果有父加载器，则由父加载器加载（即调用parent.loadClass(name,false);）.或者是调用bootstrap类加载器来加载。\n如果父加载器及bootstrap类加载器都没有找到指定的类，那么调用当前类加载器的findClass方法来完成类加载。\n\n//ClassLoader的loadClass方法，里面实现了双亲委派机制protected Class&lt;?&gt; loadClass(String name, boolean resolve)        throws ClassNotFoundException&#123;        synchronized (getClassLoadingLock(name)) &#123;                // 检查当前类加载器是否已经加载了该类                Class&lt;?&gt; c = findLoadedClass(name);                if (c == null) &#123;                        long t0 = System.nanoTime();                        try &#123;                                if (parent != null) &#123;  //如果当前加载器父加载器不为空则委托父加载器加载该类                                        c = parent.loadClass(name, false);                                &#125; else &#123;  //如果当前加载器父加载器为空则委托引导类加载器加载该类                                        c = findBootstrapClassOrNull(name);                                &#125;                        &#125; catch (ClassNotFoundException e) &#123;                                // ClassNotFoundException thrown if class not found                                // from the non-null parent class loader                        &#125;                        if (c == null) &#123;                                // If still not found, then invoke findClass in order                                // to find the class.                                long t1 = System.nanoTime();                                //都会调用URLClassLoader的findClass方法在加载器的类路径里查找并加载该类                                c = findClass(name);                                // this is the defining class loader; record the stats                                sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);                                sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);                                sun.misc.PerfCounter.getFindClasses().increment();                        &#125;                &#125;                if (resolve) &#123;  //不会执行                        resolveClass(c);                &#125;                return c;        &#125;&#125;\n\n为什么要设计双亲委派机制？\n\n沙箱安全机制：自己写的java.lang.String.class类不会被加载，这样便可以防止核心API库被随意篡改\n\n避免类的重复加载：当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次，保证被加载类的唯一性\n\n我们写的web代码，大部分都需要由应用程序类加载器进行加载，如果加载类由上至下进行寻找加载的话，在获取类的时候也需要由上之下进行获取，在获取类的时候，浪费时间。而双亲委派机制是在类加载的时候浪费时间，在获取类的时候，大部分类可以直接获取到。\n\n\n看一个类加载示例：\npackage java.lang;public class String &#123;        public static void main(String[] args) &#123;                System.out.println(&quot;**************My String Class**************&quot;);        &#125;&#125;运行结果：    错误: 在类 java.lang.String 中找不到 main 方法, 请将 main 方法定义为:public static void main(String[] args)    否则 JavaFX 应用程序类必须扩展javafx.application.Application\n\n全盘负责委托机制\n“全盘负责”是指当一个ClassLoder装载一个类时，除非显示的使用另外一个ClassLoder，该类所依赖及引用的类也由这个ClassLoder载入。\n自定义类加载器示例：\n自定义类加载器只需要继承 java.lang.ClassLoader 类，该类有两个核心方法，一个是loadClass(String, boolean)，实现了双亲委派机制，还有一个方法是findClass，默认实现是空方法，所以我们自定义类加载器主要是重写findClass方法。\npublic class MyClassLoaderTest &#123;        static class MyClassLoader extends ClassLoader &#123;                private String classPath;                public MyClassLoader(String classPath) &#123;                        this.classPath = classPath;                &#125;                private byte[] loadByte(String name) throws Exception &#123;                        name = name.replaceAll(&quot;\\\\.&quot;, &quot;/&quot;);                        FileInputStream fis = new FileInputStream(classPath + &quot;/&quot; + name                                        + &quot;.class&quot;);                        int len = fis.available();                        byte[] data = new byte[len];                        fis.read(data);                        fis.close();                        return data;                &#125;                protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123;                        try &#123;                                byte[] data = loadByte(name);                                //defineClass将一个字节数组转为Class对象，这个字节数组是class文件读取后最终的字节数组。                                return defineClass(name, data, 0, data.length);                        &#125; catch (Exception e) &#123;                                e.printStackTrace();                                throw new ClassNotFoundException();                        &#125;                &#125;        &#125;        public static void main(String args[]) throws Exception &#123;                //初始化自定义类加载器，会先初始化父类ClassLoader，其中会把自定义类加载器的父加载器设置为应用程序类加载器AppClassLoader                MyClassLoader classLoader = new MyClassLoader(&quot;D:/test&quot;);                //D盘创建 test/com/test/jvm 几级目录，将User类的复制类User1.class丢入该目录                Class clazz = classLoader.loadClass(&quot;com.test.jvm.User1&quot;);                Object obj = clazz.newInstance();                Method method = clazz.getDeclaredMethod(&quot;sout&quot;, null);                method.invoke(obj, null);                System.out.println(clazz.getClassLoader().getClass().getName());        &#125;&#125;运行结果：    =======自己的加载器加载类调用方法=======    com.test.jvm.MyClassLoaderTest$MyClassLoader\n\n打破双亲委派机制再来一个沙箱安全机制示例，尝试打破双亲委派机制，用自定义类加载器加载我们自己实现的 java.lang.String.class\npublic class MyClassLoaderTest &#123;    static class MyClassLoader extends ClassLoader &#123;        private String classPath;        public MyClassLoader(String classPath) &#123;            this.classPath = classPath;        &#125;        private byte[] loadByte(String name) throws Exception &#123;            name = name.replaceAll(&quot;\\\\.&quot;, &quot;/&quot;);            FileInputStream fis = new FileInputStream(classPath + &quot;/&quot; + name                                                      + &quot;.class&quot;);            int len = fis.available();            byte[] data = new byte[len];            fis.read(data);            fis.close();            return data;        &#125;        protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123;            try &#123;                byte[] data = loadByte(name);                return defineClass(name, data, 0, data.length);            &#125; catch (Exception e) &#123;                e.printStackTrace();                throw new ClassNotFoundException();            &#125;        &#125;        /**          * 重写类加载方法，实现自己的加载逻辑，不委派给双亲加载          * @param name          * @param resolve          * @return          * @throws ClassNotFoundException        */        protected Class&lt;?&gt; loadClass(String name, boolean resolve)            throws ClassNotFoundException &#123;            synchronized (getClassLoadingLock(name)) &#123;                // First, check if the class has already been loaded                Class&lt;?&gt; c = findLoadedClass(name);                if (c == null) &#123;                    // If still not found, then invoke findClass in order                    // to find the class.                    long t1 = System.nanoTime();                    c = findClass(name);                    // this is the defining class loader; record the stats                    sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);                    sun.misc.PerfCounter.getFindClasses().increment();                &#125;                if (resolve) &#123;                    resolveClass(c);                &#125;                return c;            &#125;        &#125;    &#125;    public static void main(String args[]) throws Exception &#123;        MyClassLoader classLoader = new MyClassLoader(&quot;D:/test&quot;);        //尝试用自己改写类加载机制去加载自己写的java.lang.String.class        Class clazz = classLoader.loadClass(&quot;java.lang.String&quot;);        Object obj = clazz.newInstance();        Method method= clazz.getDeclaredMethod(&quot;sout&quot;, null);        method.invoke(obj, null);        System.out.println(clazz.getClassLoader().getClass().getName());    &#125;&#125;运行结果：    java.lang.SecurityException: Prohibited package name: java.lang        at java.lang.ClassLoader.preDefineClass(ClassLoader.java:659)        at java.lang.ClassLoader.defineClass(ClassLoader.java:758)\n\nTomcat打破双亲委派机制以Tomcat类加载为例，Tomcat 如果使用默认的双亲委派类加载机制行不行？\n我们思考一下：Tomcat是个web容器， 那么它要解决什么问题： \n\n一个web容器可能需要部署两个应用程序，不同的应用程序可能会依赖同一个第三方类库的不同版本，不能要求同一个类库在同一个服务器只有一份，因此要保证每个应用程序的类库都是独立的，保证相互隔离。     \n部署在同一个web容器中相同的类库相同的版本可以共享。否则，如果服务器有10个应用程序，那么要有10份相同的类库加载进虚拟机。     \nweb容器也有自己依赖的类库，不能与应用程序的类库混淆。基于安全考虑，应该让容器的类库和程序的类库隔离开来。     \nweb容器要支持jsp的修改，我们知道，jsp文件最终也是要编译成class文件才能在虚拟机中运行，但程序运行后修改jsp已经是司空见惯的事情， web容器需要支持jsp修改后不用重启。\n\n再看看我们的问题：Tomcat 如果使用默认的双亲委派类加载机制行不行？ \n答案是不行的。为什么？\n第一个问题，如果使用默认的类加载器机制，那么是无法加载两个相同类库的不同版本的，默认的类加器是不管你是什么版本的，只在乎你的全限定类名，并且只有一份。\n第二个问题，默认的类加载器是能够实现的，因为他的职责就是保证唯一性。\n第三个问题和第一个问题一样。\n我们再看第四个问题，我们想我们要怎么实现jsp文件的热加载，jsp文件其实也就是class文件，那么如果修改了，但类名还是一样，类加载器会直接取方法区中已经存在的，修改后的jsp是不会重新加载的。那么怎么办呢？我们可以直接卸载掉这jsp文件的类加载器，所以你应该想到了，每个jsp文件对应一个唯一的类加载器，当一个jsp文件修改了，就直接卸载这个jsp类加载器。重新创建类加载器，重新加载jsp文件。\nTomcat自定义加载器详解\ntomcat的几个主要类加载器：\n\ncommonLoader：Tomcat最基本的类加载器，加载路径中的class可以被Tomcat容器本身以及各个Webapp访问；\ncatalinaLoader：Tomcat容器私有的类加载器，加载路径中的class对于Webapp不可见；\nsharedLoader：各个Webapp共享的类加载器，加载路径中的class对于所有Webapp可见，但是对于Tomcat容器不可见；\nWebappClassLoader：各个Webapp私有的类加载器，加载路径中的class只对当前Webapp可见，比如加载war包里相关的类，每个war包应用都有自己的WebappClassLoader，实现相互隔离，比如不同war包应用引入了不同的spring版本，这样实现就能加载各自的spring版本；\n\n从图中的委派关系中可以看出：\nCommonClassLoader能加载的类都可以被CatalinaClassLoader和SharedClassLoader使用，从而实现了公有类库的共用，而CatalinaClassLoader和SharedClassLoader自己能加载的类则与对方相互隔离。\nWebAppClassLoader可以使用SharedClassLoader加载到的类，但各个WebAppClassLoader实例之间相互隔离。\n而JasperLoader的加载范围仅仅是这个JSP文件所编译出来的那一个.Class文件，它出现的目的就是为了被丢弃：当Web容器检测到JSP文件被修改时，会替换掉目前的JasperLoader的实例，并通过再建立一个新的Jsp类加载器来实现JSP文件的热加载功能。\ntomcat 这种类加载机制违背了java 推荐的双亲委派模型了吗？答案是：违背了。 \n很显然，tomcat 不是这样实现，tomcat 为了实现隔离性，没有遵守这个约定，每个webappClassLoader加载自己的目录下的class文件，不会传递给父类加载器，打破了双亲委派机制。\n模拟实现Tomcat的webappClassLoader加载自己war包应用内不同版本类实现相互共存与隔离public class MyClassLoaderTest &#123;    static class MyClassLoader extends ClassLoader &#123;        private String classPath;        public MyClassLoader(String classPath) &#123;            this.classPath = classPath;        &#125;        private byte[] loadByte(String name) throws Exception &#123;            name = name.replaceAll(&quot;\\\\.&quot;, &quot;/&quot;);            FileInputStream fis = new FileInputStream(classPath + &quot;/&quot; + name                                                      + &quot;.class&quot;);            int len = fis.available();            byte[] data = new byte[len];            fis.read(data);            fis.close();            return data;        &#125;        protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123;            try &#123;                byte[] data = loadByte(name);                return defineClass(name, data, 0, data.length);            &#125; catch (Exception e) &#123;                e.printStackTrace();                throw new ClassNotFoundException();            &#125;        &#125;        /**            * 重写类加载方法，实现自己的加载逻辑，不委派给双亲加载            * @param name            * @param resolve            * @return            * @throws ClassNotFoundException\t\t*/        protected Class&lt;?&gt; loadClass(String name, boolean resolve)            throws ClassNotFoundException &#123;            synchronized (getClassLoadingLock(name)) &#123;                // First, check if the class has already been loaded                Class&lt;?&gt; c = findLoadedClass(name);                if (c == null) &#123;                    // If still not found, then invoke findClass in order                    // to find the class.                    long t1 = System.nanoTime();                    //非自定义的类还是走双亲委派加载                    if (!name.startsWith(&quot;com.test.jvm&quot;))&#123;                        c = this.getParent().loadClass(name);                    &#125;else&#123;                        c = findClass(name);                    &#125;                    // this is the defining class loader; record the stats                    sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);                    sun.misc.PerfCounter.getFindClasses().increment();                &#125;                if (resolve) &#123;                    resolveClass(c);                &#125;                return c;            &#125;        &#125;    &#125;    public static void main(String args[]) throws Exception &#123;        MyClassLoader classLoader = new MyClassLoader(&quot;D:/test&quot;);        Class clazz = classLoader.loadClass(&quot;com.test.jvm.User1&quot;);        Object obj = clazz.newInstance();        Method method= clazz.getDeclaredMethod(&quot;sout&quot;, null);        method.invoke(obj, null);        System.out.println(clazz.getClassLoader());        System.out.println();        MyClassLoader classLoader1 = new MyClassLoader(&quot;D:/test1&quot;);        Class clazz1 = classLoader1.loadClass(&quot;com.test.jvm.User1&quot;);        Object obj1 = clazz1.newInstance();        Method method1= clazz1.getDeclaredMethod(&quot;sout&quot;, null);        method1.invoke(obj1, null);        System.out.println(clazz1.getClassLoader());    &#125;&#125;运行结果：    =======自己的加载器加载类调用方法=======    com.test.jvm.MyClassLoaderTest$MyClassLoader@266474c2    =======另外一个User1版本：自己的加载器加载类调用方法=======    com.test.jvm.MyClassLoaderTest$MyClassLoader@66d3c617\n\n\n\n注意：同一个JVM内，两个相同包名和类名的类对象可以共存，因为他们的类加载器可以不一样，所以看两个类对象是否是同一个，除了看类的包名和类名是否都相同之外，还需要他们的类加载器也是同一个才能认为他们是同一个。\n模拟实现Tomcat的JasperLoader热加载原理：后台启动线程监听jsp文件变化，如果变化了找到该jsp对应的servlet类的加载器引用(gcroot)，重新生成新的JasperLoader加载器赋值给引用，然后加载新的jsp对应的servlet类，之前的那个加载器因为没有gcroot引用了，下一次gc的时候会被销毁。\n附下User类的代码：\npackage com.test.jvm;public class User &#123;    private int id;    private String name;    public User() &#123;    &#125;    public User(int id, String name) &#123;        super();        this.id = id;        this.name = name;    &#125;    public int getId() &#123;        return id;    &#125;    public void setId(int id) &#123;        this.id = id;    &#125;    public String getName() &#123;        return name;    &#125;    public void setName(String name) &#123;        this.name = name;    &#125;    public void sout() &#123;        System.out.println(&quot;=======自己的加载器加载类调用方法=======&quot;);    &#125;&#125;\n\n\n\n补充：Hotspot源码JVM启动执行main方法流程\n","categories":["Java"],"tags":["JVM"]},{"title":"JVM调优工具详解及调优实战","url":"/2021/10/27/Java/JVM/JVM%E8%B0%83%E4%BC%98%E5%B7%A5%E5%85%B7%E8%AF%A6%E8%A7%A3%E5%8F%8A%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/","content":"JVM调优工具使用事先启动一个web应用程序，用jps查看其进程id，接着用各种jdk自带命令优化应用\nJmap查看内存信息$ jmap -histo &lt;pid&gt; #查看历史生成的实例 $ jmap -histo:live &lt;pid&gt; #查看当前存活的实例，执行过程中可能会触发一次full gc\n\n此命令可以用来查看内存信息，实例个数以及占用内存大小\n\n\n\nnum：序号\ninstances：实例数量\nbytes：占用空间大小\nclass name：类名称，[C is a char[]，[S     is a short[]，[I is a int[]，[B is a byte[]，[[I is a int[][]\n\n\n查看堆信息jmap -heap &lt;pid&gt;\n\n\n堆内存dumpjmap -dump:format=b,file=&lt;fileName&gt;.hprof &lt;pid&gt;\n\n在程序启动的时候，也可以设置内存溢出时，自动导出dump文件 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./ （内存很大的时候，可能导不出来）\npublic class OOMTest &#123;    public static List&lt;Object&gt; list = new ArrayList&lt;&gt;();    // JVM设置        // -Xms10M -Xmx10M -XX:+PrintGCDetails -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=D:\\jvm.dump     public static void main(String[] args) &#123;        List&lt;Object&gt; list = new ArrayList&lt;&gt;();        int i = 0;        int j = 0;        while (true) &#123;            list.add(new User(i++, UUID.randomUUID().toString()));            new User(j--, UUID.randomUUID().toString());        &#125;    &#125;&#125;\n\n可以用jvisualvm命令工具导入该dump文件分析\n\nJstack查找死锁$ jstack &lt;pid&gt;\n\n实例代码：\npublic class DeadLockTest &#123;    private static Object lock1 = new Object();    private static Object lock2 = new Object();    public static void main(String[] args) &#123;        new Thread(() -&gt; &#123;            synchronized (lock1) &#123;                try &#123;                    System.out.println(&quot;thread1 begin&quot;);                    Thread.sleep(5000);                &#125; catch (InterruptedException e) &#123;                &#125;                synchronized (lock2) &#123;                    System.out.println(&quot;thread1 end&quot;);                &#125;            &#125;        &#125;).start();        new Thread(() -&gt; &#123;            synchronized (lock2) &#123;                try &#123;                    System.out.println(&quot;thread2 begin&quot;);                    Thread.sleep(5000);                &#125; catch (InterruptedException e) &#123;                &#125;                synchronized (lock1) &#123;                    System.out.println(&quot;thread2 end&quot;);                &#125;            &#125;        &#125;).start();        System.out.println(&quot;main thread end&quot;);    &#125;&#125;\n\n\n\n\n\n“Thread-1” 线程名\nprio=5 优先级=5\ntid=0x000000001fa9e000 线程id\nnid=0x2d64 线程对应的本地线程标识nid\njava.lang.Thread.State: BLOCKED     线程状态\n\n\n通过jvisualvm自动检测死锁\n\n连接时确认下端口是否通畅，可以临时关闭下防火墙\n$ systemctl stop firewalld   #临时关闭防火墙\n\n远程连接jvisualvm启动普通的jar程序JMX端口配置：\njava -Dcom.sun.management.jmxremote.port=&lt;port&gt; -Djava.rmi.server.hostname=&lt;ip&gt; -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -jar &lt;program&gt;.jar\n\n\n-Dcom.sun.management.jmxremote.port 为远程机器的JMX端口\n-Djava.rmi.server.hostname 为远程机器IP\n\ntomcat的JMX配置在catalina.sh文件里的最后一个JAVA_OPTS的赋值语句下一行增加如下配置行:\nJAVA_OPTS=&quot;$JAVA_OPTS -Dcom.sun.management.jmxremote.port=&lt;port&gt; -Djava.rmi.server.hostname=&lt;ip&gt; -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false&quot;\n\njstack找出占用cpu最高的线程堆栈信息示例代码\npackage com.tuling.jvm;/*** 运行此代码，cpu会飙高*/public class Math &#123;    public static final int initData = 666;    public static User user = new User();    public int compute() &#123;  //一个方法对应一块栈帧内存区域        int a = 1;        int b = 2;        int c = (a + b) * 10;        return c;    &#125;    public static void main(String[] args) &#123;        Math math = new Math();        while (true)&#123;            math.compute();        &#125;    &#125;&#125;\n\n查找过程\n使用命令top -p &lt;pid&gt;，显示你的java进程的内存情况，pid是你的java进程号，比如19663\n\n按H，获取每个线程的内存情况\n\n找到内存和cpu占用最高的线程tid，比如19664\n\n转为十六进制得到 0x4cd0，此为线程id的十六进制表示\n\n执行 jstack 19663|grep -A 10 4cd0，得到线程堆栈信息中 4cd0 这个线程所在行的后面10行，从堆栈中可以发现导致cpu飙高的调用方法\n\n查看对应的堆栈信息找出可能存在问题的代码\n\n\nJinfo查看正在运行的Java应用程序的扩展参数 \n查看jvm的参数$ jinfo -flags &lt;pid&gt;\n\n\n查看java系统参数$ jinfo -sysprops &lt;pid&gt;\n\n\nJstatjstat命令可以查看堆内存各部分的使用量，以及加载类的数量。(JDK版本为1.8)\n垃圾回收统计可以评估程序内存使用及GC压力整体情况,最常用\n$ jstat -gc &lt;pid&gt; &lt;间隔时间（毫秒）&gt; &lt;查询次数&gt;\n\n\n\nS0C：第一个幸存区的大小，单位KB\n\nS1C：第二个幸存区的大小\n\nS0U：第一个幸存区的使用大小\n\nS1U：第二个幸存区的使用大小\n\nEC：伊甸园区的大小\n\nEU：伊甸园区的使用大小\n\nOC：老年代大小\n\nOU：老年代使用大小\n\nMC：方法区大小(元空间)\n\nMU：方法区使用大小\n\nCCSC:压缩类空间大小\n\nCCSU:压缩类空间使用大小\n\nYGC：年轻代垃圾回收次数\n\nYGCT：年轻代垃圾回收消耗时间，单位s\n\nFGC：老年代垃圾回收次数 \n\nFGCT：老年代垃圾回收消耗时间，单位s\n\nGCT：垃圾回收消耗总时间，单位s\n\n\n堆内存统计$ jstat -gccapacity &lt;pid&gt;\n\n\n\nNGCMN：新生代最小容量\nNGCMX：新生代最大容量\nNGC：当前新生代容量\nS0C：第一个幸存区大小\nS1C：第二个幸存区的大小\nEC：伊甸园区的大小\nOGCMN：老年代最小容量\nOGCMX：老年代最大容量\nOGC：当前老年代大小\nOC:当前老年代大小\nMCMN:最小元数据容量\nMCMX：最大元数据容量\nMC：当前元数据空间大小\nCCSMN：最小压缩类空间大小\nCCSMX：最大压缩类空间大小\nCCSC：当前压缩类空间大小\nYGC：年轻代gc次数\nFGC：老年代GC次数\n\n新生代垃圾回收统计$ jstat -gcnew &lt;pid&gt;\n\n\n\nNGCMN：新生代最小容量\nNGCMX：新生代最大容量\nNGC：当前新生代容量\nS0CMX：最大幸存1区大小\nS0C：当前幸存1区大小\nS1CMX：最大幸存2区大小\nS1C：当前幸存2区大小\nECMX：最大伊甸园区大小\nEC：当前伊甸园区大小\nYGC：年轻代垃圾回收次数\nFGC：老年代回收次数\n\n老年代垃圾回收统计$ jstat -gcold &lt;pid&gt;\n\n\n\nMC：方法区大小\nMU：方法区使用大小\nCCSC:压缩类空间大小\nCCSU:压缩类空间使用大小\nOC：老年代大小\nOU：老年代使用大小\nYGC：年轻代垃圾回收次数\nFGC：老年代垃圾回收次数\nFGCT：老年代垃圾回收消耗时间\nGCT：垃圾回收消耗总时间\n\n老年代内存统计$ jstat -gcoldcapacity &lt;pid&gt;\n\n\n\nOGCMN：老年代最小容量\nOGCMX：老年代最大容量\nOGC：当前老年代大小\nOC：老年代大小\nYGC：年轻代垃圾回收次数\nFGC：老年代垃圾回收次数\nFGCT：老年代垃圾回收消耗时间\nGCT：垃圾回收消耗总时间\n\n元空间统计$ jstat -gcmetacapacity &lt;pid&gt;\n\n\n\nMCMN:最小元数据容量\nMCMX：最大元数据容量\nMC：当前元数据空间大小 \nCCSMN：最小压缩类空间大小\nCCSMX：最大压缩类空间大小\nCCSC：当前压缩类空间大小\nYGC：年轻代垃圾回收次数\nFGC：老年代垃圾回收次数\nFGCT：老年代垃圾回收消耗时间\nGCT：垃圾回收消耗总时间\n\n内存当前使用比例$ jstat -gcutil &lt;pid&gt;\n\n\n\nS0：幸存1区当前使用比例\nS1：幸存2区当前使用比例\nE：伊甸园区使用比例\nO：老年代使用比例\nM：元数据区使用比例\nCCS：压缩使用比例\nYGC：年轻代垃圾回收次数\nFGC：老年代垃圾回收次数\nFGCT：老年代垃圾回收消耗时间\nGCT：垃圾回收消耗总时间\n\nJVM运行情况预估用 jstat gc -pid 命令可以计算出如下一些关键数据，有了这些数据就可以采用之前介绍过的优化思路，先给自己的系统设置一些初始性的JVM参数，比如堆内存大小，年轻代大小，Eden和Survivor的比例，老年代的大小，大对象的阈值，大龄对象进入老年代的阈值等。\n\n年轻代对象增长的速率可以执行命令 jstat -gc pid 1000 10 (每隔1秒执行1次命令，共执行10次)，通过观察EU(eden区的使用)来估算每秒eden大概新增多少对象，如果系统负载不高，可以把频率1秒换成1分钟，甚至10分钟来观察整体情况。注意，一般系统可能有高峰期和日常期，所以需要在不同的时间分别估算不同情况下对象增长速率。\nYoung GC的触发频率和每次耗时知道年轻代对象增长速率我们就能推根据eden区的大小推算出Young GC大概多久触发一次，Young GC的平均耗时可以通过 YGCT/YGC 公式算出，根据结果我们大概就能知道系统大概多久会因为Young GC的执行而卡顿多久。\n每次Young GC后有多少对象存活和进入老年代这个因为之前已经大概知道Young GC的频率，假设是每5分钟一次，那么可以执行命令 jstat -gc pid 300000 10 ，观察每次结果eden，survivor和老年代使用的变化情况，在每次gc后eden区使用一般会大幅减少，survivor和老年代都有可能增长，这些增长的对象就是每次Young GC后存活的对象，同时还可以看出每次Young GC后进去老年代大概多少对象，从而可以推算出老年代对象增长速率。\nFull GC的触发频率和每次耗时知道了老年代对象的增长速率就可以推算出Full GC的触发频率了，Full GC的每次耗时可以用公式 FGCT/FGC 计算得出。\n\n\n优化思路其实简单来说就是尽量让每次Young GC后的存活对象小于Survivor区域的50%，都留存在年轻代里。尽量别让对象进入老年代。尽量减少Full GC的频率，避免频繁Full GC对JVM性能的影响。\n\n系统频繁Full GC导致系统卡顿是怎么回事系统情况：\n\n机器配置：2核4G\nJVM内存大小：2G\n系统运行时间：7天\n期间发生的Full GC次数和耗时：500多次，200多秒\n期间发生的Young GC次数和耗时：1万多次，500多秒\n\n大致算下来每天会发生70多次Full GC，平均每小时3次，每次Full GC在400毫秒左右；每天会发生1000多次Young GC，每分钟会发生1次，每次Young GC在50毫秒左右。\nJVM参数设置如下：\n-Xms1536M -Xmx1536M -Xmn512M -Xss256K -XX:SurvivorRatio=6  -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M -XX:+UseParNewGC  -XX:+UseConcMarkSweepGC  -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly\n\n\n结合对象挪动到老年代那些规则推理下我们这个程序可能存在的一些问题，经过分析感觉可能会由于对象动态年龄判断机制导致full gc较为频繁为了给看效果，模拟了一个示例程序(见对应工程代码：jvm-full-gc)，打印了jstat的结果如下：\n$ jstat -gc 13456 2000 10000\n\n\n对于对象动态年龄判断机制导致的full gc较为频繁可以先试着优化下JVM参数，把年轻代适当调大点：\n-Xms1536M -Xmx1536M -Xmn1024M -Xss256K -XX:SurvivorRatio=6  -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M -XX:+UseParNewGC  -XX:+UseConcMarkSweepGC  -XX:CMSInitiatingOccupancyFraction=92 -XX:+UseCMSInitiatingOccupancyOnly\n\n\n优化完发现没什么变化，full gc的次数比minor gc的次数还多了\n\n我们可以推测下full gc比minor gc还多的原因有哪些？\n\n元空间不够导致的多余full gc\n显示调用System.gc()造成多余的full     gc，这种一般线上尽量通过-XX:+DisableExplicitGC参数禁用，如果加上了这个JVM启动参数，那么代码中调用System.gc()没有任何效果\n老年代空间分配担保机制\n\n最快速度分析完这些我们推测的原因以及优化后，我们发现young gc和full gc依然很频繁了，而且看到有大量的对象频繁的被挪动到老年代，这种情况我们可以借助jmap命令大概看下是什么对象\n\n查到了有大量User对象产生，这个可能是问题所在，但不确定，还必须找到对应的代码确认，如何去找对应的代码了？\n\n代码里全文搜索生成User对象的地方(适合只有少数几处地方的情况)\n如果生成User对象的地方太多，无法定位具体代码，我们可以同时分析下占用cpu较高的线程，一般有大量对象不断产生，对应的方法代码肯定会被频繁调用，占用的cpu必然较高\n\n可以用上面讲过的jstack或jvisualvm来定位cpu使用较高的代码，最终定位到的代码如下：\nimport java.util.ArrayList;@RestControllerpublic class IndexController &#123;    @RequestMapping(&quot;/user/process&quot;)    public String processUserData() throws InterruptedException &#123;        ArrayList&lt;User&gt; users = queryUsers();        for (User user: users) &#123;            //TODO 业务处理            System.out.println(&quot;user:&quot; + user.toString());        &#125;        return &quot;end&quot;;    &#125;/*** 模拟批量查询用户场景* @return*/    private ArrayList&lt;User&gt; queryUsers() &#123;        ArrayList&lt;User&gt; users = new ArrayList&lt;&gt;();        for (int i = 0; i &lt; 5000; i++) &#123;            users.add(new User(i,&quot;test&quot;));        &#125;        return users;    &#125;&#125;\n\n同时，java的代码也是需要优化的，一次查询出500M的对象出来，明显不合适，要根据之前说的各种原则尽量优化到合适的值，尽量消除这种朝生夕死的对象导致的full gc\nGC日志详解对于java应用我们可以通过一些配置把程序运行过程中的gc日志全部打印出来，然后分析gc日志得到关键性指标，分析GC原因，调优JVM参数。打印GC日志方法，在JVM参数里增加参数，%t 代表时间 (Tomcat则直接加在JAVA_OPTS变量里)\n-Xloggc:./gc-%t.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps  -XX:+PrintGCTimeStamps -XX:+PrintGCCause -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M\n\n如何分析GC日志测试代码\npublic class HeapTest &#123;    byte[] a = new byte[1024 * 100];  //100KB    public static void main(String[] args) throws InterruptedException &#123;        ArrayList&lt;HeapTest&gt; heapTests = new ArrayList&lt;&gt;();        while (true) &#123;            heapTests.add(new HeapTest());            Thread.sleep(10);        &#125;    &#125;&#125;\n\n运行程序加上对应gc日志\njava -jar -Xloggc:./gc-%t.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:PrintGCTimeStamps -XX:+PrintGCCause -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M &lt;jarName&gt;.jar\n\n下图中是截取的JVM刚启动的一部分GC日志\n\n可以看到图中第一行红框，是项目的配置参数。这里不仅配置了打印GC日志，还有相关的VM内存参数。第二行红框中的是在这个GC时间点发生GC之后相关GC情况。\n\n对于2.909：这是从jvm启动开始计算到这次GC经过的时间，前面还有具体的发生时间日期。 \nFull GC(Metadata GC Threshold)指这是一次full gc，括号里是gc的原因，PSYoungGen是年轻代的GC，ParOldGen是老年代的GC，Metaspace是元空间的GC\n6160K-&gt;0K(141824K)，这三个数字分别对应GC之前占用年轻代的大小，GC之后年轻代占用，以及整个年轻代的大小。     \n112K-&gt;6056K(95744K)，这三个数字分别对应GC之前占用老年代的大小，GC之后老年代占用，以及整个老年代的大小。     \n6272K-&gt;6056K(237568K)，这三个数字分别对应GC之前占用堆内存的大小，GC之后堆内存占用，以及整个堆内存的大小。     \n20516K-&gt;20516K(1069056K)，这三个数字分别对应GC之前占用元空间内存的大小，GC之后元空间内存占用，以及整个元空间内存的大小。     \n0.0209707是该时间点GC总耗费时间。\n\n从日志可以发现几次fullgc都是由于元空间不够导致的，所以我们可以将元空间调大点\njava -jar -Xloggc:./gc-adjust-%t.log -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCCause -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M &lt;jarName&gt;.jar\n\n调整完我们再看下gc日志发现已经没有因为元空间不够导致的fullgc了\n对于CMS和G1收集器的日志会有一点不一样，也可以试着打印下对应的gc日志分析下，可以发现gc日志里面的gc步骤跟我们之前讲过的步骤是类似的\n\nCMS\n-Xloggc:d:/gc-cms-%t.log -Xms50M -Xmx50M -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCCause -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M -XX:+UseParNewGC -XX:+UseConcMarkSweepGC\nG1\n-Xloggc:d:/gc-g1-%t.log -Xms50M -Xmx50M -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCCause  -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M -XX:+UseG1GC \n\n上面的这些参数，能够帮我们查看分析GC的垃圾收集情况。但是如果GC日志很多很多，成千上万行。就算你一目十行，看完了，脑子也是一片空白。所以我们可以借助一些功能来帮助我们分析。这里推荐一个gceasy，可以上传gc文件，然后他会利用可视化的界面来展现GC情况。\nVM参数汇总查看命令java -XX:+PrintFlagsInitial 表示打印出所有参数选项的默认值java -XX:+PrintFlagsFinal 表示打印出所有参数选项在运行程序时生效的值\n","categories":["Java"],"tags":["JVM"]},{"title":"jvisualvm安装Visual GC插件","url":"/2021/08/31/Java/JVM/jvisualvm%E5%AE%89%E8%A3%85Visual-GC%E6%8F%92%E4%BB%B6/","content":"给jdk自带的jvisualvm安装Visual GC插件，遇到We’re sorry the java.net site has closed（我们很抱歉java.net网站已经关闭）\n找到新的更新地址visualvm新访问地址：https://visualvm.github.io/index.html\n\n进入 plugins centers,找到对应自己JDK版本的更新地址\n\n进入jvisualvm的插件管理“工具” - “插件”\n在”设置”中修改url地址为刚才我们在github上找到的对应我们JDK版本的地址\n修改成功后，可用插件即可刷新出来\n\n安装VisualGC插件因为我已经安完了，所以可用插件中不会显示，在已安装中会显示已经安装完的插件\n\n重启即可看到VisualGC\n说明：\n\n整个区域分为三部分：spaces、graphs、histogram\n\nspaces区域：代表虚拟机内存分布情况。从图中可以看出，虚拟机被分为Metaspace、 Old、Eden、S0、S1 \n\n\n（注意：如果对每个区域基本概念不是很熟悉的可以先了解下JVM内存模型深度剖析与优化这篇文章）\n\nMetaspace:元空间，也叫方法区。可以通过VM Args: -XX:MetaspaceSize=256M     -XX:MaxMetaspaceSize=256M 设置元空间的大小\nHeap:java堆（java heap）,它包括老年代(图中Old区域)和新生代(图中Eden/S0/S1三个统称新生代，分为Eden区和两个Survivor区域)，他们默认是2:1分配内存。\n\n通过VM Args:-xms512m -Xmx512m -XX:+HeapDumpOnOutofMemoryError -Xmn100m -XX:SurvivorRatio=8 设置初始堆内存、最大堆内存、内存异常打印dump、 新生代内存、新生代内存分配比例(8:1:1)，\n因为Heap分为新生代跟老年代，所以512M-100M=412M，老年代就是412M(初始内存跟最大内存最好相等，防止内存不够时扩充内 存或者Full GC，导致性能降低) \n\nGraphs区域：\n\nCompile Time(编译时间)：604654compiles 表示编译总数，1h 46m 32.133s表示编译累计时间。一个脉冲表示一次JIT编译，窄脉冲表示持续时间短，宽脉冲表示持续时间长。\n\n\nClass Loader      Time(类加载时间): 136248loaded表示加载类数量, 15448unloaded表示卸载的类数量，2m46.699s表示类加载花费的时间。\nGC Time(GC Time)：4805collections表示垃圾收集的总次数，5m35.376s表示垃圾收集花费的时间，last      cause表示最近垃圾收集的原因。\nEden Space(Eden      区)：括号内的前面665.625M表示最大容量，后面的665.625M表示当前容量，后面的292.765M表示当前使用情况，4784collections表示垃圾收集次数，3m 23.497s表示垃圾收集花费时间\nSurvivor 0/Survivor      1(S0和S1区)：括号内前面的83.188M表示最大容量，后面的83.188M表示当前容量，之后的值是当前使用情况。\nOld Gen(老年代)：括号内前面2.188G表示最大容量，后面的2.188G表示当前容量， 之后的1.067G表示当前使用情况，21collections表示垃圾收集次数，2m2.879s表示垃圾收集花费时间。\nMetaspace(元空间)：括号内前面的1.668G表示最大容量，790.395M表示当前容量，后面的759.484M表示当前使用情况。\n\n\nHistogram区域：survivor区域参数跟年龄柱状图\n\nTenuring      Threshold：表示新生代年龄大于当前值则进入老年代。\n\n\nMax Tenuring      Threshold：表示新生代最大年龄值。\nTenuring Threshold与Max Tenuring      Threshold区别：Max Tenuring Threshold是一个最大限定，所有的新生代年龄都不能超过当前值，而Tenuring      Threshold是个动态计算出来的临时值，一般情况与Max Tenuring      Threshold相等，如果在Suivivor空间中，相同年龄所有对象大小的总和大于Survivor空间的一半，则年龄大于或者等于该年龄的对象就都可以直接进入老年代(如果计算出来年龄段是5，则Tenuring      Threshold=5，age&gt;=5的Suivivor对象都符合要求)，它才是新生代是否进入老年代判断的依据。 \nDesired Survivor      Size：Survivor空间大小验证阙值(默认是survivor空间的一半)，用于Tenuring      Threshold判断对象是否提前进入老年代。\nCurrent Survivor      Size：当前survivor空间大小。\nhistogram柱状图：表示年龄段对象的存储柱状图。\n如果显示指定-XX:+UseParallelGC      –新生代并行、老年代串行收集器 ，则histogram柱状图不支持当前收集器\n\n\n\n","categories":["Java"],"tags":["JVM"]},{"title":"垃圾收集器G1&ZGC详解","url":"/2020/07/31/Java/JVM/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8G1-ZGC%E8%AF%A6%E8%A7%A3/","content":"G1收集器(-XX:+UseG1GC)G1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器。以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征。\n\n\nG1将Java堆划分为多个大小相等的独立区域（Region），JVM目标是不超过2048个Region(JVM源码里TARGET_REGION_NUMBER 定义)，实际可以超过该值，但是不推荐。一般Region大小等于堆大小除以2048，比如堆大小为4096M，则Region大小为2M，当然也可以用参数”-XX:G1HeapRegionSize”手动指定Region大小，但是推荐默认的计算方式。G1保留了年轻代和老年代的概念，但不再是物理隔阂了，它们都是（可以不连续）Region的集合。默认年轻代初始对堆内存的占比是5%，如果堆大小为4096M，那么年轻代占据200MB左右的内存，对应大概是100个Region，可以通过“-XX:G1NewSizePercent”设置新生代初始占比，在系统运行中，JVM会不停的给年轻代增加更多的Region，但是最多年轻代的占比不会超过60%，可以通过“-XX:G1MaxNewSizePercent”调整。年轻代中的Eden和Survivor对应的region也跟之前一样，默认8:1:1，假设年轻代现在有1000个region，eden区对应800个，s0对应100个，s1对应100个。一个Region可能之前是年轻代，如果Region进行了垃圾回收，之后可能又会变成老年代，也就是说Region的区域功能可能会动态变化。G1垃圾收集器对于对象什么时候会转移到老年代跟之前讲过的原则一样，唯一不同的是对大对象的处理，G1有专门分配大对象的Region叫Humongous区，而不是让大对象直接进入老年代的Region中。在G1中，大对象的判定规则就是一个大对象超过了一个Region大小的50%，比如按照上面算的，每个Region是2M，只要一个大对象超过了1M，就会被放入Humongous中，而且一个大对象如果太大，可能会横跨多个Region来存放。Humongous区专门存放短期巨型对象，不用直接进老年代，可以节约老年代的空间，避免因为老年代空间不够的GC开销。Full GC的时候除了收集年轻代和老年代之外，也会将Humongous区一并回收。\n\nG1收集器一次GC(主要值Mixed GC)的运作过程大致分为以下几个步骤：\n\n初始标记（initial mark，STW）暂停所有的其他线程，并记录下gc roots直接能引用的对象，速度很快\n并发标记（Concurrent Marking）同CMS的并发标记 \n最终标记（Remark，STW）同CMS的重新标记\n筛选回收（Cleanup，STW）筛选回收阶段首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿STW时间(可以用JVM参数 -XX:MaxGCPauseMillis指定)来制定回收计划，  比如说老年代此时有1000个Region都满了，但是因为根据预期停顿时间，本次垃圾回收可能只能停顿200毫秒，那么通过之前回收成本计算得知，可能回收其中800个Region刚好需要200ms，  那么就只会回收800个Region(Collection Set，要回收的集合)，尽量把GC导致的停顿时间控制在我们指定的范围内。这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，  时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。不管是年轻代或是老年代，回收算法主要用的是复制算法，将一个region中的存活对象复制到另一个region中，这种不会像CMS那样回收完因为有很多内存碎片还需要整理一次，G1采用复制算法回收几乎不会有太多内存碎片。(注意：CMS回收阶段是跟用户线程一起并发执行的，G1因为内部实现太复杂暂时没实现并发回收，不过到了ZGC，Shenandoah就实现了并发收集，Shenandoah可以看成是G1的升级版本)\n\nG1收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的Region(这也就是它的名字Garbage-First的由来)，比如一个Region花200ms能回收10M垃圾，另外一个Region花50ms能回收20M垃圾，在回收时间有限情况下，G1当然会优先选择后面这个Region回收。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限时间内可以尽可能高的收集效率。\nG1被视为JDK1.7以上版本Java虚拟机的一个重要进化特征。它具备以下特点：\n\n并行与并发G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿时间。部分其他收集器原本需要停顿Java线程来执行GC动作，G1收集器仍然可以通过并发的方式让java程序继续执行。\n分代收集虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但是还是保留了分代的概念\n空间整合与CMS的“标记–清理”算法不同，G1从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。\n可预测的停顿这是G1相对于CMS的另一个大优势，降低停顿时间是G1 和 CMS 共同的关注点，但G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段(通过参数”-XX:MaxGCPauseMillis“指定)内完成垃圾收集。\n\n毫无疑问，可以由用户指定期望的停顿时间是G1收集器很强大的一个功能，设置不同的期望停顿时间，可使得G1在不同应用场景中取得关注吞吐量和关注延迟之间的最佳平衡。不过，这里设置的“期望值”必须是符合实际的，不能异想天开，毕竟G1是要冻结用户线程来复制对象的，这个停顿时间再怎么低也得有个限度。它默认的停顿目标为两百毫秒，一般来说，回收阶段占到几十到一百甚至接近两百毫秒都很正常，但如果我们把停顿时间调得非常低，譬如设置为二十毫秒，很可能出现的结果就是由于停顿目标时间太短，导致每次选出来的回收集只占堆内存很小的一部分，收集器收集的速度逐渐跟不上分配器分配的速度，导致垃圾慢慢堆积。很可能一开始收集器还能从空闲的堆内存中获得一些喘息的时间，但应用运行时间一长就不行了，最终占满堆引发Full GC反而降低性能，所以通常把期望停顿时间设置为一两百毫秒或者两三百毫秒会是比较合理的。\nG1垃圾收集分类YoungGCYoungGC并不是说现有的Eden区放满了就会马上触发，G1会计算下现在Eden区回收大概要多久时间，如果回收时间远远小于参数 -XX:MaxGCPauseMills设定的值，那么增加年轻代的region，继续给新对象存放，不会马上做Young GC，直到下一次Eden区放满，G1计算回收时间接近参数 -XX:MaxGCPauseMills 设定的值，那么就会触发YoungGC\nMixedGC不是FullGC，老年代的堆占有率达到参数(-XX:InitiatingHeapOccupancyPercent)设定的值则触发，回收所有的Young和部分Old(根据期望的GC停顿时间确定old区垃圾收集的优先顺序)以及大对象区，正常情况G1的垃圾收集是先做MixedGC，主要使用复制算法，需要把各个region中存活的对象拷贝到别的region里去，拷贝过程中如果发现没有足够的空region能够承载拷贝对象就会触发一次FullGC\nFullGC停止系统程序，然后采用单线程进行标记、清理和压缩整理，好空闲出来一批Region来供下一次MixedGC使用，这个过程是非常耗时的(Shenandoah优化成多线程收集了)\nG1收集器参数设置\n-XX:+UseG1GC:使用G1收集器\n-XX:ParallelGCThreads:指定GC工作的线程数量\n-XX:G1HeapRegionSize:指定分区大小(1MB~32MB，且必须是2的N次幂)，默认将整堆划分为2048个分区\n-XX:MaxGCPauseMillis:目标暂停时间(默认200ms)\n-XX:G1NewSizePercent:新生代内存初始空间(默认整堆5%，值配置整数，默认就是百分比)\n-XX:G1MaxNewSizePercent:新生代内存最大空间\n-XX:TargetSurvivorRatio:Survivor区的填充容量(默认50%)，Survivor区域里的一批对象(年龄1+年龄2+年龄n的多个年龄对象)总和超过了Survivor区域的50%，此时就会把年龄n(含)以上的对象都放入老年代\n-XX:MaxTenuringThreshold:最大年龄阈值(默认15)\n-XX:InitiatingHeapOccupancyPercent:老年代占用空间达到整堆内存阈值(默认45%)，则执行新生代和老年代的混合收集(MixedGC)，比如我们之前说的堆默认有2048个region，如果有接近1000个region都是老年代的region，则可能就要触发MixedGC了\n-XX:G1MixedGCLiveThresholdPercent:(默认85%)region中的存活对象低于这个值时才会回收该region，如果超过这个值，存活对象过多，回收的的意义不大。\n-XX:G1MixedGCCountTarget:在一次回收过程中指定做几次筛选回收(默认8次)，在最后一个筛选回收阶段可以回收一会，然后暂停回收，恢复系统运行，一会再开始回收，这样可以让系统不至于单次停顿时间过长。\n-XX:G1HeapWastePercent(默认5%):gc过程中空出来的region是否充足阈值，在混合回收的时候，对Region回收都是基于复制算法进行的，都是把要回收的Region里的存活对象放入其他Region，然后这个Region中的垃圾对象全部清理掉，这样的话在回收过程就会不断空出来新的Region，一旦空闲出来的Region数量达到了堆内存的5%，此时就会立即停止混合回收，意味着本次混合回收就结束了。\n\nG1垃圾收集器优化建议假设参数 -XX:MaxGCPauseMills 设置的值很大，导致系统运行很久，年轻代可能都占用了堆内存的60%了，此时才触发年轻代gc。那么存活下来的对象可能就会很多，此时就会导致Survivor区域放不下那么多的对象，就会进入老年代中。或者是你年轻代gc过后，存活下来的对象过多，导致进入Survivor区域后触发了动态年龄判定规则，达到了Survivor区域的50%，也会快速导致一些对象进入老年代中。所以这里核心还是在于调节 -XX:MaxGCPauseMills 这个参数的值，在保证他的年轻代gc别太频繁的同时，还得考虑每次gc过后的存活对象有多少,避免存活对象太多快速进入老年代，频繁触发mixed gc。\n什么场景适合使用G1\n50%以上的堆被存活对象占用\n对象分配和晋升的速度变化非常大\n垃圾回收时间特别长，超过1秒\n8GB以上的堆内存(建议值)\n停顿时间是500ms以内\n\n每秒几十万并发的系统如何优化JVMKafka类似的支撑高并发消息系统大家肯定不陌生，对于kafka来说，每秒处理几万甚至几十万消息时很正常的，一般来说部署kafka需要用大内存机器(比如64G)，也就是说可以给年轻代分配个三四十G的内存用来支撑高并发处理，这里就涉及到一个问题了，我们以前常说的对于eden区的young gc是很快的，这种情况下它的执行还会很快吗？很显然，不可能，因为内存太大，处理还是要花不少时间的，假设三四十G内存回收可能最快也要几秒钟，按kafka这个并发量放满三四十G的eden区可能也就一两分钟吧，那么意味着整个系统每运行一两分钟就会因为young gc卡顿几秒钟没法处理新消息，显然是不行的。那么对于这种情况如何优化了，我们可以使用G1收集器，设置 -XX:MaxGCPauseMills 为50ms，假设50ms能够回收三到四个G内存，然后50ms的卡顿其实完全能够接受，用户几乎无感知，那么整个系统就可以在卡顿几乎无感知的情况下一边处理业务一边收集垃圾。G1天生就适合这种大内存机器的JVM运行，可以比较完美的解决大内存垃圾回收时间过长的问题。\nZGC收集器(-XX:+UseZGC)\nhttps://wiki.openjdk.java.net/display/zgc/Main\n\n\nhttp://cr.openjdk.java.net/~pliden/slides/ZGC-Jfokus-2018.pdf\n\nZGC是一款JDK 11中新加入的具有实验性质的低延迟垃圾收集器，ZGC可以说源自于是Azul System公司开发的C4（Concurrent Continuously Compacting Collector） 收集器。\n\nZGC目标\nZGC的目标主要有4个\n\n支持TB量级的堆\n我们生产环境的硬盘还没有上TB呢，这应该可以满足未来十年内，所有JAVA应用的需求了吧\n\n最大GC停顿时间不超10ms\n目前一般线上环境运行良好的JAVA应用Minor GC停顿时间在10ms左右，Major GC一般都需要100ms以上（G1可以调节停顿时间，但是如果调的过低的话，反而会适得其反），之所以能做到这一点是因为它的停顿时间主要跟Root扫描有关，而Root数量和堆大小是没有任何关系的\n\n奠定未来GC特性的基础\n\n最糟糕的情况下吞吐量会降低15%\n这都不是事，停顿时间足够优秀。至于吞吐量，通过扩容分分钟解决\n\n\n另外，Oracle官方提到了它最大的优点是：它的停顿时间不会随着堆的增大而增长！也就是说，几十G堆的停顿时间是10ms以下，几百G甚至上T堆的停顿时间也是10ms以下。\n不分代(暂时)单代，即ZGC「没有分代」。我们知道以前的垃圾回收器之所以分代，是因为源于“「大部分对象朝生夕死」”的假设，事实上大部分系统的对象分配行为也确实符合这个假设。那么为什么ZGC就不分代呢？因为分代实现起来麻烦，作者就先实现出一个比较简单可用的单代版本，后续会优化\nZGC内存布局\nZGC收集器是一款基于Region内存布局的，暂时不设分代的，使用了读屏障、 颜色指针等技术来实现可并发的标记-整理算法的，以低延迟为首要目标的一款垃圾收集器。ZGC的Region可以具有大、 中、 小三类容量：\n\n小型Region（Small Region）容量固定为2MB， 用于放置小于256KB的小对象\n\n中型Region（Medium Region）容量固定为32MB， 用于放置大于等于256KB但小于4MB的对象\n\n大型Region（Large Region）容量不固定，可以动态变化，但必须为2MB的整数倍，用于放置4MB或以上的大对象。每个大型Region中只会存放一个大对象，这也预示着虽然名字叫作“大型Region”， 但它的实际容量完全有可能小于中型Region，最小容量可低至4MB。大型Region在ZGC的实现中是不会被重分配（重分配是ZGC的一种处理动作，用于复制对象的收集器阶段，稍后会介绍到）的， 因为复制一个大对象的代价非常高昂。\n\n\nNUMA-aware(非统一内存访问)\nNUMA对应的有UMA，UMA即Uniform Memory Access Architecture，NUMA就是Non Uniform Memory Access Architecture。UMA表示内存只有一块，所有CPU都去访问这一块内存，那么就会存在竞争问题（争夺内存总线访问权），有竞争就会有锁，有锁效率就会受到影响，而且CPU核心数越多，竞争就越激烈。NUMA的话每个CPU对应有一块内存，且这块内存在主板上离这个CPU是最近的，每个CPU优先访问这块内存，那效率自然就提高了。服务器的NUMA架构在中大型系统上一直非常盛行，也是高性能的解决方案，尤其在系统延迟方面表现都很优秀。ZGC是能自动感知NUMA架构并充分利用NUMA架构特性的。\nZGC运作过程\nZGC的运作过程大致可划分为以下四个大的阶段\n\n并发标记（Concurrent Mark）与G1一样，并发标记是遍历对象图做可达性分析的阶段，它的初始标记(Mark Start)和最终标记(Mark End)也会出现短暂的停顿，与G1不同的是， ZGC的标记是在指针上而不是在对象上进行的，标记阶段会更新颜色指针(见下面详解)中的Marked 0、 Marked 1标志位\n\n并发预备重分配（Concurrent Prepare for Relocate）这个阶段需要根据特定的查询条件统计得出本次收集过程要清理哪些Region，将这些Region组成重分配集（Relocation Set）。ZGC每次回收都会扫描所有的Region，用范围更大的扫描成本换取省去G1中记忆集的维护成本。\n\n并发重分配（Concurrent Relocate）重分配是ZGC执行过程中的核心阶段，这个过程要把重分配集中的存活对象复制到新的Region上，并为重分配集中的每个Region维护一个转发表（Forward Table），记录从旧对象到新对象的转向关系。ZGC收集器能仅从引用上就明确得知一个对象是否处于重分配集之中，如果用户线程此时并发访问了位于重分配集中的对象，这次访问将会被预置的内存屏障(读屏障(见下面详解))所截获，然后立即根据Region上的转发表记录将访问转发到新复制的对象上，并同时修正更新该引用的值，使其直接指向新对象，ZGC将这种行为称为指针的“自愈”（Self-Healing）能力。\n\nZGC的颜色指针因为“自愈”（Self-Healing）能力，所以只有第一次访问旧对象会变慢， 一旦重分配集中某个Region的存活对象都复制完毕后，这个Region**就可以立即释放用于新对象的分配，但是转发表还得留着不能释放掉， 因为可能还有访问在使用这个转发表。\n\n\n并发重映射（Concurrent Remap）\n重映射所做的就是修正整个堆中指向重分配集中旧对象的所有引用，但是ZGC中对象引用存在“自愈”功能，所以这个重映射操作并不是很迫切。ZGC很巧妙地把并发重映射阶段要做的工作，合并到了下一次垃圾收集循环中的并发标记阶段里去完成，反正它们都是要遍历所有对象的，这样合并就节省了一次遍历对象图的开销。一旦所有指针都被修正之后， 原来记录新旧对象关系的转发表就可以释放掉了。\n\n\n颜色指针Colored Pointers，即颜色指针，如下图所示，ZGC的核心设计之一。以前的垃圾回收器的GC信息都保存在对象头中，而ZGC的GC信息保存在指针中。\n\n每个对象有一个64位指针，这64位被分为:\n\n18位：预留给以后使用\n1位：Finalizable标识，此位与并发引用处理有关，它表示这个对象只能通过finalizer才能访问\n1位：Remapped标识，设置此位的值后，对象未指向relocation     set中（relocation set表示需要GC的Region集合）\n1位：Marked1标识\nMarked0标识，和上面的Marked1都是标记对象用于辅助GC\n42位：对象的地址（所以它可以支持2^42=4T内存）\n\n为什么有2个mark标记？每一个GC周期开始时，会交换使用的标记位，使上次GC周期中修正的已标记状态失效，所有引用都变成未标记。GC周期1：使用mark0, 则周期结束所有引用mark标记都会成为01。GC周期2：使用mark1, 则期待的mark标记10，所有引用都能被重新标记。通过对配置ZGC后对象指针分析我们可知，对象指针必须是64位，那么ZGC就无法支持32位操作系统，同样的也就无法支持压缩指针了（CompressedOops，压缩指针也是32位）。\n颜色指针的三大优势\n一旦某个Region的存活对象被移走之后，这个Region立即就能够被释放和重用掉，而不必等待整个堆中所有指向该Region的引用都被修正后才能清理，这使得理论上只要还有一个空闲Region，ZGC就能完成收集\n颜色指针可以大幅减少在垃圾收集过程中内存屏障的使用数量，ZGC只使用了读屏障\n颜色指针具备强大的扩展性，它可以作为一种可扩展的存储结构用来记录更多与对象标记、重定位过程相关的数据，以便日后进一步提高性能\n\n读屏障之前的GC都是采用Write Barrier，这次ZGC采用了完全不同的方案读屏障，这个是ZGC一个非常重要的特性。在标记和移动对象的阶段，每次「从堆里对象的引用类型中读取一个指针」的时候，都需要加上一个Load Barriers。那么我们该如何理解它呢？看下面的代码，第一行代码我们尝试读取堆中的一个对象引用obj.fieldA并赋给引用o（fieldA也是一个对象时才会加上读屏障）。如果这时候对象在GC时被移动了，接下来JVM就会加上一个读屏障，这个屏障会把读出的指针更新到对象的新地址上，并且把堆里的这个指针“修正”到原本的字段里。这样就算GC把对象移动了，读屏障也会发现并修正指针，于是应用代码就永远都会持有更新后的有效指针，而且不需要STW。那么，JVM是如何判断对象被移动过呢？就是利用上面提到的颜色指针，如果指针是Bad Color，那么程序还不能往下执行，需要「slow path」，修正指针；如果指针是Good Color，那么正常往下执行即可:\n\n❝ 这个动作是不是非常像JDK并发中用到的CAS自旋？读取的值发现已经失效了，需要重新读取。而ZGC这里是之前持有的指针由于GC后失效了，需要通过读屏障修正指针。❞后面3行代码都不需要加读屏障：Object p = o这行代码并没有从堆中读取数据；o.doSomething()也没有从堆中读取数据；obj.fieldB不是对象引用，而是原子类型。正是因为Load Barriers的存在，所以会导致配置ZGC的应用的吞吐量会变低。官方的测试数据是需要多出额外4%的开销:\n\n那么，判断对象是Bad Color还是Good Color的依据是什么呢？就是根据上一段提到的Colored Pointers的4个颜色位。当加上读屏障时，根据对象指针中这4位的信息，就能知道当前对象是Bad/Good Color了。PS：既然低42位指针可以支持4T内存，那么能否通过预约更多位给对象地址来达到支持更大内存的目的呢？答案肯定是不可以。因为目前主板地址总线最宽只有48bit，4位是颜色位，就只剩44位了，所以受限于目前的硬件，ZGC最大只能支持16T的内存，JDK13就把最大支持堆内存从4T扩大到了16T。\nZGC存在的问题ZGC最大的问题是浮动垃圾。ZGC的停顿时间是在10ms以下，但是ZGC的执行时间还是远远大于这个时间的。假如ZGC全过程需要执行10分钟，在这个期间由于对象分配速率很高，将创建大量的新对象，这些对象很难进入当次GC，所以只能在下次GC的时候进行回收，这些只能等到下次GC才能回收的对象就是浮动垃圾。\n\nZGC没有分代概念，每次都需要进行全堆扫描，导致一些“朝生夕死”的对象没能及时的被回收。\n\n解决方案:\n目前唯一的办法是增大堆的容量，使得程序得到更多的喘息时间，但是这个也是一个治标不治本的方案。如果需要从根本上解决这个问题，还是需要引入分代收集，让新生对象都在一个专门的区域中创建，然后专门针对这个区域进行更频繁、更快的收集。\nZGC参数设置启用ZGC比较简单，设置JVM参数即可：-XX:+UnlockExperimentalVMOptions 「-XX:+UseZGC」。调优也并不难，因为ZGC调优参数并不多，远不像CMS那么复杂。它和G1一样，可以调优的参数都比较少，大部分工作JVM能很好的自动完成。\n\nZGC触发时机ZGC目前有4中机制触发GC：\n\n定时触发，默认为不使用，可通过ZCollectionInterval参数配置。\n预热触发，最多三次，在堆内存达到10%、20%、30%时触发，主要时统计GC时间，为其他GC机制使用。\n分配速率，基于正态分布统计，计算内存99.9%可能的最大分配速率，以及此速率下内存将要耗尽的时间点，在耗尽之前触发GC（耗尽时间 - 一次GC最大持续时间 - 一次GC检测周期时间）。\n主动触发，（默认开启，可通过ZProactive参数配置）距上次GC堆内存增长10%，或超过5分钟时，对比距上次GC的间隔时间跟（49 * 一次GC的最大持续时间），超过则触发。\n\n如何选择垃圾收集器\n优先调整堆的大小让服务器自己来选择\n如果内存小于100M，使用串行收集器\n如果是单核，并且没有停顿时间的要求，串行或JVM自己选择\n如果允许停顿时间超过1秒，选择并行或者JVM自己选\n如果响应时间最重要，并且不能超过1秒，使用并发收集器\n4G以下可以用parallel，4-8G可以用ParNew+CMS，8G以上可以用G1，几百G以上用ZGC\n\n下图有连线的可以搭配使用\n\n\nJDK 1.8默认使用 Parallel(年轻代和老年代都是)\n\n\nJDK 1.9默认使用G1    \n\n安全点与安全区域安全点就是指代码中一些特定的位置,当线程运行到这些位置时它的状态是确定的,这样JVM就可以安全的进行一些操作,比如GC等，所以GC不是想什么时候做就立即触发的，是需要等待所有线程运行到安全点后才能触发。这些特定的安全点位置主要有以下几种:\n\n方法返回之前\n调用某个方法之后\n抛出异常的位置\n循环的末尾\n\n大体实现思想是当垃圾收集需要中断线程的时候，不直接对线程操作，仅仅简单地设置一个标志位，各个线程执行过程时会不停地主动去轮询这个标志，一旦发现中断标志为真时就自己在最近的安全点上主动中断挂起。轮询标志的地方和安全点是重合的。\n什么是安全区域？Safe Point 是对正在执行的线程设定的。如果一个线程处于 Sleep 或中断状态，它就不能响应 JVM 的中断请求，再运行到 Safe Point 上。因此 JVM 引入了 Safe Region。Safe Region 是指在一段代码片段中，引用关系不会发生变化。在这个区域内的任意地方开始 GC 都是安全的。\n","categories":["Java"],"tags":["JVM"]},{"title":"垃圾收集器ParNew&CMS与底层三色标记算法详解","url":"/2020/07/12/Java/JVM/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8ParNew-CMS%E4%B8%8E%E5%BA%95%E5%B1%82%E4%B8%89%E8%89%B2%E6%A0%87%E8%AE%B0%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3/","content":"垃圾收集算法\n\n分代收集理论当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将java堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。比如在新生代中，每次收集都会有大量对象(近99%)死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。注意，“标记-清除”或“标记-整理”算法会比复制算法慢10倍以上。\n标记-复制算法为了解决效率问题，“复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。\n\n\n标记-清除算法算法分为“标记”和“清除”阶段：标记存活的对象， 统一回收所有未被标记的对象(一般选择这种)；也可以反过来，标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象 。它是最基础的收集算法，比较简单，但是会带来两个明显的问题：\n\n效率问题 (如果需要标记的对象太多，效率不高)\n空间问题（标记清除后会产生大量不连续的碎片）\n\n\n\n标记-整理算法根据老年代的特点特出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。\n\n\n垃圾收集器\n如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。虽然我们对各个收集器进行比较，但并非为了挑选出一个最好的收集器。因为直到现在为止还没有最好的垃圾收集器出现，更加没有万能的垃圾收集器，我们能做的就是根据具体应用场景选择适合自己的垃圾收集器。试想一下：如果有一种四海之内、任何场景下都适用的完美收集器存在，那么我们的Java虚拟机就不会实现那么多不同的垃圾收集器了。\nSerial收集器(-XX:+UseSerialGC -XX:+UseSerialOldGC)Serial（串行）收集器是最基本、历史最悠久的垃圾收集器了。看名字就知道这个收集器是一个单线程收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ “Stop The World” ），直到它收集结束。新生代采用复制算法，老年代采用标记-整理算法。\n\n虚拟机的设计者们当然知道Stop The World带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续）。但是Serial收集器有没有优于其他垃圾收集器的地方呢？当然有，它简单而高效（与其他收集器的单线程相比）。Serial收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。Serial Old收集器是Serial收集器的老年代版本，它同样是一个单线程收集器。它主要有两大用途：一种用途是在JDK1.5以及以前的版本中与Parallel Scavenge收集器搭配使用，另一种用途是作为CMS收集器的后备方案。\nParallel Scavenge收集器(-XX:+UseParallelGC(年轻代),-XX:+UseParallelOldGC(老年代))Parallel Scavenge收集器关注点是吞吐量（高效率的利用CPU）。CMS等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是CPU中用于运行用户代码的时间与CPU总消耗时间的比值。 收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解的话，可以选择把内存管理优化交给虚拟机去完成也是一个不错的选择。新生代采用复制算法，老年代采用标记-整理算法。\n\nParallel Old收集器是Parallel Scavenge收集器的老年代版本。使用多线程和“标记-整理”算法。在注重吞吐量以及CPU资源的场合，都可以优先考虑 Parallel Scavenge收集器和Parallel Old收集器**(JDK8默认的新生代和老年代收集器)**。\nParNew收集器(-XX:+UseParNewGC)ParNew收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和Serial收集器类似。默认的收集线程数跟cpu核数相同，当然也可以用参数(-XX:ParallelGCThreads)指定收集线程数，但是一般不推荐修改。\nParNew收集器其实跟Parallel收集器很类似，区别主要在于它可以和CMS收集器配合使用。新生代采用复制算法，老年代采用标记-整理算法。\n\n它是许多运行在Server模式下的虚拟机的首要选择，除了Serial收集器外，只有它能与CMS收集器（真正意义上的并发收集器，后面会介绍到）配合工作。\nCMS收集器(-XX:+UseConcMarkSweepGC(old))CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用，它是HotSpot虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。\n从名字中的Mark Sweep这两个词可以看出，CMS收集器是一种 “标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤：\n\n初始标记： \n暂停所有的其他线程(STW)，并记录下gc roots直接能引用的对象，速度很快。\n\n并发标记： \n并发标记阶段就是从GC Roots的直接关联对象开始遍历整个对象图的过程， 这个过程耗时较长但是不需要停顿用户线程， 可以与垃圾收集线程一起并发运行。因为用户程序继续运行，可能会有导致已经标记过的对象状态发生改变。\n\n重新标记：\n重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短。主要用到三色标记里的增量更新算法(见下面详解)做重新标记。\n\n并发清理：\n开启用户线程，同时GC线程开始对未标记的区域做清扫。这个阶段如果有新增对象会被标记为黑色不做任何处理(见下面三色标记算法详解)。\n\n并发重置：\n重置本次GC过程中的标记数据。\n\n\n\n从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：并发收集、低停顿。但是它有下面几个明显的缺点：\n\n对CPU资源敏感（会和服务抢资源）\n无法处理浮动垃圾(在并发标记和并发清理阶段又产生垃圾，这种浮动垃圾只能等到下一次gc再清理了)\n它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生，当然通过参数-XX:+UseCMSCompactAtFullCollection可以让jvm在执行完标记清除后再做整理\n执行过程中的不确定性，会存在上一次垃圾回收还没执行完，然后垃圾回收又被触发的情况，特别是在并发标记和并发清理阶段会出现，一边回收，系统一边运行，也许没回收完就再次触发full gc，也就是”concurrent mode failure“，此时会进入stop the world，用serial old垃圾收集器来回收\n\nCMS的相关核心参数:\n\n-XX:+UseConcMarkSweepGC：启用cms-XX:ConcGCThreads：并发的GC线程数-XX:+UseCMSCompactAtFullCollection：FullGC之后做压缩整理（减少碎片）-XX:CMSFullGCsBeforeCompaction：多少次FullGC之后压缩一次，默认是0，代表每次FullGC后都会压缩一次-XX:CMSInitiatingOccupancyFraction:     当老年代使用达到该比例时会触发FullGC（默认是92，这是百分比）-XX:+UseCMSInitiatingOccupancyOnly：只使用设定的回收阈值(-XX:CMSInitiatingOccupancyFraction设定的值)，如果不指定，JVM仅在第一次使用设定值，后续则会自动调整-XX:+CMSScavengeBeforeRemark：在CMS  GC前启动一次minor gc，降低CMS GC标记阶段(也会对年轻代一起做标记，如果在minor     gc就干掉了很多对垃圾对象，标记阶段就会减少一些标记时间)时的开销，一般CMS的GC耗时 80%都在标记阶段-XX:+CMSParallellnitialMarkEnabled：表示在初始标记的时候多线程执行，缩短STW-XX:+CMSParallelRemarkEnabled：在重新标记的时候多线程执行，缩短STW\n\n电商系统如何优化JVM参数设置(ParNew+CMS)大型电商系统后端现在一般都是拆分为多个子系统部署的，比如，商品系统，库存系统，订单系统，促销系统，会员系统等等。我们这里以比较核心的订单系统为例\n\n对于8G内存，我们一般是分配4G内存给JVM，正常的JVM参数配置如下：\n-Xms3072M -Xmx3072M -Xss1M -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M  -XX:SurvivorRatio=8\n\n这样设置可能会由于动态对象年龄判断原则导致频繁full gc。于是我们可以更新下JVM参数设置：\n-Xms3072M -Xmx3072M -Xmn2048M -Xss1M -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M  -XX:SurvivorRatio=8\n\n\n这样就降低了因为对象动态年龄判断原则导致的对象频繁进入老年代的问题，其实很多优化无非就是让短期存活的对象尽量都留在survivor里，不要进入老年代，这样在minor gc的时候这些对象都会被回收，不会进到老年代从而导致full gc。对于对象年龄应该为多少才移动到老年代比较合适，本例中一次minor gc要间隔二三十秒，大多数对象一般在几秒内就会变为垃圾，完全可以将默认的15岁改小一点，比如改为5，那么意味着对象要经过5次minor gc才会进入老年代，整个时间也有一两分钟了，如果对象这么长时间都没被回收，完全可以认为这些对象是会存活的比较长的对象，可以移动到老年代，而不是继续一直占用survivor区空间。对于多大的对象直接进入老年代(参数-XX:PretenureSizeThreshold)，这个一般可以结合你自己系统看下有没有什么大对象生成，预估下大对象的大小，一般来说设置为1M就差不多了，很少有超过1M的大对象，这些对象一般就是你系统初始化分配的缓存对象，比如大的缓存List，Map之类的对象。\n可以适当调整JVM参数如下：\n-Xms3072M -Xmx3072M -Xmn2048M -Xss1M  -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M  -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=5 -XX:PretenureSizeThreshold=1M \n对于JDK8默认的垃圾回收器是-XX:+UseParallelGC(年轻代)和-XX:+UseParallelOldGC(老年代)，如果内存较大(超过4个G，只是经验值)，系统对停顿时间比较敏感，我们可以使用ParNew+CMS(-XX:+UseParNewGC -XX:+UseConcMarkSweepGC)对于老年代CMS的参数如何设置我们可以思考下，首先我们想下当前这个系统有哪些对象可能会长期存活躲过5次以上minor gc最终进入老年代。无非就是那些Spring容器里的Bean，线程池对象，一些初始化缓存数据对象等，这些加起来充其量也就几十MB。\n还有就是某次minor gc完了之后还有超过一两百M的对象存活，那么就会直接进入老年代，比如突然某一秒瞬间要处理五六百单，那么每秒生成的对象可能有一百多M，再加上整个系统可能压力剧增，一个订单要好几秒才能处理完，下一秒可能又有很多订单过来。\n我们可以估算下大概每隔五六分钟出现一次这样的情况，那么大概半小时到一小时之间就可能因为老年代满了触发一次Full GC，Full GC的触发条件还有我们之前说过的老年代空间分配担保机制，历次的minor gc挪动到老年代的对象大小肯定是非常小的，所以几乎不会在minor gc触发之前由于老年代空间分配担保失败而产生full gc，其实在半小时后发生full gc，这时候已经过了抢购的最高峰期，后续可能几小时才做一次FullGC。\n对于碎片整理，因为都是1小时或几小时才做一次FullGC，是可以每做完一次就开始碎片整理，或者两到三次之后再做一次也行。综上，只要年轻代参数设置合理，老年代CMS的参数设置基本都可以用默认值，如下所示：\n-Xms3072M -Xmx3072M -Xmn2048M -Xss1M  -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M  -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=5 -XX:PretenureSizeThreshold=1M -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=92 -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=3\n\n垃圾收集底层算法实现三色标记在并发标记的过程中，因为标记期间应用线程还在继续跑，对象间的引用可能发生变化，多标和漏标的情况就有可能发生。\n这里我们引入“三色标记”来解释下，把Gcroots可达性分析遍历对象过程中遇到的对象， 按照“是否访问过”这个条件标记成以下三种颜色：\n\n黑色：\n表示对象已经被垃圾收集器访问过， 且这个对象的所有引用都已经扫描过。 黑色的对象代表已经扫描过， 它是安全存活的， 如果有其他对象引用指向了黑色对象， 无须重新扫描一遍。 黑色对象不可能直接（不经过灰色对象） 指向某个白色对象。\n\n灰色： \n表示对象已经被垃圾收集器访问过， 但这个对象上至少存在一个引用还没有被扫描过。\n\n白色：\n表示对象尚未被垃圾收集器访问过。 显然在可达性分析刚刚开始的阶段， 所有的对象都是白色的， 若在分析结束的阶段， 仍然是白色的对象， 即代表不可达。\n\n\n\n/*** 垃圾收集算法细节之三色标记* 为了简化例子，代码写法可能不规范，请忽略*/public class ThreeColorRemark &#123;    public static void main(String[] args) &#123;        A a = new A();        //开始做并发标记        D d = a.b.d;   // 1.读        a.b.d = null;  // 2.写        a.d = d;       // 3.写    &#125;&#125;class A &#123;    B b = new B();    D d = null;&#125;class B &#123;    C c = new C();    D d = new D();&#125;class C &#123;&#125;class D &#123;&#125;\n\n多标-浮动垃圾在并发标记过程中，如果由于方法运行结束导致部分局部变量(gcroot)被销毁，这个gcroot引用的对象之前又被扫描过(被标记为非垃圾对象)，那么本轮GC不会回收这部分内存。这部分本应该回收但是没有回收到的内存，被称之为“浮动垃圾”。浮动垃圾并不会影响垃圾回收的正确性，只是需要等到下一轮垃圾回收中才被清除。另外，针对并发标记(还有并发清理)开始后产生的新对象，通常的做法是直接全部当成黑色，本轮不会进行清除。这部分对象期间可能也会变为垃圾，这也算是浮动垃圾的一部分。\n漏标-读写屏障漏标会导致被引用的对象被当成垃圾误删除，这是严重bug，必须解决，有两种解决方案：增量更新（Incremental Update）和原始快照（Snapshot At The Beginning，SATB）。\n\n增量更新\n当黑色对象插入新的指向白色对象的引用关系时，就将这个新插入的引用记录下来，等并发扫描结束之后，再将这些记录过的引用关系中的黑色对象为根，重新扫描一次。\n这可以简化理解为，黑色对象一旦新插入了指向白色对象的引用之后，它就变回灰色对象了。\n\n原始快照\n当灰色对象要删除指向白色对象的引用关系时，就将这个要删除的引用记录下来，在并发扫描结束之后，再将这些记录过的引用关系中的灰色对象为根，重新扫描一次。\n这样就能扫描到白色的对象，将白色对象直接标记为黑色(目的就是让这种对象在本轮gc清理中能存活下来，待下一轮gc的时候重新扫描，这个对象也有可能是浮动垃圾)\n\n\n以上无论是对引用关系记录的插入还是删除， 虚拟机的记录操作都是通过写屏障实现的。 \n写屏障给某个对象的成员变量赋值时，其底层代码大概长这样：\n/*** @param field 某对象的成员变量，如 a.b.d * @param new_value 新值，如 null*/void oop_field_store(oop* field, oop new_value) &#123;     *field = new_value; // 赋值操作&#125; \n\n所谓的写屏障，其实就是指在赋值操作前后，加入一些处理（可以参考AOP的概念）\nvoid oop_field_store(oop* field, oop new_value) &#123;      pre_write_barrier(field);            // 写屏障-写前操作    *field = new_value;     post_write_barrier(field, value);  // 写屏障-写后操作&#125;\n\n\n写屏障实现SATB\n当对象B的成员变量的引用发生变化时，比如引用消失（a.b.d = null），我们可以利用写屏障，将B原来成员变量的引用对象D记录下来：\nvoid pre_write_barrier(oop* field) &#123;    oop old_value = *field;    // 获取旧值    remark_set.add(old_value); // 记录原来的引用对象&#125;\n写屏障实现增量更新\n当对象A的成员变量的引用发生变化时，比如新增引用（a.d = d），我们可以利用写屏障，将A新的成员变量引用对象D记录下来：\nvoid post_write_barrier(oop* field, oop new_value) &#123;      remark_set.add(new_value);  // 记录新引用的对象&#125;\n\n读屏障oop oop_field_load(oop* field) &#123;    pre_load_barrier(field); // 读屏障-读取前操作    return *field;&#125;\n\n读屏障是直接针对第一步：D d = a.b.d，当读取成员变量时，一律记录下来：\nvoid pre_load_barrier(oop* field) &#123;      oop old_value = *field;    remark_set.add(old_value); // 记录读取到的对象&#125;\n\n现代追踪式（可达性分析）的垃圾回收器几乎都借鉴了三色标记的算法思想，尽管实现的方式不尽相同：比如白色/黑色集合一般都不会出现（但是有其他体现颜色的地方）、灰色集合可以通过栈/队列/缓存日志等方式进行实现、遍历方式可以是广度/深度遍历等等。\n对于读写屏障，以Java HotSpot VM为例，其并发标记时对漏标的处理方案如下：\n\nCMS：写屏障 + 增量更新\nG1，Shenandoah：写屏障     + SATB\nZGC：读屏障\n\n工程实现中，读写屏障还有其他功能，比如写屏障可以用于记录跨代/区引用的变化，读屏障可以用于支持移动对象的并发执行等。功能之外，还有性能的考虑，所以对于选择哪种，每款垃圾回收器都有自己的想法。\n为什么G1用SATB？CMS用增量更新？\nSATB相对增量更新效率会高(当然SATB可能造成更多的浮动垃圾)，因为不需要在重新标记阶段再次深度扫描被删除引用对象，而CMS对增量引用的根对象会做深度扫描，G1因为很多对象都位于不同的region，CMS就一块老年代区域，重新深度扫描对象的话G1的代价会比CMS高，所以G1选择SATB不深度扫描对象，只是简单标记，等到下一轮GC再深度扫描。\n记忆集与卡表在新生代做GCRoots可达性扫描过程中可能会碰到跨代引用的对象，这种如果又去对老年代再去扫描效率太低了。为此，在新生代可以引入记录集（Remember Set）的数据结构（记录从非收集区到收集区的指针集合），避免把整个老年代加入GCRoots扫描范围。事实上并不只是新生代、 老年代之间才有跨代引用的问题， 所有涉及部分区域收集（Partial GC） 行为的垃圾收集器， 典型的如G1、 ZGC和Shenandoah收集器， 都会面临相同的问题。垃圾收集场景中，收集器只需通过记忆集判断出某一块非收集区域是否存在指向收集区域的指针即可，无需了解跨代引用指针的全部细节。hotspot使用一种叫做“卡表”(Cardtable)的方式实现记忆集，也是目前最常用的一种方式。关于卡表与记忆集的关系， 可以类比为Java语言中HashMap与Map的关系。卡表是使用一个字节数组实现：CARD_TABLE[ ]，每个元素对应着其标识的内存区域一块特定大小的内存块，称为“卡页”。hotSpot使用的卡页是2^9大小，即512字节\n\n\n一个卡页中可包含多个对象，只要有一个对象的字段存在跨代指针，其对应的卡表的元素标识就变成1，表示该元素变脏，否则为0。GC时，只要筛选本收集区的卡表中变脏的元素加入GCRoots里。\n卡表的维护卡表变脏上面已经说了，但是需要知道如何让卡表变脏，即发生引用字段赋值时，如何更新卡表对应的标识为1。Hotspot使用写屏障维护卡表状态。\n","categories":["Java"],"tags":["JVM"]},{"title":"Spring设计模式总结","url":"/2021/10/03/Java/Spring/Spring%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%80%BB%E7%BB%93/","content":"简单工厂实现方式Spring中的BeanFactory就是简单工厂模式的体现，根据传入一个唯一的标识来获得Bean对象，但是否是在传入参数后创建还是传入参数前创建这个要根据具体情况来定。\n实质由一个工厂类根据传入的参数，动态决定应该创建哪一个产品类。\n实现原理bean容器的启动阶段：\n\n读取bean的配置，讲bean元素分别转换成一个BeanDefinition对象。\n通过BeanDefinitionRegistry将这些bean注册到beanFactory中，保存在它额度一个ConcurrentHashMap中。\n将BeanDefinition注册到了beanFactory之后，在这里Spring为我们提供了一个扩展的切口，允许我们通过实现接口BeanFactoryPostProcessor 在此处来插入我们定义的代码。\n\n典型的例子就是：PropertyPlaceholderConfigurer，我们一般在配置数据库的dataSource时使用到的占位符的值，就是它注入进去的。\n容器中bean的实例化阶段：\n实例化阶段主要是通过反射或者CGLIB对bean进行实例化，在这个阶段Spring又给我们暴露了很多的扩展点\n\n各种的Aware接口：比如 BeanFactoryAware，对于实现了这些Aware接口的bean，在实例化bean时Spring会帮我们注入对应的BeanFactory的实例\nBeanPostProcessor接口：实现了BeanPostProcessor接口的bean，在实例化bean时Spring会帮我们调用接口中的方法\nInitializingBean接口：实现了InitializingBean接口的bean，在实例化bean时Spring会帮我们调用接口中的方法\nDisposableBean接口：实现了BeanPostProcessor接口的bean，在该bean死亡时Spring会帮我们调用接口中的方法\n\n设计意义松耦合可以将原来硬编码的依赖，通过Spring这个beanFactory这个工厂来注入依赖，也就是说原来只有依赖方和被依赖方，现在我们引入了第三方——spring这个beanFactory，由它来解决bean之间的依赖问题，达到了松耦合的效果。\nbean的额外处理通过Spring接口的暴露，在实例化bean的阶段我们可以进行一些额外的处理，这些额外的处理只需要让bean实现对应的接口即可，那么spring就会在bean的生命周期调用我们实现的接口来处理该bean。\n工厂方法实现方式factoryBean接口\n实现原理实现了FactoryBean接口的bean是一类叫做factory的bean。其特点是，spring会在使用getBean()调用获得该bean时，会自动调用该bean的getObject()方法，所以返回的不是factory这个bean，而是这个bean.getOjbect()方法的返回值。\n单例模式实现原理Spring依赖注入的Bean实例默认是单例的。\nSpring的依赖注入（包括lazy-init方式）都是发生在AbstractBeanFactory的getBean里。getBean的doGetBean方法调用getSingleton进行bean的创建。\ngetSingleton()方法：\npublic Object getSingleton(String beanName)&#123;    //参数true设置标识允许早期依赖    return getSingleton(beanName,true);&#125;protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123;    //检查缓存中是否存在实例    Object singletonObject = this.singletonObjects.get(beanName);    if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123;        //如果为空，则锁定全局变量并进行处理。        synchronized (this.singletonObjects) &#123;            //如果此bean正在加载，则不处理            singletonObject = this.earlySingletonObjects.get(beanName);            if (singletonObject == null &amp;&amp; allowEarlyReference) &#123;                  //当某些方法需要提前初始化的时候则会调用addSingleFactory 方法将对应的ObjectFactory初始化策略存储在singletonFactories                ObjectFactory singletonFactory = this.singletonFactories.get(beanName);                if (singletonFactory != null) &#123;                    //调用预先设定的getObject方法                    singletonObject = singletonFactory.getObject();                    //记录在缓存中，earlysingletonObjects和singletonFactories互斥                    this.earlySingletonObjects.put(beanName, singletonObject);                    this.singletonFactories.remove(beanName);                &#125;            &#125;        &#125;    &#125;    return (singletonObject != NULL_OBJECT ? singletonObject : null);&#125;\n\n流程图：\n\n单例模式定义：保证一个类仅有一个实例，并提供一个访问它的全局访问点。\nSpring对单例的实现：spring中的单例模式完成了后半句话，即提供了全局的访问点BeanFactory。但没有从构造器级别去控制单例，这是因为spring管理的是任意的java对象。\n适配器模式实现方式SpringMVC中的适配器HandlerAdatper\n实现原理HandlerAdatper根据Handler规则执行不同的Handler\n实现过程DispatcherServlet根据HandlerMapping返回的handler，向HandlerAdatper发起请求，处理Handler。\nHandlerAdapter根据规则找到对应的Handler并让其执行，执行完毕后Handler会向HandlerAdapter返回一个ModelAndView，最后由HandlerAdapter向DispatchServelet返回一个ModelAndView。\n实现意义HandlerAdatper使得Handler的扩展变得容易，只需要增加一个新的Handler和一个对应的HandlerAdapter即可。\n因此Spring定义了一个适配接口，使得每一种Controller有一种对应的适配器实现类，让适配器代替controller执行相应的方法。这样在扩展Controller时，只需要增加一个适配器类就完成了SpringMVC的扩展了。\n装饰器实现方式Spring中用到的包装器模式在类名上有两种表现：一种是类名中含有Wrapper，另一种是类名中含有Decorator。\n实现意义动态地给一个对象添加一些额外的职责。\n就增加功能来说，Decorator模式相比生成子类更为灵活。\n代理模式实现方式AOP底层，就是通过动态代理模式实现的\n动态代理在内存中构建，不需要手动编写代理类\n静态代理需要手工编写代理类，代理类引用被代理对象\n实现原理切面在应用运行的时刻被织入。一般情况下，在织入切面时，AOP容器会为目标对象创建动态的创建一个代理对象。SpringAOP就是以这种方式织入切面的。\n织入：把切面应用到目标对象并创建新的代理对象的过程。\n观察者模式实现方式spring的事件驱动模型使用的是 观察者模式 ，Spring中Observer模式常用的地方是listener的实现。\n具体实现事件机制的实现需要三个部分,事件源,事件,事件监听器\nApplicationEvent抽象类[事件]\n继承自jdk的EventObject,所有的事件都需要继承ApplicationEvent,并且通过构造器参数source得到事件源.\n该类的实现类ApplicationContextEvent表示ApplicaitonContext的容器事件.\npublic abstract class ApplicationEvent extends EventObject&#123;    private static final long serialVersionUID = 7099057708183571937L;    private final long timestamp;    public ApplicationEvent(Object source)&#123;        super(source);        this.timestamp = System.currentTimeMillis();    &#125;    public final longget Timestamp()&#123;        returnthis.timestamp;    &#125;&#125;\n\nApplicationContext接口[事件源]\nApplicationContext是spring中的全局容器，翻译过来是”应用上下文”。\n实现了ApplicationEventPublisher接口。\nSpring通过它去负责读取bean的配置文档,管理bean的加载,维护bean之间的依赖关系,可以说是负责bean的整个生命周期,再通俗一点就是我们平时所说的IOC容器。\npublic interface ApplicationEventPublisher &#123;    voidpublishEvent(ApplicationEvent event);&#125;   public voi dpublishEvent(ApplicationEvent event) &#123;    Assert.notNull(event, &quot;Event must not be null&quot;);    if (logger.isTraceEnabled()) &#123;        logger.trace(&quot;Publishing event in &quot; + getDisplayName() + &quot;: &quot; + event);    &#125;    getApplicationEventMulticaster().multicastEvent(event);    if (this.parent != null) &#123;        this.parent.publishEvent(event);    &#125;&#125;\n\nApplicationEventMulticaster抽象类[事件源中publishEvent方法需要调用其方法getApplicationEventMulticaster]\n属于事件广播器,它的作用是把Applicationcontext发布的Event广播给所有的监听器.\npublic abstract class AbstractApplicationContext extends DefaultResourceLoader    implements ConfigurableApplicationContext, DisposableBean &#123;      private ApplicationEventMulticaster applicationEventMulticaster;      protectedvoid registerListeners() &#123;          // Register statically specified listeners first.          for (ApplicationListener&gt; listener : getApplicationListeners()) &#123;              getApplicationEventMulticaster().addApplicationListener(listener);          &#125;          // Do not initialize FactoryBeans here: We need to leave all regular beans          // uninitialized to let post-processors apply to them!          String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false);          for (String lisName : listenerBeanNames) &#123;              getApplicationEventMulticaster().addApplicationListenerBean(lisName);          &#125;      &#125;  &#125;\n\n策略模式实现方式Spring框架的资源访问Resource接口。该接口提供了更强的资源访问能力，Spring 框架本身大量使用了 Resource 接口来访问底层资源\nResource 接口介绍source 接口是具体资源访问策略的抽象，也是所有资源访问类所实现的接口。\nResource 接口主要提供了如下几个方法:\n\ngetInputStream：定位并打开资源，返回资源对应的输入流。每次调用都返回新的输入流。调用者必须负责关闭输入流。\nexists：返回 Resource 所指向的资源是否存在。\nisOpen：返回资源文件是否打开，如果资源文件不能多次读取，每次读取结束应该显式关闭，以防止资源泄漏。\ngetDescription：返回资源的描述信息，通常用于资源处理出错时输出该信息，通常是全限定文件名或实际 URL。\ngetFile：返回资源对应的 File 对象。\ngetURL：返回资源对应的 URL 对象。\n\n最后两个方法通常无须使用，仅在通过简单方式访问无法实现时，Resource 提供传统的资源访问的功能。\nResource 接口本身没有提供访问任何底层资源的实现逻辑，针对不同的底层资源，Spring 将会提供不同的 Resource 实现类，不同的实现类负责不同的资源访问逻辑。\nSpring 为 Resource 接口提供了如下实现类\n\nUrlResource：访问网络资源的实现类。\nClassPathResource：访问类加载路径里资源的实现类。\nFileSystemResource：访问文件系统里资源的实现类。\nServletContextResource：访问相对于 ServletContext 路径里的资源的实现类.\nInputStreamResource：访问输入流资源的实现类。\nByteArrayResource：访问字节数组资源的实现类。\n\n这些 Resource 实现类，针对不同的的底层资源，提供了相应的资源访问逻辑，并提供便捷的包装，以利于客户端程序的资源访问。\n模板方法模式经典模板方法定义父类定义了骨架（调用哪些方法及顺序），某些特定方法由子类实现。\n最大的好处：代码复用，减少重复代码。除了子类要实现的特定方法，其他方法及方法调用顺序都在父类中预先写好了。\n所以父类模板方法中有两类方法：\n\n共同的方法：所有子类都会用到的代码\n不同的方法：子类要覆盖的方法\n\nSpring中的应用Spring几乎所有的外接扩展都采用这种模式\nJdbcTempalteJDBC的抽象和对Hibernate的集成，都采用了一种理念或者处理方式，那就是模板方法模式与相应的Callback接口相结合。\n采用模板方法模式是为了以一种统一而集中的方式来处理资源的获取和释放\npublic abstract class JdbcTemplate&#123;      public final Object execute(String sql)&#123;          Connection con=null;          Statement stmt=null;          try&#123;              con=getConnection();              stmt=con.createStatement();              Object retValue=executeWithStatement(stmt,sql);              return retValue;          &#125;catch(SQLException e)&#123;              ...          &#125;finally&#123;              closeStatement(stmt);              releaseConnection(con);          &#125;      &#125;       protected abstract Object executeWithStatement(Statement   stmt, String sql);  &#125;  \n\n引入回调原因：\nJdbcTemplate是抽象类，不能够独立使用，我们每次进行数据访问的时候都要给出一个相应的子类实现,这样肯定不方便，所以就引入了回调\npublic interface StatementCallback&#123;      Object doWithStatement（Statement stmt）;  &#125;   \n\n利用回调方法重写JdbcTemplate方法\npublic class JdbcTemplate&#123;      public final Object execute(StatementCallback callback)&#123;          Connection con=null;          Statement stmt=null;          try&#123;              con=getConnection();              stmt=con.createStatement();              Object retValue=callback.doWithStatement(stmt);              return retValue;          &#125;catch(SQLException e)&#123;              ...          &#125;finally&#123;              closeStatement(stmt);              releaseConnection(con);          &#125;      &#125;      ...//其它方法定义  &#125;   \n\nJdbc使用方法如下\nJdbcTemplate jdbcTemplate=...;  final String sql=...;  StatementCallback callback=new StatementCallback()&#123;      public Object=doWithStatement(Statement stmt)&#123;          return ...;      &#125;  &#125;    jdbcTemplate.execute(callback);  \n\n为什么JdbcTemplate没有使用继承？\n因为这个类的方法太多，但是我们还是想用到JdbcTemplate已有的稳定的、公用的数据库连接，那么我们怎么办呢？\n我们可以把变化的东西抽出来作为一个参数传入JdbcTemplate的方法中。但是变化的东西是一段代码，而且这段代码会用到JdbcTemplate中的变量。怎么办？\n那我们就用回调对象吧。在这个回调对象中定义一个操纵JdbcTemplate中变量的方法，我们去实现这个方法，就把变化的东西集中到这里了。然后我们再传入这个回调对象到JdbcTemplate，从而完成了调用。 \n责任链模式CglibAopProxy类第688行：\nnew CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed();\n\n参数 chain:拦截器链，保含了目标方法的所有切面方法 ，从chain里面的数组元素的顺序来看，拦截器的顺序before不再after前面执行\n 每一个 Interceptor有一个**invoke()**方法\nInterceptor是一个空接口  MethodInterceptor extends Interceptor  ，以下是Interceptor的继承结构\npublic interface Advice &#123;&#125;public interface Interceptor extends Advice &#123;&#125;public interface MethodInterceptor extends Interceptor &#123;    Object invoke(MethodInvocation invocation) throws Throwable;&#125;\n\nObject invoke(MethodInvocation invocation) throws Throwable方法：\n参数 ：MethodInvocation 类中有proceed()方法，以下是MethodInvocation的继承结构：\npublic interface Joinpoint &#123;    Object proceed() throws Throwable;    Object getThis();    AccessibleObject getStaticPart();&#125;public interface Invocation extends Joinpoint &#123;    Object[] getArguments();&#125;public interface MethodInvocation extends Invocation &#123;    Method getMethod();&#125;\n\nReflectiveMethodInvocation implements ProxyMethodInvocation \nProxyMethodInvocation extends MethodInvocation\nspring的拦截器 xxxInterceptor都实现了自己的 Object invoke(MethodInvocation invocation)方法\nReflectiveMethodInvocation类中的 proceed()方法会遍历拦截器链，调用每个拦截器的invoke方法，传入ReflectiveMethodInvocation自身作为参数，\n每个拦截器的invoke方法做两件事(这两件事的执行顺序因拦截器的功能而异)：\n\n执行自己的业务逻辑 \n执行ReflectiveMethodInvocation的proceed()：这样就实现了链式调用\n\n责任链模式定义统一的业务接口：Handler接口 中的方法invoke(),即业务方法\n责任链相当于一个负责人集合，每一个负责人都实现了自己的invoke()方法来处理传进来的数据或对象或对象的指定方法\n如何通知下一个负责人处理业务：\n\n设计一个责任链执行器，包含责任链集合。责任链执行器中有一个proceed(),方法内遍历执行负责人的invoke()方法，invoke方法以执行器作为参数：\n invoke(执行器)，invoke(执行器)处理完业务后，执行器又调用proceed()方法，将索引移到下一个负责人位置。\n这样：执行器和负责人的方法相互调用，而执行器通过移动索引通知下一个负责人处理业务。\n\n基于链表的责任链，每一个负责人是一个责任节点Node，包含指向下一个负责人的next引用\n负责人的处理业务的方法 invoke()这时不带参数，invoke()方法里面递归调用invoke()方法，并设置出口条件。\n如何通知下一个负责人处理业务：invoke()方法：1.处理业务，2.next.invoke()，3.出口条件可以是next!=null\n\n\n这个是脑图\n","categories":["Java"],"tags":["Spring"]},{"title":"springMvc执行流程与源码解析","url":"/2021/08/26/Java/Spring/springMvc%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E4%B8%8E%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/","content":""},{"title":"spring整体脉络","url":"/2021/12/09/Java/Spring/spring%E6%95%B4%E4%BD%93%E8%84%89%E7%BB%9C/","content":"","categories":["Java"],"tags":["Spring"]},{"title":"Atomic&Unsafe魔法类详解","url":"/2020/10/20/Java/%E5%B9%B6%E5%8F%91/Atomic-Unsafe%E9%AD%94%E6%B3%95%E7%B1%BB%E8%AF%A6%E8%A7%A3/","content":"原子操作原子（atom）本意是“不能被进一步分割的最小粒子”，而原子操作（atomic operation）意为”不可被中断的一个或一系列操作” 。在多处理器上实现原子操作就变得有点复杂。本文让我们一起来聊一聊在Inter处理器和Java里是如何实现原子操作的。\n相关术语\n\n\n术语名称\n英文\n解释\n\n\n\n缓存行\nCache line\n缓存的最小操作单位\n\n\n比较并交换\nCompare and Swap\nCAS操作需要输入两个数值，一个旧值（期望操作前的值）和一个新值，在操作期间先比较下在旧值有没有发生变化，如果没有发生变化，才交换成新值，发生了变化则不交换。\n\n\nCPU流水线\nCPU pipeline\nCPU流水线的工作方式就象工业生产上的装配流水线，在CPU中由56个不同功能的电路单元组成一条指令处理流水线，然后将一条X86指令分成56步后再由这些电路单元分别执行，这样就能实现在一个CPU时钟周期完成一条指令，因此提高CPU的运算速度。\n\n\n内存顺序冲突\nMemory order violation\n内存顺序冲突一般是由假共享引起，假共享是指多个CPU同时修改同一个缓存行的不同部分而引起其中一个CPU的操作无效，当出现这个内存顺序冲突时，CPU必须清空流水线。\n\n\n处理器如何实现原子操作32位IA-32处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。\n处理器自动保证基本内存操作的原子性首先处理器会自动保证基本的内存操作的原子性。处理器保证从系统内存当中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。奔腾6和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64位的操作是原子的，但是复杂的内存操作处理器不能自动保证其原子性，比如跨总线宽度，跨多个缓存行，跨页表的访问。但是处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。\n使用总线锁保证原子性第一个机制是通过总线锁保证原子性。如果多个处理器同时对共享变量进行读改写（i++就是经典的读改写操作）操作，那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致，举个例子：如果i=1,我们进行两次i++操作，我们期望的结果是3，但是有可能结果是2。\n\n原因是有可能多个处理器同时从各自的缓存中读取变量i，分别进行加一操作，然后分别写入系统内存当中。那么想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。\n处理器使用总线锁就是来解决这个问题的。所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住,那么该处理器可以独占使用共享内存。\n使用缓存锁保证原子性第二个机制是通过缓存锁定保证原子性。在同一时刻我们只需保证对某个内存地址的操作是原子性即可，但总线锁定把CPU和内存之间通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，最近的处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。\n频繁使用的内存会缓存在处理器的L1，L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁，在奔腾6和最近的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。所谓“缓存锁定”就是如果缓存在处理器缓存行中内存区域在LOCK操作期间被锁定，当它执行锁操作回写内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改被两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时会起缓存行无效，在例1中，当CPU1修改缓存行中的i时使用缓存锁定，那么CPU2就不能同时缓存了i的缓存行。\n但是有两种情况下处理器不会使用缓存锁定。第一种情况是：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line），则处理器会调用总线锁定。第二种情况是：有些处理器不支持缓存锁定。对于Inter486和奔腾处理器,就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。\n以上两个机制我们可以通过Inter处理器提供了很多LOCK前缀的指令来实现。比如位测试和修改指令BTS，BTR，BTC，交换指令XADD，CMPXCHG和其他一些操作数和逻辑指令，比如ADD（加），OR（或）等，被这些指令操作的内存区域就会加锁，导致其他处理器不能同时访问它。\nJava当中如何实现原子操作在java中可以通过锁和循环CAS的方式来实现原子操作。\nJVM中的CAS操作正是利用了上文中提到的处理器提供的CMPXCHG指令实现的。自旋CAS实现的基本思路就是循环进行CAS操作直到成功为止，具体的类可以参见juc下的atomic包内的原子类。\nAtomic在Atomic包里一共有12个类，四种原子更新方式，分别是原子更新基本类型，原子更新数组，原子更新引用和原子更新字段。Atomic包里的类基本都是使用Unsafe实现的包装类。\n\n基本类：AtomicInteger、AtomicLong、AtomicBoolean；\n\n引用类型：AtomicReference、AtomicReference的ABA实例、AtomicStampedRerence、AtomicMarkableReference；\n\n数组类型：AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray\n\n属性原子修改器（Updater）：AtomicIntegerFieldUpdater、AtomicLongFieldUpdater、AtomicReferenceFieldUpdater\n\n\n原子更新基本类型类用于通过原子的方式更新基本类型，Atomic包提供了以下三个类：\n\nAtomicBoolean：原子更新布尔类型。\nAtomicInteger：原子更新整型。\nAtomicLong：原子更新长整型。\n\nAtomicInteger的常用方法如下：\n\nint addAndGet(int delta) ：以原子方式将输入的数值与实例中的值（AtomicInteger里的value）相加，并返回结果\nboolean compareAndSet(int expect, int update) ：如果输入的数值等于预期值，则以原子方式将该值设置为输入的值。\nint getAndIncrement()：以原子方式将当前值加1，注意：这里返回的是自增前的值。\nvoid lazySet(int newValue)：最终会设置成newValue，使用lazySet设置值后，可能导致其他线程在之后的一小段时间内还是可以读到旧的值。\nint getAndSet(int newValue)：以原子方式设置为newValue的值，并返回旧值。\n\nAtomic包提供了三种基本类型的原子更新，但是Java的基本类型里还有char，float和double等。那么问题来了，如何原子的更新其他的基本类型呢？Atomic包里的类基本都是使用Unsafe实现的，Unsafe只提供了三种CAS方法，compareAndSwapObject，compareAndSwapInt和compareAndSwapLong，再看AtomicBoolean源码，发现其是先把Boolean转换成整型，再使用compareAndSwapInt进行CAS，所以原子更新double也可以用类似的思路来实现。\n原子更新数组类通过原子的方式更新数组里的某个元素，Atomic包提供了以下三个类：\n\nAtomicIntegerArray：原子更新整型数组里的元素。\nAtomicLongArray：原子更新长整型数组里的元素。\nAtomicReferenceArray：原子更新引用类型数组里的元素。\n\nAtomicIntegerArray类主要是提供原子的方式更新数组里的整型，其常用方法如下\n\nint addAndGet(int i, int delta)：以原子方式将输入值与数组中索引i的元素相加。\nboolean compareAndSet(int i, int expect, int update)：如果当前值等于预期值，则以原子方式将数组位置i的元素设置成update值。\n\n原子更新引用类型原子更新基本类型的AtomicInteger，只能更新一个变量，如果要原子的更新多个变量，就需要使用这个原子更新引用类型提供的类。Atomic包提供了以下三个类：\n\nAtomicReference：原子更新引用类型。\nAtomicReferenceFieldUpdater：原子更新引用类型里的字段。\nAtomicMarkableReference：原子更新带有标记位的引用类型。可以原子的更新一个布尔类型的标记位和引用类型。构造方法是AtomicMarkableReference(V initialRef, boolean initialMark)\n\n原子更新字段类如果我们只需要某个类里的某个字段，那么就需要使用原子更新字段类，Atomic包提供了以下三个类：\n\nAtomicIntegerFieldUpdater：原子更新整型的字段的更新器。\nAtomicLongFieldUpdater：原子更新长整型字段的更新器。\nAtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于原子的更数据和数据的版本号，可以解决使用CAS进行原子更新时，可能出现的ABA问题。\n\n原子更新字段类都是抽象类，每次使用都时候必须使用静态方法newUpdater创建一个更新器。原子更新类的字段的必须使用public volatile修饰符。\nUnsafe应用解析Unsafe是位于sun.misc包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升Java运行效率、增强Java语言底层资源操作能力方面起到了很大的作用。但由于Unsafe类使Java语言拥有了类似C语言指针一样操作内存空间的能力，这无疑也增加了程序发生相关指针问题的风险。在程序中过度、不正确使用Unsafe类会使得程序出错的概率变大，使得Java这种安全的语言变得不再“安全”，因此对Unsafe的使用一定要慎重。\nUnsafe类为一单例实现，提供静态方法getUnsafe获取Unsafe实例，当且仅当调用getUnsafe方法的类为引导类加载器所加载时才合法，否则抛出SecurityException异常。\npublic class Unsafe &#123;    // 单例对象    private static final Unsafe theUnsafe;    private Unsafe() &#123;    &#125;    @CallerSensitive    public static Unsafe getUnsafe() &#123;        Class var0 = Reflection.getCallerClass();        // 仅在引导类加载器`BootstrapClassLoader`加载时才合法        if(!VM.isSystemDomainLoader(var0.getClassLoader())) &#123;            throw new SecurityException(&quot;Unsafe&quot;);        &#125; else &#123;            return theUnsafe;        &#125;    &#125;&#125;\n\n如何获取Unsafe实例1 从getUnsafe方法的使用限制条件出发，通过Java命令行命令-Xbootclasspath/a把调用Unsafe相关方法的类A所在jar包路径追加到默认的bootstrap路径中，使得A被引导类加载器加载，从而通过Unsafe.getUnsafe方法安全的获取Unsafe实例。\njava -Xbootclasspath/a:$&#123;path&#125;   // 其中path为调用Unsafe相关方法的类所在jar包路径\n\n2 通过反射获取单例对象theUnsafe\npublic class UnsafeInstance &#123;    public static Unsafe reflectGetUnsafe() &#123;        try &#123;            Field field = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);            field.setAccessible(true);            return (Unsafe) field.get(null);        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;        return null;    &#125;&#125;\n\nUnsafe功能介绍Unsafe提供的API大致可分为内存操作、CAS、Class相关、对象操作、线程调度、系统信息获取、内存屏障、数组操作等几类，下面将对其相关方法和应用场景进行详细介绍。\n\n内存操作这部分主要包含堆外内存的分配、拷贝、释放、给定地址值操作等方法。\n//分配内存, 相当于C++的malloc函数public native long allocateMemory(long bytes);//扩充内存public native long reallocateMemory(long address, long bytes);//释放内存public native void freeMemory(long address);//在给定的内存块中设置值public native void setMemory(Object o, long offset, long bytes, byte value);//内存拷贝public native void copyMemory(Object srcBase, long srcOffset, Object destBase, long destOffset, long bytes);//获取给定地址值，忽略修饰限定符的访问限制。与此类似操作还有: getInt，getDouble，getLong，getChar等public native Object getObject(Object o, long offset);//为给定地址设置值，忽略修饰限定符的访问限制，与此类似操作还有: putInt,putDouble，putLong，putChar等public native void putObject(Object o, long offset, Object x);public native byte getByte(long address);//为给定地址设置byte类型的值（当且仅当该内存地址为allocateMemory分配\t时，此方法结果才是确定的）public native void putByte(long address, byte x);\n\n通常，我们在Java中创建的对象都处于堆内内存（heap）中，堆内内存是由JVM所管控的Java进程内存，并且它们遵循JVM的内存管理机制，JVM会采用垃圾回收机制统一管理堆内存。与之相对的是堆外内存，存在于JVM管控之外的内存区域，Java中对堆外内存的操作，依赖于Unsafe提供的操作堆外内存的native方法。\n使用堆外内存的原因\n对垃圾回收停顿的改善。由于堆外内存是直接受操作系统管理而不是JVM，所以当我们使用堆外内存时，即可保持较小的堆内内存规模。从而在GC时减少回收停顿对于应用的影响。\n提升程序I/O操作的性能。通常在I/O通信过程中，会存在堆内内存到堆外内存的数据拷贝操作，对于需要频繁进行内存间数据拷贝且生命周期较短的暂存数据，都建议存储到堆外内存。\n\n典型应用DirectByteBuffer是Java用于实现堆外内存的一个重要类，通常用在通信过程中做缓冲池，如在Netty、MINA等NIO框架中应用广泛。DirectByteBuffer对于堆外内存的创建、使用、销毁等逻辑均由Unsafe提供的堆外内存API来实现。\n下图为DirectByteBuffer构造函数，创建DirectByteBuffer的时候，通过Unsafe.allocateMemory分配内存、Unsafe.setMemory进行内存初始化，而后构建Cleaner对象用于跟踪DirectByteBuffer对象的垃圾回收，以实现当DirectByteBuffer被垃圾回收时，分配的堆外内存一起被释放。\nehcache就是使用的 DirectByteBuffers来实现的堆外内存本地缓存。\n\nCAS相关如下源代码释义所示，这部分主要为CAS相关操作的方法。\n/** *  CAS * @param o         包含要修改field的对象 * @param offset    对象中某field的偏移量 * @param expected  期望值 * @param update    更新值 * @return          true | false */public final native boolean compareAndSwapObject(Object var1, long var2, Object var4, Object var5);public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6);\n\n典型应用AtomicInteger的实现中，静态字段valueOffset即为字段value的内存偏移地址，valueOffset的值在AtomicInteger初始化时，在静态代码块中通过Unsafe的objectFieldOffset方法获取。在AtomicInteger中提供的线程安全方法中，通过字段valueOffset的值可以定位到AtomicInteger对象中value的内存地址，从而可以根据CAS实现对value字段的原子操作。\n\n下图为某个AtomicInteger对象自增操作前后的内存示意图，对象的基地址baseAddress=“0x110000”，通过baseAddress+valueOffset得到value的内存地址valueAddress=“0x11000c”；然后通过CAS进行原子性的更新操作，成功则返回，否则继续重试，直到更新成功为止。\n\n线程调度包括线程挂起、恢复、锁机制等方法。\n//取消阻塞线程public native void unpark(Object thread);//阻塞线程public native void park(boolean isAbsolute, long time);//获得对象锁（可重入锁）@Deprecatedpublic native void monitorEnter(Object o);//释放对象锁@Deprecatedpublic native void monitorExit(Object o);//尝试获取对象锁@Deprecatedpublic native boolean tryMonitorEnter(Object o);\n\n方法park、unpark即可实现线程的挂起与恢复，将一个线程进行挂起是通过park方法实现的，调用park方法后，线程将一直阻塞直到超时或者中断等条件出现；unpark可以终止一个挂起的线程，使其恢复正常。\n典型应用Java锁和同步器框架的核心类AbstractQueuedSynchronizer，就是通过调用**LockSupport.park()和LockSupport.unpark()**实现线程的阻塞和唤醒的，而LockSupport的park、unpark方法实际是调用Unsafe的park、unpark方式来实现。\n内存屏障在Java 8中引入，用于定义内存屏障（也称内存栅栏，内存栅障，屏障指令等，是一类同步屏障指令，是CPU或编译器在对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作），避免代码重排序。\n//内存屏障，禁止load操作重排序。屏障前的load操作不能被重排序到屏障后，屏障后的load操作不能被重排序到屏障前public native void loadFence();//内存屏障，禁止store操作重排序。屏障前的store操作不能被重排序到屏障后，屏障后的store操作不能被重排序到屏障前public native void storeFence();//内存屏障，禁止load、store操作重排序public native void fullFence();\n\n典型应用在Java 8中引入了一种锁的新机制——StampedLock，它可以看成是读写锁的一个改进版本。StampedLock提供了一种乐观读锁的实现，这种乐观读锁类似于无锁的操作，完全不会阻塞写线程获取写锁，从而缓解读多写少时写线程“饥饿”现象。由于StampedLock提供的乐观读锁不阻塞写线程获取读锁，当线程共享变量从主内存load到线程工作内存时，会存在数据不一致问题，所以当使用StampedLock的乐观读锁时，需要遵从如下图用例中使用的模式来确保数据的一致性。\n\n如上图用例所示计算坐标点Point对象，包含点移动方法move及计算此点到原点的距离的方法distanceFromOrigin。在方法distanceFromOrigin中，首先，通过tryOptimisticRead方法获取乐观读标记；然后从主内存中加载点的坐标值 (x,y)；而后通过StampedLock的validate方法校验锁状态，判断坐标点(x,y)从主内存加载到线程工作内存过程中，主内存的值是否已被其他线程通过move方法修改，如果validate返回值为true，证明(x, y)的值未被修改，可参与后续计算；否则，需加悲观读锁，再次从主内存加载(x,y)的最新值，然后再进行距离计算。其中，校验锁状态这步操作至关重要，需要判断锁状态是否发生改变，从而判断之前copy到线程工作内存中的值是否与主内存的值存在不一致。\n下图为StampedLock.validate方法的源码实现，通过锁标记与相关常量进行位运算、比较来校验锁状态，在校验逻辑之前，会通过Unsafe的loadFence方法加入一个load内存屏障，目的是避免上图用例中步骤②和StampedLock.validate中锁状态校验运算发生重排序导致锁状态校验不准确的问题。\n\n","categories":["Java"],"tags":["并发"]},{"title":"CountDownLatch&Semaphore原理与应用","url":"/2020/10/13/Java/%E5%B9%B6%E5%8F%91/CountDownLatch-Semaphore%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/","content":"SemaphoreSemaphore 字面意思是信号量的意思，它的作用是控制访问特定资源的线程数目，底层依赖AQS的状态State，是在生产当中比较常用的一个工具类。\n怎么使用 Semaphore?public Semaphore(int permits)public Semaphore(int permits, boolean fair)\n\n\npermits 表示许可线程的数量\nfair 表示公平性，如果这个设为 true 的话，下次执行的线程会是等待最久的线程\n\n重要方法public void acquire() throws InterruptedExceptionpublic void release()tryAcquire(int args,long timeout, TimeUnit unit)\n\n\nacquire() 表示阻塞并获取许可\nrelease() 表示释放许可\n\n基本使用需求场景资源访问，服务限流(Hystrix里限流就有基于信号量方式)。\n代码实现public class SemaphoreRunner &#123;    public static void main(String[] args) &#123;        Semaphore semaphore = new Semaphore(2);        for (int i=0;i&lt;5;i++)&#123;            new Thread(new Task(semaphore,&quot;test+&quot;+i)).start();        &#125;    &#125;    static class Task extends Thread&#123;        Semaphore semaphore;        public Task(Semaphore semaphore,String tname)&#123;            this.semaphore = semaphore;            this.setName(tname);        &#125;        public void run() &#123;            try &#123;                semaphore.acquire();                               System.out.println(Thread.currentThread().getName()+&quot;:aquire() at time:&quot;+System.currentTimeMillis());                Thread.sleep(1000);                semaphore.release();                               System.out.println(Thread.currentThread().getName()+&quot;:release() at time:&quot;+System.currentTimeMillis());            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;&#125;\n\n打印结果\nThread-1:aquire() at time:1630934824009Thread-5:aquire() at time:1630934824009Thread-5:release() at time:1630934825014Thread-3:aquire() at time:1630934825014Thread-1:release() at time:1630934825014Thread-7:aquire() at time:1630934825014Thread-3:release() at time:1630934826024Thread-7:release() at time:1630934826024Thread-9:aquire() at time:1630934826024Thread-9:release() at time:1630934827033\n\n从打印结果可以看出，一次只有两个线程执行 acquire()，只有线程进行 release() 方法后才会有别的线程执行 acquire()。\nCountDownLatchCountDownLatch这个类能够使一个线程等待其他线程完成各自的工作后再执行。例如，应用程序的主线程希望在负责启动框架服务的线程已经启动所有的框架服务之后再执行。\n使用场景Zookeeper分布式锁,Jmeter模拟高并发等\nCountDownLatch如何工作CountDownLatch是通过一个计数器来实现的，计数器的初始值为线程的数量。每当一个线程完成了自己的任务后，计数器的值就会减1。当计数器值到达0时，它表示所有的线程已经完成了任务，然后在闭锁上等待的线程就可以恢复执行任务。\nCountDownLatch.countDown()CountDownLatch.await();\n\nCountDownLatch使用场景例子当主线程需要创建多个子线程协同工作，并且主线程需要等待子线程均执行完后再执行时，可以用CountDownLatch\nCyclicBarrier栅栏屏障，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续运行。\nCyclicBarrier默认的构造方法是CyclicBarrier（int parties），其参数表示屏障拦截的线程数量，每个线程调用await方法告CyclicBarrier我已经到达了屏障，然后当前线程被阻塞。\ncyclicBarrier.await();\n\n应用场景可以用于多线程计算数据，最后合并计算结果的场景。例如，用一个Excel保存了用户所有银行流水，每个Sheet保存一个账户近一年的每笔银行流水，现在需要统计用户的日均银行流水，先用多线程处理每个sheet里的银行流水，都执行完之后，得到每个sheet的日均银行流水，最后，再用barrierAction用这些线程的计算结果，计算出整个Excel的日均银行流水。\n","categories":["Java"],"tags":["并发"]},{"title":"HashMap与CopyOnWrite机制","url":"/2020/11/02/Java/%E5%B9%B6%E5%8F%91/HashMap%E4%B8%8ECopyOnWrite%E6%9C%BA%E5%88%B6/","content":"HashMap数据结构​    数组+链表+(红黑树jdk&gt;=8)\n源码原理分析重要成员变量\nDEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; Hash表默认初始容量\nMAXIMUM_CAPACITY = 1 &lt;&lt; 30; 最大Hash表容量\nDEFAULT_LOAD_FACTOR = 0.75f；默认加载因子\nTREEIFY_THRESHOLD = 8；链表转红黑树阈值\nUNTREEIFY_THRESHOLD = 6；红黑树转链表阈值\nMIN_TREEIFY_CAPACITY = 64；链表转红黑树时hash表最小容量阈值，达不到优先扩容\n\nHashMap是线程不安全的，不安全的具体原因就是在高并发场景下，扩容可能产生死锁(Jdk1.7存在)以及get操作可能带来的数据丢失\nJdk7-扩容死锁分析死锁问题核心在于下面代码，JDK7中扩容采用的是头插法，多线程扩容导致形成的链表环!\nvoid transfer(Entry[] newTable, boolean rehash) &#123;    int newCapacity = newTable.length;    for (Entry&lt;K,V&gt; e : table) &#123;        while(null != e) &#123;            Entry&lt;K,V&gt; next = e.next;//第一行            if (rehash) &#123;                e.hash = null == e.key ? 0 : hash(e.key);            &#125;            int i = indexFor(e.hash, newCapacity);//第二行            e.next = newTable[i];//第三行            newTable[i] = e;//第四行            e = next;//第五行        &#125;    &#125;&#125;\n\n去掉了一些冗余的代码， 层次结构更加清晰了\n\n第一行：记录oldhash表中e.next\n第二行：rehash计算出数组的位置(hash表中桶的位置)\n第三行：e要插入链表的头部， 所以要先将e.next指向new hash表中的第一个元素\n第四行：将e放入到new hash表的头部\n第五行： 转移e到下一个节点， 继续循环下去\n\n单线程扩容假设：hash算法就是简单的key与length(数组长度)求余。hash表长度为2，如果不扩容， 那么元素key为3,5,7按照计算(key%table.length)的话都应该碰撞到table[1]上。\n扩容：hash表长度会扩容为4重新hash，key=3 会落到table[3]上(3%4=3)， 当前e.next为key(7), 继续while循环重新hash，key=7 会落到table[3]上(7%4=3), 产生碰撞， 这里采用的是头插入法，所以key=7的Entry会排在key=3前面(这里可以具体看while语句中代码)当前e.next为key(5), 继续while循环重新hash，key=5 会落到table[1]上(5%4=3)， 当前e.next为null, 跳出while循环，resize结束\n\n多线程扩容下面就是多线程同时put的情况了， 然后同时进入transfer方法中：假设这里有两个线程同时执行了put()操作，并进入了transfer()环节\nwhile(null != e) &#123;      Entry&lt;K,V&gt; next = e.next;//第一行，线程1执行到此被调度挂起      int i = indexFor(e.hash, newCapacity);//第二行      e.next = newTable[i];//第三行      newTable[i] = e;//第四行      e = next;//第五行&#125;\n\n那么此时状态为：\n\n从上面的图我们可以看到，因为线程1的 e 指向了 key(3)，而 next 指向了 key(7)，在线程2 rehash 后，就指向了线程2 rehash 后的链表。\n然后线程1被唤醒了：\n\n执行e.next = newTable[i]，于是 key(3)的 next 指向了线程1的新 Hash 表，因为新 Hash 表为空，所以e.next = null，\n执行newTable[i] = e，所以线程1的新 Hash 表第一个元素指向了线程2新 Hash 表的 key(3)。好了，e 处理完毕。\n执行e = next，将 e 指向 next，所以新的 e 是 key(7)\n\n然后该执行 key(3)的 next 节点 key(7)了:\n\n现在的 e 节点是 key(7)，首先执行Entry next = e.next,那么 next 就是 key(3)了\n执行e.next = newTable[i]，于是key(7) 的 next 就成了 key(3)\n执行newTable[i] = e，那么线程1的新 Hash 表第一个元素变成了 key(7)\n执行e = next，将 e 指向 next，所以新的 e 是 key(3)\n\n此时状态为：\n\n然后又该执行 key(7)的 next 节点 key(3)了：\n\n现在的 e 节点是 key(3)，首先执行Entry next = e.next,那么 next 就是 null\n执行e.next = newTable[i]，于是key(3) 的 next 就成了 key(7)\n执行newTable[i] = e，那么线程1的新 Hash 表第一个元素变成了 key(3)\n执行e = next，将 e 指向 next，所以新的 e 是 key(7)\n\n这时候的状态如图所示：\n\n很明显，环形链表出现了。\nJDK8扩容分析截取resize()方法的主要部分\nfor (int j = 0; j &lt; oldCap; ++j) &#123;    Node&lt;K,V&gt; e;    if ((e = oldTab[j]) != null) &#123;        oldTab[j] = null;        if (e.next == null)            newTab[e.hash &amp; (newCap - 1)] = e;        else if (e instanceof TreeNode)            ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap);        else &#123; // preserve order            Node&lt;K,V&gt; loHead = null, loTail = null;            Node&lt;K,V&gt; hiHead = null, hiTail = null;            Node&lt;K,V&gt; next;            do &#123;                next = e.next;                if ((e.hash &amp; oldCap) == 0) &#123;                    if (loTail == null)                        loHead = e;                    else                        loTail.next = e;                    loTail = e;                &#125;                else &#123;                    if (hiTail == null)                        hiHead = e;                    else                        hiTail.next = e;                    hiTail = e;                &#125;            &#125; while ((e = next) != null);            if (loTail != null) &#123;                loTail.next = null;                newTab[j] = loHead;            &#125;            if (hiTail != null) &#123;                hiTail.next = null;                newTab[j + oldCap] = hiHead;            &#125;        &#125;    &#125;&#125;\n\n在未发生hash碰撞的槽位，扩容后的数组下角标为：hash &amp; (newCap - 1)即当前元素的hash值和新数组长度-1做&amp;运算。\n在发生hash碰撞的槽位，会将旧槽位中的链表数据拆为两个链表，其中loHead与loTail分别指向(hash &amp; oldCap) == 0的头元素与尾元素，hiHead与hiTail分别指向(hash &amp; oldCap) == oldCap的头元素与尾元素。将底位列表（loHead）放入新数组的下角标为：旧槽位下角标，即旧槽位的下角标值就为此列表的新槽位值。将高位列表（hiHead）放入新数组的下角标为：旧槽位下角标+旧数组长度。\n这就是为什么数组的扩容必须是2的整数倍，如果不是2的整数倍的话，在扩容的时候就无法使用此算法。\nJDK8中并发情况下存在的问题if ((p = tab[i = (n - 1) &amp; hash]) == null)    tab[i] = newNode(hash, key, value, null);\n\n在putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict)方法中，在确定槽位的过程中，如果定位的槽位为null,则直接将当前K,V包装为Node,放入当前槽位的头节点上，在并发的情况下，当多个线程同时通过if判断时，会将值进行覆盖。\nConcurrentHashMapConcurrentHashMap的数据结构与HashMap基本类似，区别在于：\n1、内部在数据写入时加了同步机制(分段锁)保证线程安全，读操作是无锁操作；\n2、扩容时老数据的转移是并发执行的，这样扩容的效率更高。\n并发安全控制Java7 ConcurrentHashMap基于ReentrantLock实现分段锁\n\nJava8 ConcurrentHashMap基于分段锁+CAS保证线程安全，分段锁基于synchronized关键字实现；\n\nConcurrentHashMap拥有出色的性能, 在真正掌握内部结构时, 先要掌握比较重要的成员:\n\nLOAD_FACTOR: 负载因子, 默认75%, 当table使用率达到75%时, 为减少table的hash碰撞, tabel长度将扩容一倍。负载因子计算: 元素总个数%table.lengh\n\nTREEIFY_THRESHOLD: 默认8, 当链表长度达到8时, 将结构转变为红黑树。\n\nUNTREEIFY_THRESHOLD: 默认6, 红黑树转变为链表的阈值。\n\nMIN_TRANSFER_STRIDE: 默认16, table扩容时, 每个线程最少迁移table的槽位个数。\n\nMOVED: 值为-1, 当Node.hash为MOVED时, 代表着table正在扩容\n\nTREEBIN, 置为-2, 代表此元素后接红黑树。\n\nnextTable: table迁移过程临时变量, 在迁移过程中将元素全部迁移到nextTable上。\n\nsizeCtl: 用来标志table初始化和扩容的,不同的取值代表着不同的含义:\n\n\n\n0: table还没有被初始化\n-1: table正在初始化\n小于-1: 实际值为resizeStamp(n)\n大于0: 初始化完成后, 代表table最大存放元素的个数, 默认为0.75*n\n\n\n\n\ntransferIndex: table容量从n扩到2n时, 是从索引n-&gt;1的元素开始迁移, transferIndex代表当前已经迁移的元素下标\n\nForwardingNode: 一个特殊的Node节点, 其hashcode=MOVED, 代表着此时table正在做扩容操作。扩容期间, 若table某个元素为null, 那么该元素设置为ForwardingNode, 当下个线程向这个元素插入数据时, 检查hashcode=MOVED, 就会帮着扩容。\nConcurrentHashMap由三部分构成, table+链表+红黑树, 其中table是一个数组, 既然是数组, 必须要在使用时确定数组的大小, 当table存放的元素过多时, 就需要扩容, 以减少碰撞发生次数, 本文就讲解扩容的过程。扩容检查主要发生在插入元素(putVal())的过程:\n\n一个线程插完元素后, 检查table使用率, 若超过阈值, 调用transfer进行扩容\n\n一个线程插入数据时, 发现table对应元素的hash=MOVED, 那么调用helpTransfer()协助扩容。\n\n\n协助扩容helpTransferfinal Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; //table扩容    Node&lt;K,V&gt;[] nextTab; int sc;    if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp;        (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123;        // 根据 length 得到一个标识符号        int rs = resizeStamp(tab.length);        while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp;               (sc = sizeCtl) &lt; 0) &#123;//说明还在扩容            //判断是否标志发生了变化||  扩容结束了            if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||                //达到最大的帮助线程 ||  判断扩容转移下标是否在调整（扩容结束）                sc == rs + MAX_RESIZERS || transferIndex &lt;= 0)                break;            // 将 sizeCtl + 1, （表示增加了一个线程帮助其扩容）            if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123;                transfer(tab, nextTab);                break;            &#125;        &#125;        return nextTab;    &#125;    return table;&#125;\n\n主要做了如下事情:\n\n检查是否扩容完成\n\n对sizeCtrl = sizeCtrl+1, 然后调用transfer()进行真正的扩容。\n\n\ntable扩容过程就是将table元素迁移到新的table上, 在元素迁移时, 可以并发完成, 加快了迁移速度, 同时不至于阻塞线程。所有元素迁移完成后, 旧的table直接丢失, 直接使用新的table。\nCopyOnWrite机制核心思想：读写分离，空间换时间，避免为保证并发安全导致的激烈的锁竞争。\n\nCopyOnWrite适用于读多写少的情况，最大程度的提高读的效率；\n\nCopyOnWrite是最终一致性，在写的过程中，原有的读的数据是不会发生更新的，只有新的读才能读到最新数据；\n\n如何使其他线程能够及时读到新的数据，需要使用volatile变量；\n\n写的时候不能并发写，需要对写操作进行加锁；\n\n\n\n/* *   添加元素api */public boolean add(E e) &#123;    final ReentrantLock lock = this.lock;    lock.lock();    try &#123;        Object[] elements = getArray();        int len = elements.length;        Object[] newElements = Arrays.copyOf(elements, len + 1); //复制一个array副本        newElements[len] = e; //往副本里写入        setArray(newElements); //副本替换原本，成为新的原本        return true;    &#125; finally &#123;        lock.unlock();    &#125;&#125;//读apipublic E get(int index) &#123;    return get(getArray(), index); //无锁&#125;\n\n使用场景黑白名单\n","categories":["Java"],"tags":["并发"]},{"title":"JAVA内存模型","url":"/2020/08/07/Java/%E5%B9%B6%E5%8F%91/JAVA%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/","content":"什么是JMM模型Java内存模型(Java Memory Model简称JMM)是一种抽象的概念，并不真实存在，它描述的是一组规则或规范，通过这组规范定义了程序中各个变量（包括实例字段，静态字段和构成数组对象的元素）的访问方式。JVM运行程序的实体是线程，而每个线程创建时JVM都会为其创建一个工作内存(有些地方称为栈空间)，用于存储线程私有的数据，而Java内存模型中规定所有变量都存储在主内存，主内存是共享内存区域，所有线程都可以访问，但线程对变量的操作(读取赋值等)必须在工作内存中进行，首先要将变量从主内存拷贝的自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，工作内存中存储着主内存中的变量副本拷贝，前面说过，工作内存是每个线程的私有数据区域，因此不同的线程间无法访问对方的工作内存，线程间的通信(传值)必须通过主内存来完成。\nJMM不同于JVM内存区域模型JMM与JVM内存区域的划分是不同的概念层次，更恰当说JMM描述的是一组规则，通过这组规则控制程序中各个变量在共享数据区域和私有数据区域的访问方式，JMM是围绕原子性，有序性、可见性展开。JMM与Java内存区域唯一相似点，都存在共享数据区域和私有数据区域，在JMM中主内存属于共享数据区域，从某个程度上讲应该包括了堆和方法区，而工作内存数据线程私有数据区域，从某个程度上讲则应该包括程序计数器、虚拟机栈以及本地方法栈。线程，工作内存，主内存工作交互图（基于JMM规范）：\n\n主内存主要存储的是Java实例对象，所有线程创建的实例对象都存放在主内存中，不管该**实例对象是成员变量还是方法中的本地变量(也称局部变量)**，当然也包括了共享的类信息、常量、静态变量。由于是共享数据区域，多条线程对同一个变量进行访问可能会发生线程安全问题。\n工作内存主要存储当前方法的所有本地变量信息(工作内存中存储着主内存中的变量副本拷贝)，每个线程只能访问自己的工作内存，即线程中的本地变量对其它线程是不可见的，就算是两个线程执行的是同一段代码，它们也会各自在自己的工作内存中创建属于当前线程的本地变量，当然也包括了字节码行号指示器、相关Native方法的信息。注意由于工作内存是每个线程的私有数据，线程间无法相互访问工作内存，因此存储在工作内存的数据不存在线程安全问题。根据JVM虚拟机规范主内存与工作内存的数据存储类型以及操作方式，对于一个实例对象中的成员方法而言，如果方法中包含本地变量是基本数据类型（boolean,byte,short,char,int,long,float,double），将直接存储在工作内存的帧栈结构中，但倘若本地变量是引用类型，那么该变量的引用会存储在功能内存的帧栈中，而对象实例将存储在主内存(共享数据区域，堆)中。但对于实例对象的成员变量，不管它是基本数据类型或者包装类型(Integer、Double等)还是引用类型，都会被存储到堆区。至于static变量以及类本身相关信息将会存储在主内存中。需要注意的是，在主内存中的实例对象可以被多线程共享，倘若两个线程同时调用了同一个对象的同一个方法，那么两条线程会将要操作的数据拷贝一份到自己的工作内存中，执行完成操作后才刷新到主内存。模型如下图所示\n\nJava内存模型与硬件内存架构的关系通过对前面的硬件内存架构、Java内存模型以及Java多线程的实现原理的了解，我们应该已经意识到，多线程的执行最终都会映射到硬件处理器上进行执行，但Java内存模型和硬件内存架构并不完全一致。对于硬件内存来说只有寄存器、缓存内存、主内存的概念，并没有工作内存(线程私有数据区域)和主内存(堆内存)之分，也就是说Java内存模型对内存的划分对硬件内存并没有任何影响，因为JMM只是一种抽象的概念，是一组规则，并不实际存在，不管是工作内存的数据还是主内存的数据，对于计算机硬件来说都会存储在计算机主内存中，当然也有可能存储到CPU缓存或者寄存器中，因此总体上来说，Java内存模型和计算机硬件内存架构是一个相互交叉的关系，是一种抽象概念划分与真实物理硬件的交叉。(注意对于Java内存区域划分也是同样的道理)\nJMM存在的必要性在明白了Java内存区域划分、硬件内存架构、Java多线程的实现原理与Java内存模型的具体关系后，接着来谈谈Java内存模型存在的必要性。由于JVM运行程序的实体是线程，而每个线程创建时JVM都会为其创建一个工作内存(有些地方称为栈空间)，用于存储线程私有的数据，线程与主内存中的变量操作必须通过工作内存间接完成，主要过程是将变量从主内存拷贝的每个线程各自的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，如果存在两个线程同时对一个主内存中的实例对象的变量进行操作就有可能诱发线程安全问题。假设主内存中存在一个共享变量x，现在有A和B两条线程分别对该变量x=1进行操作，A/B线程各自的工作内存中存在共享变量副本x。假设现在A线程想要修改x的值为2，而B线程却想要读取x的值，那么B线程读取到的值是A线程更新后的值2还是更新前的值1呢？答案是，不确定，即B线程有可能读取到A线程更新前的值1，也有可能读取到A线程更新后的值2，这是因为工作内存是每个线程私有的数据区域，而线程A变量x时，首先是将变量从主内存拷贝到A线程的工作内存中，然后对变量进行操作，操作完成后再将变量x写回主内，而对于B线程的也是类似的，这样就有可能造成主内存与工作内存间数据存在一致性问题，假如A线程修改完后正在将数据写回主内存，而B线程此时正在读取主内存，即将x=1拷贝到自己的工作内存中，这样B线程读取到的值就是x=1，但如果A线程已将x=2写回主内存后，B线程才开始读取的话，那么此时B线程读取到的就是x=2，但到底是哪种情况先发生呢？如以下示例图所示案例：\n以上关于主内存与工作内存之间的具体交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步到主内存之间的实现细节，Java内存模型定义了以下八种操作来完成。\n数据同步八大原子操作\n**lock(锁定)**：作用于主内存的变量，把一个变量标记为一条线程独占状态\n**unlock(解锁)**：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定\n**read(读取)**：作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用\n**load(载入)**：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中\n**use(使用)**：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎\n**assign(赋值)**：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量\n**store(存储)**：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作\n**write(写入)**：作用于工作内存的变量，它把store操作从工作内存中的一个变量的值传送到主内存的变量中\n\n如果要把一个变量从主内存中复制到工作内存中，就需要按顺序地执行read和load操作，如果把变量从工作内存中同步到主内存中，就需要按顺序地执行store和write操作。但Java内存模型只要求上述操作必须按顺序执行，而没有保证必须是连续执行。\n同步规则分析\n不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步回主内存中\n一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或者assign）的变量。即就是对一个变量实施use和store操作之前，必须先自行assign和load操作。\n一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。lock和unlock必须成对出现。\n如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量之前需要重新执行load或assign操作初始化变量的值。\n如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。\n对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）\n\n并发编程的可见性，原子性与有序性问题原子性原子性指的是一个操作是不可中断的，即使是在多线程环境下，一个操作一旦开始就不会被其他线程影响。在java中，对基本数据类型的变量的读取和赋值操作是原子性操作有点要注意的是，对于32位系统的来说，long类型数据和double类型数据(对于基本数据类型，byte,short,int,float,boolean,char读写是原子操作)，它们的读写并非原子性的，也就是说如果存在两条线程同时对long类型或者double类型的数据进行读写是存在相互干扰的，因为对于32位虚拟机来说，每次原子读写是32位的，而long和double则是64位的存储单元，这样会导致一个线程在写时，操作完前32位的原子操作后，轮到B线程读取时，恰好只读取到了后32位的数据，这样可能会读取到一个既非原值又不是线程修改值的变量，它可能是“半个变量”的数值，即64位数据被两个线程分成了两次读取。但也不必太担心，因为读取到“半个变量”的情况比较少见，至少在目前的商用的虚拟机中，几乎都把64位的数据的读写操作作为原子操作来执行，因此对于这个问题不必太在意，知道这么回事即可。\nX=10;  //原子性（简单的读取、将数字赋值给变量）Y = x;  //变量之间的相互赋值，不是原子操作X++;  //对变量进行计算操作X = x+1;\n\n可见性理解了指令重排现象后，可见性容易了，可见性指的是当一个线程修改了某个共享变量的值，其他线程是否能够马上得知这个修改的值。对于串行程序来说，可见性是不存在的，因为我们在任何一个操作中修改了某个变量的值，后续的操作中都能读取这个变量值，并且是修改过的新值。但在多线程环境中可就不一定了，前面分析过，由于线程对共享变量的操作都是线程拷贝到各自的工作内存进行操作后才写回到主内存中的，这就可能存在一个线程A修改了共享变量x的值，还未写回主内存时，另外一个线程B又对主内存中同一个共享变量x进行操作，但此时A线程工作内存中共享变量x对线程B来说并不可见，这种工作内存与主内存同步延迟现象就造成了可见性问题，另外指令重排以及编译器优化也可能导致可见性问题，通过前面的分析，我们知道无论是编译器优化还是处理器优化的重排现象，在多线程环境下，确实会导致程序轮序执行的问题，从而也就导致可见性问题。\n有序性有序性是指对于单线程的执行代码，我们总是认为代码的执行是按顺序依次执行的，这样的理解并没有毛病，毕竟对于单线程而言确实如此，但对于多线程环境，则可能出现乱序现象，因为程序编译成机器码指令后可能会出现指令重排现象，重排后的指令与原指令的顺序未必一致，要明白的是，在Java程序中，倘若在本线程内，所有操作都视为有序行为，如果是多线程环境下，一个线程中观察另外一个线程，所有操作都是无序的，前半句指的是单线程内保证串行语义执行的一致性，后半句则指指令重排现象和工作内存与主内存同步延迟现象。\nJMM如何解决原子性&amp;可见性&amp;有序性问题原子性问题除了JVM自身提供的对基本数据类型读写操作的原子性外，可以通过 synchronized和Lock实现原子性。因为synchronized和Lock能够保证任一时刻只有一个线程访问该代码块。\n可见性问题volatile关键字保证可见性。当一个共享变量被volatile修饰时，它会保证修改的值立即被其他的线程看到，即修改的值立即更新到主存中，当其他线程需要读取时，它会去内存中读取新值。synchronized和Lock也可以保证可见性，因为它们可以保证任一时刻只有一个线程能访问共享资源，并在其释放锁之前将修改的变量刷新到内存中。\n有序性问题在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述volatile关键字）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。\n\nJava内存模型\n每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。\n\n指令重排序\nJava语言规范规定JVM线程内部维持顺序化语义。即只要程序的最终结果与它顺序化情况的结果相等，那么指令的执行顺序可以与代码顺序不一致，此过程叫指令的重排序。指令重排序的意义是什么？JVM能根据处理器特性（CPU多级缓存系统、多核处理器等）适当的对机器指令进行重排序，使机器指令能更符合CPU的执行特性，最大限度的发挥机器性能。\n\n\n下图为从源码到最终执行的指令序列示意图：\n​    \n\nas-if-serial语义\nas-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。\n为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被编译器和处理器重排序。\n\nhappens-before 原则\n只靠sychronized和volatile关键字来保证原子性、可见性以及有序性，那么编写并发程序可能会显得十分麻烦，幸运的是，从JDK 5开始，Java使用新的JSR-133内存模型，提供了happens-before 原则来辅助保证程序执行的原子性、可见性以及有序性的问题，它是判断数据是否存在竞争、线程是否安全的依据，happens-before 原则内容如下：\n\n程序顺序原则 即在一个线程内必须保证语义串行性，也就是说按照代码顺序执行。\n\n锁规则 解锁(unlock)操作必然发生在后续的同一个锁的加锁(lock)之前，也就是说，如果对于一个锁解锁后，再加锁，那么加锁的动作必须在解锁动作之后(同一个锁)。\n\nvolatile规则 volatile变量的写，先发生于读，这保证了volatile变量的可见性，简单的理解就是，volatile变量在每次被线程访问时，都强迫从主内存中读该变量的值，而当该变量发生变化时，又会强迫将最新的值刷新到主内存，任何时刻，不同的线程总是能够看到该变量的最新值。\n\n线程启动规则 线程的start()方法先于它的每一个动作，即如果线程A在执行线程B的start方法之前修改了共享变量的值，那么当线程B执行start方法时，线程A对共享变量的修改对线程B可见\n\n传递性 A先于B ，B先于C 那么A必然先于C\n\n线程终止规则 线程的所有操作先于线程的终结，Thread.join()方法的作用是等待当前执行的线程终止。假设在线程B终止之前，修改了共享变量，线程A从线程B的join方法成功返回后，线程B对共享变量的修改将对线程A可见。\n\n线程中断规则 对线程 interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测线程是否中断。\n\n对象终结规则 对象的构造函数执行，结束先于finalize()方法\n\n\n\nvolatile内存语义\nvolatile是Java虚拟机提供的轻量级的同步机制。volatile关键字有如下两个作用\n\n保证被volatile修饰的共享变量对所有线程总是可见的，也就是当一个线程修改了一个被volatile修饰共享变量的值，新值总是可以被其他线程立即得知。\n禁止指令重排序优化。\n\n\nvolatile的可见性\n\n\n关于volatile的可见性作用，我们必须意识到被volatile修饰的变量对所有线程总是立即可见的，对volatile变量的所有写操作总是能立刻反应到其他线程中示例\npublic class VolatileVisibilitySample &#123;    volatile boolean initFlag = false;    public void save()&#123;        this.initFlag = true;        String threadname = Thread.currentThread().getName();        System.out.println(&quot;线程：&quot;+threadname+&quot;:修改共享变量initFlag&quot;);    &#125;    public void load()&#123;        String threadname = Thread.currentThread().getName();        while (!initFlag)&#123;            //线程在此处空跑，等待initFlag状态改变        &#125;        System.out.println(&quot;线程：&quot;+threadname+&quot;当前线程嗅探到initFlag的状态的改变&quot;);    &#125;    public static void main(String[] args)&#123;        VolatileVisibilitySample sample = new VolatileVisibilitySample();        Thread threadA = new Thread(()-&gt;&#123;            sample.save();        &#125;,&quot;threadA&quot;);        Thread threadB = new Thread(()-&gt;&#123;            sample.load();        &#125;,&quot;threadB&quot;);        threadB.start();        try &#123;            Thread.sleep(1000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        threadA.start();    &#125;&#125;\n\n\n线程A改变initFlag属性之后，线程B马上感知到\n\n\nvolatile无法保证原子性\n\n//示例public class VolatileVisibility &#123;    public static volatile int i =0;    public static void increase()&#123;        i++;    &#125;&#125;\n\n在并发场景下，i变量的任何改变都会立马反应到其他线程中，但是如此存在多条线程同时调用increase()方法的话，就会出现线程安全问题，毕竟i++;操作并不具备原子性，该操作是先读取值，然后写回一个新值，相当于原来的值加上1，分两步完成，如果第二个线程在第一个线程读取旧值和写回新值期间读取i的域值，那么第二个线程就会与第一个线程一起看到同一个值，并执行相同值的加1操作，这也就造成了线程安全失败，因此对于increase方法必须使用synchronized修饰，以便保证线程安全，需要注意的是一旦使用synchronized修饰方法后，由于synchronized本身也具备与volatile相同的特性，即可见性，因此在这样种情况下就完全可以省去volatile修饰变量。\n\nvolatile禁止重排优化\n\nvolatile关键字另一个作用就是禁止指令重排优化，从而避免多线程环境下程序出现乱序执行的现象，关于指令重排优化前面已详细分析过，这里主要简单说明一下volatile是如何实现禁止指令重排优化的。先了解一个概念，内存屏障(Memory Barrier）。 \n硬件层的内存屏障Intel硬件提供了一系列的内存屏障，主要有： \n\nlfence，是一种Load Barrier 读屏障 \n\nsfence, 是一种Store Barrier 写屏障 \n\nmfence, 是一种全能型的屏障，具备ifence和sfence的能力 \n\nLock前缀，Lock不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁。它后面可以跟ADD, ADC, AND, BTC, BTR, BTS, CMPXCHG, CMPXCH8B, DEC, INC, NEG, NOT, OR, SBB, SUB, XOR, XADD, and XCHG等指令。\n\n\n不同硬件实现内存屏障的方式不同，Java内存模型屏蔽了这种底层硬件平台的差异，由JVM来为不同的平台生成相应的机器码。 JVM中提供了四类内存屏障指令：\n\n\n\n屏障类型\n指令示例\n说明\n\n\n\nLoadLoad\nLoad1; LoadLoad; Load2\n保证load1的读取操作在load2及后续读取操作之前执行\n\n\nStoreStore\nStore1; StoreStore; Store2\n在store2及其后的写操作执行前，保证store1的写操作已刷新到主内存\n\n\nLoadStore\nLoad1; LoadStore; Store2\n在stroe2及其后的写操作执行前，保证load1的读操作已读取结束\n\n\nStoreLoad\nStore1; StoreLoad; Load2\n保证store1的写操作已刷新到主内存之后，load2及其后的读操作才能执行\n\n\n内存屏障，又称内存栅栏，是一个CPU指令，它的作用有两个，一是保证特定操作的执行顺序，二是保证某些变量的内存可见性（利用该特性实现volatile的内存可见性）。由于编译器和处理器都能执行指令重排优化。如果在指令间插入一条Memory Barrier则会告诉编译器和CPU，不管什么指令都不能和这条Memory Barrier指令重排序，也就是说通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化。Memory Barrier的另外一个作用是强制刷出各种CPU的缓存数据，因此任何CPU上的线程都能读取到这些数据的最新版本。总之，volatile变量正是通过内存屏障实现其在内存中的语义，即可见性和禁止重排优化。下面看一个非常典型的禁止重排优化的例子DCL，如下：\npublic class DoubleCheckLock &#123;    private static DoubleCheckLock instance;    private DoubleCheckLock()&#123;&#125;    public static DoubleCheckLock getInstance()&#123;        //第一次检测        if (instance==null)&#123;            //同步            synchronized (DoubleCheckLock.class)&#123;                if (instance == null)&#123;                    //多线程环境下可能会出现问题的地方                    instance = new  DoubleCheckLock();                &#125;            &#125;        &#125;        return instance;    &#125;&#125;\n\n上述代码一个经典的单例的双重检测的代码，这段代码在单线程环境下并没有什么问题，但如果在多线程环境下就可以出现线程安全问题。原因在于某一个线程执行到第一次检测，读取到的instance不为null时，instance的引用对象可能没有完成初始化。因为instance = new DoubleCheckLock();可以分为以下3步完成(伪代码)\nmemory = allocate(); //1.分配对象内存空间instance(memory);    //2.初始化对象instance = memory;   //3.设置instance指向刚分配的内存地址，此时instance！=null\n\n由于步骤2和步骤3间可能会重排序，如下：\nmemory=allocate(); //1.分配对象内存空间instance=memory;   //3.设置instance指向刚分配的内存地址，此时instance！=null，但是对象还没有初始化完成！instance(memory);  //2.初始化对象\n由于步骤2和步骤3不存在数据依赖关系，而且无论重排前还是重排后程序的执行结果在单线程中并没有改变，因此这种重排优化是允许的。但是指令重排只会保证串行语义的执行的一致性(单线程)，但并不会关心多线程间的语义一致性。所以当一条线程访问instance不为null时，由于instance实例未必已初始化完成，也就造成了线程安全问题。那么该如何解决呢，很简单，我们使用volatile禁止instance变量被执行指令重排优化即可。\n//禁止指令重排优化private volatile static DoubleCheckLock instance;\n\nvolatile内存语义的实现前面提到过重排序分为编译器重排序和处理器重排序。为了实现volatile内存语义，JMM会分别限制这两种类型的重排序类型。\n下图是JMM针对编译器制定的volatile重排序规则表。\n\n\n\n第一个操作\n第二个操作：普通读写\n第二个操作：volatile读\n第二个操作：volatile写\n\n\n\n普通读写\n可以重排\n可以重排\n不可以重排\n\n\nvolatile读\n不可以重排\n不可以重排\n不可以重排\n\n\nvolatile写\n可以重排\n不可以重排\n不可以重排\n\n\n举例来说，第二行最后一个单元格的意思是：在程序中，当第一个操作为普通变量的读或写时，如果第二个操作为volatile写，则编译器不能重排序这两个操作。\n从上图可以看出：\n\n当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。\n当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。\n当第一个操作是volatile写，第二个操作是volatile读或写时，不能重排序。\n\n为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能。为此，JMM采取保守策略。下面是基于保守策略的JMM内存屏障插入策略。\n\n在每个volatile写操作的前面插入一个StoreStore屏障。\n在每个volatile写操作的后面插入一个StoreLoad屏障。\n在每个volatile读操作的前面插入一个LoadLoad屏障。\n在每个volatile读操作的后面插入一个LoadStore屏障。\n\n上述内存屏障插入策略非常保守，但它可以保证在任意处理器平台，任意的程序中都能得到正确的volatile内存语义。\n下面是保守策略下，volatile写插入内存屏障后生成的指令序列示意图\n\n上图中StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作已经对任意处理器可见了。这是因为StoreStore屏障将保障上面所有的普通写在volatile写之前刷新到主内存。这里比较有意思的是，volatile写后面的StoreLoad屏障。此屏障的作用是避免volatile写与后面可能有的volatile读/写操作重排序。因为编译器常常无法准确判断在一个volatile写的后面 是否需要插入一个StoreLoad屏障（比如，一个volatile写之后方法立即return）。为了保证能正确 实现volatile的内存语义，JMM在采取了保守策略：在每个volatile写的后面，或者在每个volatile 读的前面插入一个StoreLoad屏障。从整体执行效率的角度考虑，JMM最终选择了在每个 volatile写的后面插入一个StoreLoad屏障。因为volatile写-读内存语义的常见使用模式是：一个 写线程写volatile变量，多个读线程读同一个volatile变量。当读线程的数量大大超过写线程时，选择在volatile写之后插入StoreLoad屏障将带来可观的执行效率的提升。从这里可以看到JMM 在实现上的一个特点：首先确保正确性，然后再去追求执行效率。下图是在保守策略下，volatile读插入内存屏障后生成的指令序列示意图 \n上图中LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序。LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序。\n上述volatile写和volatile读的内存屏障插入策略非常保守。在实际执行时，只要不改变 volatile写-读的内存语义，编译器可以根据具体情况省略不必要的屏障。下面通过具体的示例代码进行说明。\nclass VolatileBarrierExample &#123;       int a;       volatile int v1 = 1;       volatile int v2 = 2;       void readAndWrite() &#123;           int i = v1;　　    // 第一个volatile读           int j = v2;    　  // 第二个volatile读           a = i + j;         // 普通写           v1 = i + 1;     　 // 第一个volatile写          v2 = j * 2;    　  // 第二个 volatile写       &#125;&#125;\n针对readAndWrite()方法，编译器在生成字节码时可以做如下的优化。 \n注意，最后的StoreLoad屏障不能省略。因为第二个volatile写之后，方法立即return。此时编 译器可能无法准确断定后面是否会有volatile读或写，为了安全起见，编译器通常会在这里插 入一个StoreLoad屏障。上面的优化针对任意处理器平台，由于不同的处理器有不同“松紧度”的处理器内存模型，内存屏障的插入还可以根据具体的处理器内存模型继续优化。以X86处理器为例，上图中除最后的StoreLoad屏障外，其他的屏障都会被省略。前面保守策略下的volatile读和写，在X86处理器平台可以优化成如下图所示。前文提到过，X86处理器仅会对写-读操作做重排序。X86不会对读-读、读-写和写-写操作做重排序，因此在X86处理器中会省略掉这3种操作类型对应的内存屏障。在X86中，JMM仅需 在volatile写后面插入一个StoreLoad屏障即可正确实现volatile写-读的内存语义。这意味着在 X86处理器中，volatile写的开销比volatile读的开销会大很多（因为执行StoreLoad屏障开销会比较大）。\n \n引用资料：\n《并发编程的艺术》\n","categories":["Java"],"tags":["并发"]},{"title":"JVM内置锁synchronized","url":"/2020/09/09/Java/%E5%B9%B6%E5%8F%91/JVM%E5%86%85%E7%BD%AE%E9%94%81synchronized/","content":"设计同步器的意义多线程编程中，有可能会出现多个线程同时访问同一个共享、可变资源的情况，这个资源我们称之其为临界资源；这种资源可能是：对象、变量、文件等。\n\n共享：资源可以由多个线程同时访问可变：资源可以在其生命周期内被修改\n\n引出的问题：由于线程执行的过程是不可控的，所以需要采用同步机制来协同对对象可变状态的访问！\n如何解决线程并发安全问题？实际上，所有的并发模式在解决线程安全问题时，采用的方案都是序列化访问临界资源。即在同一时刻，只能有一个线程访问临界资源，也称作同步互斥访问。Java 中，提供了两种方式来实现同步互斥访问：synchronized 和 Lock同步器的本质就是加锁加锁目的：序列化访问临界资源，即同一时刻只能有一个线程访问临界资源(同步互斥访问)不过有一点需要区别的是：当多个线程执行一个方法时，该方法内部的局部变量并不是临界资源，因为这些局部变量是在每个线程的私有栈中，因此不具有共享性，不会导致线程安全问题。\nsynchronized原理详解synchronized内置锁是一种对象锁(锁的是对象而非引用)，作用粒度是对象，可以用来实现对临界资源的同步互斥访问，是可重入的。加锁的方式：\n\n对于普通同步方法，锁的是当前实例对象\n对于静态同步方法，锁的是当前类Class对象\n对于同步方法块，锁的是Synchronized括号里配置的对象\n\nsynchronized底层原理synchronized是基于JVM内置锁实现，通过内部对象Monitor(监视器锁)实现，基于进入与退出Monitor对象实现方法与代码块同步，监视器锁的实现依赖底层操作系统的Mutex lock（互斥锁）实现，它是一个重量级锁性能较低。当然，JVM内置锁在1.5之后版本做了重大的优化，如锁粗化（Lock Coarsening）、锁消除（Lock Elimination）、轻量级锁（Lightweight Locking）、偏向锁（Biased Locking）、适应性自旋（Adaptive Spinning）等技术来减少锁操作的开销，，内置锁的并发性能已经基本与Lock持平。synchronized关键字被编译成字节码后会被翻译成monitorenter 和 monitorexit 两条指令分别在同步块逻辑代码的起始位置与结束位置。 每个同步对象都有一个自己的Monitor(监视器锁)，加锁过程如下图所示：  \nMonitor监视器锁 任何一个对象都有一个Monitor与之关联，当且一个Monitor被持有后，它将处于锁定状态。Synchronized在JVM里的实现都是 基于进入和退出Monitor对象来实现方法同步和代码块同步，虽然具体实现细节不一样，但是都可以通过成对的MonitorEnter和MonitorExit指令来实现。\n\nmonitorenter：每个对象都是一个监视器锁（monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下：\n\n如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者；\n如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1；\n如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权；\n\n\nmonitorexit：执行monitorexit的线程必须是objectref所对应的monitor的所有者。指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者。其他被这个monitor阻塞的线程可以尝试去获取这个 monitor 的所有权。\n\n\n\nmonitorexit，指令出现了两次，第1次为同步正常退出释放锁；第2次为发生异步退出释放锁；\n通过上面两段描述，我们应该能很清楚的看出Synchronized的实现原理，Synchronized的语义底层是通过一个monitor的对象来完成，其实wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。看一个同步方法：\npublic class SynchronizedMethod &#123;    public synchronized void method() &#123;        System.out.println(&quot;Hello World!&quot;);    &#125;&#125;\n反编译结果： \n从编译的结果来看，方法的同步并没有通过指令 monitorenter 和 monitorexit 来完成（理论上其实也可以通过这两条指令来实现），不过相对于普通方法，其常量池中多了 ACC_SYNCHRONIZED 标示符。JVM就是根据该标示符来实现方法的同步的：当方法调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个monitor对象。两种同步方式本质上没有区别，只是方法的同步是一种隐式的方式来实现，无需通过字节码来完成。两个指令的执行是JVM通过调用操作系统的互斥原语mutex来实现，被阻塞的线程会被挂起、等待重新调度，会导致“用户态和内核态”两个态之间来回切换，对性能有较大影响。\n什么是monitor？可以把它理解为 一个同步工具，也可以描述为 一种同步机制，它通常被 描述为一个对象。与一切皆对象一样，所有的Java对象是天生的Monitor，每一个Java对象都有成为Monitor的潜质，因为在Java的设计中 ，每一个Java对象自打娘胎里出来就带了一把看不见的锁，它叫做内部锁或者Monitor锁。也就是通常说Synchronized的对象锁，MarkWord锁标识位为10，其中指针指向的是Monitor对象的起始地址。在Java虚拟机（HotSpot）中，Monitor是由ObjectMonitor实现的，其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的）：\nObjectMonitor() &#123;    _header       = NULL;    _count        = 0; // 记录个数    _waiters      = 0,    _recursions   = 0;    _object       = NULL;    _owner        = NULL;    _WaitSet      = NULL; // 处于wait状态的线程，会被加入到_WaitSet    _WaitSetLock  = 0 ;    _Responsible  = NULL ;    _succ         = NULL ;    _cxq          = NULL ;    FreeNext      = NULL ;    _EntryList    = NULL ; // 处于等待锁block状态的线程，会被加入到该列表    _SpinFreq     = 0 ;    _SpinClock    = 0 ;    OwnerIsThread = 0 ;  &#125;\n\nObjectMonitor中有两个队列，**_WaitSet 和 _EntryList，用来保存ObjectWaiter对象列表（ 每个等待锁的线程都会被封装成ObjectWaiter对象 ），_owner指向持有ObjectMonitor对象的线程**，当多个线程同时访问一段同步代码时：\n\n首先会进入 _EntryList 集合，当线程获取到对象的monitor后，进入 _Owner区域并把monitor中的owner变量设置为当前线程，同时monitor中的计数器count加1；\n若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入 WaitSet集合中等待被唤醒；\n若当前线程执行完毕，**也将释放monitor（锁）并复位count的值，以便其他线程进入获取monitor(锁)**；\n\n同时，Monitor对象存在于每个Java对象的对象头Mark Word中（存储的指针的指向），Synchronized锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因，同时notify/notifyAll/wait等方法会使用到Monitor锁对象，所以必须在同步代码块中使用。监视器Monitor有两种同步方式：互斥与协作。多线程环境下线程之间如果需要共享数据，需要解决互斥访问数据的问题，监视器可以确保监视器上的数据在同一时刻只会有一个线程在访问。那么有个问题来了，我们知道synchronized加锁加在对象上，对象是如何记录锁状态的呢？答案是锁状态是被记录在每个对象的对象头（Mark Word）中，下面我们一起认识一下对象的内存布局\n对象的内存布局HotSpot虚拟机中，对象在内存中存储的布局可以分为三块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。\n\n对象头：比如 hash码，对象所属的年代，对象锁，锁状态标志，偏向锁（线程）ID，偏向时间，数组长度（数组对象）等。Java对象头一般占有2个机器码（在32位虚拟机中，1个机器码等于4字节，也就是32bit，在64位虚拟机中，1个机器码是8个字节，也就是64bit），但是 如果对象是数组类型，则需要3个机器码，因为JVM虚拟机可以通过Java对象的元数据信息确定Java对象的大小，但是无法从数组的元数据来确认数组的大小，所以用一块来记录数组长度。\n实例数据：存放类的属性数据信息，包括父类的属性信息；\n对齐填充：由于虚拟机要求 对象起始地址必须是8字节的整数倍。填充数据不是必须存在的，仅仅是为了字节对齐；\n\n​    \n对象头HotSpot虚拟机的对象头包括两部分信息，第一部分是“Mark Word”，用于存储对象自身的运行时数据， 如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等等，它是实现轻量级锁和偏向锁的关键。，这部分数据的长度在32位和64位的虚拟机（暂 不考虑开启压缩指针的场景）中分别为32个和64个Bits，官方称它为“Mark Word”。对象需要存储的运行时数据很多，其实已经超出了32、64位Bitmap结构所能记录的限度，但是对象头信息是与对象自身定义的数据无关的额 外存储成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。例如在32位的HotSpot虚拟机 中对象未被锁定的状态下，Mark Word的32个Bits空间中的25Bits用于存储对象哈希码（HashCode），4Bits用于存储对象分代年龄，2Bits用于存储锁标志位，1Bit固定为0，在其他状态（轻量级锁定、重量级锁定、GC标记、可偏向）下对象的存储内容如下表所示。但是如果对象是数组类型，则需要三个机器码，因为JVM虚拟机可以通过Java对象的元数据信息确定Java对象的大小，但是无法从数组的元数据来确认数组的大小，所以用一块来记录数组长度。对象头信息是与对象自身定义的数据无关的额外存储成本，但是考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据，它会根据对象的状态复用自己的存储空间，也就是说，Mark Word会随着程序的运行发生变化。变化状态如下：\n32位虚拟机\n\n64位虚拟机\n\n现在我们虚拟机基本是64位的，而64位的对象头有点浪费空间,JVM默认会开启指针压缩，所以基本上也是按32位的形式记录对象头的。手动设置-XX:+UseCompressedOops \n哪些信息会被压缩？\n\n对象的全局静态变量(即类属性)\n对象头信息：64位平台下，原生对象头大小为16字节，压缩后为12字节\n对象的引用类型：64位平台下，引用类型本身大小为8字节，压缩后为4字节\n对象数组类型：64位平台下，数组类型本身大小为24字节，压缩后16字节\n\n在Scott oaks写的《java性能权威指南》第八章8.22节提到了当heap size堆内存大于32GB是用不了压缩指针的，对象引用会额外占用20%左右的堆空间，也就意味着要38GB的内存才相当于开启了指针压缩的32GB堆空间。\n锁的膨胀升级过程锁的状态总共有四种，无锁状态、偏向锁、轻量级锁和重量级锁。随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁，但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级。从JDK 1.6 中默认是开启偏向锁和轻量级锁的，可以通过-XX:-UseBiasedLocking来禁用偏向锁。下图为锁的升级全过程：\n偏向锁偏向锁是Java 6之后加入的新锁，它是一种针对加锁操作的优化手段，经过研究发现，在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，因此为了减少同一线程获取锁(会涉及到一些CAS操作,耗时)的代价而引入偏向锁。偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提供程序的性能。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果，毕竟极有可能连续多次是同一个线程申请相同的锁。但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。下面我们接着了解轻量级锁。默认开启偏向锁\n\n开启偏向锁：-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0关闭偏向锁：-XX:-UseBiasedLocking\n\n轻量级锁倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)，此时Mark Word 的结构也变为轻量级锁的结构。轻量级锁能够提升程序性能的依据是“对绝大部分的锁，在整个同步周期内都不存在竞争”，注意这是经验数据。需要了解的是，轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁。\n自旋锁轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。这是基于在大多数情况下，线程持有锁的时间都不会太长，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环(这也是称为自旋的原因)，一般不会太久，可能是50个循环或100循环，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式，这种方式确实也是可以提升效率的。最后没办法也就只能升级为重量级锁了。\n锁消除消除锁是虚拟机另外一种锁的优化，这种优化更彻底，Java虚拟机在JIT编译时(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编译)，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间，比如说StringBuffer的append是一个同步方法，但是若将期定义为局部变量，并且不被其他线程所使用，那么StringBuffer不可能存在共享资源竞争的情景，JVM会自动将其锁消除。锁消除的依据是逃逸分析的数据支持。\n锁消除，前提是java必须运行在server模式（server模式会比client模式作更多的优化），同时必须开启逃逸分析\n\n-XX:+DoEscapeAnalysis 开启逃逸分析-XX:+EliminateLocks 表示开启锁消除。\n\n","categories":["Java"],"tags":["并发"]},{"title":"MESI缓存一致性协议","url":"/2020/08/20/Java/%E5%B9%B6%E5%8F%91/MESI%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AE/","content":"CPU高速缓存（Cache Memory）CPU为何要有高速缓存CPU在摩尔定律的指导下以每18个月翻一番的速度在发展，然而内存和硬盘的发展速度远远不及CPU。这就造成了高性能能的内存和硬盘价格及其昂贵。然而CPU的高度运算需要高速的数据。为了解决这个问题，CPU厂商在CPU中内置了少量的高速缓存以解决I\\O速度和CPU运算速度之间的不匹配问题。在CPU访问存储设备时，无论是存取数据抑或存取指令，都趋于聚集在一片连续的区域中，这就被称为局部性原理。时间局部性（Temporal Locality）：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。比如循环、递归、方法的反复调用等。空间局部性（Spatial Locality）：如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。比如顺序执行的代码、连续创建的两个对象、数组等。\n带有高速缓存的CPU执行计算的流程\n程序以及数据被加载到主内存\n指令和数据被加载到CPU的高速缓存\nCPU执行指令，把结果写到高速缓存\n高速缓存中的数据写回主内存\n\n目前流行的多级缓存结构由于CPU的运算速度超越了1级缓存的数据I\\O能力，CPU厂商又引入了多级的缓存结构。多级缓存结构\n多核CPU多级缓存一致性协议MESI多核CPU的情况下有多个一级缓存，如何保证缓存内部数据的一致,不让系统数据混乱。这里就引出了一个一致性的协议MESI。\nMESI协议缓存状态MESI 是指4种状态的首字母。缓存行（Cache line）为缓存的最小存储单位，每个缓存行有4个状态，可用2个bit表示，它们分别是：\n\n\n\n状态\n描述\n监听任务\n\n\n\nM 修改 (Modified)\n该Cache line有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。\n缓存行必须时刻监听所有试图读该缓存行相对应的内存的操作，其他缓存须在本缓存行写回内存并将状态置为E之后才能操作该缓存行对应的内存数据\n\n\nE 独享、互斥 (Exclusive)\n该Cache line有效，数据和内存中的数据一致，数据只存在于本Cache中。\n缓存行也必须监听其它缓存读主存中该缓存行的操作，一旦有这种操作，该缓存行需要变成S（共享）状态。\n\n\nS 共享 (Shared)\n该Cache line有效，数据和内存中的数据一致，数据存在于很多Cache中。\n缓存行也必须监听其它缓存使该缓存行无效或者独享该缓存行的请求，并将该缓存行变成无效（Invalid）。\n\n\nI 无效 (Invalid)\n该Cache line无效。\n无\n\n\n注意：\n对于M和E状态而言总是精确的，他们在和该缓存行的真正状态是一致的，而S状态可能是非一致的。如果一个缓存将处于S状态的缓存行作废了，而另一个缓存实际上可能已经独享了该缓存行，但是该缓存却不会将该缓存行升迁为E状态，这是因为其它缓存不会广播他们作废掉该缓存行的通知，同样由于缓存并没有保存该缓存行的copy的数量，因此（即使有这种通知）也没有办法确定自己是否已经独享了该缓存行。从上面的意义看来E状态是一种投机性的优化：如果一个CPU想修改一个处于S状态的缓存行，总线事务需要将所有该缓存行的copy变成invalid状态，而修改E状态的缓存不需要使用总线事务。\nMESI状态转换​    \n理解该图的前置说明：\n\n触发事件\n\n\n\n触发事件\n描述\n\n\n\n本地读取（Local read）\n本地cache读取本地cache数据\n\n\n本地写入（Local write）\n本地cache写入本地cache数据\n\n\n远端读取（Remote read）\n其他cache读取本地cache数据\n\n\n远端写入（Remote write）\n其他cache写入本地cache数据\n\n\n\ncache分类\n前提：所有的cache共同缓存了主内存中的某一条数据。本地cache: 指当前cpu的cache。触发cache: 触发读写事件的cache。其他cache: 指既除了以上两种之外的cache。注意：本地的事件触发 本地cache和触发cache为相同。\n\n\n上图的切换解释：\n\n\n\n状态\n触发本地读取\n触发本地写入\n触发远端读取\n触发远端写入\n\n\n\nM状态（修改）\n本地cache:M 触发cache:M其他cache:I\n本地cache:M 触发cache:M其他cache:I\n本地cache:M→E→S触发cache:I→S其他cache:I→S同步主内存后修改为E独享,同步触发、其他cache后本地、触发、其他cache修改为S共享\n本地cache:M→E→S→I触发cache:I→S→E→M其他cache:I→S→I同步和读取一样,同步完成后触发cache改为M，本地、其他cache改为I\n\n\nE状态（独享）\n本地cache:E触发cache:E其他cache:I\n本地cache:E→M触发cache:E→M其他cache:I本地cache变更为M,其他cache状态应当是I（无效）\n本地cache:E→S触发cache:I→S其他cache:I→S当其他cache要读取该数据时，其他、触发、本地cache都被设置为S(共享)\n本地cache:E→S→I触发cache:I→S→E→M其他cache:I→S→I当触发cache修改本地cache独享数据时时，将本地、触发、其他cache修改为S共享.然后触发cache修改为独享，其他、本地cache修改为I（无效），触发cache再修改为M\n\n\nS状态(共享)\n本地cache:S触发cache:S其他cache:S\n本地cache:S→E→M触发cache:S→E→M其他cache:S→I 当本地cache修改时，将本地cache修改为E,其他cache修改为I,然后再将本地cache为M状态\n本地cache:S触发cache:S其他cache:S\n本地cache:S→I触发cache：S→E→M其他cache:S→I当触发cache要修改本地共享数据时，触发cache修改为E（独享）,本地、其他cache修改为I（无效）,触发cache再次修改为M(修改)\n\n\nI状态（无效）\n本地cache:I→S或者I→E触发cache:I→S或者I →E其他cache:E、M、I→S、I本地、触发cache将从I无效修改为S共享或者E独享，其他cache将从E、M、I 变为S或者I\n本地cache:I→S→E→M触发cache:I→S→E→M其他cache:M、E、S→S→I\n既然是本cache是I，其他cache操作与它无关\n既然是本cache是I，其他cache操作与它无关\n\n\n下图示意了，当一个cache line的调整的状态的时候，另外一个cache line 需要调整的状态。\n\n\n\n\nM\nE\nS\nI\n\n\n\nM\n×\n×\n×\n√\n\n\nE\n×\n×\n×\n√\n\n\nS\n×\n×\n√\n√\n\n\nI\n√\n√\n√\n√\n\n\n举个栗子来说：假设cache 1 中有一个变量x = 0的cache line 处于S状态(共享)。那么其他拥有x变量的cache 2、cache 3等x的cache line调整为S状态（共享）或者调整为 I 状态（无效）。\n多核缓存协同操作假设有三个CPU A、B、C，对应三个缓存分别是cache a、b、 c。在主内存中定义了x的引用值为0。\n单核读取那么执行流程是：\n\nCPU A发出了一条指令，从主内存中读取x。\n从主内存通过bus读取到缓存中（远端读取Remote read）,这时该Cache line修改为E状态（独享）。\n\n \n双核读取那么执行流程是：\n\nCPU A发出了一条指令，从主内存中读取x。\nCPU A从主内存通过bus读取到 cache a中并将该cache line 设置为E状态。\nCPU B发出了一条指令，从主内存中读取x。\nCPU B试图从主内存中读取x时，CPU A检测到了地址冲突。这时CPU A对相关数据做出响应。此时x 存储于cache a和cache b中，x在chche a和cache b中都被设置为S状态(共享)。\n\n \n修改数据那么执行流程是：\n\nCPU A 计算完成后发指令需要修改x.\nCPU A 将x设置为M状态（修改）并通知缓存了x的CPU B, CPU B将本地cache b中的x设置为I状态(无效)\nCPU A 对x进行赋值。\n\n \n同步数据那么执行流程是：\n\nCPU B 发出了要读取x的指令。\nCPU B 通知CPU A,CPU A将修改后的数据同步到主内存时cache a 修改为E（独享）\nCPU A同步CPU B的x,将cache a和同步后cache b中的x设置为S状态（共享）。\n\nvolatile为何能够保证可见性volatile会将变量带上lock标志，lock会触发硬件缓存锁定机制, 锁定机制有两种: 总线锁和缓存一致性协议，早期cpu核数较少，当cpu想要去内存读取数据时，会经过bus总线。如果多个cpu想要读取带有lock的变量，则需要获取总线锁，只有获取到总线锁的才可以对变量进行操作。可以看到这种方法的缺点, 一旦抢到锁, 那么只有这个cpu可以执行,其他cpu就没有办法在访问内存里的这个变量了。没有办法发挥多核并发的能力。因此发展出了缓存一致性协议。\n我们知道加了volatile的变量, 就被lock标记了. 那么被lock标记后的变量是如何工作的呢\n\n计算器启动, 有两个cpu, 那么两个cpu都会监听bus总线上带有lock标记的变量\n内存中有一个变量initFlag=false\ncpu core0 要调用initFlag, 这时候 ,首先拷贝一份initFlag 放入到bus总线, bus总线监控到initFlag带有lock标记, 于是所有cpu都监控到这个变量. \n然后将initFlag 拷贝到L3 cache–&gt;L2 cache ,此时, 只有一个cpu使用到这个变量, 所以, initFlag此时的状态是独享的状态.\n另一个cpu core1 也要调用initFlag变量, 通过bus总线监控到已经有线程在使用这个变量了, 于是, cpu core0也监控到cpu core1 使用这个变量了, 此时, 将initFlag的状态由独占变为共享状态. 同时cpu core1的中initFlag的状态也是共享状态. \n接下来, cpu core1和cpu core2都想要去修改这个变量, 是如何操作的呢? 我们知道, 在缓存中, 有一个缓存行, 变量保存在缓存行里, 每个cpu需要抢占锁, 然后锁住缓存行, 并告诉bus总线, 我抢到锁了, 监听bus总线的所有cpu都将得知, 当前已经有一个线程获取的锁, 我们要将这个变量丢弃, 于是变量从共享状态变为丢弃状态. \n获得锁的cpu, 修改变量, 这时变量的状态从共享状态变为修改状态. 然后重新写回到主内存, 在经过bus总线的时候, 所有cpu都被告知initFlag变量已经被修改, 需要重新获取新的initFlag变量.\n当两个线程同时修改initFlag, 并同时抢到锁, 怎么办呢? 他们会同时告诉bus总线, 我抢到锁了, 由bus总线裁决, 到底有谁来执行. \ncache line 的大小为64byte，如果一个变量大小大于了64byte,则会直接加总线锁。\n\nvolatile为什么不能保证原子性缓存一致性协议只能失效缓存行的数据, 而不能失效寄存器的数据, 导致volatile不能做到原子性。\n比如: cpu core0 从内存里读取了一个volatile变量 counter = 0, 然后将其从L1缓存总将变量加载到寄存器进行计算. 计算完写回到L1 缓存, 此时, 变量的状态是修改, 然后通知bus总线, 所有的cpu都会监测到counter变量已经被修改, 丢弃自己现有的变量.  cpu core1 此时会丢弃counter = 0, 但是如果counter已经被读取到寄存器进行计算了. 即使在L1内存中的数据被丢弃, 获取到了新的counter值, 当寄存器计算完以后, 会重新回写到L1缓存, 此时会覆盖刚刚读取到的counter=1, 将自己计算的counter=1写入内存中。\n不加volatile就不能够保证可见性吗？加volatile可以保证变量即时可见，而不添加volatile cpu也会将缓存中的数据刷新到内存中，但是不会保证立即进行刷新，而是仅当缓存控制器别无选择，只能将新的缓存块放入已占用的空间时，才将缓存刷新回主内存。 先前占用该空间的块将被删除，并将其值写回到主存储器。\n参考\n\nhttps://superuser.com/questions/869525/when-is-cpu-cache-flushed-back-to-main-memory\nhttp://en.wikipedia.org/wiki/MESI_protocol\n","categories":["Java"],"tags":["并发"]},{"title":"以Java的角度认识操作系统底层","url":"/2020/08/05/Java/%E5%B9%B6%E5%8F%91/%E4%BB%A5Java%E7%9A%84%E8%A7%92%E5%BA%A6%E8%AE%A4%E8%AF%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%BA%95%E5%B1%82/","content":"冯诺依曼计算机模型详解现代计算机模型是基于-冯诺依曼计算机模型计算机在运行时，先从内存中取出第一条指令，通过控制器的译码，按指令的要求，从存储器中取出数据进行指定的运算和逻辑操作等加工，然后再按地址把结果送到内存中去。接下来，再取出第二条指令，在控制器的指挥下完成规定操作。依此进行下去。直至遇到停止指令。程序与数据一样存贮，按程序编排的顺序，一步一步地取出指令，自动地完成指令规定的操作是计算机最基本的工作模型。这一原理最初是由美籍匈牙利数学家冯.诺依曼于1945年提出来的，故称为冯.诺依曼计算机模型。\n计算机五大核心组成部分\n控制器(Control)：是整个计算机的中枢神经，其功能是对程序规定的控制信息进行解释，根据其要求进行控制，调度程序、数据、地址，协调计算机各部分工作及内存与外设的访问等。\n运算器(Datapath)：运算器的功能是对数据进行各种算术运算和逻辑运算，即对数据进行加工处理。\n存储器(Memory)：存储器的功能是存储程序、数据和各种信号、命令等信息，并在需要时提供这些信息。\n输入(Input system)：输入设备是计算机的重要组成部分，输入设备与输出设备合你为外部设备，简称外设，输入设备的作用是将程序、原始数据、文字、字符、控制命令或现场采集的数据等信息输入到计算机。常见的输入设备有键盘、鼠标器、光电输入机、磁带机、磁盘机、光盘机等。\n输出(Output system)：输出设备与输入设备同样是计算机的重要组成部分，它把外算机的中间结果或最后结果、机内的各种数据符号及文字或各种控制信号等信息输出出来。微机常用的输出设备有显示终端CRT、打印机、激光印字机、绘图仪及磁带、光盘机等。下图-冯诺依曼计算机模型图\n\n​    \n上面的模型是一个理论的抽象简化模型，它的具体应用就是现代计算机当中的硬件结构设计：\n​    \n在上图硬件结构当中，配件很多，但最核心的只有两部分：CPU、内存。所以我们重点学习的也是这两部分。\nCPU结构CPU指令结构CPU内部结构\n\n控制单元\n运算单元\n数据单元​    \n\n控制单元控制单元是整个CPU的指挥控制中心，由指令寄存器IR（Instruction Register）、指令译码器ID（Instruction Decoder）和 操作控制器OC（Operation Controller） 等组成，对协调整个电脑有序工作极为重要。它根据用户预先编好的程序，依次从存储器中取出各条指令，放在指令寄存器IR中，通过指令译码（分析）确定应该进行什么操作，然后通过操作控制器OC，按确定的时序，向相应的部件发出微操作控制信号。操作控制器OC中主要包括：节拍脉冲发生器、控制矩阵、时钟脉冲发生器、复位电路和启停电路等控制逻辑。\n运算单元运算单元是运算器的核心。可以执行算术运算（包括加减乘数等基本运算及其附加运算）和逻辑运算（包括移位、逻辑测试或两个值比较）。相对控制单元而言，运算器接受控制单元的命令而进行动作，即运算单元所进行的全部操作都是由控制单元发出的控制信号来指挥的，所以它是执行部件。\n存储单元存储单元包括 CPU 片内缓存Cache和寄存器组，是 CPU 中暂时存放数据的地方，里面保存着那些等待处理的数据，或已经处理过的数据，CPU 访问寄存器所用的时间要比访问内存的时间短。 寄存器是CPU内部的元件，寄存器拥有非常高的读写速度，所以在寄存器之间的数据传送非常快。采用寄存器，可以减少 CPU 访问内存的次数，从而提高了 CPU 的工作速度。寄存器组可分为专用寄存器和通用寄存器。专用寄存器的作用是固定的，分别寄存相应的数据；而通用寄存器用途广泛并可由程序员规定其用途。\n下表列出了CPU关键技术的发展历程以及代表系列，每一个关键技术的诞生都是环环相扣的，处理器这些技术发展历程都围绕着如何不让“CPU闲下来”这一个核心目标展开。\n\n\n\n关键技术\n时间\n描述\n\n\n\n指令缓存(L1)\n1982\n预读多条指令\n\n\n数据缓存(L1)\n1985\n预读一定长度的数据\n\n\n流水线\n1989\n一条指令被拆分由多个单元协同处理, i486\n\n\n多流水线\n1993\n多运算单元多流水线并行处理, 奔腾1\n\n\n乱序+分支预测\n1995\n充分利用不同组件协同处理, 奔腾Pro\n\n\n超线程\n2002\n引入多组前端部件共享执行引擎, 奔腾4\n\n\n多核处理器\n2006\n取消超线程，降低时钟频率，改用多核心, Core酷睿\n\n\n多核超线程\n2008\n重新引入超线程技术，iX系列\n\n\nCPU缓存结构现代CPU为了提升执行效率，减少CPU与内存的交互(交互影响CPU效率)，一般在CPU上集成了多级缓存架构，常见的为三级缓存结构\n\nL1 Cache，分为数据缓存和指令缓存，逻辑核独占\nL2 Cache，物理核独占，逻辑核共享\nL3 Cache，所有物理核共享\n\n​    \n存储器存储空间大小：内存&gt;L3&gt;L2&gt;L1&gt;寄存器；存储器速度快慢排序：寄存器&gt;L1&gt;L2&gt;L3&gt;内存；还有一点值得注意的是：缓存是由最小的存储区块-缓存行(cacheline)组成，缓存行大小通常为64byte。缓存行是什么意思呢？比如你的L1缓存大小是512kb,而cacheline = 64byte,那么就是L1里有512 * 1024/64个cacheline\nCPU读取存储器数据过程\nCPU要取寄存器X的值，只需要一步：直接读取。\nCPU要取L1 cache的某个值，需要1-3步（或者更多）：把cache行锁住，把某个数据拿来，解锁，如果没锁住就慢了。\nCPU要取L2 cache的某个值，先要到L1 cache里取，L1当中不存在，在L2里，L2开始加锁，加锁以后，把L2里的数据复制到L1，再执行读L1的过程，上面的3步，再解锁。\nCPU取L3 cache的也是一样，只不过先由L3复制到L2，从L2复制到L1，从L1到CPU。\nCPU取内存则最复杂：通知内存控制器占用总线带宽，通知内存加锁，发起内存读请求，等待回应，回应数据保存到L3（如果没有就到L2），再从L3/2到L1，再从L1到CPU，之后解除总线锁定。\n\nCPU为何要有高速缓存CPU在摩尔定律的指导下以每18个月翻一番的速度在发展，然而内存和硬盘的发展速度远远不及CPU。这就造成了高性能的内存和硬盘价格及其昂贵。然而CPU的高度运算需要高速的数据。为了解决这个问题，CPU厂商在CPU中内置了少量的高速缓存以解决I\\O速度和CPU运算速度之间的不匹配问题。在CPU访问存储设备时，无论是存取数据抑或存取指令，都趋于聚集在一片连续的区域中，这就被称为局部性原理。时间局部性（Temporal Locality）：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。比如循环、递归、方法的反复调用等。空间局部性（Spatial Locality）：如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。比如顺序执行的代码、连续创建的两个对象、数组等。\n举个空间局部性原则例子：\npublic class TwoDimensionalArraySum &#123;    private static final int RUNS = 100;    private static final int DIMENSION_1 = 1024 * 1024;    private static final int DIMENSION_2 = 6;    private static long[][] longs;    public static void main(String[] args) throws Exception &#123;        /*                     * 初始化数组                     */        longs = new long[DIMENSION_1][];        for (int i = 0; i &lt; DIMENSION_1; i++) &#123;            longs[i] = new long[DIMENSION_2];            for (int j = 0; j &lt; DIMENSION_2; j++) &#123;                longs[i][j] = 1L;            &#125;        &#125;        System.out.println(&quot;Array初始化完毕....&quot;);        long sum = 0L;        long start = System.currentTimeMillis();        for (int r = 0; r &lt; RUNS; r++) &#123;            for (int i = 0; i &lt; DIMENSION_1; i++) &#123;//DIMENSION_1=1024*1024                for (int j=0;j&lt;DIMENSION_2;j++)&#123;//6                    sum+=longs[i][j];                &#125;            &#125;        &#125;        System.out.println(&quot;spend time1:&quot;+(System.currentTimeMillis()-start));        System.out.println(&quot;sum1:&quot;+sum);        sum = 0L;        start = System.currentTimeMillis();        for (int r = 0; r &lt; RUNS; r++) &#123;            for (int j=0;j&lt;DIMENSION_2;j++) &#123;//6                for (int i = 0; i &lt; DIMENSION_1; i++)&#123;//1024*1024                    sum+=longs[i][j];                &#125;            &#125;        &#125;        System.out.println(&quot;spend time2:&quot;+(System.currentTimeMillis()-start));        System.out.println(&quot;sum2:&quot;+sum);    &#125;&#125;  \n\n带有高速缓存的CPU执行计算的流程\n程序以及数据被加载到主内存\n指令和数据被加载到CPU的高速缓存\nCPU执行指令，把结果写到高速缓存\n高速缓存中的数据写回主内存\n\nCPU运行安全等级CPU有4个运行级别，分别为：\n\nring0\nring1\nring2\nring3\n\nLinux与Windows只用到了2个级别:ring0、ring3，操作系统内部内部程序指令通常运行在ring0级别，操作系统以外的第三方程序运行在ring3级别，第三方程序如果要调用操作系统内部函数功能，由于运行安全级别不够,必须切换CPU运行状态，从ring3切换到ring0,然后执行系统函数，说到这里应该明白为什么JVM创建线程，线程阻塞唤醒是重型操作了，因为CPU要切换运行状态。JVM创建线程CPU的工作过程：step1：CPU从ring3切换ring0创建线程step2：创建完毕,CPU从ring0切换回ring3step3：线程执行JVM程序step4：线程执行完毕，销毁还得切回ring0\n操作系统内存管理执行空间保护操作系统有用户空间与内核空间两个概念，目的也是为了做到程序运行安全隔离与稳定，以32位操作系统4G大小的内存空间为例    \nLinux为内核代码和数据结构预留了几个页框，这些页永远不会被转出到磁盘上。从 0x00000000 到 0xC0000000（PAGE_OFFSET） 的线性地址可由用户代码 和 内核代码进行引用（即用户空间）。从0xC0000000（PAGE_OFFSET）到 0xFFFFFFFFF的线性地址只能由内核代码进行访问（即内核空间）。内核代码及其数据结构都必须位于这 1 GB的地址空间中，但是对于此地址空间而言，更大的消费者是物理地址的虚拟映射。\n这意味着在 4 GB 的内存空间中，只有 3 GB 可以用于用户应用程序。进程与线程只能运行在用户方式（usermode）或内核方式（kernelmode）下。用户程序运行在用户方式下，而系统调用运行在内核方式下。在这两种方式下所用的堆栈不一样：用户方式下用的是一般的堆栈(用户空间的堆栈)，而内核方式下用的是固定大小的堆栈（内核空间的堆栈，一般为一个内存页的大小），即每个进程与线程其实有两个堆栈，分别运行在用户态与内核态。由空间划分我们再引深一下，CPU调度的基本单位线程，也划分为：\n\n内核线程模型(KLT)：Kernel Level Thread\n用户线程模型(ULT)：User Level Thread\n\n\n内核线程模型\n\n\n内核线程(KLT)：系统内核管理线程(KLT),内核保存线程的状态和上下文信息，线程阻塞不会引起进程阻塞。在多处理器系统上，多线程在多处理器上并行运行。线程的创建、调度和管理由内核完成，效率比ULT要慢，比进程操作快。 \n\n用户线程模型\n\n\n用户线程(ULT)：用户程序实现,不依赖操作系统核心,应用提供创建、同步、调度和管理线程的函数来控制用户线程。不需要用户态/内核态切换，速度快。内核对ULT无感知，线程阻塞则进程（包括它的所有线程）阻塞。\nJVM是ULT模型\n进程与线程什么是进程？\n现代操作系统在运行一个程序时，会为其创建一个进程；例如，启动一个Java程序，操作系统就会创建一个Java进程。进程是OS(操作系统)资源分配的最小单位。\n什么是线程？\n线程是OS(操作系统)调度CPU的最小单元，也叫轻量级进程（Light Weight Process），在一个进程里可以创建多个线程，这些线程都拥有各自的计数器、堆栈和局部变量等属性，并且能够访问共享的内存变量。CPU在这些线程上高速切换，让使用者感觉到这些线程在同时执行，即并发的概念，相似的概念还有并行！\n线程上下文切换过程：\n​    \n虚拟机指令集架构\n虚拟机指令集架构主要分两种：\n\n栈指令集架构\n\n寄存器指令集架构\n\n\n关于指令集架构的wiki详细说明\n栈指令集架构\n 设计和实现更简单,适用于资源受限的系统;\n 避开了寄存器的分配难题:使用零地址指令方式分配;\n 指令流中的指令大部分是零地址指令,其执行过程依赖于操作栈,指令集更小,编译器容易实现;\n 不需要硬件支持,可移植性更好,更好实现跨平台。\n\n寄存器指令集架构\n典型的应用是x86的二进制指令集:比如传统的PC以及Android的Davlik虚拟机。\n指令集架构则完全依赖硬件,可移植性差。\n性能优秀和执行更高效。\n花费更少的指令去完成一项操作。\n在大部分情况下,基于寄存器架构的指令集往往都以一地址指令、二地址指令和三地址指令为主,而基于栈式架构的指令集却是以零地址指令为主。\n\nJava符合典型的栈指令集架构特征，像Python、Go都属于这种架构。\n","categories":["Java"],"tags":["并发"]},{"title":"定时任务与定时线程池","url":"/2021/12/03/Java/%E5%B9%B6%E5%8F%91/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E4%B8%8E%E5%AE%9A%E6%97%B6%E7%BA%BF%E7%A8%8B%E6%B1%A0/","content":"ScheduledThreadPoolExecutor\n它用来处理延时任务或定时任务\n\n它接收SchduledFutureTask类型的任务，是线程池调度任务的最小单位，有三种提交任务的方式：\n\nschedule\nscheduledAtFixedRate\nscheduledWithFixedDelay\n\n它采用DelayQueue存储等待的任务\n\nDelayQueue内部封装了一个PriorityQueue，它会根据time的先后时间排序，若time相同则根据sequenceNumber排序\nDelayQueue也是一个无界队列\n\nSchduledFutureTaskSchduledFutureTask接收的参数(成员变量)：\n\nprivate long time：任务开始的时间\nprivate final long sequenceNumber;：任务的序号\nprivate final long period：任务执行的时间间隔\n\n工作线程的执行过程：\n\n工作线程会从DelayQueue取已经到期的任务去执行；\n执行结束后重新设置任务的到期时间，再次放回DelayQueue\n\nScheduledThreadPoolExecutor会把待执行的任务放到工作队列DelayQueue中，DelayQueue封装了一个PriorityQueue，PriorityQueue会对队列中的ScheduledFutureTask进行排序，具体的排序算法实现如下：\npublic int compareTo(Delayed other) &#123;  if (other == this) // compare zero if same object    return 0;  if (other instanceof ScheduledFutureTask) &#123;    ScheduledFutureTask&lt;?&gt; x = (ScheduledFutureTask&lt;?&gt;)other;    long diff = time - x.time;    if (diff &lt; 0)      return -1;    else if (diff &gt; 0)      return 1;    else if (sequenceNumber &lt; x.sequenceNumber)      return -1;    else      return 1;  &#125;  long diff = getDelay(NANOSECONDS) - other.getDelay(NANOSECONDS);  return (diff &lt; 0) ? -1 : (diff &gt; 0) ? 1 : 0;&#125;\n\n\n首先按照time排序，time小的排在前面，time大的排在后面；\n如果time相同，按照sequenceNumber排序，sequenceNumber小的排在前面，sequenceNumber大的排在后面，换句话说，如果两个task的执行时间相同，优先执行先提交的task\n\nSchduledFutureTask之run方法实现run方法是调度task的核心，task的执行实际上是run方法的执行\npublic void run() &#123;  boolean periodic = isPeriodic();  //如果当前线程池已经不支持执行任务，则取消  if (!canRunInCurrentRunState(periodic))    cancel(false);  //如果不需要周期性执行，则直接执行run方法然后结束  else if (!periodic)    ScheduledFutureTask.super.run();  //如果需要周期执行，则在执行完任务以后，设置下一次执行时间  else if (ScheduledFutureTask.super.runAndReset()) &#123;    // 计算下次执行该任务的时间    setNextRunTime();    //重复执行任务    reExecutePeriodic(outerTask);  &#125;&#125;\n\n\n如果当前线程池运行状态不可以执行任务，取消该任务，然后直接返回，否则执行步骤2；\n如果不是周期性任务，调用FutureTask中的run方法执行，会设置执行结果，然后直接返回，否则执行步骤3；\n如果是周期性任务，调用FutureTask中的runAndReset方法执行，不会设置执行结果，然后直接返回，否则执行步骤4和步骤5；\n计算下次执行该任务的具体时间；\n重复执行任务。\n\nreExecutePeriodic方法void reExecutePeriodic(RunnableScheduledFuture&lt;?&gt; task) &#123;  if (canRunInCurrentRunState(true)) &#123;    super.getQueue().add(task);    if (!canRunInCurrentRunState(true) &amp;&amp; remove(task))      task.cancel(false);    else      ensurePrestart();  &#125;&#125;\n\n该方法和delayedExecute方法类似，不同的是：\n\n由于调用reExecutePeriodic方法时已经执行过一次周期性任务了，所以不会reject当前任务；\n传入的任务一定是周期性任务。\n\n线程池任务的提交首先是schedule方法，该方法是指任务在指定延迟时间到达后触发，只会执行一次\npublic ScheduledFuture&lt;?&gt; schedule(Runnable command,                                   long delay,                                   TimeUnit unit) &#123;  //参数校验  if (command == null || unit == null)    throw new NullPointerException();  //这里是一个嵌套结构，首先把用户提交的任务包装成ScheduledFutureTask  //然后在调用decorateTask进行包装，该方法是留给用户去扩展的，默认是个空方法  RunnableScheduledFuture&lt;?&gt; t = decorateTask(command, new ScheduledFutureTask&lt;Void&gt;(command, null, triggerTime(delay, unit)));  //包装好任务以后，就进行提交了  delayedExecute(t);  return t;&#125;\n\n任务提交\nprivate void delayedExecute(RunnableScheduledFuture&lt;?&gt; task) &#123;  //如果线程池已经关闭，则使用拒绝策略把提交任务拒绝掉  if (isShutdown())    reject(task);  else &#123;    //与ThreadPoolExecutor不同，这里直接把任务加入延迟队列    super.getQueue().add(task);//使用用的DelayedWorkQueue    //如果当前状态无法执行任务，则取消    if (isShutdown() &amp;&amp;        !canRunInCurrentRunState(task.isPeriodic()) &amp;&amp;        remove(task))      task.cancel(false);    else      //这里是增加一个worker线程，避免提交的任务没有worker去执行      //原因就是该类没有像ThreadPoolExecutor一样，woker满了才放入队列      ensurePrestart();  &#125;&#125;\n\nDelayedWorkQueueScheduledThreadPoolExecutor之所以要自己实现阻塞的工作队列，是因为ScheduledThreadPoolExecutor要求的工作队列有些特殊。\nDelayedWorkQueue是一个基于堆的数据结构，类似于DelayQueue和PriorityQueue。在执行定时任务的时候，每个任务的执行时间都不同，所以DelayedWorkQueue的工作就是按照执行时间的升序来排列，执行时间距离当前时间越近的任务在队列的前面（注意：这里的顺序并不是绝对的，堆中的排序只保证了子节点的下次执行时间要比父节点的下次执行时间要大，而叶子节点之间并不一定是顺序的，下文中会说明）\n堆结构\n\n\n可见，DelayedWorkQueue是一个基于最小堆结构的队列。堆结构可以使用数组表示，可以转换成如下的数组：\n\n在这种结构中，可以发现有如下特性：\n假设，索引值从0开始，子节点的索引值为k，父节点的索引值为p，则：\n\n一个节点的左子节点的索引为：k = p * 2 + 1；\n一个节点的右子节点的索引为：k = (p + 1) * 2；\n一个节点的父节点的索引为：p = (k - 1) / 2。\n\n为什么要使用DelayedWorkQueue呢？\n定时任务执行时需要取出最近要执行的任务，所以任务在队列中每次出队时一定要是当前队列中执行时间最靠前的，所以自然要使用优先级队列。DelayedWorkQueue是一个优先级队列，它可以保证每次出队的任务都是当前队列中执行时间最靠前的，由于它是基于堆结构的队列，堆结构在执行插入和删除操作时的最坏时间复杂度是 *O(logN)*。\nDelayedWorkQueue属性// 队列初始容量private static final int INITIAL_CAPACITY = 16;// 根据初始容量创建RunnableScheduledFuture类型的数组private RunnableScheduledFuture&lt;?&gt;[] queue =    new RunnableScheduledFuture&lt;?&gt;[INITIAL_CAPACITY];private final ReentrantLock lock = new ReentrantLock();private int size = 0;// leader线程private Thread leader = null;// 当较新的任务在队列的头部可用时，或者新线程可能需要成为leader，则通过该条件发出信号private final Condition available = lock.newCondition();\n\n注意这里的leader，它是Leader-Follower模式的变体，用于减少不必要的定时等待。什么意思呢？对于多线程的网络模型来说：所有线程会有三种身份中的一种：leader和follower，以及一个干活中的状态：proccesser。它的基本原则就是，永远最多只有一个leader。而所有follower都在等待成为leader。线程池启动时会自动产生一个Leader负责等待网络IO事件，当有一个事件产生时，Leader线程首先通知一个Follower线程将其提拔为新的Leader，然后自己就去干活了，去处理这个网络事件，处理完毕后加入Follower线程等待队列，等待下次成为Leader。这种方法可以增强CPU高速缓存相似性，及消除动态内存分配和线程间的数据交换。\noffer方法public boolean offer(Runnable x) &#123;  //参数校验  if (x == null)    throw new NullPointerException();  RunnableScheduledFuture&lt;?&gt; e = (RunnableScheduledFuture&lt;?&gt;)x;  final ReentrantLock lock = this.lock;  lock.lock();  try &#123;    //查看当前元素数量，如果大于队列长度则进行扩容    int i = size;    if (i &gt;= queue.length)      grow();    //元素数量加1    size = i + 1;    //如果当前队列还没有元素，则直接加入头部    if (i == 0) &#123;      queue[0] = e;      //记录索引      setIndex(e, 0);    &#125; else &#123;      //把任务加入堆中，并调整堆结构，这里就会根据任务的触发时间排列      //把需要最早执行的任务放在前面      siftUp(i, e);    &#125;    //如果新加入的元素就是队列头，这里有两种情况    //1.这是用户提交的第一个任务    //2.新任务进行堆调整以后，排在队列头    if (queue[0] == e) &#123;      // leader设置为null为了使在take方法中的线程在通过available.signal();后会执行available.awaitNanos(delay);      leader = null;      //加入元素以后，唤醒worker线程      available.signal();    &#125;  &#125; finally &#123;    lock.unlock();  &#125;  return true;&#125;\n\n任务排序sift方法private void siftUp(int k, RunnableScheduledFuture&lt;?&gt; key) &#123;\t// 找到父节点的索引  while (k &gt; 0) &#123;    // 获取父节点    int parent = (k - 1) &gt;&gt;&gt; 1;    RunnableScheduledFuture&lt;?&gt; e = queue[parent];    // 如果key节点的执行时间大于父节点的执行时间，不需要再排序了    if (key.compareTo(e) &gt;= 0)      break;    // 如果key.compareTo(e) &lt; 0，说明key节点的执行时间小于父节点的执行时间，需要把父节点移到后面    queue[k] = e;    setIndex(e, k);    // 设置索引为k    k = parent;  &#125;  // key设置为排序后的位置中  queue[k] = key;  setIndex(key, k);&#125;\n\n代码很好理解，就是循环的根据key节点与它的父节点来判断，如果key节点的执行时间小于父节点，则将两个节点交换，使执行时间靠前的节点排列在队列的前面。\n假设新入队的节点的延迟时间（调用getDelay()方法获得）是5，执行过程如下：\n\n先将新的节点添加到数组的尾部，这时新节点的索引k为7：\n\n\n\n\n计算新父节点的索引：parent = (k - 1) &gt;&gt;&gt; 1，parent = 3，那么queue[3]的时间间隔值为8，因为 5 &lt; 8 ，将执行queue[7] = queue[3]：\n\n\n\n\n这时将k设置为3，继续循环，再次计算parent为1，queue[1]的时间间隔为3，因为 5 &gt; 3 ，这时退出循环，最终k为3：\n\n\n\n可见，每次新增节点时，只是根据父节点来判断，而不会影响兄弟节点\ntake方法public RunnableScheduledFuture&lt;?&gt; take() throws InterruptedException &#123;  final ReentrantLock lock = this.lock;  lock.lockInterruptibly();  try &#123;    for (; ; ) &#123;      RunnableScheduledFuture&lt;?&gt; first = queue[0];      if (first == null)        available.await();      else &#123;        // 计算当前时间到执行时间的时间间隔        long delay = first.getDelay(NANOSECONDS);        if (delay &lt;= 0)          return finishPoll(first);        first = null; // don&#x27;t retain ref while waiting        // leader不为空，阻塞线程        if (leader != null)          available.await();        else &#123;          // leader为空，则把leader设置为当前线程，          Thread thisThread = Thread.currentThread();          leader = thisThread;          try &#123;            // 阻塞到执行时间            available.awaitNanos(delay);          &#125; finally &#123;            // 设置leader = null，让其他线程执行available.awaitNanos(delay);            if (leader == thisThread)              leader = null;          &#125;        &#125;      &#125;    &#125;  &#125; finally &#123;    // 如果leader不为空，则说明leader的线程正在执行available.awaitNanos(delay);    // 如果queue[0] == null，说明队列为空    if (leader == null &amp;&amp; queue[0] != null)      available.signal();    lock.unlock();  &#125;&#125;\n\ntake方法是什么时候调用的呢？在ThreadPoolExecutor中，介绍了getTask方法，工作线程会循环地从workQueue中取任务。但定时任务却不同，因为如果一旦getTask方法取出了任务就开始执行了，而这时可能还没有到执行的时间，所以在take方法中，要保证只有在到指定的执行时间的时候任务才可以被取走。\n再来说一下leader的作用，这里的leader是为了减少不必要的定时等待，当一个线程成为leader时，它只等待下一个节点的时间间隔，但其它线程无限期等待。 leader线程必须在从take（）或poll（）返回之前signal其它线程，除非其他线程成为了leader。\n举例来说，如果没有leader，那么在执行take时，都要执行available.awaitNanos(delay)，假设当前线程执行了该段代码，这时还没有signal，第二个线程也执行了该段代码，则第二个线程也要被阻塞。多个这时执行该段代码是没有作用的，因为只能有一个线程会从take中返回queue[0]（因为有lock），其他线程这时再返回for循环执行时取的queue[0]，已经不是之前的queue[0]了，然后又要继续阻塞。\n所以，为了不让多个线程频繁的做无用的定时等待，这里增加了leader，如果leader不为空，则说明队列中第一个节点已经在等待出队，这时其它的线程会一直阻塞，减少了无用的阻塞（注意，在finally中调用了signal()来唤醒一个线程，而不是signalAll()）\npoll 方法下面看下poll方法，与take类似，但这里要提供超时功能：\npublic RunnableScheduledFuture&lt;?&gt; poll(long timeout, TimeUnit unit) throws InterruptedException &#123;  long nanos = unit.toNanos(timeout);  final ReentrantLock lock = this.lock;  lock.lockInterruptibly();  try &#123;    for (; ; ) &#123;      RunnableScheduledFuture&lt;?&gt; first = queue[0];      if (first == null) &#123;        if (nanos &lt;= 0)          return null;        else          nanos = available.awaitNanos(nanos);      &#125; else &#123;        long delay = first.getDelay(NANOSECONDS);        // 如果delay &lt;= 0，说明已经到了任务执行的时间，返回。        if (delay &lt;= 0)          return finishPoll(first);        // 如果nanos &lt;= 0，说明已经超时，返回null        if (nanos &lt;= 0)          return null;        first = null; // don&#x27;t retain ref while waiting        // nanos &lt; delay 说明需要等待的时间小于任务要执行的延迟时间        // leader != null 说明有其它线程正在对任务进行阻塞        // 这时阻塞当前线程nanos纳秒        if (nanos &lt; delay || leader != null)          nanos = available.awaitNanos(nanos);        else &#123;          Thread thisThread = Thread.currentThread();          leader = thisThread;          try &#123;            // 这里的timeLeft表示delay减去实际的等待时间            long timeLeft = available.awaitNanos(delay);            // 计算剩余的等待时间             nanos -= delay - timeLeft;          &#125; finally &#123;            if (leader == thisThread)              leader = null;          &#125;        &#125;      &#125;    &#125;  &#125; finally &#123;    if (leader == null &amp;&amp; queue[0] != null)      available.signal();    lock.unlock();  &#125;&#125;\n\nfinishPoll方法当调用了take或者poll方法能够获取到任务时，会调用该方法进行返回：\nprivate RunnableScheduledFuture&lt;?&gt; finishPoll(RunnableScheduledFuture&lt;?&gt; f) &#123;  // 数组长度-1  int s = --size;  // 取出最后一个节点  RunnableScheduledFuture&lt;?&gt; x = queue[s];  queue[s] = null;  // 长度不为0，则从第一个元素开始排序，目的是要把最后一个节点放到合适的位置上  if (s != 0)    siftDown(0, x);  setIndex(f, -1);  return f;&#125;\n\nsiftDown方法siftDown方法使堆从k开始向下调整：\nprivate void siftDown(int k, RunnableScheduledFuture&lt;?&gt; key) &#123;  // 根据二叉树的特性，数组长度除以2，表示取有子节点的索引  int half = size &gt;&gt;&gt; 1;  // 判断索引为k的节点是否有子节点  while (k &lt; half) &#123;    // 左子节点的索引    int child = (k &lt;&lt; 1) + 1;    RunnableScheduledFuture&lt;?&gt; c = queue[child];    // 右子节点的索引    int right = child + 1;    // 如果有右子节点并且左子节点的时间间隔大于右子节点，取时间间隔最小的节点    if (right &lt; size &amp;&amp; c.compareTo(queue[right]) &gt; 0)      c = queue[child = right];    // 如果key的时间间隔小于等于c的时间间隔，跳出循环    if (key.compareTo(c) &lt;= 0)      break;    // 设置要移除索引的节点为其子节点    queue[k] = c;    setIndex(c, k);    k = child;  &#125;  // 将key放入索引为k的位置  queue[k] = key;  setIndex(key, k);&#125;\n\nsiftDown方法执行时包含两种情况，一种是没有子节点，一种是有子节点（根据half判断）。例如：\n没有子节点的情况：\n假设初始的堆如下：\n\n\n假设 k = 3 ，那么 k = half ，没有子节点，在执行siftDown方法时直接把索引为3的节点设置为数组的最后一个节点：\n\n\n有子节点的情况：\n假设 k = 0 ，那么执行以下步骤：\n\n获取左子节点，child = 1 ，获取右子节点， right = 2 \n\n由于 right &lt; size ，这时比较左子节点和右子节点时间间隔的大小，这里 3 &lt; 7 ，所以 c = queue[child] \n\n比较key的时间间隔是否小于c的时间间隔，这里不满足，继续执行，把索引为k的节点设置为c，然后将k设置为child\n\n因为 half = 3 ，k = 1 ，继续执行循环，这时的索引变为\n\n这时再经过如上判断后，将k的值为3，最终的结果如下\n\n最后，如果在finishPoll方法中调用的话，会把索引为0的节点的索引设置为-1，表示已经删除了该节点，并且size也减了1，最后的结果如下\n\n\n可见，siftdown方法在执行完并不是有序的，但可以发现，子节点的下次执行时间一定比父节点的下次执行时间要大，由于每次都会取左子节点和右子节点中下次执行时间最小的节点，所以还是可以保证在take和poll时出队是有序的。\nremove方法public boolean remove(Object x) &#123;  final ReentrantLock lock = this.lock;  lock.lock();  try &#123;    int i = indexOf(x);    if (i &lt; 0)      return false;    setIndex(queue[i], -1);    int s = --size;    RunnableScheduledFuture&lt;?&gt; replacement = queue[s];    queue[s] = null;    if (s != i) &#123;      // 从i开始向下调整      siftDown(i, replacement);      // 如果queue[i] == replacement，说明i是叶子节点      // 如果是这种情况，不能保证子节点的下次执行时间比父节点的大      // 这时需要进行一次向上调整      if (queue[i] == replacement)        siftUp(i, replacement);    &#125;    return true;  &#125; finally &#123;    lock.unlock();  &#125;&#125;\n\n假设初始的堆结构如下：\n\n\n这时要删除8的节点，那么这时 k = 1，key为最后一个节点\n\n\n这时通过上文对siftDown方法的分析，siftDown方法执行后的结果如下\n\n\n这时会发现，最后一个节点的值比父节点还要小，所以这里要执行一次siftUp方法来保证子节点的下次执行时间要比父节点的大，所以最终结果如下\n\n\n","categories":["Java"],"tags":["并发"]},{"title":"并发基础之CAS","url":"/2020/10/02/Java/%E5%B9%B6%E5%8F%91/%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80%E4%B9%8BCAS/","content":"CAS 的全称是 Compare And Swap 即比较交换，其算法核心思想如下函数：CAS(V,E,N) 参数：V 表示要更新的变量 E 预期值 N 新值如果 V 值等于 E 值，则将 V 的值设为 N。若 V 值和 E 值不同，则说明已经有其他线程做了更新，则当前线程什么都不做。通俗的理解就是 CAS 操作需要我们提供一个期望值，当期望值与当前线程的变量值相同时，说明还没线程修改该值，当前线程可以进行修改，也就是执行 CAS 操作，但如果期望值与当前线程不符，则说明该值已被其他线程修改，此时不执行更新操作，但可以选择重新读取该变量再尝试再次修改该变量，也可以放弃操作\nJAVA中提供有JVM实现的CAS操作，sun.misc包下的Unsafe类所提供\npublic final native boolean compareAndSwapObject(Object var1, long var2, Object var4, Object var5);public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6);\n\n而JVM底层实现是依赖于机器源语cmpxchg,而cmpxchg汇编命令并不是原子性，会用lock cmpxchg来实现原子性操作，而Lock怎么保证的原子性就需要看MESI缓存一致性协议了\nCAS的缺陷引入ABA问题因为CAS需要在操作值的时候，检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值 原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。\n解决思路就是使用版本号。在变量前面追加版本号，每次变量更新的时候把版本号+1，那么A-&gt;B-&gt;A 就会变成1A-&gt;2B-&gt;3A。从JDK1.5 开始，JDK的Atomic包里提供了一个类Atomic包里提供了一个AtomicStampedReference来解决ABA问题，\npublic boolean compareAndSet(V expectedReference, // 预期引用V newReference, // 更新后的引用int expectedStamp, // 预期标志int newStamp // 更新后的标志)\n\ncompareAndSet方法的作用首先检查当前引用是否等于预期引用，并且检查当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。\nCPU开销增大自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销\n只能保证一个共享变量的原子操作当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。还有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如，有两个共享变量i＝2，j=a，合并一下ij=2a，然后用CAS来操作ij。从Java 1.5开始，JDK提供了AtomicReference类来保证引用对之间的原子性，就可以把多个变量放在一个对象里来进行CAS操作。\n","categories":["Java"],"tags":["并发"]},{"title":"抽象队列同步器AQS","url":"/2020/09/27/Java/%E5%B9%B6%E5%8F%91/%E6%8A%BD%E8%B1%A1%E9%98%9F%E5%88%97%E5%90%8C%E6%AD%A5%E5%99%A8AQS/","content":"Java并发编程核心在于java.concurrent.util包而juc当中的大多数同步器实现都是围绕着共同的基础行为，比如等待队列、条件队列、独占获取、共享获取等，而这个行为的抽象就是基于AbstractQueuedSynchronizer简称AQS，AQS定义了一套多线程访问共享资源的同步器框架，是一个依赖状态(state)的同步器。\nAbstrackQueuedSynchronizer同步器同步器是用来构建锁或其他同步组件的基础框架，是并发的基石，由Doug Lea进行的实现。同步器的设计是基于模板方法模式的，也就是说，使用者需要继承同步器并重写指定的方法，随后将同步器组合在自定义同步组件的实现中，并调用同步器提供的模板方法，而这些模板方法将会调用使用者重写的方法同步器内部通过一个int 类型的成员变量state来控制同步状态：\n\nstate=0: 说明没有任何线程占有共享资源的锁。\nstate = 1:说明有线程正在使用共享变量，其他线程必须加入同步队列进行等待。\n\nAQS内部通过内部类Node构成FIFO的同步队列来 完成线程获取锁的排队工作，同时利用内部类ConditionObject构建等待队列。\n\nCondition调用wait()方法后，线程将会加入等待队列中。\nCondition调用signal()方法后，线程将从等待队列移动同步队列中进行锁竞争。\n\nAQS具备特性\n阻塞等待队列\n共享/独占\n公平/非公平\n可重入\n允许中断\n\n除了Lock外，Java.concurrent.util当中同步器的实现如Latch,Barrier,BlockingQueue等，都是基于AQS框架实现\n\n一般通过定义内部类Sync继承AQS\n将同步器所有调用都映射到Sync对应的方法\n\n同步等待队列同步器依赖内部的同步队列（FIFO双向队列）来完成同步状态的管理，当前线程获取状态失败时，同步器会将当前线程以及等待状态等信息构造成称为一个节点（Node)并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点中的线程唤醒，使其再次尝试获取同步状态。\nAQS当中的同步等待队列也称CLH队列，CLH队列是Craig、Landin、Hagersten三人发明的一种基于双向链表数据结构的队列，是FIFO先入先出线程等待队列，Java中的CLH队列是原CLH队列的一个变种,线程由原自旋机制改为阻塞机制。\n\n同步器与同步等待队列\n同步器包含了两个节点类型的引用，一个指向头节点，而另一个指向尾节点。当一个线程成功地获取了同步状态（或者锁），其他线程将无法获取到同步状态，转而被构造成节点并加入到同步队列中，而这个加入队列的操作必须要保证线程安全，因此同步器提供了一个基于CAS的设置尾节点的方法：compareAndSetTail(Node expect,Node update),它需要传递当前线程“认为”的尾节点和当前节点，只有设置成功后，当前节点才正式与之前的尾节点建立关联。\n添加节点过程\n设置首节点\n同步队列遵循FIFO，首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，将唤醒后继节点，而后继节点将会在获取同步状态成功时，将自己设置为首节点。设置首节点是通过获取同步状态成功的线程来完成的，由于只有一个线程能获取到同步状态，因此设置头节点的方法并不需要使用CAS来保证，它只需要将首节点设置成为原首节点的后继节点并断开原首节点的next引用即可。\n独占式同步状态获取与释放 独占锁:同一时刻只能有一个线程获取到锁，而其他获取锁的线程只能处于同步队列中等待，只有获取锁的线程释放了锁，后继的线程才能获取锁。通过调用同步的acquire(int arg)方法可以获取同步状态，该方法对中断不敏感，也就是由于线程获取同步 状态失败后进入同步队列中，后续对线程进行中断操作时，线程不会从同步队列中移除，该代码如下：\npublic final void acquire(int arg) &#123;    if (!tryAcquire(arg) &amp;&amp;        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))        selfInterrupt();&#125;\n\n上述代码主要完成同步状态获、节点构造、加入同步队列以及在同步对队列中自旋等待的相关工作。\n主要逻辑如下：\n首先调用自定义同步器实现的tryAcquire(int arg)方法，该方法保证线程安全的获取同步状态，如果同步状态获取失败，则构造同步节点(独占式 Node.EXCLUSIVE,同一时刻只能有一个线程成功获取同步状态)并通过addWaiter(Node node)方法将该节点加入到同步队列的尾部，最后调用acquireQueued(Node node,int arg)方法，使得该节点以”以死循环”的方式获取同步状态。如果获取不到则阻塞节点中的线程，而被阻塞线程的唤醒主要依靠前驱节点 的出队或阻塞线程被中断来实现。\nprivate Node addWaiter(Node mode) &#123;    Node node = new Node(Thread.currentThread(), mode);    // Try the fast path of enq; backup to full enq on failure    Node pred = tail;    if (pred != null) &#123;        node.prev = pred;        if (compareAndSetTail(pred, node)) &#123;            pred.next = node;            return node;        &#125;    &#125;    enq(node);    return node;&#125;\n\nprivate Node enq(final Node node) &#123;    for (;;) &#123;        Node t = tail;        if (t == null) &#123; // Must initialize            if (compareAndSetHead(new Node()))                tail = head;        &#125; else &#123;            node.prev = t;            if (compareAndSetTail(t, node)) &#123;                t.next = node;                return t;            &#125;        &#125;    &#125;&#125;\n\n上述代码通过使用compareAndSetTail方法来确保节点能够被线程安全添加。试想一下：如果使用一个普通的List来维护节点之间的关系，那么当一个线程获取了同步状态，而其他多个线程由于调用tryAcquire方法获取同步状态失败而并发地被添加到List时，List将难以保证Node的正确添加，最终的结果可能是节点的数量有偏差，而且顺序也是混乱的。\n在enq(final Node node)方法中，同步器通过“死循环”来保证节点的正确添加，在“死循环”中只有通过CAS将节点设置成为尾节点之后，当前线程才能从该方法返回，否则，当前线程不断地尝试设置。\nfinal boolean acquireQueued(final Node node, int arg) &#123;    boolean failed = true;    try &#123;        boolean interrupted = false;        for (;;) &#123;            final Node p = node.predecessor();            if (p == head &amp;&amp; tryAcquire(arg)) &#123;                setHead(node);                p.next = null; // help GC                failed = false;                return interrupted;            &#125;            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;                parkAndCheckInterrupt())                interrupted = true;        &#125;    &#125; finally &#123;        if (failed)            cancelAcquire(node);    &#125;&#125;\n\n在acquireQueued(final Node node, int arg)方法中，当前线程在“死循环”中尝试获取同步状态，而只有前驱节点才能够尝试获取同步状态，这是为什么？原因有两个：\n\n头节点是成功获取到同步状态的节点，而头节点的线程释放了同步状态后，将会唤醒其后继节点，后继节点的线程被唤醒后需要检查自己的前驱节点是否是头节点。\n维护同步队列的FIFO原则\n\n整体流程\n\n共享式同步状态获取与释放public final void acquireShared(int arg) &#123;    if (tryAcquireShared(arg) &lt; 0)        doAcquireShared(arg);&#125;\n\nprivate void doAcquireShared(int arg) &#123;    final Node node = addWaiter(Node.SHARED);    boolean failed = true;    try &#123;        boolean interrupted = false;        for (;;) &#123;            final Node p = node.predecessor();            if (p == head) &#123;                int r = tryAcquireShared(arg);                if (r &gt;= 0) &#123;                    setHeadAndPropagate(node, r);                    p.next = null; // help GC                    if (interrupted)                        selfInterrupt();                    failed = false;                    return;                &#125;            &#125;            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;                parkAndCheckInterrupt())                interrupted = true;        &#125;    &#125; finally &#123;        if (failed)            cancelAcquire(node);    &#125;&#125;\n\npublic final boolean releaseShared(int arg) &#123;    if (tryReleaseShared(arg)) &#123;        doReleaseShared();        return true;    &#125;    return false;&#125;\n\n\n\n在acquireShared(int arg)方法中，同步器调用tryAcquireShared(arg)方法尝试获取同步状态，tryAcquireShared(arg) 方法返回值为int类型，当返回值大于0时，表示能够获取到同步状态。因此，在共享式获取的自旋过程中，成功获取到同步状态并退出自旋的条件就是tryAcquireShared(arg)方法返回值大于等于0。可以看到，在doAcquireShared(int arg)方法的自旋过程中，如果当前节点的前驱为头节点时，尝试获取同步状态，如果返回值大于等于0，表示该次获取同步状态成功并从自旋中退出。与独占式一样，共享式获取也需要释放同步状态，通过调用releaseShared(int arg)方法可以释放同步状态。\n条件等待队列CondiitonObject是同步器AbstractQueuedSynchronizer的内部类 ，因为Condition的操作需要获取相关联的锁，所以作为同步器的内部类也会是比较合理的，每个Condition对象都包含着一个队列（等待队列），该队列是Condition对象实现等待/通知功能的关键。\n等待队列等待队列是一个FIFO的队列，在队列的每个节点都包含一个线程引用，该线程就是在Condition对象等待的线程，如果一个线程调用了Condition.await()方法，那么该线程将会释放锁、构造节点加入等待队列进入等待状态。事实上，节点的定义复用了同步器中节点的定义，也就是说，同步队列和等待队列中节点类型都是同步器的经静态内部类AbstractQueuedSynchronizer.Node一个Condition包含一个等待队列Condition拥有首节点(fristWaiter)和尾节点(lastWriter）。当前线程调用Condition.await()方法，将会以当前线程构造节点，并将节点从尾部加入等待队列。\n\n等待调用Condition 的await()方法，会使当前线程进入等待队列并释放锁，同时线程状态变为等待状态，当 从await()方法返回时，当前线程一定获取了Condition 相关联的锁，\n如果从队列 (同步队列和等待队列）的角度看await()方法，当调用await()方法时，相当于同步队列的首节点(获取了锁的节点）移动到Condition的等待队列中。\n通知调用Condition的signal()方法，将唤醒在等待队列中等待时间最长的节点(首节点),在唤醒节点之前，会将节点移动到同步队列中。\nReentrantLock中的AbstractQueuedSynchronized\n","categories":["Java"],"tags":["并发"]},{"title":"线程池Executor","url":"/2021/09/22/Java/%E5%B9%B6%E5%8F%91/%E7%BA%BF%E7%A8%8B%E6%B1%A0Executor/","content":"线程线程是调度CPU资源的最小单位，线程模型分为KLT模型与ULT模型，JVM使用的KLT模型，Java线程与OS线程保持1:1的映射关系，也就是说有一个java线程也会在操作系统里有一个对应的线程。Java线程有多种生命状态\n\nNEW：新建\nRUNNABLE：运行\nBLOCKED：阻塞\nWAITING：等待\nTIMED_WAITING：超时等待\nTERMINATED：终结\n\n状态切换如下图所示：\n\n协程协程    (纤程，用户级线程)，目的是为了追求最大力度的发挥硬件性能和提升软件的速度，协程基本原理是:在某个点挂起当前的任务，并且保存栈信息，去执行另一个任务；等完成或达到某个条件时，再还原原来的栈信息并继续执行(整个过程线程不需要上下文切换)。\n\n Java原生不支持协程，在纯java代码里需要使用协程的话需要引入第三方包,如：quasar\n\n线程池“线程池”，顾名思义就是一个线程缓存，线程是稀缺资源，如果被无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，因此Java中提供线程池对线程进行统一分配、调优和监控\n线程池介绍在web开发中，服务器需要接受并处理请求，所以会为一个请求来分配一个线程来进行处理。如果每次请求都新创建一个线程的话实现起来非常简便，但是存在一个问题：如果并发的请求数量非常多，但每个线程执行的时间很短，这样就会频繁的创建和销毁线程，如此一来会大大降低系统的效率。可能出现服务器在为每个请求创建新线程和销毁线程上花费的时间和消耗的系统资源要比处理实际的用户请求的时间和资源更多。那么有没有一种办法使执行完一个任务，并不被销毁，而是可以继续执行其他的任务呢？这就是线程池的目的了。线程池为线程生命周期的开销和资源不足问题提供了解决方案。通过对多个任务重用线程，线程创建的开销被分摊到了多个任务上。\n什么时候使用线程池？\n\n单个任务处理时间比较短\n需要处理的任务数量很大\n\n线程池优势是什么？\n\n重用存在的线程，减少线程创建，消亡的开销，提高性能\n提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。\n提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。\n\n线程的实现方式Runnable,Thread,Callable\n// 实现Runnable接口的类将被Thread执行，表示一个基本的任务public interface Runnable &#123;    // run方法就是它所有的内容，就是实际执行的任务    public abstract void run();&#125;//Callable同样是任务，与Runnable接口的区别在于它接收泛型，同时它执行任务后带有返回内容public interface Callable&lt;V&gt; &#123;    // 相对于run方法的带有返回值的call方法    V call() throws Exception;&#125;\n\nExecutor框架Executor接口是线程池框架中最基础的部分，定义了一个用于执行Runnable的execute方法。\n\n从图中可以看出Executor下有一个重要子接口ExecutorService，其中定义了线程池的具体行为\n\n**execute(Runnable command)**：履行Ruannable类型的任务\n**submit(task)**：可用来提交Callable或Runnable任务，并返回代表此任务的Future对象\n**shutdown()**：在完成已提交的任务后封闭办事，不再接管新任务,\n**shutdownNow()**：停止所有正在履行的任务并封闭办事。\n**isTerminated()**：测试是否所有任务都履行完毕了。\n**isShutdown()**：测试是否该ExecutorService已被关闭。\n\n线程池重点属性private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int CAPACITY   = (1 &lt;&lt; COUNT_BITS) - 1;\n\n\nctl 是对线程池的运行状态和线程池中有效线程的数量进行控制的一个字段， 它包含两部分的信息: 线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)，这里可以看到，使用了Integer类型来保存，高3位保存runState，低29位保存workerCount。COUNT_BITS 就是29，CAPACITY就是1左移29位减1（29个1），这个常量表示workerCount的上限值，大约是5亿。\n\nctl相关方法private static int runStateOf(int c)     &#123; return c &amp; ~CAPACITY; &#125;private static int workerCountOf(int c)  &#123; return c &amp; CAPACITY; &#125;private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125;\n\n\nrunStateOf：获取运行状态；\nworkerCountOf：获取活动线程数；\nctlOf：获取运行状态和活动线程数的值。\n\n线程池存在5种状态\nRUNNING    = -1 &lt;&lt; COUNT_BITS; //高3位为111SHUTDOWN   =  0 &lt;&lt; COUNT_BITS; //高3位为000STOP       =  1 &lt;&lt; COUNT_BITS; //高3位为001TIDYING    =  2 &lt;&lt; COUNT_BITS; //高3位为010TERMINATED =  3 &lt;&lt; COUNT_BITS; //高3位为011\n\n\nRUNNING状态说明：线程池处在RUNNING状态时，能够接收新任务，以及对已添加的任务进行处理。状态切换：线程池的初始化状态是RUNNING。换句话说，线程池被一旦被创建，就处于RUNNING状态，并且线程池中的任务数为0！\n\nSHUTDOWN状态说明：线程池处在SHUTDOWN状态时，不接收新任务，但能处理已添加的任务。 状态切换：调用线程池的shutdown()接口时，线程池由RUNNING -&gt; SHUTDOWN。\n\nSTOP状态说明：线程池处在STOP状态时，不接收新任务，不处理已添加的任务，并且会中断正在处理的任务。 状态切换：调用线程池的shutdownNow()接口时，线程池由(RUNNING or SHUTDOWN ) -&gt; STOP。\n\nTIDYING状态说明：当所有的任务已终止，ctl记录的”任务数量”为0，线程池会变为TIDYING状态。当线程池变为TIDYING状态时，会执行钩子函数terminated()。terminated()在ThreadPoolExecutor类中是空的，若用户想在线程池变为TIDYING时，进行相应的处理；可以通过重载terminated()函数来实现。状态切换：当线程池在SHUTDOWN状态下，阻塞队列为空并且线程池中执行的任务也为空时，就会由 SHUTDOWN -&gt; TIDYING。 当线程池在STOP状态下，线程池中执行的任务为空时，就会由STOP -&gt; TIDYING。\n\nTERMINATED状态说明：线程池彻底终止，就变成TERMINATED状态。 状态切换：线程池处在TIDYING状态时，执行完terminated()之后，就会由 TIDYING -&gt; TERMINATED。\n\n\n进入TERMINATED的条件如下：\n\n线程池不是RUNNING状态；\n线程池状态不是TIDYING状态或TERMINATED状态；\n如果线程池状态是SHUTDOWN并且workerQueue为空；\nworkerCount为0；\n设置TIDYING状态成功。\n\n线程池的具体实现ThreadPoolExecutor 默认线程池ScheduledThreadPoolExecutor 定时线程池\nThreadPoolExecutor线程池的创建public ThreadPoolExecutor(int corePoolSize,                          int maximumPoolSize,                          long keepAliveTime,                          TimeUnit unit,                          BlockingQueue&lt;Runnable&gt; workQueue,                          ThreadFactory threadFactory,                          RejectedExecutionHandler handler) \n\n任务提交public void execute() //提交任务无返回值public Future&lt;?&gt; submit() //任务执行完成后有返回值\n\n线程池七大参数\ncorePoolSize线程池中的核心线程数，当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于corePoolSize；如果当前线程数为corePoolSize，继续提交的任务被保存到阻塞队列中，等待被执行；如果执行了线程池的prestartAllCoreThreads()方法，线程池会提前创建并启动所有核心线程。\n\nmaximumPoolSize线程池中允许的最大线程数。如果当前阻塞队列满了，且继续提交任务，则创建新的线程执行任务，前提是当前线程数小于maximumPoolSize。\n\nkeepAliveTime线程池维护线程所允许的空闲时间。当线程池中的线程数量大于corePoolSize的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了keepAliveTime。\n\nunitkeepAliveTime的单位\n\nworkQueue用来保存等待被执行的任务的阻塞队列，且任务必须实现Runable接口，在JDK中提供了如下阻塞队列：\n\nArrayBlockingQueue：基于数组结构的有界阻塞队列，按FIFO排序任务\nLinkedBlockingQuene：基于链表结构的阻塞队列，按FIFO排序任务，吞吐量通常要高于ArrayBlockingQuene\nSynchronousQuene：一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQuene\npriorityBlockingQuene：具有优先级的无界阻塞队列\n\n\nthreadFactory它是ThreadFactory类型的变量，用来创建新线程。默认使用Executors.defaultThreadFactory() 来创建线程。使用默认的ThreadFactory来创建线程时，会使新创建的线程具有相同的NORM_PRIORITY优先级并且是非守护线程，同时也设置了线程的名称。\n\nhandler线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务，线程池提供了4种策略：\n\nAbortPolicy：直接抛出异常，默认策略\nCallerRunsPolicy：用调用者所在的线程来执行任务\nDiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务\nDiscardPolicy：直接丢弃任务\n\n上面的4种策略都是ThreadPoolExecutor的内部类。当然也可以根据应用场景实现RejectedExecutionHandler接口，自定义饱和策略，如记录日志或持久化存储不能处理的任务\n\n\n线程池监控public long getTaskCount() //线程池已执行与未执行的任务总数public long getCompletedTaskCount() //已完成的任务数public int getPoolSize() //线程池当前的线程数public int getActiveCount() //线程池中正在执行任务的线程数量\n\n线程池原理\n源码分析execute方法public void execute(Runnable command) &#123;    if (command == null)        throw new NullPointerException();/* * clt记录着runState和workerCount */    int c = ctl.get();/* * workerCountOf方法取出低29位的值，表示当前活动的线程数； * 如果当前活动线程数小于corePoolSize，则新建一个线程放入线程池中； * 并把任务添加到该线程中。 */    if (workerCountOf(c) &lt; corePoolSize) &#123;/* * addWorker中的第二个参数表示限制添加线程的数量是根据corePoolSize来判断还是maximumPoolSize来判断； * 如果为true，根据corePoolSize来判断； * 如果为false，则根据maximumPoolSize来判断 */        if (addWorker(command, true))            return;/* * 如果添加失败，则重新获取ctl值 */        c = ctl.get();    &#125;/* * 如果当前线程池是运行状态并且任务添加到队列成功 */    if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123;// 重新获取ctl值        int recheck = ctl.get(); // 再次判断线程池的运行状态，如果不是运行状态，由于之前已经把command添加到workQueue中了，// 这时需要移除该command// 执行过后通过handler使用拒绝策略对该任务进行处理，整个方法返回        if (! isRunning(recheck) &amp;&amp; remove(command))            reject(command);/* * 获取线程池中的有效线程数，如果数量是0，则执行addWorker方法 * 这里传入的参数表示： * 1. 第一个参数为null，表示在线程池中创建一个线程，但不去启动； * 2. 第二个参数为false，将线程池的有限线程数量的上限设置为maximumPoolSize，添加线程时根据maximumPoolSize来判断； * 如果判断workerCount大于0，则直接返回，在workQueue中新增的command会在将来的某个时刻被执行。 */        else if (workerCountOf(recheck) == 0)            addWorker(null, false);    &#125;/* * 如果执行到这里，有两种情况： * 1. 线程池已经不是RUNNING状态； * 2. 线程池是RUNNING状态，但workerCount &gt;= corePoolSize并且workQueue已满。 * 这时，再次调用addWorker方法，但第二个参数传入为false，将线程池的有限线程数量的上限设置为maximumPoolSize； * 如果失败则拒绝该任务 */    else if (!addWorker(command, false))        reject(command);&#125;\n\n简单来说，在执行execute()方法时如果状态一直是RUNNING时，的执行过程如下：\n\n如果workerCount &lt; corePoolSize，则创建并启动一个线程来执行新提交的任务；\n如果workerCount &gt;= corePoolSize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中；\n如果workerCount &gt;= corePoolSize &amp;&amp; workerCount &lt; maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务；\n如果workerCount &gt;= maximumPoolSize，并且线程池内的阻塞队列已满, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。\n\n这里要注意一下addWorker(null, false);，也就是创建一个线程，但并没有传入任务，因为任务已经被添加到workQueue中了，所以worker在执行的时候，会直接从workQueue中获取任务。所以，在workerCountOf(recheck) == 0时执行addWorker(null, false);也是为了保证线程池在RUNNING状态下必须要有一个线程来执行任务。\nexecute方法执行流程如下：\n\naddWorker方法addWorker方法的主要工作是在线程池中创建一个新的线程并执行，firstTask参数 用于指定新增的线程执行的第一个任务，core参数为true表示在新增线程时会判断当前活动线程数是否少于corePoolSize，false表示新增线程前需要判断当前活动线程数是否少于maximumPoolSize。\nprivate boolean addWorker(Runnable firstTask, boolean core) &#123;    retry:    for (;;) &#123;        int c = ctl.get();    // 获取运行状态        int rs = runStateOf(c);    /*     * 这个if判断     * 如果rs &gt;= SHUTDOWN，则表示此时不再接收新任务；     * 接着判断以下3个条件，只要有1个不满足，则返回false：     * 1. rs == SHUTDOWN，这时表示关闭状态，不再接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务     * 2. firsTask为空     * 3. 阻塞队列不为空     *      * 首先考虑rs == SHUTDOWN的情况     * 这种情况下不会接受新提交的任务，所以在firstTask不为空的时候会返回false；     * 然后，如果firstTask为空，并且workQueue也为空，则返回false，     * 因为队列中已经没有任务了，不需要再添加线程了     */     // Check if queue empty only if necessary.        if (rs &gt;= SHUTDOWN &amp;&amp;                ! (rs == SHUTDOWN &amp;&amp;                        firstTask == null &amp;&amp;                        ! workQueue.isEmpty()))            return false;        for (;;) &#123;            // 获取线程数            int wc = workerCountOf(c);            // 如果wc超过CAPACITY，也就是ctl的低29位的最大值（二进制是29个1），返回false；            // 这里的core是addWorker方法的第二个参数，如果为true表示根据corePoolSize来比较，            // 如果为false则根据maximumPoolSize来比较。            //             if (wc &gt;= CAPACITY ||                    wc &gt;= (core ? corePoolSize : maximumPoolSize))                return false;            // 尝试增加workerCount，如果成功，则跳出第一个for循环            if (compareAndIncrementWorkerCount(c))                break retry;            // 如果增加workerCount失败，则重新获取ctl的值            c = ctl.get();  // Re-read ctl            // 如果当前的运行状态不等于rs，说明状态已被改变，返回第一个for循环继续执行            if (runStateOf(c) != rs)                continue retry;            // else CAS failed due to workerCount change; retry inner loop        &#125;    &#125;    boolean workerStarted = false;    boolean workerAdded = false;    Worker w = null;    try &#123;     // 根据firstTask来创建Worker对象        w = new Worker(firstTask);     // 每一个Worker对象都会创建一个线程        final Thread t = w.thread;        if (t != null) &#123;            final ReentrantLock mainLock = this.mainLock;            mainLock.lock();            try &#123;                int rs = runStateOf(ctl.get());                // rs &lt; SHUTDOWN表示是RUNNING状态；                // 如果rs是RUNNING状态或者rs是SHUTDOWN状态并且firstTask为null，向线程池中添加线程。                // 因为在SHUTDOWN时不会在添加新的任务，但还是会执行workQueue中的任务                if (rs &lt; SHUTDOWN ||                        (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123;                    if (t.isAlive()) // precheck that t is startable                        throw new IllegalThreadStateException();                    // workers是一个HashSet                    workers.add(w);                    int s = workers.size();                    // largestPoolSize记录着线程池中出现过的最大线程数量                    if (s &gt; largestPoolSize)                        largestPoolSize = s;                    workerAdded = true;                &#125;            &#125; finally &#123;                mainLock.unlock();            &#125;            if (workerAdded) &#123;                // 启动线程                t.start();                workerStarted = true;            &#125;        &#125;    &#125; finally &#123;        if (! workerStarted)            addWorkerFailed(w);    &#125;    return workerStarted;&#125;\n\nWorker类线程池中的每一个线程被封装成一个Worker对象，ThreadPool维护的其实就是一组Worker对象，请参见JDK源码。\nWorker类继承了AQS，并实现了Runnable接口，注意其中的firstTask和thread属性：firstTask用它来保存传入的任务；thread是在调用构造方法时通过ThreadFactory来创建的线程，是用来处理任务的线程。\n在调用构造方法时，需要把任务传入，这里通过getThreadFactory().newThread(this);来新建一个线程，newThread方法传入的参数是this，因为Worker本身继承了Runnable接口，也就是一个线程，所以一个Worker对象在启动的时候会调用Worker类中的run方法。\nWorker继承了AQS，使用AQS来实现独占锁的功能。为什么不使用ReentrantLock来实现呢？可以看到tryAcquire方法，它是不允许重入的，而ReentrantLock是允许重入的：\n\nlock方法一旦获取了独占锁，表示当前线程正在执行任务中\n如果正在执行任务，则不应该中断线程\n如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断\n线程池在执行shutdown方法或tryTerminate方法时会调用interruptIdleWorkers方法来中断空闲的线程，interruptIdleWorkers方法会使用tryLock方法来判断线程池中的线程是否是空闲状态\n之所以设置为不可重入，是因为我们不希望任务在调用像setCorePoolSize这样的线程池控制方法时重新获取锁。如果使用ReentrantLock，它是可重入的，这样如果在任务中调用了如setCorePoolSize这类线程池控制的方法，会中断正在运行的线程。\n\n所以，Worker继承自AQS，用于判断线程是否空闲以及是否可以被中断。\n此外，在构造方法中执行了setState(-1);，把state变量设置为-1，为什么这么做呢？是因为AQS中默认的state是0，如果刚创建了一个Worker对象，还没有执行任务时，这时就不应该被中断，看一下tryAquire方法：\nprotected boolean tryAcquire(int unused) &#123;//cas修改state，不可重入    if (compareAndSetState(0, 1)) &#123;         setExclusiveOwnerThread(Thread.currentThread());        return true;    &#125;    return false;&#125;\n\nryAcquire方法是根据state是否是0来判断的，所以，setState(-1);将state设置为-1是为了禁止在执行任务前对线程进行中断。正因为如此，在runWorker方法中会先调用Worker对象的unlock方法将state设置为0。\nrunWorker方法在Worker类中的run方法调用了runWorker方法来执行任务，runWorker方法的代码如下：\nfinal void runWorker(Worker w) &#123;    Thread wt = Thread.currentThread();    // 获取第一个任务    Runnable task = w.firstTask;    w.firstTask = null;    // 允许中断    w.unlock(); // allow interrupts    // 是否因为异常退出循环    boolean completedAbruptly = true;    try &#123;        // 如果task为空，则通过getTask来获取任务        while (task != null || (task = getTask()) != null) &#123;            w.lock();            if ((runStateAtLeast(ctl.get(), STOP) ||                    (Thread.interrupted() &amp;&amp;                            runStateAtLeast(ctl.get(), STOP))) &amp;&amp;                    !wt.isInterrupted())                wt.interrupt();            try &#123;                beforeExecute(wt, task);                Throwable thrown = null;                try &#123;                    task.run();                &#125; catch (RuntimeException x) &#123;                    thrown = x; throw x;                &#125; catch (Error x) &#123;                    thrown = x; throw x;                &#125; catch (Throwable x) &#123;                    thrown = x; throw new Error(x);                &#125; finally &#123;                    afterExecute(task, thrown);                &#125;            &#125; finally &#123;                task = null;                w.completedTasks++;                w.unlock();            &#125;        &#125;        completedAbruptly = false;    &#125; finally &#123;        processWorkerExit(w, completedAbruptly);    &#125;&#125;\n\n这里说明一下第一个if判断，目的是：\n\n如果线程池正在停止，那么要保证当前线程是中断状态；\n如果不是的话，则要保证当前线程不是中断状态；\n\n这里要考虑在执行该if语句期间可能也执行了shutdownNow方法，shutdownNow方法会把状态设置为STOP，回顾一下STOP状态：\n不能接受新任务，也不处理队列中的任务，会中断正在处理任务的线程。在线程池处于 RUNNING 或 SHUTDOWN 状态时，调用 shutdownNow() 方法会使线程池进入到该状态。STOP状态要中断线程池中的所有线程，而这里使用Thread.interrupted()来判断是否中断是为了确保在RUNNING或者SHUTDOWN状态时线程是非中断状态的，因为Thread.interrupted()方法会复位中断的状态。\n总结一下runWorker方法的执行过程：\n\nwhile循环不断地通过getTask()方法获取任务\ngetTask()方法从阻塞队列中取任务\n如果线程池正在停止，那么要保证当前线程是中断状态，否则要保证当前线程不是中断状态\n调用task.run()执行任务\n如果task为null则跳出循环，执行processWorkerExit()方法\nrunWorker方法执行完毕，也代表着Worker中的run方法执行完毕，销毁线程\n\n这里的beforeExecute方法和afterExecute方法在ThreadPoolExecutor类中是空的，留给子类来实现。\ncompletedAbruptly变量来表示在执行任务过程中是否出现了异常，在processWorkerExit方法中会对该变量的值进行判断。\ngetTask方法getTask方法用来从阻塞队列中取任务，代码如下：\nprivate Runnable getTask() &#123;    // timeOut变量的值表示上次从阻塞队列中取任务时是否超时    boolean timedOut = false; // Did the last poll() time out?    for (;;) &#123;        int c = ctl.get();        int rs = runStateOf(c);        // Check if queue empty only if necessary.    /*     * 如果线程池状态rs &gt;= SHUTDOWN，也就是非RUNNING状态，再进行以下判断：     * 1. rs &gt;= STOP，线程池是否正在stop；     * 2. 阻塞队列是否为空。     * 如果以上条件满足，则将workerCount减1并返回null。     * 因为如果当前线程池状态的值是SHUTDOWN或以上时，不允许再向阻塞队列中添加任务。     */        if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123;            decrementWorkerCount();            return null;        &#125;        int wc = workerCountOf(c);        // Are workers subject to culling?        // timed变量用于判断是否需要进行超时控制。        // allowCoreThreadTimeOut默认是false，也就是核心线程不允许进行超时；        // wc &gt; corePoolSize，表示当前线程池中的线程数量大于核心线程数量；        // 对于超过核心线程数量的这些线程，需要进行超时控制        boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize;    /*     * wc &gt; maximumPoolSize的情况是因为可能在此方法执行阶段同时执行了setMaximumPoolSize方法；     * timed &amp;&amp; timedOut 如果为true，表示当前操作需要进行超时控制，并且上次从阻塞队列中获取任务发生了超时     * 接下来判断，如果有效线程数量大于1，或者阻塞队列是空的，那么尝试将workerCount减1；     * 如果减1失败，则返回重试。     * 如果wc == 1时，也就说明当前线程是线程池中唯一的一个线程了。     */        if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut))                &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123;            if (compareAndDecrementWorkerCount(c))                return null;            continue;        &#125;        try &#123;        /*         * 根据timed来判断，如果为true，则通过阻塞队列的poll方法进行超时控制，如果在keepAliveTime时间内没有获取到任务，则返回null；         * 否则通过take方法，如果这时队列为空，则take方法会阻塞直到队列不为空。         *         */            Runnable r = timed ?                    workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :                    workQueue.take();            if (r != null)                return r;            // 如果 r == null，说明已经超时，timedOut设置为true            timedOut = true;        &#125; catch (InterruptedException retry) &#123;            // 如果获取任务时当前线程发生了中断，则设置timedOut为false并返回循环重试            timedOut = false;        &#125;    &#125;&#125;\n\n这里重要的地方是第二个if判断，目的是控制线程池的有效线程数量。由上文中的分析可以知道，在执行execute方法时，如果当前线程池的线程数量超过了corePoolSize且小于maximumPoolSize，并且workQueue已满时，则可以增加工作线程，但这时如果超时没有获取到任务，也就是timedOut为true的情况，说明workQueue已经为空了，也就说明了当前线程池中不需要那么多线程来执行任务了，可以把多于corePoolSize数量的线程销毁掉，保持线程数量在corePoolSize即可。\n什么时候会销毁？当然是runWorker方法执行完之后，也就是Worker中的run方法执行完，由JVM自动回收。\ngetTask方法返回null时，在runWorker方法中会跳出while循环，然后会执行processWorkerExit方法。\nprocessWorkerExit方法private void processWorkerExit(Worker w, boolean completedAbruptly) &#123;    // 如果completedAbruptly值为true，则说明线程执行时出现了异常，需要将workerCount减1；    // 如果线程执行时没有出现异常，说明在getTask()方法中已经已经对workerCount进行了减1操作，这里就不必再减了。      if (completedAbruptly) // If abrupt, then workerCount wasn&#x27;t adjusted        decrementWorkerCount();    final ReentrantLock mainLock = this.mainLock;    mainLock.lock();    try &#123;        //统计完成的任务数        completedTaskCount += w.completedTasks;        // 从workers中移除，也就表示着从线程池中移除了一个工作线程        workers.remove(w);    &#125; finally &#123;        mainLock.unlock();    &#125;    // 根据线程池状态进行判断是否结束线程池    tryTerminate();    int c = ctl.get();/* * 当线程池是RUNNING或SHUTDOWN状态时，如果worker是异常结束，那么会直接addWorker； * 如果allowCoreThreadTimeOut=true，并且等待队列有任务，至少保留一个worker； * 如果allowCoreThreadTimeOut=false，workerCount不少于corePoolSize。 */    if (runStateLessThan(c, STOP)) &#123;        if (!completedAbruptly) &#123;            int min = allowCoreThreadTimeOut ? 0 : corePoolSize;            if (min == 0 &amp;&amp; ! workQueue.isEmpty())                min = 1;            if (workerCountOf(c) &gt;= min)                return; // replacement not needed        &#125;        addWorker(null, false);    &#125;&#125;\n\n至此，processWorkerExit执行完之后，工作线程被销毁，以上就是整个工作线程的生命周期，从execute方法开始，Worker使用ThreadFactory创建新的工作线程，runWorker通过getTask获取任务，然后执行任务，如果getTask返回null，进入processWorkerExit方法，整个线程结束，如图所示：\n\n","categories":["Java"],"tags":["并发"]},{"title":"阻塞队列BlockingQueue","url":"/2020/10/06/Java/%E5%B9%B6%E5%8F%91/%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97BlockingQueue/","content":"BlockingQueue，是java.util.concurrent 包提供的用于解决并发生产者 - 消费者问题的最有用的类，它的特性是在任意时刻只有一个线程可以进行take或者put操作，并且BlockingQueue提供了超时return null的机制，在许多生产场景里都可以看到这个工具的身影。\n阻塞队列(BlockingQueue)是一个支持两个附加操作的队列。这两个附加的操作支持阻塞的插入和移除操作。\n\n支持阻塞的插入方法：意思是当队列满时，队列 会阻塞插入 元素的线程，直到队列不满。\n支持阻塞 的移除方法：意思是在队列为空时，获取元素的线程会等待队列变为非空。\n\n队列类型\n无限队列 （unbounded queue ） - 几乎可以无限增长\n有限队列 （ bounded queue ） - 定义了最大容量\n\n队列数据结构队列实质就是一种存储数据的结构\n\n通常用链表或者数组实现\n一般而言队列具备FIFO先进先出的特性，当然也有双端队列（Deque）优先级队列\n主要操作：入队（EnQueue）与出队（Dequeue）\n\n \n常见的4种阻塞队列\n\nArrayBlockingQueue 由数组支持的有界队列\nLinkedBlockingQueue 由链接节点支持的可选有界队列\nPriorityBlockingQueue 由优先级堆支持的无界优先级队列\nDelayQueue 由优先级堆支持的、基于时间的调度队列\n\nArrayBlockingQueue队列基于数组实现,容量大小在创建ArrayBlockingQueue对象时已定义好\n数据结构如图\n队列创建BlockingQueue&lt;String&gt; blockingQueue = new ArrayBlockingQueue&lt;&gt;();\n\n应用场景在线程池中有比较多的应用，生产者消费者场景\n工作原理基于ReentrantLock保证线程安全，根据Condition实现队列满时的阻塞\nLinkedBlockingQueue是一个基于链表的无界队列(理论上有界)\nBlockingQueue&lt;String&gt; blockingQueue = new LinkedBlockingQueue&lt;&gt;();\n\n上面这段代码中，blockingQueue 的容量将设置为Integer.MAX_VALUE。向无限队列添加元素的所有操作都将永远不会阻塞，[注意这里不是说不会加锁保证线程安全]，因此它可以增长到非常大的容量。使用无限 BlockingQueue 设计生产者 - 消费者模型时最重要的是 消费者应该能够像生产者向队列添加消息一样快地消费消息 。否则，内存可能会填满，然后就会得到一个 OutOfMemory 异常。\nPriorityBlockingQueuePriorityBlockingQueue是一个支持优先级的无界阻塞队列。默认情况下元素采取自然顺序升序排列。也可以自定义类实现compareTo()方法来指定元素排序规则，或者初始化PriorityBlockingQueue时，指定构造参数Comparator来对元素进行排序。需要注意的是不能保证同优先级元素的顺序。\nDelayQueue由优先级堆支持的(最小堆/最大堆)、基于时间的调度队列，内部基于无界队列PriorityQueue实现，而无界队列基于数组的扩容实现，在扩容时，如果容量小于64，那么就扩大两个，如果大于等于64，那么就会扩容百分之50。\n要求入队的对象必须要实现Delayed接口,而Delayed集成自Comparable接口\n应用场景接口失败延迟重试\nTimerQueue\nBlockingQueue APIBlockingQueue 接口的所有方法可以分为两大类：负责向队列添加元素的方法和检索这些元素的方法。在队列满/空的情况下，来自这两个组的每个方法的行为都不同。\n添加元素\n\n\n方法\n说明\n\n\n\nadd()\n如果插入成功则返回 true，否则抛出 IllegalStateException 异常\n\n\nput()\n将指定的元素插入队列，如果队列满了，那么会阻塞直到有空间插入\n\n\noffer()\n如果插入成功则返回 true，否则返回 false\n\n\noffer(E e, long timeout, TimeUnit unit)\n尝试将元素插入队列，如果队列已满，那么会阻塞直到有空间插入\n\n\n检索元素\n\n\n方法\n说明\n\n\n\ntake()\n获取队列的头部元素并将其删除，如果队列为空，则阻塞并等待元素变为可用\n\n\npoll(long timeout, TimeUnit unit)\n检索并删除队列的头部，如有必要，等待指定的等待时间以使元素可用，如果超时，则返回 null\n\n\n\n抛出异常： 当队列满时 ，如果再往队列 里插入元素，会抛出IllegalStateException(“Queue full”)。当队列空时，从队列里获取元素会抛出throw new NoSuchElementException();\n返回特殊值：当往队列插入元素时，会返回元素是否插入成功，成功返回true。如果是移除方法，则是从队列里取出一个元素，如果没有则返回null。\n一直阻塞：当阻塞队列满时，如果生产者线程往队列里put元素，队列会一直阻塞生产者线程，直到队列可用或者响应中断退出。当队列空时，如果消费者线程从队列里take元素，队列会阻塞住消费者线程，直到队列不为空。\n超时退出：当阻塞队列满时，如果生产者线程往队列里插入元素，队列会阻塞生产者线程一段时间，如果超过了指定的时间，生产者线程就会退出。\n\n","categories":["Java"],"tags":["并发"]},{"title":"Kafka快速实战与基本原理详解","url":"/2021/11/29/%E4%B8%AD%E9%97%B4%E4%BB%B6/Kafka/Kafka%E5%BF%AB%E9%80%9F%E5%AE%9E%E6%88%98%E4%B8%8E%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/","content":"\nKafka是最初由Linkedin公司开发，是一个分布式、支持分区的（partition）、多副本的（replica），基于zookeeper协调的分布式消息系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于hadoop的批处理系统、低延迟的实时系统、Storm/Spark流式处理引擎，web/nginx日志、访问日志，消息服务等等，用scala语言编写，Linkedin于2010年贡献给了Apache基金会并成为顶级开源 项目\nKafka的使用场景\n日志收集：一个公司可以用Kafka收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、Hbase、Solr等\n消息系统：解耦和生产者和消费者、缓存消息等\n用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘\n运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告\n\n\nKafka基本概念kafka是一个分布式的，分区的消息(官方称之为commit log)服务。它提供一个消息系统应该具备的功能，但是确有着独特的设计。可以这样来说，Kafka借鉴了JMS规范的思想，但是确并没有完全遵循JMS规范。\n首先，让我们来看一下基础的消息(Message)相关术语：\n\n\n\n名称\n解释\n\n\n\nBroker\n消息中间件处理节点，一个Kafka节点就是一个broker，一个或者多个Broker可以组成一个Kafka集群\n\n\nTopic\nKafka根据topic对消息进行归类，发布到Kafka集群的每条消息都需要指定一个topic\n\n\nProducer\n消息生产者，向Broker发送消息的客户端\n\n\nConsumer\n消息消费者，从Broker读取消息的客户端\n\n\nConsumerGroup\n每个Consumer属于一个特定的Consumer Group，一条消息可以被多个不同的Consumer Group消费，但是一个Consumer Group中只能有一个Consumer能够消费该消息\n\n\nPartition\n物理上的概念，一个topic可以分为多个partition，每个partition内部消息是有序的\n\n\n因此，从一个较高的层面上来看，producer通过网络发送消息到Kafka集群，然后consumer来进行消费，如下图：\n\n服务端(brokers)和客户端(producer、consumer)之间通信通过TCP协议来完成\nkafka基本使用安装前的环境准备由于Kafka是用Scala语言开发的，运行在JVM上，因此在安装Kafka之前需要先安装JDK\nyum install java-1.8.0-openjdk* -y\n\nkafka依赖zookeeper，所以需要先安装zookeeper\nwget https://archive.apache.org/dist/zookeeper/zookeeper-3.5.8/apache-zookeeper-3.5.8-bin.tar.gztar -zxvf apache-zookeeper-3.5.8-bin.tar.gzcd  apache-zookeeper-3.5.8-bincp conf/zoo_sample.cfg conf/zoo.cfg# 启动zookeeperbin/zkServer.sh startbin/zkCli.sh ls /\t\t\t#查看zk的根目录相关节点\n\n下载安装包下载2.4.1 release版本，并解压：\nwget https://archive.apache.org/dist/kafka/2.4.1/kafka_2.11-2.4.1.tgz  # 2.11是scala的版本，2.4.1是kafka的版本tar -xzf kafka_2.11-2.4.1.tgzcd kafka_2.11-2.4.1\n\n修改配置修改配置文件config/server.properties\n#broker.id属性在kafka集群中必须要是唯一broker.id=0#kafka部署的机器ip和提供服务的端口号listeners=PLAINTEXT://192.168.65.60:9092   #kafka的消息存储文件log.dir=/usr/local/data/kafka-logs#kafka连接zookeeper的地址zookeeper.connect=192.168.65.60:2181\n\n启动服务现在来启动kafka服务\n启动脚本语法：kafka-server-start.sh [-daemon] server.properties\n可以看到，server.properties的配置路径是一个强制的参数，-daemon表示以后台进程运行，否则ssh客户端退出后，就会停止服务。(注意，在启动kafka时会使用linux主机名关联的ip地址，所以需要把主机名和linux的ip映射配置到本地host里，用vim /etc/hosts)\n# 启动kafka，运行日志在logs目录的server.log文件里bin/kafka-server-start.sh -daemon config/server.properties   #后台启动，不会打印日志到控制台或者用bin/kafka-server-start.sh config/server.properties &amp;# 我们进入zookeeper目录通过zookeeper客户端查看下zookeeper的目录树bin/zkCli.sh ls /\t\t#查看zk的根目录kafka相关节点ls /brokers/ids\t#查看kafka节点# 停止kafkabin/kafka-server-stop.sh\n\n创建主题现在我们来创建一个名字为“test”的Topic，这个topic只有一个partition，并且备份因子也设置为1：\nbin/kafka-topics.sh --create --zookeeper 192.168.65.60:2181 --replication-factor 1 --partitions 1 --topic test\n\n现在我们可以通过以下命令来查看kafka中目前存在的topic\nbin/kafka-topics.sh --list --zookeeper 192.168.65.60:2181\n\n除了我们通过手工的方式创建Topic，当producer发布一个消息到某个指定的Topic，这个Topic如果不存在，就自动创建\n删除主题\nbin/kafka-topics.sh --delete --topic test --zookeeper 192.168.65.60:2181\n\n发送消息kafka自带了一个producer命令客户端，可以从本地文件中读取内容，或者我们也可以以命令行中直接输入内容，并将这些内容以消息的形式发送到kafka集群中。在默认情况下，每一个行会被当做成一个独立的消息\n首先我们要运行发布消息的脚本，然后在命令中输入要发送的消息的内容：\nbin/kafka-console-producer.sh --broker-list 192.168.65.60:9092 --topic test &gt;this is a msg&gt;this is a another msg \n\n消费消息对于consumer，kafka同样也携带了一个命令行客户端，会将获取到内容在命令中进行输出，默认是消费最新的消息：\nbin/kafka-console-consumer.sh --bootstrap-server 192.168.65.60:9092 --topic test\n\n如果想要消费之前的消息可以通过–from-beginning参数指定，如下命令：\nbin/kafka-console-consumer.sh --bootstrap-server 192.168.65.60:9092 --from-beginning --topic test\n\n如果你是通过不同的终端窗口来运行以上的命令，你将会看到在producer终端输入的内容，很快就会在consumer的终端窗口上显示出来。\n以上所有的命令都有一些附加的选项；当我们不携带任何参数运行命令的时候，将会显示出这个命令的详细用法。\n消费多主题\nbin/kafka-console-consumer.sh --bootstrap-server 192.168.65.60:9092 --whitelist &quot;test|test-2&quot;\n\n单播消费一条消息只能被某一个消费者消费的模式，类似queue模式，只需让所有消费者在同一个消费组里即可\n分别在两个客户端执行如下消费命令，然后往主题里发送消息，结果只有一个客户端能收到消息\nbin/kafka-console-consumer.sh --bootstrap-server 192.168.65.60:9092  --consumer-property group.id=testGroup --topic test\n\n多播消费一条消息能被多个消费者消费的模式，类似publish-subscribe模式费，针对Kafka同一条消息只能被同一个消费组下的某一个消费者消费的特性，要实现多播只要保证这些消费者属于不同的消费组即可。我们再增加一个消费者，该消费者属于testGroup-2消费组，结果两个客户端都能收到消息\nbin/kafka-console-consumer.sh --bootstrap-server 192.168.65.60:9092 --consumer-property group.id=testGroup-2 --topic test\n\n查看消费组名bin/kafka-consumer-groups.sh --bootstrap-server 192.168.65.60:9092 --list\n\n查看消费组的消费偏移量bin/kafka-consumer-groups.sh --bootstrap-server 192.168.65.60:9092 --describe --group testGroup\n\n\n\ncurrent-offset：当前消费组的已消费偏移量\nlog-end-offset：主题对应分区消息的结束偏移量(HW)\nlag：当前消费组未消费的消息数\n\n主题Topic和消息日志Log可以理解Topic是一个类别的名称，同类消息发送到同一个Topic下面。对于每一个Topic，下面可以有多个分区(Partition)日志文件:\n\nPartition是一个有序的message序列，这些message按顺序添加到一个叫做commit log的文件中。每个partition中的消息都有一个唯一的编号，称之为offset，用来唯一标示某个分区中的message。 \n每个partition，都对应一个commit log文件。一个partition中的message的offset都是唯一的，但是不同的partition中的message的offset可能是相同的。\nkafka一般不会删除消息，不管这些消息有没有被消费。只会根据配置的日志保留时间(log.retention.hours)确认消息多久被删除，默认保留最近一周的日志消息。kafka的性能与保留的消息数据量大小没有关系，因此保存大量的数据消息日志信息不会有什么影响。\n每个consumer是基于自己在commit log中的消费进度(offset)来进行工作的。在kafka中，消费offset由consumer自己来维护；一般情况下我们按照顺序逐条消费commit log中的消息，当然我可以通过指定offset来重复消费某些消息，或者跳过某些消息。\n这意味kafka中的consumer对集群的影响是非常小的，添加一个或者减少一个consumer，对于集群或者其他consumer来说，都是没有影响的，因为每个consumer维护各自的消费offset。\n创建多个分区的主题bin/kafka-topics.sh --create --zookeeper 192.168.65.60:2181 --replication-factor 1 --partitions 2 --topic test1\n\n查看下topic的情况\nbin/kafka-topics.sh --describe --zookeeper 192.168.65.60:2181 --topic test1\n\n\n以下是输出内容的解释，第一行是所有分区的概要信息，之后的每一行表示每一个partition的信息\n\nleader节点负责给定partition的所有读写请求\nreplicas 表示某个partition在哪几个broker上存在备份。不管这个几点是不是”leader“，甚至这个节点挂了，也会列出\nisr 是replicas的一个子集，它只列出当前还存活着的，并且已同步备份了该partition的节点\n\n我们可以运行相同的命令查看之前创建的名称为”test“的topic\nbin/kafka-topics.sh --describe --zookeeper 192.168.65.60:2181 --topic test\n\n\n之前设置了topic的partition数量为1，备份因子为1，因此显示就如上所示了\n可以进入kafka的数据文件存储目录查看test和test1主题的消息日志文件：\n\n消息日志文件主要存放在分区文件夹里的以log结尾的日志文件里，如下是test1主题对应的分区0的消息日志：\n\n当然我们也可以通过如下命令**增加topic的分区数量(目前kafka不支持减少分区)**：\nbin/kafka-topics.sh -alter --partitions 3 --zookeeper 192.168.65.60:2181 --topic test\n\n怎么理解Topic，Partition和Broker一个topic，代表逻辑上的一个业务数据集，比如按数据库里不同表的数据操作消息区分放入不同topic，订单相关操作消息放入订单topic，用户相关操作消息放入用户topic，对于大型网站来说，后端数据都是海量的，订单消息很可能是非常巨量的，比如有几百个G甚至达到TB级别，如果把这么多数据都放在一台机器上可定会有容量限制问题，那么就可以在topic内部划分多个partition来分片存储数据，不同的partition可以位于不同的机器上，每台机器上都运行一个Kafka的进程Broker。\n为什么要对Topic下数据进行分区存储\ncommit log文件会受到所在机器的文件系统大小的限制，分区之后可以将不同的分区放在不同的机器上，相当于对数据做了分布式存储，理论上一个topic可以处理任意数量的数据\n为了提高并行度\n\nkafka集群对于kafka来说，一个单独的broker意味着kafka集群中只有一个节点。要想增加kafka集群中的节点数量，只需要多启动几个broker实例即可。为了有更好的理解，现在我们在一台机器上同时启动三个broker实例。\n首先，我们需要建立好其他2个broker的配置文件\ncp config/server.properties config/server-1.propertiescp config/server.properties config/server-2.properties\n\n配置文件的需要修改的内容分别如下\nconfig/server-1.properties:\n#broker.id属性在kafka集群中必须要是唯一broker.id=1#kafka部署的机器ip和提供服务的端口号listeners=PLAINTEXT://192.168.65.60:9093   log.dir=/usr/local/data/kafka-logs-1#kafka连接zookeeper的地址，要把多个kafka实例组成集群，对应连接的zookeeper必须相同zookeeper.connect=192.168.65.60:2181\n\nconfig/server-2.properties:\nbroker.id=2listeners=PLAINTEXT://192.168.65.60:9094log.dir=/usr/local/data/kafka-logs-2zookeeper.connect=192.168.65.60:2181\n\n目前我们已经有一个zookeeper实例和一个broker实例在运行了，现在我们只需要在启动2个broker实例即可：\nbin/kafka-server-start.sh -daemon config/server-1.propertiesbin/kafka-server-start.sh -daemon config/server-2.properties\n\n查看zookeeper确认集群节点是否都注册成功：\n\n现在我们创建一个新的topic，副本数设置为3，分区数设置为2：\nbin/kafka-topics.sh --create --zookeeper 192.168.65.60:2181 --replication-factor 3 --partitions 2 --topic my-replicated-topic\n\n查看下topic的情况\nbin/kafka-topics.sh --describe --zookeeper 192.168.65.60:2181 --topic my-replicated-topic\n\n\n以下是输出内容的解释，第一行是所有分区的概要信息，之后的每一行表示每一个partition的信息:\n\nleader节点负责给定partition的所有读写请求，同一个主题不同分区leader副本一般不一样(为了容灾)\nreplicas 表示某个partition在哪几个broker上存在备份。不管这个几点是不是”leader“，甚至这个节点挂了，也会列出。\nisr 是replicas的一个子集，它只列出当前还存活着的，并且已同步备份了该partition的节点\n\n现在我们向新建的 my-replicated-topic 中发送一些message，kafka集群可以加上所有kafka节点：\nbin/kafka-console-producer.sh --broker-list 192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094 --topic my-replicated-topic&gt;my test msg 1&gt;my test msg 2\n\n现在开始消费：\nbin/kafka-console-consumer.sh --bootstrap-server 192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094 --from-beginning --topic my-replicated-topicmy test msg 1my test msg 2\n\n查看主题分区对应的leader信息：\n\nkafka将很多集群关键信息记录在zookeeper里，保证自己的无状态，从而在水平扩容时非常方便\n集群消费log的partitions分布在kafka集群中不同的broker上，每个broker可以请求备份其他broker上partition上的数据。kafka集群支持配置一个partition备份的数量。\n针对每个partition，都有一个broker起到“leader”的作用，0个或多个其他的broker作为“follwers”的作用。**leader处理所有的针对这个partition的读写请求，而followers被动复制leader的结果，不提供读写(主要是为了保证多副本数据与消费的一致性)**。如果这个leader失效了，其中的一个follower将会自动的变成新的leader。\nProducers生产者将消息发送到topic中去，同时负责选择将message发送到topic的哪一个partition中。通过round-robin做简单的负载均衡。也可以根据消息中的某一个关键字来进行区分。通常第二种方式使用的更多。\nConsumers传统的消息传递模式有2种：队列( queue) 和发布订阅（publish-subscribe）\n\nqueue模式：多个consumer从服务器中读取数据，消息只会到达一个consumer。\npublish-subscribe模式：消息会被广播给所有的consumer\n\nKafka基于这2种模式提供了一种consumer的抽象概念：consumer group\n\nqueue模式：所有的consumer都位于同一个consumer group 下\npublish-subscribe模式：所有的consumer都有着自己唯一的consumer group\n\n\n由2个broker组成的kafka集群，某个主题总共有4个partition(P0-P3)，分别位于不同的broker上。这个集群由2个Consumer Group消费， A有2个consumer instances ，B有4个。\n通常一个topic会有几个consumer group，每个consumer group都是一个逻辑上的订阅者（ logical subscriber ）。每个consumer group由多个consumer instance组成，从而达到可扩展和容灾的功能。\n消费顺序一个partition同一个时刻在一个consumer group中只能有一个consumer instance在消费，从而保证消费顺序。\nconsumer group中的consumer instance的数量不能比一个Topic中的partition的数量多，否则，多出来的consumer消费不到消息。\nKafka只在partition的范围内保证消息消费的局部顺序性，不能在同一个topic中的多个partition中保证总的消费顺序性。\n如果有在总体上保证消费顺序的需求，那么我们可以通过将topic的partition数量设置为1，将consumer group中的consumer instance数量也设置为1，但是这样会影响性能，所以kafka的顺序消费很少用。\n相关参数配置Broker Configs\n\n\nProperty\nDefault\nDescription\n\n\n\nbroker.id\n-1\n每个broker都可以用一个唯一的非负整数id进行标识；这个id可以作为broker的“名字”，你可以选择任意你喜欢的数字作为id，只要id是唯一的即可。\n\n\nlog.dirs\n/tmp/kafka-logs\nkafka存放数据的路径。这个路径并不是唯一的，可以是多个，路径之间只需要使用逗号分隔即可；每当创建新partition时，都会选择在包含最少partitions的路径下进行。\n\n\nlisteners\nPLAINTEXT://192.168.65.60:9092\nserver接受客户端连接的端口，ip配置kafka本机ip即可\n\n\nzookeeper.connect\nlocalhost:2181\nzooKeeper连接字符串的格式为：hostname:port，此处hostname和port分别是ZooKeeper集群中某个节点的host和port；zookeeper如果是集群，连接方式为 hostname1:port1, hostname2:port2, hostname3:port3\n\n\nlog.retention.hours\n168\n每个日志文件删除之前保存的时间。默认数据保存时间对所有topic都一样。\n\n\nnum.partitions\n1\n创建topic的默认分区数\n\n\ndefault.replication.factor\n1\n自动创建topic的默认副本数量，建议设置为大于等于2\n\n\nmin.insync.replicas\n1\n当producer设置acks为-1时，min.insync.replicas指定replicas的最小数目（必须确认每一个repica的写数据都是成功的），如果这个数目没有达到，producer发送消息会产生异常\n\n\ndelete.topic.enable\ntrue\n是否允许删除主题\n\n\nProducer Configs\n\n\nProperties\nDefault\nDescription\n\n\n\nbootstrap.servers\n“”\n连接kafka集群的地址与端口号，可以把集群所有的broker地址写上。格式：host1:port1,host2:port2,…\n\n\nacks\nall\nacks=0： 表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息。性能最高，但是最容易丢消息acks=1： 至少要等待leader已经成功将数据写入本地log，但是不需要等待所有follower是否成功写入。就可以继续发送下一条消息。这种情况下，如果follower没有成功备份数据，而此时leader又挂掉，则消息会丢失acks=-1或all： 需要等待 min.insync.replicas(默认为1，推荐配置大于等于2) 这个参数配置的副本个数都成功写入日志，这种策略会保证只要有一个备份存活就不会丢失数据。这是最强的数据保证。一般除非是金融级别，或跟钱打交道的场景才会使用这种配置\n\n\nretries\n2147483647\n发送失败会重试，默认重试间隔100ms，重试能保证消息发送的可靠性，但是也可能造成消息重复发送，比如网络抖动，所以需要在接收者那边做好消息接收的幂等性处理\n\n\nretry.backoff.ms\n100\n重试间隔\n\n\nbuffer.memory\n33554432\n设置发送消息的本地缓冲区，如果设置了该缓冲区，消息会先发送到本地缓冲区，可以提高消息发送性能，默认值是33554432，即32MB\n\n\nbatch.size\n16384\nkafka本地线程会从缓冲区取数据，批量发送到broker，设置批量发送消息的大小，默认值是16384，即16kb，就是说一个batch满了16kb就发送出去\n\n\nlinger.ms\n0\n默认值是0，意思就是消息必须立即被发送，但这样会影响性能。一般设置10毫秒左右，就是说这个消息发送完后会进入本地的一个batch，如果10毫秒内，这个batch满了16kb就会随batch一起被发送出去。如果10毫秒内，batch没满，那么也必须把消息发送出去，不能让消息的发送延迟时间太长\n\n\nenable.idempotence\ntrue\n如果retries设置大于0，并且acks设置为all,则会开启kafka生产者的幂等性\n\n\nConsumer Configs\n\n\nProperties\nDefault\nDescription\n\n\n\nbootstrap.servers\n“”\n连接kafka集群的地址与端口号，可以把集群所有的broker地址写上。格式：host1:port1,host2:port2,…\n\n\ngroup.id\nnull\n一个唯一的字符串，用于识别本消费者所属的消费者组。如果消费者使用订阅（主题）或基于Kafka的偏移管理策略，则需要此属性\n\n\nenable.auto.commit\ntrue\n是否自动提交offset，默认就是true\n\n\nauto.commit.interval.ms\n5000 (5 seconds)\n自动提交offset的间隔时间\n\n\nauto.offset.reset\nlatest\n当消费者消费一个新的主题，应如何消费：latest(默认) ：只消费自己启动之后发送到主题的消息earliest：第一次从头开始消费，以后按照消费offset记录继续消费\n\n\nheartbeat.interval.ms\n3000 (3 seconds)\nconsumer给broker发送心跳的间隔时间，broker接收到心跳如果此时有rebalance发生会通过心跳响应将      rebalance方案下发给consumer，这个时间可以稍微短一点\n\n\nsession.timeout.ms\n45000 (45 seconds)\n服务端broker多久感知不到一个consumer心跳就认为他故障了，会将其踢出消费组，对应的Partition也会被重新分配给其他consumer\n\n\nmax.poll.records\n500\n一次poll最大拉取消息的条数，如果消费者处理速度很快，可以设置大点，如果处理速度一般，可以设置小点\n\n\nmax.poll.interval.ms\n300000 (5 minutes)\n如果两次poll操作间隔超过了这个时间，broker就会认为这个consumer处理能力太弱，        会将其踢出消费组，将分区分配给别的consumer消费\n\n\n","categories":["中间件"],"tags":["Kafka"]},{"title":"Kafka生产问题总结及性能优化实践","url":"/2021/11/30/%E4%B8%AD%E9%97%B4%E4%BB%B6/Kafka/Kafka%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%E5%8F%8A%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/","content":"线上环境规划\nJVM参数设置kafka是scala语言开发，运行在JVM上，需要对JVM参数合理设置，参看JVM调优专题\n修改bin/kafka-start-server.sh中的jvm设置，假设机器是32G内存，可以如下设置：\nexport KAFKA_HEAP_OPTS=&quot;-Xmx16G -Xms16G -Xmn10G -XX:MetaspaceSize=256M -XX:+UseG1GC -XX:MaxGCPauseMillis=50 -XX:G1HeapRegionSize=16M&quot;\n\n这种大内存的情况一般都要用G1垃圾收集器，因为年轻代内存比较大，用G1可以设置GC最大停顿时间，不至于一次minor gc就花费太长时间，当然，因为像kafka，rocketmq，es这些中间件，写数据到磁盘会用到操作系统的page cache，所以JVM内存不宜分配过大，需要给操作系统的缓存留出几个G。\n线上问题及优化消息丢失消息发送端：\n\nacks=0： 表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息。性能最高，但是最容易丢消息。大数据统计报表场景，对性能要求很高，对数据丢失不敏感的情况可以用这种。\n\nacks=1： 至少要等待leader已经成功将数据写入本地log，但是不需要等待所有follower是否成功写入。就可以继续发送下一条消息。这种情况下，如果follower没有成功备份数据，而此时leader又挂掉，则消息会丢失。\n\nacks=-1或all： 这意味着leader需要等待所有备份(min.insync.replicas配置的备份个数)都成功写入日志，这种策略会保证只要有一个备份存活就不会丢失数据。这是最强的数据保证。一般除非是金融级别，或跟钱打交道的场景才会使用这种配置。当然如果min.insync.replicas配置的是1则也可能丢消息，跟acks=1情况类似。\n\n\n消息消费端：\n如果消费这边配置的是自动提交，万一消费到数据还没处理完，就自动提交offset了，但是此时你consumer直接宕机了，未处理完的数据丢失了，下次也消费不到了。\n消息重复消费消息发送端：\n发送消息如果配置了重试机制，比如网络抖动时间过长导致发送端发送超时，实际broker可能已经接收到消息，但发送方会重新发送消息\n消息消费端：\n如果消费这边配置的是自动提交，刚拉取了一批数据处理了一部分，但还没来得及提交，服务挂了，下次重启又会拉取相同的一批数据重复处理\n一般消费端都是要做消费幂等处理的。\n以数据库类应用为例，常用做法是：\n\n发送消息时，传入key作为唯一流水号ID。\n消费消息时，判断key是否已经消费过，如果已经被消费，则忽略，如果没消费过，则消费一次。\n\n消息乱序如果发送端配置了重试机制，kafka不会等之前那条消息完全发送成功才去发送下一条消息，这样可能会出现，发送了1，2，3条消息，第一条超时了，后面两条发送成功，再重试发送第1条消息，这时消息在broker端的顺序就是2，3，1了。\n所以，是否一定要配置重试要根据业务情况而定。也可以用同步发送的模式去发消息，当然acks不能设置为0，这样也能保证消息发送的有序。\nkafka保证全链路消息顺序消费，需要从发送端开始，将所有有序消息发送到同一个分区，然后用一个消费者去消费，但是这种性能比较低，可以在消费者端接收到消息后将需要保证顺序消费的几条消费发到内存队列(可以搞多个)，一个内存队列开启一个线程顺序处理消息。\n消息积压\n线上有时因为发送方发送消息速度过快，或者消费方处理消息过慢，可能会导致broker积压大量未消费消息。\n消费速度跟不上生产速度，此时应该提高消费速度，提高消费速度有以下两个办法：\n\n增加Consumer实例个数可以在进程内直接增加（需要保证每个实例对应一个线程，否则没有太大意义），也可以部署多个消费实例进程；需要注意的是，实例个数超过分区数量后就不再能提高速度，将会有消费实例不工作。\n增加消费线程\n增加Consumer实例本质上也是增加线程的方式来提升速度，因此更加重要的性能提升方式是增加消费线程，最基本的步骤如下：\n定义一个线程池。\nPoll数据。\n把数据提交到线程池进行并发处理。\n等并发结果返回成功后，再次poll数据执行。\n\n\n\n\n由于消息数据格式变动或消费者程序有bug，导致消费者一直消费不成功，也可能导致broker积压大量未消费消息。\n此种情况可以将这些消费不成功的消息转发到其它队列里去(类似死信队列)，后面再慢慢分析死信队列里的消息处理问题。\n\n\n延时队列延时队列存储的对象是延时消息。所谓的“延时消息”是指消息被发送以后，并不想让消费者立刻获取，而是等待特定的时间后，消费者才能获取这个消息进行消费，延时队列的使用场景有很多， 比如 ：\n1）在订单系统中， 一个用户下单之后通常有 30 分钟的时间进行支付，如果 30 分钟之内没有支付成功，那么这个订单将进行异常处理，这时就可以使用延时队列来处理这些订单了。\n2）订单完成1小时后通知用户进行评价。\n实现思路：发送延时消息时先把消息按照不同的延迟时间段发送到指定的队列中（topic_1s，topic_5s，topic_10s，…topic_2h，这个一般不能支持任意时间段的延时），然后通过定时器（hash时间轮）进行轮训消费这些topic，查看消息是否到期，如果到期就把这个消息发送到具体业务处理的topic中，队列中消息越靠前的到期时间越早，具体来说就是定时器在一次消费过程中，对消息的发送时间做判断，看下是否延迟到对应时间了，如果到了就转发，如果还没到这一次定时任务就可以提前结束了。\n消息回溯如果某段时间对已消费消息计算的结果觉得有问题，可能是由于程序bug导致的计算错误，当程序bug修复后，这时可能需要对之前已消费的消息重新消费，可以指定从多久之前的消息回溯消费，这种可以用consumer的offsetsForTimes、seek等方法指定从某个offset偏移的消息开始消费。\n分区数越多吞吐量越高吗可以用kafka压测工具自己测试分区数不同，各种情况下的吞吐量\n# 往test里发送一百万消息，每条设置1KB# throughput 用来进行限流控制，当设定的值小于 0 时不限流，当设定的值大于 0 时，当发送的吞吐量大于该值时就会被阻塞一段时间bin/kafka-producer-perf-test.sh --topic test --num-records 1000000 --record-size 1024 --throughput -1 --producer-props bootstrap.servers=192.168.65.60:9092 acks=1\n\n\n网络上很多资料都说分区数越多吞吐量越高 ， 但从压测结果来看，分区数到达某个值吞吐量反而开始下降，实际上很多事情都会有一个临界值，当超过这个临界值之后，很多原本符合既定逻辑的走向又会变得不同。一般情况分区数跟集群机器数量相当就差不多了。\n当然吞吐量的数值和走势还会和磁盘、文件系统、 I/O调度策略等因素相关。\n注意：如果分区数设置过大，比如设置10000，可能会设置不成功，后台会报错”java.io.IOException : Too many open files”。\n异常中最关键的信息是“ Too many open flies”，这是一种常见的 Linux 系统错误，通常意味着文件描述符不足，它一般发生在创建线程、创建 Socket、打开文件这些场景下 。 在 Linux系统的默认设置下，这个文件描述符的个数不是很多 ，通过 ulimit -n 命令可以查看：一般默认是1024，可以将该值增大，比如：ulimit -n 65535\n消息传递保障\nat most once(消费者最多收到一次消息，0–1次)：acks = 0 可以实现。\nat least once(消费者至少收到一次消息，1–多次)：ack = all 可以实现。\nexactly once(消费者刚好收到一次消息)：at least once 加上消费者幂等性可以实现，还可以用kafka生产者的幂等性来实现。\n\nkafka生产者的幂等性：因为发送端重试导致的消息重复发送问题，kafka的幂等性可以保证重复发送的消息只接收一次，只需在生产者加上参数 props.put(“enable.idempotence”, true) 即可，默认是false不开启。    \n具体实现原理是，kafka每次发送消息会生成PID和Sequence Number，并将这两个属性一起发送给broker，broker会将PID和Sequence Number跟消息绑定一起存起来，下次如果生产者重发相同消息，broker会检查PID和Sequence Number，如果相同不会再接收。\n\nPID：每个新的 Producer 在初始化的时候会被分配一个唯一的 PID，这个PID 对用户完全是透明的。生产者如果重启则会生成新的PID。\nSequence Number：对于每个 PID，该 Producer 发送到每个 Partition 的数据都有对应的序列号，这些序列号是从0开始单调递增的。              \n\nkafka的事务afka的事务不同于Rocketmq，Rocketmq是保障本地事务(比如数据库)与mq消息发送的事务一致性，Kafka的事务主要是保障一次发送多条消息的事务一致性(要么同时成功要么同时失败)，一般在kafka的流式计算场景用得多一点，比如，kafka需要对一个topic里的消息做不同的流式计算处理，处理完分别发到不同的topic里，这些topic分别被不同的下游系统消费(比如hbase，redis，es等)，这种我们肯定希望系统发送到多个topic的数据保持事务一致性。Kafka要实现类似Rocketmq的分布式事务需要额外开发功能。\nkafka的事务处理可以参考官方文档：\nProperties props = new Properties();props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);props.put(&quot;transactional.id&quot;, &quot;my-transactional-id&quot;);Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props, new StringSerializer(), new StringSerializer());producer.initTransactions();try &#123;    producer.beginTransaction();    for (int i = 0; i &lt; 100; i++)        producer.send(new ProducerRecord&lt;&gt;(&quot;my-topic&quot;, Integer.toString(i), Integer.toString(i)));    producer.commitTransaction();&#125; catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) &#123;    // We can&#x27;t recover from these exceptions, so our only option is to close the producer and exit.    producer.close();&#125; catch (KafkaException e) &#123;    // For all other exceptions, just abort the transaction and try again.    producer.abortTransaction();&#125;producer.close();\n\nkafka高性能的原因\n磁盘顺序读写：kafka消息不能修改以及不会从文件中间删除保证了磁盘顺序读，kafka的消息写入文件都是追加在文件末尾，不会写入文件中的某个位置(随机写)保证了磁盘顺序写。\n数据传输的零拷贝\n读写数据的批量batch处理以及压缩传输\n\n数据传输零拷贝原理：\n\n","categories":["中间件"],"tags":["Kafka"]},{"title":"Kafka设计原理详解","url":"/2021/11/30/%E4%B8%AD%E9%97%B4%E4%BB%B6/Kafka/Kafka%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/","content":"\nKafka设计原理详解Kafka核心总控制器Controller在Kafka集群中会有一个或者多个broker，其中有一个broker会被选举为控制器（Kafka Controller），它负责管理整个集群中所有分区和副本的状态。\n\n当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本。\n当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息。\n当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由控制器负责让新分区被其他节点感知到。\n\nController选举机制在kafka集群启动的时候，会自动选举一台broker作为controller来管理整个集群，选举的过程是集群中每个broker都会尝试在zookeeper上创建一个 /controller 临时节点，zookeeper会保证有且仅有一个broker能创建成功，这个broker就会成为集群的总控器controller。\n当这个controller角色的broker宕机了，此时zookeeper临时节点会消失，集群里其他broker会一直监听这个临时节点，发现临时节点消失了，就竞争再次创建临时节点，就是我们上面说的选举机制，zookeeper又会保证有一个broker成为新的controller。\n具备控制器身份的broker需要比其他普通的broker多一份职责，具体细节如下：\n\n监听broker相关的变化，为Zookeeper中的/brokers/ids/节点添加BrokerChangeListener，用来处理broker增减的变化。\n监听topic相关的变化。为Zookeeper中的/brokers/topics节点添加TopicChangeListener，用来处理topic增减的变化；为Zookeeper中的/admin/delete_topics节点添加TopicDeletionListener，用来处理删除topic的动作。\n从Zookeeper中读取获取当前所有与topic、partition以及broker有关的信息并进行相应的管理。对于所有topic所对应的Zookeeper中的/brokers/topics/[topic]节点添加PartitionModificationsListener，用来监听topic中的分区分配变化。\n更新集群的元数据信息，同步到其他普通的broker节点中。\n\nPartition副本选举Leader机制controller感知到分区leader所在的broker挂了(controller监听了很多zk节点可以感知到broker存活)，controller会从ISR列表(参数unclean.leader.election.enable=false的前提下)里挑第一个broker作为leader(第一个broker最先放进ISR列表，可能是同步数据最多的副本)，如果参数unclean.leader.election.enable为true，代表在ISR列表里所有副本都挂了的时候可以在ISR列表以外的副本中选leader，这种设置，可以提高可用性，但是选出的新leader有可能数据少很多。\n副本进入ISR列表有两个条件：\n\n副本节点不能产生分区，必须能与zookeeper保持会话以及跟leader副本网络连通\n副本能复制leader上的所有写操作，并且不能落后太多。(与leader副本同步滞后的副本，是由 replica.lag.time.max.ms 配置决定的，超过这个时间都没有跟leader同步过的一次的副本会被移出ISR列表)\n\n消费者消费者消费消息的offset记录机制每个consumer会定期将自己消费分区的offset提交给kafka内部topic：__consumer_offsets，提交过去的时候，key是consumerGroupId+topic+分区号,value就是当前offset的值，kafka会定期清理topic里的消息，最后就保留最新的那条数据\n 因为__consumer_offsets可能会接收高并发的请求，kafka默认给其分配50个分区(可以通过offsets.topic.num.partitions设置)，这样可以通过加机器的方式抗大并发。\n通过如下公式可以选出consumer消费的offset要提交到__consumer_offsets的哪个分区hash(consumerGroupId)  %  __consumer_offsets主题的分区数\n消费者Rebalance机制rebalance就是说如果消费组里的消费者数量有变化或消费的分区数有变化，kafka会重新分配消费者消费分区的关系。比如consumer group中某个消费者挂了，此时会自动把分配给他的分区交给其他的消费者，如果他又重启了，那么又会把一些分区重新交还给他。\n注意：rebalance只针对subscribe这种不指定分区消费的情况，如果通过assign这种消费方式指定了分区，kafka不会进行rebanlance。\n如下情况可能会触发消费者rebalance\n\n消费组里的consumer增加或减少了\n动态给topic增加了分区\n消费组订阅了更多的topic\n\nrebalance过程中，消费者无法从kafka消费消息，这对kafka的TPS会有影响，如果kafka集群内节点较多，比如数百个，那重平衡可能会耗时极多，所以应尽量避免在系统高峰期的重平衡发生。\n消费者Rebalance分区分配策略主要有三种rebalance的策略：range、round-robin、sticky\nKafka 提供了消费者客户端参数partition.assignment.strategy 来设置消费者与订阅主题之间的分区分配策略。默认情况为range分配策略\n假设一个主题有10个分区(0-9)，现在有三个consumer消费：\n\nrange策略就是按照分区序号排序，假设 n＝分区数／消费者数量 = 3， m＝分区数%消费者数量 = 1，那么前 m 个消费者每个分配 n+1 个分区，后面的（消费者数量－m ）个消费者每个分配 n 个分区比如分区0-3给一个consumer，分区4-6给一个consumer，分区7-9给一个consumer。\n\nround-robin策略就是轮询分配，比如分区0、3、6、9给一个consumer，分区1、4、7给一个consumer，分区2、5、8给一个consumer\n\nsticky策略初始时分配策略与round-robin类似，但是在rebalance的时候，需要保证如下两个原则\n\n分区的分配要尽可能均匀 \n分区的分配尽可能与上次分配的保持相同\n\n当两者发生冲突时，第一个目标优先于第二个目标 。这样可以最大程度维持原来的分区分配的策略。比如对于第一种range情况的分配，如果第三个consumer挂了，那么重新用sticky策略分配的结果如下：consumer1除了原有的0-3，会再分配一个7consumer2除了原有的4-6，会再分配8和9\n\n\nRebalance过程当有消费者加入消费组时，消费者、消费组及组协调器之间会经历以下几个阶段\n\n选择组协调器\n组协调器GroupCoordinator每个consumer group都会选择一个broker作为自己的组协调器coordinator，负责监控这个消费组里的所有消费者的心跳，以及判断是否宕机，然后开启消费者rebalance。consumer group中的每个consumer启动时会向kafka集群中的某个节点发送 FindCoordinatorRequest 请求来查找对应的组协调器GroupCoordinator，并跟其建立网络连接。\n\n组协调器选择方式consumer消费的offset要提交到__consumer_offsets的哪个分区，这个分区leader对应的broker就是这个consumer group的coordinator\n\n\n加入消费组JOIN GROUP在成功找到消费组所对应的 GroupCoordinator 之后就进入加入消费组的阶段，在此阶段的消费者会向 GroupCoordinator 发送 JoinGroupRequest 请求，并处理响应。然后GroupCoordinator 从一个consumer group中选择第一个加入group的consumer作为leader(消费组协调器)，把consumer group情况发送给这个leader，接着这个leader会负责制定分区方案。\nSYNC GROUPconsumer leader通过给GroupCoordinator发送SyncGroupRequest，接着GroupCoordinator就把分区方案下发给各个consumer，他们会根据指定分区的leader broker进行网络连接以及消息消费。\n生产者生产者发布消息流程写入方式producer 采用 push 模式将消息发布到 broker，每条消息都被 append 到 patition 中，属于顺序写磁盘（顺序写磁盘效率比随机写内存要高，保障 kafka 吞吐率）。\n消息路由producer 发送消息到 broker 时，会根据分区算法选择将其存储到哪一个 partition。其路由机制为：\n\n指定了 patition，则直接使用\n未指定 patition 但指定 key，通过对 key 的 value 进行hash 选出一个 patition\n patition 和 key 都未指定，使用轮询选出一个 patition\n\n写入流程\n\nproducer 先从 zookeeper 的 “/brokers/…/state” 节点找到该 partition 的 leader\nproducer 将消息发送给该 leader\nleader 将消息写入本地 log\nfollowers 从 leader pull 消息，写入本地 log 后 向leader 发送 ACK\nleader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset） 并向 producer 发送 ACK\n\nHW与LEO详解HW俗称高水位，HighWatermark的缩写，取一个partition对应的ISR中最小的LEO(log-end-offset)作为HW，consumer最多只能消费到HW所在的位置。另外每个replica都有HW,leader和follower各自负责更新自己的HW的状态。对于leader新写入的消息，consumer不能立刻消费，leader会等待该消息被所有ISR中的replicas同步后更新HW，此时消息才能被consumer消费。这样就保证了如果leader所在的broker失效，该消息仍然可以从新选举的leader中获取。对于来自内部broker的读取请求，没有HW的限制。\n下图详细的说明了当producer生产消息至broker后，ISR以及HW和LEO的流转过程：\n\n由此可见，Kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。事实上，同步复制要求所有能工作的follower都复制完，这条消息才会被commit，这种复制方式极大的影响了吞吐率。而异步复制方式下，follower异步的从leader复制数据，数据只要被leader写入log就被认为已经commit，这种情况下如果follower都还没有复制完，落后于leader时，突然leader宕机，则会丢失数据。而Kafka的这种使用ISR的方式则很好的均衡了确保数据不丢失以及吞吐率。\nacks=1的情况\n\n日志分段存储Kafka一个分区的消息数据对应存储在一个文件夹下，以topic名称+分区号命名，消息在分区内是分段(segment)存储，每个段的消息都存储在不一样的log文件里，这种特性方便old segment file快速被删除，kafka规定了一个段位的 log 文件最大为 1G，做这个限制目的是为了方便把 log 文件加载到内存去操作\n# 部分消息的offset索引文件，kafka每次往分区发4K(可配置)消息就会记录一条当前消息的offset到index文件，# 如果要定位消息的offset会先在这个文件里快速定位，再去log文件里找具体消息00000000000000000000.index# 消息存储文件，主要存offset和消息体00000000000000000000.log# 消息的发送时间索引文件，kafka每次往分区发4K(可配置)消息就会记录一条当前消息的发送时间戳与对应的offset到timeindex文件，# 如果需要按照时间来定位消息的offset，会先在这个文件里查找00000000000000000000.timeindex00000000000005367851.index00000000000005367851.log00000000000005367851.timeindex00000000000009936472.index00000000000009936472.log00000000000009936472.timeindex\n\n这个 9936472 之类的数字，就是代表了这个日志段文件里包含的起始 Offset，也就说明这个分区里至少都写入了接近 1000 万条数据了。\nKafka Broker 有一个参数，log.segment.bytes，限定了每个日志段文件的大小，最大就是 1GB。\n一个日志段文件满了，就自动开一个新的日志段文件来写入，避免单个文件过大，影响文件的读写性能，这个过程叫做 log rolling，正在被写入的那个日志段文件，叫做 active log segment。\nzookeeper节点数据图\n","categories":["中间件"],"tags":["Kafka"]},{"title":"NIO与Epoll","url":"/2021/12/15/%E4%B8%AD%E9%97%B4%E4%BB%B6/Netty/NIO%E4%B8%8EEpoll/","content":"IO模型IO模型就是说用什么样的通道进行数据的发送和接收，Java共支持3种网络编程IO模式：BIO，NIO，AIO\nBIO(Blocking IO)同步阻塞模型，一个客户端连接对应一个处理线程\n\nBIO代码示例：\n//服务端代码public class SocketServer &#123;    public static void main(String[] args) throws IOException &#123;        ServerSocket serverSocket = new ServerSocket(9000);        while (true) &#123;            System.out.println(&quot;等待连接。。&quot;);            //阻塞方法            Socket clientSocket = serverSocket.accept();            System.out.println(&quot;有客户端连接了。。&quot;);            handler(clientSocket);        &#125;    &#125;    private static void handler(Socket clientSocket) throws IOException &#123;        byte[] bytes = new byte[1024];        System.out.println(&quot;准备read。。&quot;);        //接收客户端的数据，阻塞方法，没有数据可读时就阻塞        int read = clientSocket.getInputStream().read(bytes);        System.out.println(&quot;read完毕。。&quot;);        if (read != -1) &#123;            System.out.println(&quot;接收到客户端的数据：&quot; + new String(bytes, 0, read));        &#125;        clientSocket.getOutputStream().write(&quot;HelloClient&quot;.getBytes());        clientSocket.getOutputStream().flush();    &#125;&#125;\n\n//客户端代码public class SocketClient &#123;    public static void main(String[] args) throws IOException &#123;        Socket socket = new Socket(&quot;localhost&quot;, 9000);        //向服务端发送数据        socket.getOutputStream().write(&quot;HelloServer&quot;.getBytes());        socket.getOutputStream().flush();        System.out.println(&quot;向服务端发送数据结束&quot;);        byte[] bytes = new byte[1024];        //接收服务端回传的数据        socket.getInputStream().read(bytes);        System.out.println(&quot;接收到服务端的数据：&quot; + new String(bytes));        socket.close();    &#125;&#125;\n\n缺点：\n\nIO代码里read操作是阻塞操作，如果连接不做数据读写操作会导致线程阻塞，浪费资源\n\n如果线程很多，会导致服务器线程太多，压力太大，比如C10K问题\n\n\n应用场景：\nBIO 方式适用于连接数目比较小且固定的架构， 这种方式对服务器资源要求比较高，  但程序简单易理解。\nNIO(Non Blocking IO)同步非阻塞，服务器实现模式为一个线程可以处理多个请求(连接)，客户端发送的连接请求都会注册到多路复用器selector上，多路复用器轮询到连接有IO请求就进行处理，JDK1.4开始引入。\n应用场景：\nNIO方式适用于连接数目多且连接比较短（轻操作） 的架构， 比如聊天服务器， 弹幕系统， 服务器间通讯，编程比较复杂\nNIO非阻塞代码示例：\npublic class NioServer &#123;    // 保存客户端连接    static List&lt;SocketChannel&gt; channelList = new ArrayList&lt;&gt;();    public static void main(String[] args) throws IOException, InterruptedException &#123;        // 创建NIO ServerSocketChannel,与BIO的serverSocket类似        ServerSocketChannel serverSocket = ServerSocketChannel.open();        serverSocket.socket().bind(new InetSocketAddress(9000));        // 设置ServerSocketChannel为非阻塞        serverSocket.configureBlocking(false);        System.out.println(&quot;服务启动成功&quot;);        while (true) &#123;            // 非阻塞模式accept方法不会阻塞，否则会阻塞            // NIO的非阻塞是由操作系统内部实现的，底层调用了linux内核的accept函数            SocketChannel socketChannel = serverSocket.accept();            if (socketChannel != null) &#123; // 如果有客户端进行连接                System.out.println(&quot;连接成功&quot;);                // 设置SocketChannel为非阻塞                socketChannel.configureBlocking(false);                // 保存客户端连接在List中                channelList.add(socketChannel);            &#125;            // 遍历连接进行数据读取            Iterator&lt;SocketChannel&gt; iterator = channelList.iterator();            while (iterator.hasNext()) &#123;                SocketChannel sc = iterator.next();                ByteBuffer byteBuffer = ByteBuffer.allocate(128);                // 非阻塞模式read方法不会阻塞，否则会阻塞                int len = sc.read(byteBuffer);                // 如果有数据，把数据打印出来                if (len &gt; 0) &#123;                    System.out.println(&quot;接收到消息：&quot; + new String(byteBuffer.array()));                &#125; else if (len == -1) &#123; // 如果客户端断开，把socket从集合中去掉                    iterator.remove();                    System.out.println(&quot;客户端断开连接&quot;);                &#125;            &#125;        &#125;    &#125;&#125;\n\n总结：如果连接数太多的话，会有大量的无效遍历，假如有10000个连接，其中只有1000个连接有写数据，但是由于其他9000个连接并没有断开，我们还是要每次轮询遍历一万次，其中有十分之九的遍历都是无效的，这显然不是一个让人很满意的状态。\nNIO引入多路复用器public class NioSelectorServer &#123;    public static void main(String[] args) throws IOException, InterruptedException &#123;        // 创建NIO ServerSocketChannel        ServerSocketChannel serverSocket = ServerSocketChannel.open();        serverSocket.socket().bind(new InetSocketAddress(9000));        // 设置ServerSocketChannel为非阻塞        serverSocket.configureBlocking(false);        // 打开Selector处理Channel，即创建epoll        Selector selector = Selector.open();        // 把ServerSocketChannel注册到selector上，并且selector对客户端accept连接操作感兴趣        serverSocket.register(selector, SelectionKey.OP_ACCEPT);        System.out.println(&quot;服务启动成功&quot;);        while (true) &#123;            // 阻塞等待需要处理的事件发生            selector.select();            // 获取selector中注册的全部事件的 SelectionKey 实例            Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys();            Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator();            // 遍历SelectionKey对事件进行处理            while (iterator.hasNext()) &#123;                SelectionKey key = iterator.next();                // 如果是OP_ACCEPT事件，则进行连接获取和事件注册                if (key.isAcceptable()) &#123;                    ServerSocketChannel server = (ServerSocketChannel) key.channel();                    SocketChannel socketChannel = server.accept();                    socketChannel.configureBlocking(false);                    // 这里只注册了读事件，如果需要给客户端发送数据可以注册写事件                    socketChannel.register(selector, SelectionKey.OP_READ);                    System.out.println(&quot;客户端连接成功&quot;);                &#125; else if (key.isReadable()) &#123;  // 如果是OP_READ事件，则进行读取和打印                    SocketChannel socketChannel = (SocketChannel) key.channel();                    ByteBuffer byteBuffer = ByteBuffer.allocate(128);                    int len = socketChannel.read(byteBuffer);                    // 如果有数据，把数据打印出来                    if (len &gt; 0) &#123;                        System.out.println(&quot;接收到消息：&quot; + new String(byteBuffer.array()));                    &#125; else if (len == -1) &#123; // 如果客户端断开连接，关闭Socket                        System.out.println(&quot;客户端断开连接&quot;);                        socketChannel.close();                    &#125;                &#125;                //从事件集合里删除本次处理的key，防止下次select重复处理                iterator.remove();            &#125;        &#125;    &#125;&#125;\n\nNIO 有三大核心组件： Channel(通道)， Buffer(缓冲区)，Selector(多路复用器)\n\nchannel 类似于流，每个 channel 对应一个 buffer缓冲区，buffer 底层就是个数组\n\nchannel 会注册到 selector 上，由 selector 根据 channel 读写事件的发生将其交由某个空闲的线程处理\n\nNIO 的 Buffer 和 channel 都是既可以读也可以写\n\n\n\nNIO底层在JDK1.4版本是用linux的内核函数select()或poll()来实现，跟上面的NioServer代码类似，selector每次都会轮询所有的sockchannel看下哪个channel有读写事件，有的话就处理，没有就继续遍历，JDK1.5开始引入了epoll基于事件响应机制来优化NIO。\nNioSelectorServer 代码里如下几个方法非常重要，我们从Hotspot与Linux内核函数级别来理解下\nSelector.open()  //创建多路复用器socketChannel.register(selector, SelectionKey.OP_READ)  //将channel注册到多路复用器上selector.select()  //阻塞等待需要处理的事件发生\n\n\n总结：NIO整个调用流程就是Java调用了操作系统的内核函数来创建Socket，获取到Socket的文件描述符，再创建一个Selector对象，对应操作系统的Epoll描述符，将获取到的Socket连接的文件描述符的事件绑定到Selector对应的Epoll文件描述符上，进行事件的异步通知，这样就实现了使用一条线程，并且不需要太多的无效的遍历，将事件处理交给了操作系统内核(操作系统中断程序实现)，大大提高了效率。\nEpoll函数详解int epoll_create(int size);\n\n创建一个epoll实例，并返回一个非负数作为文件描述符，用于对epoll接口的所有后续调用。参数size代表可能会容纳size个描述符，但size不是一个最大值，只是提示操作系统它的数量级，现在这个参数基本上已经弃用了。\nint epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);\n\n使用文件描述符epfd引用的epoll实例，对目标文件描述符fd执行op操作。\n参数epfd表示epoll对应的文件描述符，参数fd表示socket对应的文件描述符。\n参数op有以下几个值：\nEPOLL_CTL_ADD：注册新的fd到epfd中，并关联事件event；\nEPOLL_CTL_MOD：修改已经注册的fd的监听事件；\nEPOLL_CTL_DEL：从epfd中移除fd，并且忽略掉绑定的event，这时event可以为null；\n参数event是一个结构体\nstruct epoll_event &#123;    __uint32_t   events;      /* Epoll events */    epoll_data_t data;        /* User data variable */&#125;;typedef union epoll_data &#123;    void        *ptr;    int          fd;    __uint32_t   u32;    __uint64_t   u64;&#125; epoll_data_t;\n\nevents有很多可选值，这里只举例最常见的几个：\nEPOLLIN：表示对应的文件描述符是可读的；\nEPOLLOUT：表示对应的文件描述符是可写的；\nEPOLLERR：表示对应的文件描述符发生了错误；\n成功则返回0，失败返回-1\nint epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);\n\n等待文件描述符epfd上的事件。\nepfd是Epoll对应的文件描述符，events表示调用者所有可用事件的集合，maxevents表示最多等到多少个事件就返回，timeout是超时时间。\nI/O多路复用底层主要用的Linux 内核·函数（select，poll，epoll）来实现，windows不支持epoll实现，windows底层是基于winsock2的select函数实现的(不开源)\n\n\n\n\nselect\npoll\nepoll(jdk 1.5及以上)\n\n\n\n操作方式\n遍历\n遍历\n回调\n\n\n底层实现\n数组\n链表\n哈希表\n\n\nIO效率\n每次调用都进行线性遍历，时间复杂度为O(n)\n每次调用都进行线性遍历，时间复杂度为O(n)\n事件通知方式，每当有IO事件就绪，系统注册的回调函数就会被调用，时间复杂度O(1)\n\n\n最大连接\n有上限\n无上限\n无上限\n\n\nRedis线程模型Redis就是典型的基于epoll的NIO线程模型(nginx也是)，epoll实例收集所有事件(连接与读写事件)，由一个服务端线程连续处理所有事件命令。\nRedis底层关于epoll的源码实现在redis的src源码目录的ae_epoll.c文件里，感兴趣可以自行研究。\nAIO(NIO 2.0)异步非阻塞， 由操作系统完成后回调通知服务端程序启动线程去处理， 一般适用于连接数较多且连接时间较长的应用\n应用场景：\nAIO方式适用于连接数目多且连接比较长(重操作)的架构，JDK7 开始支持\nAIO代码示例：\npublic class AIOServer &#123;    public static void main(String[] args) throws Exception &#123;        final AsynchronousServerSocketChannel serverChannel =            AsynchronousServerSocketChannel.open().bind(new InetSocketAddress(9000));        serverChannel.accept(null, new CompletionHandler&lt;AsynchronousSocketChannel, Object&gt;() &#123;            @Override            public void completed(AsynchronousSocketChannel socketChannel, Object attachment) &#123;                try &#123;                    System.out.println(&quot;2--&quot;+Thread.currentThread().getName());                    // 再此接收客户端连接，如果不写这行代码后面的客户端连接连不上服务端                    serverChannel.accept(attachment, this);                    System.out.println(socketChannel.getRemoteAddress());                    ByteBuffer buffer = ByteBuffer.allocate(1024);                    socketChannel.read(buffer, buffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123;                        @Override                        public void completed(Integer result, ByteBuffer buffer) &#123;                            System.out.println(&quot;3--&quot;+Thread.currentThread().getName());                            buffer.flip();                            System.out.println(new String(buffer.array(), 0, result));                            socketChannel.write(ByteBuffer.wrap(&quot;HelloClient&quot;.getBytes()));                        &#125;                        @Override                        public void failed(Throwable exc, ByteBuffer buffer) &#123;                            exc.printStackTrace();                        &#125;                    &#125;);                &#125; catch (IOException e) &#123;                    e.printStackTrace();                &#125;            &#125;            @Override            public void failed(Throwable exc, Object attachment) &#123;                exc.printStackTrace();            &#125;        &#125;);        System.out.println(&quot;1--&quot;+Thread.currentThread().getName());        Thread.sleep(Integer.MAX_VALUE);    &#125;&#125;\n\npublic class AIOClient &#123;    public static void main(String... args) throws Exception &#123;        AsynchronousSocketChannel socketChannel = AsynchronousSocketChannel.open();        socketChannel.connect(new InetSocketAddress(&quot;127.0.0.1&quot;, 9000)).get();        socketChannel.write(ByteBuffer.wrap(&quot;HelloServer&quot;.getBytes()));        ByteBuffer buffer = ByteBuffer.allocate(512);        Integer len = socketChannel.read(buffer).get();        if (len != -1) &#123;            System.out.println(&quot;客户端收到信息：&quot; + new String(buffer.array(), 0, len));        &#125;    &#125;&#125;\n\nBIO、 NIO、 AIO 对比：\n\n为什么Netty使用NIO而不是AIO？\n在Linux系统上，AIO的底层实现仍使用Epoll，没有很好实现AIO，因此在性能上没有明显的优势，而且被JDK封装了一层不容易深度优化，Linux上AIO还不够成熟。Netty是异步非阻塞框架，Netty在NIO上做了很多异步的封装。\n","categories":["中间件"],"tags":["Netty"]},{"title":"Netty核心功能与线程模型","url":"/2021/12/20/%E4%B8%AD%E9%97%B4%E4%BB%B6/Netty/Netty%E6%A0%B8%E5%BF%83%E5%8A%9F%E8%83%BD%E4%B8%8E%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/","content":"Netty初探NIO 的类库和 API 繁杂， 使用麻烦： 需要熟练掌握Selector、 ServerSocketChannel、 SocketChannel、 ByteBuffer等。开发工作量和难度都非常大： 例如客户端面临断线重连、 网络闪断、心跳处理、半包读写、 网络拥塞和异常流的处理等等。Netty 对 JDK 自带的 NIO 的 API 进行了良好的封装，解决了上述问题。且Netty拥有高性能、 吞吐量更高，延迟更低，减少资源消耗，最小化不必要的内存复制等优点。Netty 现在都在用的是4.x，5.x版本已经废弃，Netty 4.x 需要JDK 6以上版本支持。\nNetty的使用场景\n互联网行业：在分布式系统中，各个节点之间需要远程服务调用，高性能的 RPC 框架必不可少，Netty 作为异步高性能的通信框架，往往作为基础通信组件被这些 RPC 框架使用。典型的应用有：阿里分布式服务框架 Dubbo 的 RPC 框架使用 Dubbo 协议进行节点间通信，Dubbo 协议默认使用 Netty 作为基础通信组件，用于实现。各进程节点之间的内部通信。Rocketmq底层也是用的Netty作为基础通信组件。\n游戏行业：无论是手游服务端还是大型的网络游戏，Java 语言得到了越来越广泛的应用。Netty 作为高性能的基础通信组件，它本身提供了 TCP/UDP 和 HTTP 协议栈。\n大数据领域：经典的 Hadoop 的高性能通信和序列化组件 Avro 的 RPC 框架，默认采用 Netty 进行跨界点通信，它的 Netty Service 基于 Netty 框架二次封装实现。\n\nnetty相关开源项目：https://netty.io/wiki/related-projects.html\nNetty代码示例maven依赖：\n&lt;dependency&gt;    &lt;groupId&gt;io.netty&lt;/groupId&gt;    &lt;artifactId&gt;netty-all&lt;/artifactId&gt;    &lt;version&gt;4.1.35.Final&lt;/version&gt;&lt;/dependency&gt;\n\n服务端代码：\npublic class NettyServer &#123;    public static void main(String[] args) throws Exception &#123;        //创建两个线程组bossGroup和workerGroup, 含有的子线程NioEventLoop的个数默认为cpu核数的两倍        // bossGroup只是处理连接请求 ,真正的和客户端业务处理，会交给workerGroup完成        EventLoopGroup bossGroup = new NioEventLoopGroup(1);        EventLoopGroup workerGroup = new NioEventLoopGroup();        try &#123;            //创建服务器端的启动对象            ServerBootstrap bootstrap = new ServerBootstrap();            //使用链式编程来配置参数            bootstrap.group(bossGroup, workerGroup) //设置两个线程组                .channel(NioServerSocketChannel.class) //使用NioServerSocketChannel作为服务器的通道实现                // 初始化服务器连接队列大小，服务端处理客户端连接请求是顺序处理的,所以同一时间只能处理一个客户端连接。                // 多个客户端同时来的时候,服务端将不能处理的客户端连接请求放在队列中等待处理                .option(ChannelOption.SO_BACKLOG, 1024)                .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123;//创建通道初始化对象，设置初始化参数                    @Override                    protected void initChannel(SocketChannel ch) throws Exception &#123;                        //对workerGroup的SocketChannel设置处理器                        ch.pipeline().addLast(new NettyServerHandler());                    &#125;                &#125;);            System.out.println(&quot;netty server start。。&quot;);            //绑定一个端口并且同步, 生成了一个ChannelFuture异步对象，通过isDone()等方法可以判断异步事件的执行情况            //启动服务器(并绑定端口)，bind是异步操作，sync方法是等待异步操作执行完毕            ChannelFuture cf = bootstrap.bind(9000).sync();            //给cf注册监听器，监听我们关心的事件            /*cf.addListener(new ChannelFutureListener() &#123;                @Override                public void operationComplete(ChannelFuture future) throws Exception &#123;                    if (cf.isSuccess()) &#123;                        System.out.println(&quot;监听端口9000成功&quot;);                    &#125; else &#123;                        System.out.println(&quot;监听端口9000失败&quot;);                    &#125;                &#125;            &#125;);*/            //对通道关闭进行监听，closeFuture是异步操作，监听通道关闭            // 通过sync方法同步等待通道关闭处理完毕，这里会阻塞等待通道关闭完成            cf.channel().closeFuture().sync();        &#125; finally &#123;            bossGroup.shutdownGracefully();            workerGroup.shutdownGracefully();        &#125;    &#125;&#125;/** * 自定义Handler需要继承netty规定好的某个HandlerAdapter(规范) */public class NettyServerHandler extends ChannelInboundHandlerAdapter &#123;    /**     * 读取客户端发送的数据     *     * @param ctx 上下文对象, 含有通道channel，管道pipeline     * @param msg 就是客户端发送的数据     * @throws Exception     */    @Override    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123;        System.out.println(&quot;服务器读取线程 &quot; + Thread.currentThread().getName());        //Channel channel = ctx.channel();        //ChannelPipeline pipeline = ctx.pipeline(); //本质是一个双向链接, 出站入站        //将 msg 转成一个 ByteBuf，类似NIO 的 ByteBuffer        ByteBuf buf = (ByteBuf) msg;        System.out.println(&quot;客户端发送消息是:&quot; + buf.toString(CharsetUtil.UTF_8));    &#125;    /**     * 数据读取完毕处理方法     *     * @param ctx     * @throws Exception     */    @Override    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123;        ByteBuf buf = Unpooled.copiedBuffer(&quot;HelloClient&quot;, CharsetUtil.UTF_8);        ctx.writeAndFlush(buf);    &#125;    /**     * 处理异常, 一般是需要关闭通道     *     * @param ctx     * @param cause     * @throws Exception     */    @Override    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123;        ctx.close();    &#125;&#125;\n\n客户端代码：\npublic class NettyClient &#123;    public static void main(String[] args) throws Exception &#123;        //客户端需要一个事件循环组        EventLoopGroup group = new NioEventLoopGroup();        try &#123;            //创建客户端启动对象            //注意客户端使用的不是 ServerBootstrap 而是 Bootstrap            Bootstrap bootstrap = new Bootstrap();            //设置相关参数            bootstrap.group(group) //设置线程组                .channel(NioSocketChannel.class) // 使用 NioSocketChannel 作为客户端的通道实现                .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123;                    @Override                    protected void initChannel(SocketChannel channel) throws Exception &#123;                        //加入处理器                        channel.pipeline().addLast(new NettyClientHandler());                    &#125;                &#125;);            System.out.println(&quot;netty client start&quot;);            //启动客户端去连接服务器端            ChannelFuture channelFuture = bootstrap.connect(&quot;127.0.0.1&quot;, 9000).sync();            //对关闭通道进行监听            channelFuture.channel().closeFuture().sync();        &#125; finally &#123;            group.shutdownGracefully();        &#125;    &#125;&#125;public class NettyClientHandler extends ChannelInboundHandlerAdapter &#123;    /**     * 当客户端连接服务器完成就会触发该方法     *     * @param ctx     * @throws Exception     */    @Override    public void channelActive(ChannelHandlerContext ctx) throws Exception &#123;        ByteBuf buf = Unpooled.copiedBuffer(&quot;HelloServer&quot;, CharsetUtil.UTF_8);        ctx.writeAndFlush(buf);    &#125;    //当通道有读取事件时会触发，即服务端发送数据给客户端    @Override    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123;        ByteBuf buf = (ByteBuf) msg;        System.out.println(&quot;收到服务端的消息:&quot; + buf.toString(CharsetUtil.UTF_8));        System.out.println(&quot;服务端的地址： &quot; + ctx.channel().remoteAddress());    &#125;    @Override    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123;        cause.printStackTrace();        ctx.close();    &#125;&#125;\n\n看完代码，我们发现Netty框架的目标就是让你的业务逻辑从网络基础应用编码中分离出来，让你可以专注业务的开发，而不需写一大堆类似NIO的网络处理操作。\nNetty线程模型可以先理解下《Scalable IO in Java》这篇文章里说的一些IO处理模式，Netty的线程模型如下图所示：\n\n模型解释：\n\nNetty 抽象出两组线程池BossGroup和WorkerGroup，BossGroup专门负责接收客户端的连接, WorkerGroup专门负责网络的读写\nBossGroup和WorkerGroup类型都是NioEventLoopGroup\nNioEventLoopGroup 相当于一个事件循环线程组, 这个组中含有多个事件循环线程 ， 每一个事件循环线程是NioEventLoop\n每个NioEventLoop都有一个selector , 用于监听注册在其上的socketChannel的网络通讯\n每个Boss  NioEventLoop线程内部循环执行的步骤有 3 步\n处理accept事件 , 与client 建立连接 , 生成 NioSocketChannel \n将NioSocketChannel注册到某个worker  NIOEventLoop上的selector\n处理任务队列的任务 ， 即runAllTasks\n\n\n每个worker  NIOEventLoop线程循环执行的步骤\n轮询注册到自己selector上的所有NioSocketChannel 的read, write事件\n处理 I/O 事件， 即read , write 事件， 在对应NioSocketChannel 处理业务\nrunAllTasks处理任务队列TaskQueue的任务 ，一些耗时的业务处理一般可以放入TaskQueue中慢慢处理，这样不影响数据在 pipeline 中的流动处理\n\n\n每个worker NIOEventLoop处理NioSocketChannel业务时，会使用 pipeline (管道)，管道中维护了很多 handler 处理器用来处理 channel 中的数据\n\nNetty模块组件【Bootstrap、ServerBootstrap】：\nBootstrap 意思是引导，一个 Netty 应用通常由一个 Bootstrap 开始，主要作用是配置整个 Netty 程序，串联各个组件，Netty 中 Bootstrap 类是客户端程序的启动引导类，ServerBootstrap 是服务端启动引导类。\n【Future、ChannelFuture】：\n正如前面介绍，在 Netty 中所有的 IO 操作都是异步的，不能立刻得知消息是否被正确处理。但是可以过一会等它执行完成或者直接注册一个监听，具体的实现就是通过 Future 和 ChannelFutures，他们可以注册一个监听，当操作执行成功或失败时监听会自动触发注册的监听事件。\n【Channel】：\nNetty 网络通信的组件，能够用于执行网络 I/O 操作。Channel 为用户提供：\n\n当前网络连接的通道的状态（例如是否打开？是否已连接？）\n网络连接的配置参数 （例如接收缓冲区大小）\n提供异步的网络 I/O 操作(如建立连接，读写，绑定端口)，异步调用意味着任何 I/O 调用都将立即返回，并且不保证在调用结束时所请求的 I/O 操作已完成。\n调用立即返回一个 ChannelFuture 实例，通过注册监听器到 ChannelFuture 上，可以 I/O 操作成功、失败或取消时回调通知调用方。\n支持关联 I/O 操作与对应的处理程序。\n\n不同协议、不同的阻塞类型的连接都有不同的 Channel 类型与之对应。\n下面是一些常用的 Channel 类型：\nNioSocketChannel //异步的客户端 TCP Socket 连接。NioServerSocketChannel //异步的服务器端 TCP Socket 连接。NioDatagramChannel //异步的 UDP 连接。NioSctpChannel //异步的客户端 Sctp 连接。NioSctpServerChannel //异步的 Sctp 服务器端连接。这些通道涵盖了 UDP 和 TCP 网络 IO 以及文件 IO。\n\n【Selector】：\nNetty 基于 Selector 对象实现 I/O 多路复用，通过 Selector 一个线程可以监听多个连接的 Channel 事件。当向一个 Selector 中注册 Channel 后，Selector 内部的机制就可以自动不断地查询(Select) 这些注册的 Channel 是否有已就绪的 I/O 事件（例如可读，可写，网络连接完成等），这样程序就可以很简单地使用一个线程高效地管理多个 Channel 。\n【NioEventLoop】：\nNioEventLoop 中维护了一个线程和任务队列，支持异步提交执行任务，线程启动时会调用 NioEventLoop 的 run 方法，执行 I/O 任务和非 I/O 任务：I/O 任务，即 selectionKey 中 ready 的事件，如 accept、connect、read、write 等，由 processSelectedKeys 方法触发。非 IO 任务，添加到 taskQueue 中的任务，如 register0、bind0 等任务，由 runAllTasks 方法触发。\n【NioEventLoopGroup】：\nNioEventLoopGroup，主要管理 eventLoop 的生命周期，可以理解为一个线程池，内部维护了一组线程，每个线程(NioEventLoop)负责处理多个 Channel 上的事件，而一个 Channel 只对应于一个线程。\n【ChannelHandler】：\nChannelHandler 是一个接口，处理 I/O 事件或拦截 I/O 操作，并将其转发到其 ChannelPipeline(业务处理链)中的下一个处理程序。ChannelHandler 本身并没有提供很多方法，因为这个接口有许多的方法需要实现，方便使用期间，可以继承它的子类：\nChannelInboundHandler //用于处理入站 I/O 事件ChannelOutboundHandler //用于处理出站 I/O 操作\n\n或者使用以下适配器类：\nChannelInboundHandlerAdapter //用于处理入站 I/O 事件ChannelOutboundHandlerAdapter //用于处理出站 I/O 操作\n\n【ChannelHandlerContext】：\n保存 Channel 相关的所有上下文信息，同时关联一个 ChannelHandler 对象。\n【ChannelPipline】：\n保存 ChannelHandler 的 List，用于处理或拦截 Channel 的入站事件和出站操作。\nChannelPipeline 实现了一种高级形式的拦截过滤器模式，使用户可以完全控制事件的处理方式，以及 Channel 中各个的 ChannelHandler 如何相互交互。\n在 Netty 中每个 Channel 都有且仅有一个 ChannelPipeline 与之对应，它们的组成关系如下： \n\n一个 Channel 包含了一个 ChannelPipeline，而 ChannelPipeline 中又维护了一个由 ChannelHandlerContext 组成的双向链表，并且每个 ChannelHandlerContext 中又关联着一个 ChannelHandler。\nread事件(入站事件)和write事件(出站事件)在一个双向链表中，入站事件会从链表 head 往后传递到最后一个入站的 handler，出站事件会从链表 tail 往前传递到最前一个出站的 handler，两种类型的 handler 互不干扰。\nByteBuf详解从结构上来说，ByteBuf 由一串字节数组构成。数组中每个字节用来存放信息。\nByteBuf 提供了两个索引，一个用于读取数据，一个用于写入数据。这两个索引通过在字节数组中移动，来定位需要读或者写信息的位置。\n当从 ByteBuf 读取时，它的 readerIndex（读索引）将会根据读取的字节数递增。\n同样，当写 ByteBuf 时，它的 writerIndex 也会根据写入的字节数进行递增。\n\n需要注意的是极限的情况是 readerIndex 刚好读到了 writerIndex 写入的地方。\n如果 readerIndex 超过了 writerIndex 的时候，Netty 会抛出 IndexOutOf-BoundsException 异常。\n示例代码：\nimport io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.util.CharsetUtil;public class NettyByteBuf &#123;    public static void main(String[] args) &#123;        // 创建byteBuf对象，该对象内部包含一个字节数组byte[10]        // 通过readerindex和writerIndex和capacity，将buffer分成三个区域        // 已经读取的区域：[0,readerindex)        // 可读取的区域：[readerindex,writerIndex)        // 可写的区域: [writerIndex,capacity)        ByteBuf byteBuf = Unpooled.buffer(10);        System.out.println(&quot;byteBuf=&quot; + byteBuf);        for (int i = 0; i &lt; 8; i++) &#123;            byteBuf.writeByte(i);        &#125;        System.out.println(&quot;byteBuf=&quot; + byteBuf);        for (int i = 0; i &lt; 5; i++) &#123;            System.out.println(byteBuf.getByte(i));        &#125;        System.out.println(&quot;byteBuf=&quot; + byteBuf);        for (int i = 0; i &lt; 5; i++) &#123;            System.out.println(byteBuf.readByte());        &#125;        System.out.println(&quot;byteBuf=&quot; + byteBuf);        //用Unpooled工具类创建ByteBuf        ByteBuf byteBuf2 = Unpooled.copiedBuffer(&quot;hello,zhuge!&quot;, CharsetUtil.UTF_8);        //使用相关的方法        if (byteBuf2.hasArray()) &#123;            byte[] content = byteBuf2.array();            //将 content 转成字符串            System.out.println(new String(content, CharsetUtil.UTF_8));            System.out.println(&quot;byteBuf2=&quot; + byteBuf2);            System.out.println(byteBuf2.getByte(0)); // 获取数组0这个位置的字符h的ascii码，h=104            int len = byteBuf2.readableBytes(); //可读的字节数  12            System.out.println(&quot;len=&quot; + len);            //使用for取出各个字节            for (int i = 0; i &lt; len; i++) &#123;                System.out.println((char) byteBuf2.getByte(i));            &#125;            //范围读取            System.out.println(byteBuf2.getCharSequence(0, 6, CharsetUtil.UTF_8));            System.out.println(byteBuf2.getCharSequence(6, 6, CharsetUtil.UTF_8));        &#125;    &#125;&#125;\n\nNetty实战聊天室详见代码com.test.netty.chat包\n","categories":["中间件"],"tags":["Netty"]},{"title":"Netty核心源码剖析","url":"/2021/12/20/%E4%B8%AD%E9%97%B4%E4%BB%B6/Netty/Netty%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/","content":"为什么要看源码\n提升技术功底：学习源码里的优秀设计思想，比如一些疑难问题的解决思路，还有一些优秀的设计模式，整体提升自己的技术功底\n深度掌握技术框架：源码看多了，对于一个新技术或框架的掌握速度会有大幅提升，看下框架demo大致就能知道底层的实现，技术框架更新再快也不怕\n快速定位线上问题：遇到线上问题，特别是框架源码里的问题(比如bug)，能够快速定位，这就是相比其他没看过源码的人的优势\n对面试大有裨益：面试一线互联网公司对于框架技术一般都会问到源码级别的实现\n知其然知其所以然：对技术有追求的人必做之事，使用了一个好的框架，很想知道底层是如何实现的\n拥抱开源社区：参与到开源项目的研发，结识更多大牛，积累更多优质人脉\n\n看源码方法(凭经验去猜)：\n\n先使用：先看官方文档快速掌握框架的基本使用\n抓主线：找一个demo入手，顺藤摸瓜快速静态看一遍框架的主线源码(抓大放小)，画出源码主流程图，切勿一开始就陷入源码的细枝末节，否则会把自己绕晕\n画图做笔记：总结框架的一些核心功能点，从这些功能点入手深入到源码的细节，边看源码边画源码走向图，并对关键源码的理解做笔记，把源码里的闪光点都记录下来，后续借鉴到工作项目中，理解能力强的可以直接看静态源码，也可以边看源码边debug源码执行过程，观察一些关键变量的值\n整合总结：所有功能点的源码都分析完后，回到主流程图再梳理一遍，争取把自己画的所有图都在脑袋里做一个整合\n\nNetty线程模型图\nNetty线程模型源码剖析图\nNetty高并发高性能架构设计精髓\n主从Reactor线程模型\nNIO多路复用非阻塞\n无锁串行化设计思想\n支持高性能序列化协议\n零拷贝(直接内存的使用)\nByteBuf内存池设计\n灵活的TCP参数配置能力\n并发优化\n\n无锁串行化设计思想在大多数场景下，并行多线程处理可以提升系统的并发性能。但是，如果对于共享资源的并发访问处理不当，会带来严重的锁竞争，这最终会导致性能的下降。为了尽可能的避免锁竞争带来的性能损耗，可以通过串行化设计，即消息的处理尽可能在同一个线程内完成，期间不进行线程切换，这样就避免了多线程竞争和同步锁。NIO的多路复用就是一种无锁串行化的设计思想(理解下Redis和Netty的线程模型)\n为了尽可能提升性能，Netty采用了串行无锁化设计，在IO线程内部进行串行操作，避免多线程竞争导致的性能下降。表面上看，串行化设计似乎CPU利用率不高，并发程度不够。但是，通过调整NIO线程池的线程参数，可以同时启动多个串行化的线程并行运行，这种局部无锁化的串行线程设计相比一个队列-多个工作线程模型性能更优。\nNetty的NioEventLoop读取到消息之后，直接调用ChannelPipeline的fireChannelRead(Object msg)，只要用户不主动切换线程，一直会由NioEventLoop调用到用户的Handler，期间不进行线程切换，这种串行化处理方式避免了多线程操作导致的锁的竞争，从性能角度看是最优的。\n直接内存直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域，某些情况下这部分内存也会被频繁地使用，而且也可能导致OutOfMemoryError异常出现。Java里用DirectByteBuffer可以分配一块直接内存(堆外内存)，元空间对应的内存也叫作直接内存，它们对应的都是机器的物理内存。\n\n/** * 直接内存与堆内存的区别 */public class DirectMemoryTest &#123;    public static void heapAccess() &#123;        long startTime = System.currentTimeMillis();        //分配堆内存        ByteBuffer buffer = ByteBuffer.allocate(1000);        for (int i = 0; i &lt; 100000; i++) &#123;            for (int j = 0; j &lt; 200; j++) &#123;                buffer.putInt(j);            &#125;            buffer.flip();            for (int j = 0; j &lt; 200; j++) &#123;                buffer.getInt();            &#125;            buffer.clear();        &#125;        long endTime = System.currentTimeMillis();        System.out.println(&quot;堆内存访问:&quot; + (endTime - startTime) + &quot;ms&quot;);    &#125;    public static void directAccess() &#123;        long startTime = System.currentTimeMillis();        //分配直接内存        ByteBuffer buffer = ByteBuffer.allocateDirect(1000);        for (int i = 0; i &lt; 100000; i++) &#123;            for (int j = 0; j &lt; 200; j++) &#123;                buffer.putInt(j);            &#125;            buffer.flip();            for (int j = 0; j &lt; 200; j++) &#123;                buffer.getInt();            &#125;            buffer.clear();        &#125;        long endTime = System.currentTimeMillis();        System.out.println(&quot;直接内存访问:&quot; + (endTime - startTime) + &quot;ms&quot;);    &#125;    public static void heapAllocate() &#123;        long startTime = System.currentTimeMillis();        for (int i = 0; i &lt; 100000; i++) &#123;            ByteBuffer.allocate(100);        &#125;        long endTime = System.currentTimeMillis();        System.out.println(&quot;堆内存申请:&quot; + (endTime - startTime) + &quot;ms&quot;);    &#125;    public static void directAllocate() &#123;        long startTime = System.currentTimeMillis();        for (int i = 0; i &lt; 100000; i++) &#123;            ByteBuffer.allocateDirect(100);        &#125;        long endTime = System.currentTimeMillis();        System.out.println(&quot;直接内存申请:&quot; + (endTime - startTime) + &quot;ms&quot;);    &#125;    public static void main(String args[]) &#123;        for (int i = 0; i &lt; 10; i++) &#123;            heapAccess();            directAccess();        &#125;        System.out.println();        for (int i = 0; i &lt; 10; i++) &#123;            heapAllocate();            directAllocate();        &#125;    &#125;&#125;运行结果：堆内存访问:44ms直接内存访问:29ms堆内存访问:33ms直接内存访问:19ms堆内存访问:55ms直接内存访问:38ms堆内存访问:39ms直接内存访问:20ms堆内存访问:38ms直接内存访问:18ms堆内存访问:36ms直接内存访问:19ms堆内存访问:34ms直接内存访问:19ms堆内存访问:40ms直接内存访问:20ms堆内存访问:37ms直接内存访问:24ms堆内存访问:59ms直接内存访问:25ms堆内存申请:11ms直接内存申请:36ms堆内存申请:13ms直接内存申请:52ms堆内存申请:62ms直接内存申请:40ms堆内存申请:2ms直接内存申请:37ms堆内存申请:1ms直接内存申请:81ms堆内存申请:2ms直接内存申请:23ms堆内存申请:1ms直接内存申请:31ms堆内存申请:2ms直接内存申请:32ms堆内存申请:7ms直接内存申请:41ms堆内存申请:8ms直接内存申请:142ms\n\n从程序运行结果看出直接内存申请较慢，但访问效率高。在java虚拟机实现上，本地IO一般会直接操作直接内存（直接内存=&gt;系统调用=&gt;硬盘/网卡），而非直接内存则需要二次拷贝（堆内存=&gt;直接内存=&gt;系统调用=&gt;硬盘/网卡）。\n直接内存分配源码分析public static ByteBuffer allocateDirect(int capacity) &#123;    return new DirectByteBuffer(capacity);&#125;DirectByteBuffer(int cap) &#123;                   // package-private    super(-1, 0, cap, cap);    boolean pa = VM.isDirectMemoryPageAligned();    int ps = Bits.pageSize();    long size = Math.max(1L, (long)cap + (pa ? ps : 0));    //判断是否有足够的直接内存空间分配，可通过-XX:MaxDirectMemorySize=&lt;size&gt;参数指定直接内存最大可分配空间，如果不指定默认为最大堆内存大小，    //在分配直接内存时如果发现空间不够会显示调用System.gc()触发一次full gc回收掉一部分无用的直接内存的引用对象，同时直接内存也会被释放掉    //如果释放完分配空间还是不够会抛出异常java.lang.OutOfMemoryError    Bits.reserveMemory(size, cap);    long base = 0;    try &#123;        // 调用unsafe本地方法分配直接内存        base = unsafe.allocateMemory(size);    &#125; catch (OutOfMemoryError x) &#123;        // 分配失败，释放内存        Bits.unreserveMemory(size, cap);        throw x;    &#125;    unsafe.setMemory(base, size, (byte) 0);    if (pa &amp;&amp; (base % ps != 0)) &#123;        // Round up to page boundary        address = base + ps - (base &amp; (ps - 1));    &#125; else &#123;        address = base;    &#125;    // 使用Cleaner机制注册内存回收处理函数，当直接内存引用对象被GC清理掉时，    // 会提前调用这里注册的释放直接内存的Deallocator线程对象的run方法    cleaner = Cleaner.create(this, new Deallocator(base, size, cap));    att = null;&#125;// 申请一块本地内存。内存空间是未初始化的，其内容是无法预期的。// 使用freeMemory释放内存，使用reallocateMemory修改内存大小public native long allocateMemory(long bytes);// openjdk8/hotspot/src/share/vm/prims/unsafe.cppUNSAFE_ENTRY(jlong, Unsafe_AllocateMemory(JNIEnv *env, jobject unsafe, jlong size))    UnsafeWrapper(&quot;Unsafe_AllocateMemory&quot;);size_t sz = (size_t)size;if (sz != (julong)size || size &lt; 0) &#123;    THROW_0(vmSymbols::java_lang_IllegalArgumentException());&#125;if (sz == 0) &#123;    return 0;&#125;sz = round_to(sz, HeapWordSize);// 调用os::malloc申请内存，内部使用malloc这个C标准库的函数申请内存void* x = os::malloc(sz, mtInternal);if (x == NULL) &#123;    THROW_0(vmSymbols::java_lang_OutOfMemoryError());&#125;//Copy::fill_to_words((HeapWord*)x, sz / HeapWordSize);return addr_to_java(x);UNSAFE_END\n\n使用直接内存的优缺点优点：\n\n不占用堆内存空间，减少了发生GC的可能\njava虚拟机实现上，本地IO会直接操作直接内存（直接内存=&gt;系统调用=&gt;硬盘/网卡），而非直接内存则需要二次拷贝（堆内存=&gt;直接内存=&gt;系统调用=&gt;硬盘/网卡）\n\n缺点：\n\n初始分配较慢\n没有JVM直接帮助管理内存，容易发生内存溢出。为了避免一直没有FULL GC，最终导致直接内存把物理内存耗完。我们可以指定直接内存的最大值，通过-XX：MaxDirectMemorySize来指定，当达到阈值的时候，调用system.gc来进行一次FULL GC，间接把那些没有被使用的直接内存回收掉。\n\nNetty零拷贝\nNetty的接收和发送ByteBuf采用DIRECT BUFFERS，使用堆外直接内存进行Socket读写，不需要进行字节缓冲区的二次拷贝。\n如果使用传统的JVM堆内存（HEAP BUFFERS）进行Socket读写，JVM会将堆内存Buffer拷贝一份到直接内存中，然后才能写入Socket中。JVM堆内存的数据是不能直接写入Socket中的。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。\n可以看下netty的读写源码，比如read源码NioByteUnsafe.read()\n\n\n\nByteBuf内存池设计随着JVM虚拟机和JIT即时编译技术的发展，对象的分配和回收是个非常轻量级的工作。但是对于缓冲区Buffer(相当于一个内存块)，情况却稍有不同，特别是对于堆外直接内存的分配和回收，是一件耗时的操作。为了尽量重用缓冲区，Netty提供了基于ByteBuf内存池的缓冲区重用机制。需要的时候直接从池子里获取ByteBuf使用即可，使用完毕之后就重新放回到池子里去。下面我们一起看下Netty ByteBuf的实现：\n\n可以看下netty的读写源码里面用到的ByteBuf内存池，比如read源码NioByteUnsafe.read()\n\n\n\n 继续看newDirectBuffer方法，我们发现它是一个抽象方法，由AbstractByteBufAllocator的子类负责具体实现，代码如下：\n\n 代码跳转到PooledByteBufAllocator的newDirectBuffer方法，从Cache中获取内存区域PoolArena，调用它的allocate方法进行内存分配：\n\n PoolArena的allocate方法如下：\n\n 我们重点分析newByteBuf的实现，它同样是个抽象方法，由子类DirectArena和HeapArena来实现不同类型的缓冲区分配\n\n 我们这里使用的是直接内存，因此重点分析DirectArena的实现\n\n 最终执行了PooledUnsafeDirectByteBuf的newInstance方法，代码如下：\n\n 通过RECYCLER的get方法循环使用ByteBuf对象，如果是非内存池实现，则直接创建一个新的ByteBuf对象。\n灵活的TCP参数配置能力合理设置TCP参数在某些场景下对于性能的提升可以起到显著的效果，例如接收缓冲区SO_RCVBUF和发送缓冲区SO_SNDBUF。如果设置不当，对性能的影响是非常大的。通常建议值为128K或者256K。\nNetty在启动辅助类ChannelOption中可以灵活的配置TCP参数，满足不同的用户场景。\n\n并发优化\nvolatile的大量、正确使用;\nCAS和原子类的广泛使用；\n线程安全容器的使用；\n通过读写锁提升并发性能。\n\nByteBuf扩容机制 如果我们需要了解ByteBuf的扩容,我们需要先了解ByteBuf中定义的几个成员变量，再从源码的角度来分析扩容。\n\n\nminNewCapacity：表用户需要写入的值大小\nthreshold：阈值，为Bytebuf内部设定容量的最大值\nmaxCapacity：Netty最大能接受的容量大小，一般为int的最大值\n\nByteBuf核心扩容方法进入ByteBuf源码中，深入分析其扩容方法： idea源码进入：ByteBuf.writeByte()-&gt;AbstractByteBuf-&gt;calculateNewCapacity\n\n判断目标值与阈值threshold（4MB）的大小关系，等于直接返回阈值\n采用步进4MB的方式完成扩容\n采用64为基数，做倍增的方式完成扩容\n\n总结：Netty的ByteBuf需要动态扩容来满足需要，扩容过程： 默认门限阈值为4MB(这个阈值是一个经验值，不同场景，可能取值不同)，当需要的容量等于门限阈值，使用阈值作为新的缓存区容量 目标容量，如果大于阈值，采用每次步进4MB的方式进行内存扩张（(需要扩容值/4MB)*4MB），扩张后需要和最大内存（maxCapacity）进行比较，大于maxCapacity的话就用maxCapacity,否则使用扩容值 目标容量，如果小于阈值，采用倍增的方式，以64（字节）作为基本数值，每次翻倍增长64 –&gt;128 –&gt; 256，直到倍增后的结果大于或等于需要的容量值。\n补充handler的生命周期回调接口调用顺序/** *  在channel的pipeline里如下handler: ch.pipeline().addLast(new LifeCycleInBoundHandler()); *  handler的生命周期回调接口调用顺序: *  handlerAdded -&gt; channelRegistered -&gt; channelActive -&gt; channelRead -&gt; channelReadComplete *  -&gt; channelInactive -&gt; channelUnRegistered -&gt; handlerRemoved * * handlerAdded: 新建立的连接会按照初始化策略，把handler添加到该channel的pipeline里面，也就是channel.pipeline.addLast(new LifeCycleInBoundHandler)执行完成后的回调； * channelRegistered: 当该连接分配到具体的worker线程后，该回调会被调用。 * channelActive: channel的准备工作已经完成，所有的pipeline添加完成，并分配到具体的线上上，说明该channel准备就绪，可以使用了。 * channelRead: 客户端向服务端发来数据，每次都会回调此方法，表示有数据可读； * channelReadComplete: 服务端每次读完一次完整的数据之后，回调该方法，表示数据读取完毕； * channelInactive: 当连接断开时，该回调会被调用，说明这时候底层的TCP连接已经被断开了。 * channelUnRegistered: 对应channelRegistered，当连接关闭后，释放绑定的workder线程； * handlerRemoved: 对应handlerAdded，将handler从该channel的pipeline移除后的回调方法。 */public class LifeCycleInBoundHandler extends ChannelInboundHandlerAdapter &#123;    @Override    public void channelRegistered(ChannelHandlerContext ctx)        throws Exception &#123;        System.out.println(&quot;channelRegistered: channel注册到NioEventLoop&quot;);        super.channelRegistered(ctx);    &#125;    @Override    public void channelUnregistered(ChannelHandlerContext ctx)         throws Exception &#123;        System.out.println(&quot;channelUnregistered: channel取消和NioEventLoop的绑定&quot;);        super.channelUnregistered(ctx);    &#125;    @Override    public void channelActive(ChannelHandlerContext ctx)         throws Exception &#123;        System.out.println(&quot;channelActive: channel准备就绪&quot;);        super.channelActive(ctx);    &#125;    @Override    public void channelInactive(ChannelHandlerContext ctx)         throws Exception &#123;        System.out.println(&quot;channelInactive: channel被关闭&quot;);        super.channelInactive(ctx);    &#125;    @Override    public void channelRead(ChannelHandlerContext ctx, Object msg)         throws Exception &#123;        System.out.println(&quot;channelRead: channel中有可读的数据&quot; );        super.channelRead(ctx, msg);    &#125;    @Override    public void channelReadComplete(ChannelHandlerContext ctx)         throws Exception &#123;        System.out.println(&quot;channelReadComplete: channel读数据完成&quot;);        super.channelReadComplete(ctx);    &#125;    @Override    public void handlerAdded(ChannelHandlerContext ctx)         throws Exception &#123;        System.out.println(&quot;handlerAdded: handler被添加到channel的pipeline&quot;);        super.handlerAdded(ctx);    &#125;    @Override    public void handlerRemoved(ChannelHandlerContext ctx)         throws Exception &#123;        System.out.println(&quot;handlerRemoved: handler从channel的pipeline中移除&quot;);        super.handlerRemoved(ctx);    &#125;&#125;\n\n","categories":["中间件"],"tags":["Netty"]},{"title":"Netty编解码&粘包拆包&心跳机制&断线自动重连","url":"/2021/12/20/%E4%B8%AD%E9%97%B4%E4%BB%B6/Netty/Netty%E7%BC%96%E8%A7%A3%E7%A0%81-%E7%B2%98%E5%8C%85%E6%8B%86%E5%8C%85-%E5%BF%83%E8%B7%B3%E6%9C%BA%E5%88%B6-%E6%96%AD%E7%BA%BF%E8%87%AA%E5%8A%A8%E9%87%8D%E8%BF%9E/","content":"Netty编解码Netty涉及到编解码的组件有Channel、ChannelHandler、ChannelPipe等，先大概了解下这几个组件的作用。\n【ChannelHandler】\nChannelHandler充当了处理入站和出站数据的应用程序逻辑容器。例如，实现ChannelInboundHandler接口（或ChannelInboundHandlerAdapter），你就可以接收入站事件和数据，这些数据随后会被你的应用程序的业务逻辑处理。当你要给连接的客户端发送响应时，也可以从ChannelInboundHandler冲刷数据。你的业务逻辑通常写在一个或者多个ChannelInboundHandler中。ChannelOutboundHandler原理一样，只不过它是用来处理出站数据的。\n【ChannelPipeline】\nChannelPipeline提供了ChannelHandler链的容器。以客户端应用程序为例，如果事件的运动方向是从客户端到服务端的，那么我们称这些事件为出站的，即客户端发送给服务端的数据会通过pipeline中的一系列ChannelOutboundHandler(ChannelOutboundHandler调用是从tail到head方向逐个调用每个handler的逻辑)，并被这些Handler处理，反之则称为入站的，**入站只调用pipeline里的ChannelInboundHandler逻辑(ChannelInboundHandler调用是从head到tail方向逐个调用每个handler的逻辑)**。\n\n编码解码器当你通过Netty发送或者接受一个消息的时候，就将会发生一次数据转换。入站消息会被解码：从字节转换为另一种格式（比如java对象）；如果是出站消息，它会被编码成字节。\nNetty提供了一系列实用的编码解码器，他们都实现了ChannelInboundHadnler或者ChannelOutboundHandler接口。在这些类中，channelRead方法已经被重写了。以入站为例，对于每个从入站Channel读取的消息，这个方法会被调用。随后，它将调用由已知解码器所提供的decode()方法进行解码，并将已经解码的字节转发给ChannelPipeline中的下一个ChannelInboundHandler。\nNetty提供了很多编解码器，比如编解码字符串的StringEncoder和StringDecoder，编解码对象的ObjectEncoder和ObjectDecoder等。\n如果要实现高效的编解码可以用protobuf，但是protobuf需要维护大量的proto文件比较麻烦，现在一般可以使用protostuff。\nprotostuff是一个基于protobuf实现的序列化方法，它较于protobuf最明显的好处是，在几乎不损耗性能的情况下做到了不用我们写.proto文件来实现序列化。使用它也非常简单。\n代码如下：\n&lt;dependency&gt;    &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt;    &lt;artifactId&gt;protostuff-api&lt;/artifactId&gt;    &lt;version&gt;1.0.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt;    &lt;artifactId&gt;protostuff-core&lt;/artifactId&gt;    &lt;version&gt;1.0.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt;    &lt;artifactId&gt;protostuff-runtime&lt;/artifactId&gt;    &lt;version&gt;1.0.10&lt;/version&gt;&lt;/dependency&gt;\n\nprotostuff使用示例：\nimport com.dyuproject.protostuff.LinkedBuffer;import com.dyuproject.protostuff.ProtostuffIOUtil;import com.dyuproject.protostuff.Schema;import com.dyuproject.protostuff.runtime.RuntimeSchema;import java.util.Map;import java.util.concurrent.ConcurrentHashMap;/** * protostuff 序列化工具类，基于protobuf封装 */public class ProtostuffUtil &#123;    private static Map&lt;Class&lt;?&gt;, Schema&lt;?&gt;&gt; cachedSchema = new ConcurrentHashMap&lt;Class&lt;?&gt;, Schema&lt;?&gt;&gt;();    private static &lt;T&gt; Schema&lt;T&gt; getSchema(Class&lt;T&gt; clazz) &#123;        @SuppressWarnings(&quot;unchecked&quot;)        Schema&lt;T&gt; schema = (Schema&lt;T&gt;) cachedSchema.get(clazz);        if (schema == null) &#123;            schema = RuntimeSchema.getSchema(clazz);            if (schema != null) &#123;                cachedSchema.put(clazz, schema);            &#125;        &#125;        return schema;    &#125;    /**     * 序列化     *     * @param obj     * @return     */    public static &lt;T&gt; byte[] serializer(T obj) &#123;        @SuppressWarnings(&quot;unchecked&quot;)        Class&lt;T&gt; clazz = (Class&lt;T&gt;) obj.getClass();        LinkedBuffer buffer = LinkedBuffer.allocate(LinkedBuffer.DEFAULT_BUFFER_SIZE);        try &#123;            Schema&lt;T&gt; schema = getSchema(clazz);            return ProtostuffIOUtil.toByteArray(obj, schema, buffer);        &#125; catch (Exception e) &#123;            throw new IllegalStateException(e.getMessage(), e);        &#125; finally &#123;            buffer.clear();        &#125;    &#125;    /**     * 反序列化     *     * @param data     * @param clazz     * @return     */    public static &lt;T&gt; T deserializer(byte[] data, Class&lt;T&gt; clazz) &#123;        try &#123;            T obj = clazz.newInstance();            Schema&lt;T&gt; schema = getSchema(clazz);            ProtostuffIOUtil.mergeFrom(data, obj, schema);            return obj;        &#125; catch (Exception e) &#123;            throw new IllegalStateException(e.getMessage(), e);        &#125;    &#125;    public static void main(String[] args) &#123;        byte[] userBytes = ProtostuffUtil.serializer(new User(1, &quot;zhuge&quot;));        User user = ProtostuffUtil.deserializer(userBytes, User.class);        System.out.println(user);    &#125;&#125;\n\nNetty粘包拆包TCP是一个流协议，就是没有界限的一长串二进制数据。TCP作为传输层协议并不不了解上层业务数据的具体含义，它会根据TCP缓冲区的实际情况进行数据包的划分，所以在业务上认为是一个完整的包，可能会被TCP拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，这就是所谓的TCP粘包和拆包问题。面向流的通信是无消息保护边界的。\n如下图所示，client发了两个数据包D1和D2，但是server端可能会收到如下几种情况的数据。\n\n解决方案:定义报文边界\n\n消息定长度，传输的数据大小固定长度，例如每段的长度固定为100字节，如果不够空位补空格\n在数据包尾部添加特殊分隔符，比如下划线，中划线等，这种方法简单易行，但选择分隔符的时候一定要注意每条数据的内部一定不能出现分隔符。\n发送长度：发送每条数据的时候，将数据的长度一并发送，比如可以选择每条数据的前4位是数据的长度，应用层处理时可以根据长度来判断每条数据的开始和结束。\n\nNetty提供了多个解码器，可以进行分包的操作，如下：\n\nLineBasedFrameDecoder （回车换行分包）\nDelimiterBasedFrameDecoder（特殊分隔符分包）\nFixedLengthFrameDecoder（固定长度报文来分包）\n\nNetty心跳检测机制所谓心跳, 即在 TCP 长连接中, 客户端和服务器之间定期发送的一种特殊的数据包, 通知对方自己还在线, 以确保 TCP 连接的有效性.\n在 Netty 中, 实现心跳机制的关键是 IdleStateHandler, 看下它的构造器：\npublic IdleStateHandler(int readerIdleTimeSeconds, int writerIdleTimeSeconds, int allIdleTimeSeconds) &#123;    this((long)readerIdleTimeSeconds, (long)writerIdleTimeSeconds, (long)allIdleTimeSeconds, TimeUnit.SECONDS);&#125;\n\n这里解释下三个参数的含义：\n\nreaderIdleTimeSeconds: 读超时. 即当在指定的时间间隔内没有从 Channel 读取到数据时, 会触发一个 READER_IDLE 的 IdleStateEvent 事件.\nwriterIdleTimeSeconds: 写超时. 即当在指定的时间间隔内没有数据写入到 Channel 时, 会触发一个 WRITER_IDLE 的 IdleStateEvent 事件.\nallIdleTimeSeconds: 读/写超时. 即当在指定的时间间隔内没有读或写操作时, 会触发一个 ALL_IDLE 的 IdleStateEvent 事件.\n\n注：这三个参数默认的时间单位是秒。若需要指定其他时间单位，可以使用另一个构造方法：\nIdleStateHandler(boolean observeOutput, long readerIdleTime, long writerIdleTime, long allIdleTime, TimeUnit unit)\n\n要实现Netty服务端心跳检测机制需要在服务器端的ChannelInitializer中加入如下的代码：\npipeline.addLast(new IdleStateHandler(3, 0, 0, TimeUnit.SECONDS));\n\n初步地看下IdleStateHandler源码，先看下IdleStateHandler中的channelRead方法：\n\n红框代码其实表示该方法只是进行了透传，不做任何业务逻辑处理，让channelPipe中的下一个handler处理channelRead方法\n我们再看看channelActive方法：\n\n这里有个initialize的方法，这是IdleStateHandler的精髓，接着探究：\n\n这边会触发一个Task，ReaderIdleTimeoutTask，这个task里的run方法源码是这样的：\n\n第一个红框代码是用当前时间减去最后一次channelRead方法调用的时间，假如这个结果是6s，说明最后一次调用channelRead已经是6s之前的事情了，你设置的是5s，那么nextDelay则为-1，说明超时了，那么第二个红框代码则会触发下一个handler的userEventTriggered方法：\n\n如果没有超时则不触发userEventTriggered方法。\nNetty心跳检测代码示例：\n//服务端代码public class HeartBeatServer &#123;    public static void main(String[] args) throws Exception &#123;        EventLoopGroup boss = new NioEventLoopGroup();        EventLoopGroup worker = new NioEventLoopGroup();        try &#123;            ServerBootstrap bootstrap = new ServerBootstrap();            bootstrap.group(boss, worker)                .channel(NioServerSocketChannel.class)                .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123;                    @Override                    protected void initChannel(SocketChannel ch) throws Exception &#123;                        ChannelPipeline pipeline = ch.pipeline();                        pipeline.addLast(&quot;decoder&quot;, new StringDecoder());                        pipeline.addLast(&quot;encoder&quot;, new StringEncoder());                        //IdleStateHandler的readerIdleTime参数指定超过3秒还没收到客户端的连接，                        //会触发IdleStateEvent事件并且交给下一个handler处理，下一个handler必须                        //实现userEventTriggered方法处理对应事件                        pipeline.addLast(new IdleStateHandler(3, 0, 0, TimeUnit.SECONDS));                        pipeline.addLast(new HeartBeatHandler());                    &#125;                &#125;);            System.out.println(&quot;netty server start。。&quot;);            ChannelFuture future = bootstrap.bind(9000).sync();            future.channel().closeFuture().sync();        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125; finally &#123;            worker.shutdownGracefully();            boss.shutdownGracefully();        &#125;    &#125;&#125;\n\n//服务端处理handlerpublic class HeartBeatServerHandler extends SimpleChannelInboundHandler&lt;String&gt; &#123;    int readIdleTimes = 0;    @Override    protected void channelRead0(ChannelHandlerContext ctx, String s) throws Exception &#123;        System.out.println(&quot; ====== &gt; [server] message received : &quot; + s);        if (&quot;Heartbeat Packet&quot;.equals(s)) &#123;            ctx.channel().writeAndFlush(&quot;ok&quot;);        &#125; else &#123;            System.out.println(&quot; 其他信息处理 ... &quot;);        &#125;    &#125;    @Override    public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123;        IdleStateEvent event = (IdleStateEvent) evt;        String eventType = null;        switch (event.state()) &#123;            case READER_IDLE:                eventType = &quot;读空闲&quot;;                readIdleTimes++; // 读空闲的计数加1                break;            case WRITER_IDLE:                eventType = &quot;写空闲&quot;;                // 不处理                break;            case ALL_IDLE:                eventType = &quot;读写空闲&quot;;                // 不处理                break;        &#125;        System.out.println(ctx.channel().remoteAddress() + &quot;超时事件：&quot; + eventType);        if (readIdleTimes &gt; 3) &#123;            System.out.println(&quot; [server]读空闲超过3次，关闭连接，释放更多资源&quot;);            ctx.channel().writeAndFlush(&quot;idle close&quot;);            ctx.channel().close();        &#125;    &#125;    @Override    public void channelActive(ChannelHandlerContext ctx) throws Exception &#123;        System.err.println(&quot;=== &quot; + ctx.channel().remoteAddress() + &quot; is active ===&quot;);    &#125;&#125;\n\n//客户端代码public class HeartBeatClient &#123;    public static void main(String[] args) throws Exception &#123;        EventLoopGroup eventLoopGroup = new NioEventLoopGroup();        try &#123;            Bootstrap bootstrap = new Bootstrap();            bootstrap.group(eventLoopGroup).channel(NioSocketChannel.class)                .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123;                    @Override                    protected void initChannel(SocketChannel ch) throws Exception &#123;                        ChannelPipeline pipeline = ch.pipeline();                        pipeline.addLast(&quot;decoder&quot;, new StringDecoder());                        pipeline.addLast(&quot;encoder&quot;, new StringEncoder());                        pipeline.addLast(new HeartBeatClientHandler());                    &#125;                &#125;);            System.out.println(&quot;netty client start。。&quot;);            Channel channel = bootstrap.connect(&quot;127.0.0.1&quot;, 9000).sync().channel();            String text = &quot;Heartbeat Packet&quot;;            Random random = new Random();            while (channel.isActive()) &#123;                int num = random.nextInt(10);                Thread.sleep(num * 1000);                channel.writeAndFlush(text);            &#125;        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125; finally &#123;            eventLoopGroup.shutdownGracefully();        &#125;    &#125;    static class HeartBeatClientHandler extends SimpleChannelInboundHandler&lt;String&gt; &#123;        @Override        protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception &#123;            System.out.println(&quot; client received :&quot; + msg);            if (msg != null &amp;&amp; msg.equals(&quot;idle close&quot;)) &#123;                System.out.println(&quot; 服务端关闭连接，客户端也关闭&quot;);                ctx.channel().closeFuture();            &#125;        &#125;    &#125;&#125;\n\nNetty断线自动重连实现\n客户端启动连接服务端时，如果网络或服务端有问题，客户端连接失败，可以重连，重连的逻辑加在客户端。参见代码com.test.netty.reconnect.NettyClient\n系统运行过程中网络故障或服务端故障，导致客户端与服务端断开连接了也需要重连，可以在客户端处理数据的Handler的channelInactive方法中进行重连。参见代码com.test.netty.reconnect.NettyClientHandler\n\n","categories":["中间件"],"tags":["Netty"]},{"title":"Redis持久化、主从与哨兵架构详解","url":"/2021/11/29/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E3%80%81%E4%B8%BB%E4%BB%8E%E4%B8%8E%E5%93%A8%E5%85%B5%E6%9E%B6%E6%9E%84%E8%AF%A6%E8%A7%A3/","content":"Redis持久化RDB快照（snapshot）在默认情况下， Redis 将内存数据库快照保存在名字为 dump.rdb 的二进制文件中。你可以对 Redis 进行设置， 让它在“ N 秒内数据集至少有 M 个改动”这一条件被满足时， 自动保存一次数据集。比如说， 以下设置会让 Redis 在满足“ 60 秒内有至少有 1000 个键被改动”这一条件时， 自动保存一次数据集：\n# save 60 1000    //关闭RDB只需要将所有的save保存策略注释掉即可\n\n还可以手动执行命令生成RDB快照，进入redis客户端执行命令save或bgsave可以生成dump.rdb文件，每次命令执行都会将所有redis内存快照到一个新的rdb文件里，并覆盖原有rdb快照文件。\nbgsave的写时复制(COW)机制Redis 借助操作系统提供的写时复制技术（Copy-On-Write, COW），在生成快照的同时，依然可以正常处理写命令。简单来说，bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。此时，如果主线程对这些数据也都是读操作，那么，主线程和 bgsave 子进程相互不影响。但是，如果主线程要修改一块数据，那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。\nsave与bgsave对比：\n\n\n\n命令\nsave\nbgsave\n\n\n\nIO类型\n同步\n异步\n\n\n是否阻塞redis其它命令\n是\n否(在生成子进程执行调用fork函数时会有短暂阻塞)\n\n\n复杂度\nO(n)\nO(n)\n\n\n优点\n不会消耗额外内存\n不阻塞客户端命令\n\n\n缺点\n阻塞客户端命令\n需要fork子进程，消耗内存\n\n\n配置自动生成rdb文件后台使用的是bgsave方式。\nAOF（append-only file）快照功能并不是非常耐久（durable）： 如果 Redis 因为某些原因而造成故障停机， 那么服务器将丢失最近写入、且仍未保存到快照中的那些数据。从 1.1 版本开始， Redis 增加了一种完全耐久的持久化方式： AOF 持久化，将修改的每一条指令记录进文件appendonly.aof中(先写入os cache，每隔一段时间fsync到磁盘)\n比如执行命令“set zhuge 666”，aof文件里会记录如下数据\n*3$3set$5zhuge$3666\n\n这是一种resp协议格式数据，星号后面的数字代表命令有多少个参数，$号后面的数字代表这个参数有几个字符\n注意，如果执行带过期时间的set命令，aof文件里记录的是并不是执行的原始命令，而是记录key过期的时间戳\n比如执行“set tuling 888 ex 1000”，对应aof文件里记录如下\n*3$3set$6tuling$3888*3$9PEXPIREAT$6tuling$131604249786301\n\n可以通过修改配置文件来打开 AOF 功能：\n# appendonly yes\n\n从现在开始， 每当 Redis 执行一个改变数据集的命令时（比如 SET）， 这个命令就会被追加到 AOF 文件的末尾。\n这样的话， 当 Redis 重新启动时， 程序就可以通过重新执行 AOF 文件中的命令来达到重建数据集的目的。\n你可以配置 Redis 多久才将数据 fsync 到磁盘一次。\n有三个选项\nappendfsync always   #每次有新命令追加到 AOF 文件时就执行一次 fsync ，非常慢，也非常安全。appendfsync everysec #每秒 fsync 一次，足够快，并且在故障时只会丢失 1 秒钟的数据。appendfsync no       #从不 fsync ，将数据交给操作系统来处理。更快，也更不安全的选择。\n\n推荐（并且也是默认）的措施为每秒 fsync 一次， 这种 fsync 策略可以兼顾速度和安全性。\nAOF重写AOF文件里可能有太多没用指令，所以AOF会定期根据内存的最新数据生成aof文件\n例如，执行了如下几条命令：\n127.0.0.1:6379&gt; incr readcount(integer) 1127.0.0.1:6379&gt; incr readcount(integer) 2127.0.0.1:6379&gt; incr readcount(integer) 3127.0.0.1:6379&gt; incr readcount(integer) 4127.0.0.1:6379&gt; incr readcount(integer) 5\n\n重写后AOF文件里变成\n*3$3SET$2readcount$15\n\n如下两个配置可以控制AOF自动重写频率\n# auto-aof-rewrite-min-size 64mb   //aof文件至少要达到64M才会自动重写，文件太小恢复速度本来就很快，重写的意义不大# auto-aof-rewrite-percentage 100  //aof文件自上一次重写后文件大小增长了100%则再次触发重写\n\n当然AOF还可以手动重写，进入redis客户端执行命令bgrewriteaof重写AOF\n注意，AOF重写redis会fork出一个子进程去做(与bgsave命令类似)，不会对redis正常命令处理有太多影响\nRDB 和 AOF ，我应该用哪一个？\n\n\n\n命令\nRDB\nAOF\n\n\n\n启动优先级\n低\n高\n\n\n体积\n小\n大\n\n\n恢复速度\n快\n慢\n\n\n数据安全性\n容易丢数据\n根据策略决定\n\n\n生产环境可以都启用，redis启动时如果既有rdb文件又有aof文件则优先选择aof文件恢复数据，因为aof一般来说数据更全一点。\nRedis 4.0 混合持久化重启 Redis 时，我们很少使用 RDB来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 RDB来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。 Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。\n通过如下配置可以开启混合持久化(必须先开启aof)：\n# aof-use-rdb-preamble yes\n\n如果开启了混合持久化，AOF在重写时，不再是单纯将内存数据转换为RESP命令写入AOF文件，而是将重写这一刻之前的内存做RDB快照处理，并且将RDB快照内容和增量的AOF修改内存数据的命令存在一起，都写入新的AOF文件，新的文件一开始不叫appendonly.aof，等到重写完新的AOF文件才会进行改名，覆盖原有的AOF文件，完成新旧两个AOF文件的替换。\n于是在 Redis 重启的时候，可以先加载 RDB 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，因此重启效率大幅得到提升。\n混合持久化AOF文件结构如下\n\n Redis数据备份策略：\n\n写crontab定时调度脚本，每小时都copy一份rdb或aof的备份到一个目录中去，仅仅保留最近48小时的备份\n每天都保留一份当日的数据备份到一个目录中去，可以保留最近1个月的备份\n每次copy备份的时候，都把太旧的备份给删了\n每天晚上将当前机器上的备份复制一份到其他机器上，以防机器损坏\n\nRedis主从架构\nredis主从架构搭建，配置从节点步骤：\n# 1、复制一份redis.conf文件# 2、将相关配置修改为如下值：port 6380pidfile /var/run/redis_6380.pid  # 把pid进程号写入pidfile配置的文件logfile &quot;6380.log&quot;dir /usr/local/redis-5.0.3/data/6380  # 指定数据存放目录# 需要注释掉bind# bind 127.0.0.1（bind绑定的是自己机器网卡的ip，如果有多块网卡可以配多个ip，代表允许客户端通过机器的哪些网卡ip去访问，内网一般可以不配置bind，注释掉即可）# 3、配置主从复制replicaof 192.168.0.60 6379   # 从本机6379的redis实例复制数据，Redis 5.0之前使用slaveofreplica-read-only yes  # 配置从节点只读# 4、启动从节点redis-server redis.conf# 5、连接从节点redis-cli -p 6380# 6、测试在6379实例上写数据，6380实例是否能及时同步新修改数据# 7、可以自己再配置一个6381的从节点\n\nRedis主从工作原理如果你为master配置了一个slave，不管这个slave是否是第一次连接上Master，它都会发送一个PSYNC命令给master请求复制数据。\nmaster收到PSYNC命令后，会在后台进行数据持久化通过bgsave生成最新的rdb快照文件，持久化期间，master会继续接收客户端的请求，它会把这些可能修改数据集的请求缓存在内存中。当持久化进行完毕以后，master会把这份rdb文件数据集发送给slave，slave会把接收到的数据进行持久化生成rdb，然后再加载到内存中。然后，master再将之前缓存在内存中的命令发送给slave。\n当master与slave之间的连接由于某些原因而断开时，slave能够自动重连Master，如果master收到了多个slave并发连接请求，它只会进行一次持久化，而不是一个连接一次，然后再把这一份持久化的数据发送给多个并发连接的slave。\n当master与slave之间的连接由于某些原因而断开时，slave能够自动重连Master，如果master收到了多个slave并发连接请求，它只会进行一次持久化，而不是一个连接一次，然后再把这一份持久化的数据发送给多个并发连接的slave。\n主从复制(全量复制)流程图：\n\n数据部分复制当master和slave断开重连后，一般都会对整份数据进行复制。但从redis2.8版本开始，redis改用可以支持部分数据复制的命令PSYNC去master同步数据，slave与master能够在网络连接断开重连后只进行部分数据复制(断点续传)。\nmaster会在其内存中创建一个复制数据用的缓存队列，缓存最近一段时间的数据，master和它所有的slave都维护了复制的数据下标offset和master的进程id，因此，当网络连接断开后，slave会请求master继续进行未完成的复制，从所记录的数据下标开始。如果master进程id变化了，或者从节点数据下标offset太旧，已经不在master的缓存队列里了，那么将会进行一次全量数据的复制。\n主从复制(部分复制，断点续传)流程图：\n\n如果有很多从节点，为了缓解主从复制风暴(多个从节点同时复制主节点导致主节点压力过大)，可以做如下架构，让部分从节点与从节点(与主节点同步)同步数据\n\nredis管道与调用lua脚本管道（Pipeline）客户端可以一次性发送多个请求而不用等待服务器的响应，待所有命令都发送完后再一次性读取服务的响应，这样可以极大的降低多条命令执行的网络传输开销，管道执行多条命令的网络开销实际上只相当于一次命令执行的网络开销。需要注意到是用pipeline方式打包命令发送，redis必须在处理完所有命令前先缓存起所有命令的处理结果。打包的命令越多，缓存消耗内存也越多。所以并不是打包的命令越多越好。\npipeline中发送的每个command都会被server立即执行，如果执行失败，将会在此后的响应中得到信息；也就是pipeline并不是表达“所有command都一起成功”的语义，管道中前面命令失败，后面命令不会有影响，继续执行。\nRedis Lua脚本Redis在2.6推出了脚本功能，允许开发者使用Lua语言编写脚本传到Redis中执行。使用脚本的好处如下:\n\n减少网络开销：本来5次网络请求的操作，可以用一个请求完成，原先5次请求的逻辑放在redis服务器上完成。使用脚本，减少了网络往返时延。这点跟管道类似。\n原子操作：Redis会将整个脚本作为一个整体执行，中间不会被其他命令插入。管道不是原子的，不过redis的批量操作命令(类似mset)是原子的。\n替代redis的事务功能：redis自带的事务功能很鸡肋，而redis的lua脚本几乎实现了常规的事务功能，官方推荐如果要使用redis的事务功能可以用redis lua替代。\n\n官网文档上有这样一段话：\n\nA Redis script is transactional by definition, so everything you can do with a Redis transaction, you can also do with a script,  and usually the script will be both simpler and faster.              \n\n从Redis2.6.0版本开始，通过内置的Lua解释器，可以使用EVAL命令对Lua脚本进行求值。EVAL命令的格式如下：\nEVAL script numkeys key [key ...] arg [arg ...]　\n\nscript参数是一段Lua脚本程序，它会被运行在Redis服务器上下文中，这段脚本不必(也不应该)定义为一个Lua函数。numkeys参数用于指定键名参数的个数。键名参数 key [key …] 从EVAL的第三个参数开始算起，表示在脚本中所用到的那些Redis键(key)，这些键名参数可以在 Lua中通过全局变量KEYS数组，用1为基址的形式访问( KEYS[1] ， KEYS[2] ，以此类推)。\n在命令的最后，那些不是键名参数的附加参数 arg [arg …] ，可以在Lua中通过全局变量ARGV数组访问，访问的形式和KEYS变量类似( ARGV[1] 、 ARGV[2] ，诸如此类)。\n例如：\n127.0.0.1:6379&gt; eval &quot;return &#123;KEYS[1],KEYS[2],ARGV[1],ARGV[2]&#125;&quot; 2 key1 key2 first second1) &quot;key1&quot;2) &quot;key2&quot;3) &quot;first&quot;4) &quot;second&quot;\n\n其中 “return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}” 是被求值的Lua脚本，数字2指定了键名参数的数量， key1和key2是键名参数，分别使用 KEYS[1] 和 KEYS[2] 访问，而最后的 first 和 second 则是附加参数，可以通过 ARGV[1] 和 ARGV[2] 访问它们。\n在 Lua 脚本中，可以使用**redis.call()**函数来执行Redis命令\nJedis调用示例详见上面jedis连接示例：\njedis.set(&quot;product_stock_10016&quot;, &quot;15&quot;);  //初始化商品10016的库存String script = &quot; local count = redis.call(&#x27;get&#x27;, KEYS[1]) &quot; +                &quot; local a = tonumber(count) &quot; +                &quot; local b = tonumber(ARGV[1]) &quot; +                &quot; if a &gt;= b then &quot; +                &quot;   redis.call(&#x27;set&#x27;, KEYS[1], a-b) &quot; +                &quot;   return 1 &quot; +                &quot; end &quot; +                &quot; return 0 &quot;;Object obj = jedis.eval(script, Arrays.asList(&quot;product_stock_10016&quot;), Arrays.asList(&quot;10&quot;));System.out.println(obj);\n\n注意，不要在Lua脚本中出现死循环和耗时的运算，否则redis会阻塞，将不接受其他的命令， 所以使用时要注意不能出现死循环、耗时的运算。redis是单进程、单线程执行脚本。管道不会阻塞redis。\nRedis哨兵高可用架构\nsentinel哨兵是特殊的redis服务，不提供读写服务，主要用来监控redis实例节点。\n哨兵架构下client端第一次从哨兵找出redis的主节点，后续就直接访问redis的主节点，不会每次都通过sentinel代理访问redis的主节点，当redis的主节点发生变化，哨兵会第一时间感知到，并且将新的redis主节点通知给client端(这里面redis的client端一般都实现了订阅功能，订阅sentinel发布的节点变动消息)\nredis哨兵架构搭建步骤：\n# 1、复制一份sentinel.conf文件cp sentinel.conf sentinel-26379.conf# 2、将相关配置修改为如下值：port 26379daemonize yespidfile &quot;/var/run/redis-sentinel-26379.pid&quot;logfile &quot;26379.log&quot;dir &quot;/usr/local/redis-5.0.3/data&quot;# sentinel monitor &lt;master-redis-name&gt; &lt;master-redis-ip&gt; &lt;master-redis-port&gt; &lt;quorum&gt;# quorum是一个数字，指明当有多少个sentinel认为一个master失效时(值一般为：sentinel总数/2 + 1)，master才算真正失效sentinel monitor mymaster 192.168.0.60 6379 2   # mymaster这个名字随便取，客户端访问时会用到# 3、启动sentinel哨兵实例src/redis-sentinel sentinel-26379.conf# 4、查看sentinel的info信息src/redis-cli -p 26379127.0.0.1:26379&gt;info可以看到Sentinel的info里已经识别出了redis的主从# 5、可以自己再配置两个sentinel，端口26380和26381，注意上述配置文件里的对应数字都要修改\n\nsentinel集群都启动完毕后，会将哨兵集群的元数据信息写入所有sentinel的配置文件里去(追加在文件的最下面)，我们查看下如下配置文件sentinel-26379.conf，如下所示：\nsentinel known-replica mymaster 192.168.0.60 6380 #代表redis主节点的从节点信息sentinel known-replica mymaster 192.168.0.60 6381 #代表redis主节点的从节点信息sentinel known-sentinel mymaster 192.168.0.60 26380 52d0a5d70c1f90475b4fc03b6ce7c3c56935760f  #代表感知到的其它哨兵节点sentinel known-sentinel mymaster 192.168.0.60 26381 e9f530d3882f8043f76ebb8e1686438ba8bd5ca6  #代表感知到的其它哨兵节点\n\n当redis主节点如果挂了，哨兵集群会重新选举出新的redis主节点，同时会修改所有sentinel节点配置文件的集群元数据信息，比如6379的redis如果挂了，假设选举出的新主节点是6380，则sentinel文件里的集群元数据信息会变成如下所示：\nsentinel known-replica mymaster 192.168.0.60 6379 #代表主节点的从节点信息sentinel known-replica mymaster 192.168.0.60 6381 #代表主节点的从节点信息sentinel known-sentinel mymaster 192.168.0.60 26380 52d0a5d70c1f90475b4fc03b6ce7c3c56935760f  #代表感知到的其它哨兵节点sentinel known-sentinel mymaster 192.168.0.60 26381 e9f530d3882f8043f76ebb8e1686438ba8bd5ca6  #代表感知到的其它哨兵节点\n\n同时还会修改sentinel文件里之前配置的mymaster对应的6379端口，改为6380\nsentinel monitor mymaster 192.168.0.60 6380 2\n\n当6379的redis实例再次启动时，哨兵集群根据集群元数据信息就可以将6379端口的redis节点作为从节点加入集群\n","categories":["中间件"],"tags":["Redis"]},{"title":"Redis核心设计原理","url":"/2021/09/10/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/Redis%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/","content":"redisDB数据结构redis内存存储数据的数据结构为数组，即存储的key进行hash运算后对数组大小取模，即可得到value所在的位置。由于存在hash碰撞，数组中存储的为单向链表，每个链表存在一个指向下一个数据的指针，redis采用头插法，当发生hash碰撞时，会将数据放入头部。hash table默认数组大小为4。\ntypedef struct redisDb &#123;    dict *dict; /* redisDb数据存储的具体位置 */                   dict *expires;              dict *blocking_keys;              dict *ready_keys;               dict *watched_keys;             int id;                          long long avg_ttl;               unsigned long expires_cursor;      list *defrag_later;          &#125; redisDb;/* 里面定义了两个dictht，就是为了在扩容时，进行渐进式rehash */typedef struct dict &#123;    dictType *type;    void *privdata;    dictht ht[2];    long rehashidx;     unsigned long iterators;      &#125; dict;/* 这个是数据存储的hash table */typedef struct dictht &#123;    dictEntry **table; /* 数组 */    unsigned long size; /* 数组长度 */    unsigned long sizemask;/* size-1 */    unsigned long used;/* hash table 元素个数 */&#125; dictht;/* 每个具体的数据所存储结构 */typedef struct dictEntry &#123;    void *key; /* 数据所对应的key,即SDS对象 */    union &#123;        void *val;/* 指向redisObject */        uint64_t u64;        int64_t s64;        double d;    &#125; v;    struct dictEntry *next; /* 在产生hash碰撞时，指向下一个对象 */&#125; dictEntry;typedef struct redisObject &#123;    unsigned type:4;       // 4  bite 数据的具体类型，用来指定当前value的数据类型 如string,set,zset,list,hash    unsigned encoding:4;   // 4  bite 数据的value在redis底层所对应的数据类型 如 int,row,embstr,ziplist等    unsigned lru:LRU_BITS; // 24 byte     int refcount;          // 4  byte 引用计数法来管理内存    void *ptr;             // 8  byte 数据真实所存在的地址&#125; robj;\t\t\t\t\t   // redisObject总大小为16 byte\n\n渐进式rehash当dictht中used:size=1:1时，redisDb会进行扩容，每次会扩大一倍的大小，如果扩容前数据量较大时，进行扩容并将老数组中的数据迁移到新数组会消耗掉大量的资源造成客户端的卡顿，所以redis没有采用扩容后直接将老数据迁移到新数组中，而是会进行渐进式的rehash，即在扩容的过程中当客户端访问某个key时，先在ht[0]中来查询value是否存在，如果不存在会去ht[1]中查询；如果ht[0]中存在的话，计算这个key所在原桶的位置，并将这个桶中所有的数据都迁移到新的桶中。如果长时间没有进行访问，会通过事件的轮询来进行迁移。在将所有的数据均迁移完后，将ht[0]指向新的数组，并将ht[1]指向null,代表迁移完毕。\nhash确定桶的下角标优化在hash桶的大小为2^n的时候，在对hash值确定桶的位置时可以通过hash%2^n来确定，而模运算相对于位运算操作的时间不是一个数量级，可以进行优化，在对hash值确定桶的位置时，可以通过hash&amp;(2^n-1)来确定。但是前提是桶的长度必须是2^n\nString设计理念底层数据结构Redis中所有的key都是String类型的数据结构，由于Redis是由C语言进行编写的，C语言存储字符串会在字符串末尾添加“\\0”来区分边界。如果是这样的话，在我们存储二进制带有\\0的数据时，会导致数据的丢失。所以Redis存储字符串时，用的是自己的数据结构SDS（Simple Dynamic String），结构如下（redis3.2之前）：\nstruct sdshdr &#123;    int len;    int free;    char buf[];&#125;;\n\n在进行append,bitmap操作的时候，字符串会进行扩容，buf并不会扩容拼接大小，而是会扩容到(len+addlen)*2大小，len中记录的是数据的大小，而free中则记录的是数组的空闲大小，在buf大小超过1M 即1024*1024个字符后，每次扩容时，均会增大1M，不会遵循(len+addlen)*2来进行扩容。所以为了避免空间的浪费，尽量数据不要大于1M。\n在buf中为了兼容c语言的函数库，SDS会在最后追加\\0。\n综上，Redis设计SDS数据结构的有点为：\n\n提供二进制安全的数据结构\n提供了内存预分配机制，避免了频繁的内存分配（空间换时间）\n兼容C语言函数库\n\n在redis3.2之后，SDS数据结构发生了改变:\ntypedef char *sds;struct __attribute__ ((__packed__)) sdshdr5 &#123;    unsigned char flags; /* 3 lsb of type, and 5 msb of string length */    char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr8 &#123;    uint8_t len; /* used */    uint8_t alloc; /* excluding the header and null terminator */    unsigned char flags; /* 3 lsb of type, 5 unused bits */    char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr16 &#123;    uint16_t len; /* used */    uint16_t alloc; /* excluding the header and null terminator */    unsigned char flags; /* 3 lsb of type, 5 unused bits */    char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr32 &#123;    uint32_t len; /* used */    uint32_t alloc; /* excluding the header and null terminator */    unsigned char flags; /* 3 lsb of type, 5 unused bits */    char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr64 &#123;........\n\n\nbuf：存储数据大小\nalloc：已分配大小，即buf大小\nlen：总大小\n\n为什么对len进行了区分？因为int类型占4个字节，4*8bit=32bit,大约40亿的大小，而buf中存储这么大的数据的可能性不是很大，就造成了len资源的浪费，所以redis3.2之后，将len进行了分段。\n\n在数据向左偏移一个字节后，会得到flags标识，这个标识总共占五位，通过前三位可以确定数据用哪个数据结构来进行存储。\n#define SDS_TYPE_5  0#define SDS_TYPE_8  1#define SDS_TYPE_16 2#define SDS_TYPE_32 3#define SDS_TYPE_64 4\n\n底层编码对于数据类型String来讲，底层的编码结构有三种\n\nembstr\nint\nraw\n\ninttypedef struct redisObject &#123;    unsigned type:4;       // 4  bite 数据的具体类型，用来指定当前value的数据类型 如string,set,zset,list,hash    unsigned encoding:4;   // 4  bite 数据的value在redis底层所对应的数据类型 如 int,row,embstr,ziplist等    unsigned lru:LRU_BITS; // 24 byte     int refcount;          // 4  byte 引用计数法来管理内存    void *ptr;             // 8  byte 数据真实所存在的地址&#125; robj;\t\t\t\t\t   // redisObject总大小为16 byte\n\nredisObject中，在set值得时候，通过sdslen来获取value的字符串长度，如果字符串长度小于等于20，并且可以转换为long，则直接可以通过*ptr来存储所对应的value,这样减少了存储空间的并且减少了一次CPU的IO，因为如果*ptr存储对应的地址的话，还需要通过地址获取到对应的值。\nembstr（embedded string）CPU在获取内存的时候，并不是每次可以获取随意的大小，内存操作的最基本单位是cache line，每个cache line占64byte。而redisObject的大小为16 byte,在一次内存的获取中，多余的48 byte可能没有用，并且还需要通过*ptr再一次获取到真实的数据。那可不可以把48 byte利用上呢?对于sdshdr8来讲，len占用1个字节，alloc占用一个字节，flags占用一个字节，由于兼容c语言函数库，会在buf末尾拼接上\\0也会占用一个字节，此时还剩下44个字节，所以如果存储的字符串长度小于等于44时，会优化为embstr，这样的好处是内存一次读取的操作，就可以将值获取出来。\nstruct __attribute__ ((__packed__)) sdshdr8 &#123;    uint8_t len; /* used */    uint8_t alloc; /* excluding the header and null terminator */    unsigned char flags; /* 3 lsb of type, 5 unused bits */    char buf[];&#125;;\n\nraw就是最原始的SDS数据。\nbitmap底层数据结构底层数据结构为string,编码格式为sdshdr32,即位图存储数据最大为2^32-1，\nstruct __attribute__ ((__packed__)) sdshdr32 &#123;    uint32_t len; /* used */    uint32_t alloc; /* excluding the header and null terminator */    unsigned char flags; /* 3 lsb of type, 5 unused bits */    char buf[];&#125;;\n\nbitcount怎么实现的？汉明重量，通过位运算来进行统计的\nList底层设计list底层设计的时候，没通过链表去实现，可以看到redis中的list是双向链表，如果在64位操作系统中进行实现的话，每个对象需要包含一个指向前一个数据的指针与指向后一个数据的指针，每个指针占用8byte。在value比较小的情况下，每个对象占用的大小可能比value占用的还多，这在程序设计上有个名称叫胖指针。\n另一个缺点是，链表的指针，每个对象在内存中空间不连续，会产生大量的碎片。\nRedis采用quicklist(双端链表)和ziplist作为list的底层实现\nzipList\n\nzlbytes:32bit，表示ziplist占用的字节总数。\n\nzltail:  32bit，表示ziplist表中最后一项（entry）在ziplist中的偏移字节数。通过zltail我们可以很方便地找到最后一项，从而可以在ziplist尾端快速地执行push或pop操作\n\nzlen:   16bit， 表示ziplist中数据项（entry）的个数。\n\nentry:表示真正存放数据的数据项，长度不定\n\nzlend: ziplist最后1个字节，是一个结束标记，值固定等于255。\n\nprerawlen: 前一个entry的数据长度。\n\nlen: entry中数据的长度\n\ndata: 真实数据存储\n\n\n在数据进行删除与新增时，会重新生成一个zipList并将原ziplist中的数据拷贝到新的ziplist中，在数据量较大的时候，在增删时，耗费性能较大。\nquickList由于考虑到ziplist在数据量较大时，进行增删性能消耗较大，redis设计了quickList,在ziplist数据量较大时，会进行分裂，分裂成多个ziplist。多大时进行分裂可以进行配置，ziplist也可以进行压缩存储，比如说数据不是经常用，可以压缩来节省空间。\nlist-max-ziplist-size  -2 //  单个ziplist节点最大能存储8kb,超过则进行分裂,将数据存储在新的ziplist节点中list-compress-depth  1    //  0代表所有节点，都不进行压缩；1代表从头节点往后走一个，尾节点往前走一个不用压缩，其他的全部压缩；2，3，4 ... 以此类推\n\n\nHash底层设计Hash 数据结构底层实现为一个字典( dict ),也是RedisBb用来存储K-V的数据结构,当数据量比较小，或者单个元素比较小时，底层用ziplist存储，数据大小和元素数量阈值可以通过如下参数设置\n\nhash-max-ziplist-entries  512     //  ziplist元素个数超过512，将改为hashtable编码 hash-max-ziplist-value    64      //  单个元素大小超过64byte时，将改为hashtable编码\n\nSet底层设计Set 为无序的，自动去重的集合数据类型，Set 数据结构底层实现为一个value 为 null 的 字典( dict ),当数据可以用整形表示时，Set集合将被编码为intset数据结构。两个条件任意满足时Set将用hashtable存储数据。\n\n元素个数大于 set-max-intset-entries \n\n元素无法用整形表示 \n\n\nset-max-intset-entries 512       // intset 能存储的最大元素个数，超过则用hashtable编码\n\n当数据存储为intset数据结构的时候，通过smembers查看数据会发现数据是有序的，为什么是有序的呢？因为如果数据是有序的，可以进行快速的数据查找\nintset整数集合是一个有序的，存储整型数据的结构。整型集合在Redis中可以保存int16_t,int32_t,int64_t类型的整型数据，并且可以保证集合中不会出现重复数据\ntypedef struct intset &#123;    uint32_t  encoding;     //编码类型    uint32_t  length;       //元素个数    int8_t    contents[];   //元素存储&#125; intset;  #define INTSET_ENC_INT16 (sizeof(int16_t))#define INTSET_ENC_INT32 (sizeof(int32_t))#define INTSET_ENC_INT64 (sizeof(int64_t))\n\n\nzset底层设计ZSet 为有序的，自动去重的集合数据类型，ZSet 数据结构底层实现为 字典(dict) + 跳表(skiplist) ,当数据比较少时，用ziplist编码结构存储。dict用来存储数据与分数的对应关系，这样可以让命令zscore可以直接通过元素来获取到分值，时间复杂度为O(1),skiplist用来根据分数查询数据（可能是范围查找）\n\nzset-max-ziplist-entries  128    // 元素个数超过128 ，将用skiplist编码zset-max-ziplist-value     64    // 单个元素大小超过64byte, 将用skiplist编码\n\nskipList通过用空间换时间的方式，进行创建索引层冗余数据，时间复杂度为O(logn),而redis并不是按照正常的跳表来进行创建的索引层，进行了改良。\n\n  // 创建zset 数据结构: 字典 + 跳表robj *createZsetObject(void) &#123;    zset *zs = zmalloc(sizeof(*zs));    robj *o;    // dict用来查询数据到分数的对应关系， 如 zscore 就可以直接根据 元素拿到分值     zs-&gt;dict = dictCreate(&amp;zsetDictType,NULL);        // skiplist用来根据分数查询数据（可能是范围查找）    zs-&gt;zsl = zslCreate();    // 设置对象类型     o = createObject(OBJ_ZSET,zs);    // 设置编码类型     o-&gt;encoding = OBJ_ENCODING_SKIPLIST;    return o;&#125;\n\ntypedef struct zskiplistNode &#123;    sds ele;    double score;    struct zskiplistNode *backward;    struct zskiplistLevel &#123;        struct zskiplistNode *forward;        unsigned long span;    &#125; level[];&#125; zskiplistNode;typedef struct zskiplist &#123;    struct zskiplistNode *header, *tail;    unsigned long length;    int level;&#125; zskiplist;typedef struct zset &#123;    dict *dict;    zskiplist *zsl;&#125; zset;\n\n\nzskiplist元素包括\n\nheader：头节点，不进行数据的存储\ntail：指向尾节点\nlength：数据的个数\nlevel：索引的层高\n\nzskiplist中存储的元素对象为zskiplistNode,每个zskipNode包含以下元素\n\nele：存储的具体元素\nscore：分值\nbackword：后退指针\nforward：所指向的下一个索引\nspan：索引高度\n\n\n层高的确定#define ZSKIPLIST_MAXLEVEL 32 /* Should be enough for 2^32 elements */#define ZSKIPLIST_P 0.25      /* Skiplist P = 1/4 */int zslRandomLevel(void) &#123;    int level = 1;    while ((random()&amp;0xFFFF) &lt; (ZSKIPLIST_P * 0xFFFF)) // 如果随机整型小于整型的四分之一,即四分之一的概率为true        level += 1;    return (level&lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;&#125;\n\nzskiplist在放入数据的时候，会随机生成索引层高,如果生成的索引层高大于目前的索引层高的话，会初始化新的层高。\nGeoHash算法GeoHash是一种地理位置编码方法。 由Gustavo Niemeyer 和 G.M. Morton于2008年发明，它将地理位置编码为一串简短的字母和数字。它是一种分层的空间数据结构，将空间细分为网格形状的桶，这是所谓的z顺序曲线的众多应用之一，通常是空间填充曲线。Redis通过GEO API可以通过经纬度查找指定区间范围的目标，GEO的底层数据类型为zset。\nGeoHash经纬度编码经度范围是东经180到西经180，纬度范围是南纬90到北纬90，我们设定西经为负，南纬为负，所以地球上的经度范围就是[-180， 180]，纬度范围就是[-90，90]。如果以本初子午线、赤道为界，地球可以分成4个部分。如果纬度范围[-90°, 0°)用二进制0代表，（0°, 90°]用二进制1代表，经度范围[-180°, 0°)用二进制0代表，（0°, 180°]用二进制1代表，那么地球可以分成如下(左图 )4个部分，如果每个区域再次进行划分，则可以看到划分的区域又多了，也更精确了（右图）\n\n通过GeoHash算法，可以将经纬度的二维坐标变成一个可排序、可比较的的字符串编码。 在编码中的每个字符代表一个区域，并且前面的字符是后面字符的父区域。其算法的过程如下：根据GeoHash 来计算 纬度的 二进制编码地球纬度区间是[-90,90]， 如某纬度是39.92324，可以通过下面算法来进行维度编码:\n\n区间[-90,90]进行二分为[-90,0),[0,90]，称为左右区间，可以确定39.92324属于右区间[0,90]，给标记为1\n接着将区间[0,90]进行二分为 [0,45),[45,90]，可以确定39.92324属于左区间 [0,45)，给标记为0\n递归上述过程39.92324总是属于某个区间[a,b]。随着每次迭代区间[a,b]总在缩小，并越来越逼近39.928167\n如果给定的纬度（39.92324）属于左区间，则记录0，如果属于右区间则记录1，这样随着算法的进行会产生一个序列1011 1000 1100 0111 1001，序列的长度跟给定的区间划分次数有关\n同理，经度产生的编码为1101 0010 1100 0100 0100\n偶数位放经度，奇数位放纬度，把2串编码组合生成新串：11100 11101 00100 01111 00000 01101 01011 00001\n\n\n\n\n最后使用0-9、b-z（去掉a, i, l, o）这32个字母进行base32编码，首先将11100 11101 00100 01111 00000 01101 01011 00001转成十进制 28，29，4，15，0，13，11，1，十进制对应的编码就是wx4g0ec1。同理，将编码转换成经纬度的解码算法与之相反。\n\n\nGeoHash的缺陷这种类型的空间填充曲线的优点是将二维空间转换成一维曲线（事实上是分形维），对大部分而言，编码相似的距离也相近，但Peano空间填充曲线最大的缺点就是突变性，有些编码相邻但距离却相差很远，比如0111与1000，编码是相邻的，但距离相差很大。即具有相似前缀的字符串在附近，但反之则不然，具有不同前缀的字符串也可能在附近。\nRedis中的实现Redis中进行了26次切分，即经度与维度均切分了26次,位置使用52位整数进行编码会生成11个字符的Geohash字符串，可以看到redis实现的Geohash可以确定范围为0.15m以内的精度。Redis中将传入经纬度进行编码为一个整型值，并封装为一个String,作为zadd的score。\n\nRedis6.0新特性\n多线程\n客户端缓存\n权限\n\n多线程redis 6.0 提供了多线程的支持，redis 6 以前的版本，严格来说也是多线程，只不过执行用户命令的请求时单线程模型，还有一些线程用来执行后台任务， 比如 unlink 删除 大key，rdb持久化等。redis 6.0 提供了多线程的读写IO, 但是最终执行用户命令的线程依然是单线程的，这样，就没有多线程数据的竞争关系，依然很高效。\nredis 6.0 以前线程执行模式，如下操作在一个线程中执行完成\n\nredis 6.0 可以通过如下参数配置多线程模型：\nio-threads 4  // 这里说有三个IO线程，还有一个线程是main线程，main线程负责IO读写和命令执行操作,而其余三个IO线程只负责将数据写回到客户端\n\n\n也可以开启让io线程进行读操作：\nio-threads-do-reads yes // IO线程执行读写任务\n\n\n客户端缓存（client side caching ）redis 6 提供了服务端追踪key的变化，客户端缓存数据的特性，这需要客户端实现\n\n当客户端访问某个key时，服务端将记录key 和 client ，客户端拿到数据后，进行客户端缓存，这时，当key再次被访问时，key将被直接返回，避免了与redis 服务器的再次交互，节省服务端资源，当数据被其他请求修改时，服务端将主动通知客户端失效的key，客户端进行本地失效，下次请求时，重新获取最新数据。\n权限控制（ACL）ACL 是对于命令的访问和执行权限的控制，默认情况下，可以有执行任意的指令，兼容以前版本ACL设置有两种方式：\n\n命令方式 ACL SETUSER + 具体的权限规则， 通过 ACL SAVE 进行持久化\n对 ACL 配置文件进行编写，并且执行 ACL LOAD 进行加载\n\nACL存储有两种方式，但是两种方式不能同时配置，否则直接报错退出进程\n\nredis 配置文件： redis.conf\nACL配置文件：在redis.conf 中通过 aclfile  /path  配置acl文件的路径\n\n命令使用ACL SETUSER alice   // 创建一个 用户名为alice的用户\n\n用如上的命令创建的用户语义为：\n\n处于 off 状态， 它是被禁用的，不能用auth进行认证\n不能访问任何命令\n不能访问任意的key\n没有密码\n\n创建一个对 cached: 前缀具有get命令执行权限的用户，并且设置密码：\nacl setuser alice on &gt;pass123  ~cached:* +get \n\nauth alice pass123set a a(error) NOPERM this user has no permissions to run the &#x27;set&#x27; command or its subcommandget a a (error) NOPERM this user has no permissions to access one of the keys used as argumentsget cached:namevvv\n\n如上，如果访问没有被授权的命令，或者key， 将报错，set 命令没有被授权， key  a 没有被授权，cached:name 可以通过验证。\n添加多个访问模式，空格分隔， 注意，切换其他用户进行登录，alice没有admin权限\nACL SETUSER alice ~objects:* ~items:* ~public:*\n\n针对类型命令的约束ACL SETUSER alice on +@all -@dangerous &gt;密码 ~*\n\n这里+@all:  包含所有得命令 然后用-@ 去除在redis command table 中定义的 dangerous 命令\n\n可以通过如下命令进行查看具体有哪些命令属于某个类别\nacl cat // 查看所有类别acl cat dangerous // 查看所有的 dangerous 命令\n\n开放子命令禁用client 命令，但是开放 client 命令中的子命令  setname 和 getname ，只能是先禁用，后追加子命令，因为后续可能会有新的命令增加。 \nACL SETUSER myuser -client +client|setname +client|getname\n\n","categories":["中间件"],"tags":["Redis"]},{"title":"Redis核心设计结构与高性能原理","url":"/2021/11/23/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/Redis%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1%E7%BB%93%E6%9E%84%E4%B8%8E%E9%AB%98%E6%80%A7%E8%83%BD%E5%8E%9F%E7%90%86/","content":"五种数据结构\nString结构基本操作\n\n\n命令\n含义\n\n\n\nSET key value \n存入字符串键值对\n\n\nMSET key value [key value ...] \n批量存储字符串键值对\n\n\nSETNX key value \n存入一个不存在的字符串键值对\n\n\nGET key \n获取一个字符串键值\n\n\nMGET key [key ...]\n批量获取字符串键值\n\n\nDEL key [key ...] \n删除一个键\n\n\nEXPIRE key seconds \n设置一个键的过期时间(秒)\n\n\nINCR key \n原子将key中储存的数字值加1\n\n\nDECR key \n原子将key中储存的数字值减1\n\n\nINCRBY key increment \n原子将key所储存的值加上increment\n\n\nDECRBY key decrement \n原子将key所储存的值减去decrement\n\n\n应用场景单值缓存比如token的缓存\n对象缓存有两种格式\n\n对象进行序列化，保存序列化后的格式\nSET  user:1  value(json格式数据)\n通过key来组建对象\nMSET  user:1:name  zhuge   user:1:balance  1888MGET  user:1:name   user:1:balance \n\n分布式锁SETNX  product:10001  true \t\t//返回1代表获取锁成功SETNX  product:10001  true \t\t//返回0代表获取锁失败。。。执行业务操作DEL  product:10001\t\t\t//执行完业务释放锁SET product:10001 true  ex  10  nx\t//防止程序意外终止导致死锁\n\n文章计数器\nINCR article:readcount:&#123;文章id&#125;  \tGET article:readcount:&#123;文章id&#125; \n\n分布式系统全局序列号redis批量生成序列号提升性能\nINCRBY  orderId  1000\n\nHash结构基本操作\n\n\n命令\n含义\n\n\n\nHSET  key  field  value \n存储一个哈希表key的键值\n\n\nHSETNX key field value \n存储一个不存在的哈希表key的键值\n\n\nHMSET  key  field  value [field value ...]  \n在一个哈希表key中存储多个键值对\n\n\nHGET  key  field  \n获取哈希表key对应的field键值\n\n\nHMGET  key  field  [field ...] \n批量获取哈希表key中多个field键值\n\n\nHDEL  key  field  [field ...]  \n删除哈希表key中的field键值\n\n\nHLEN  key \n返回哈希表key中field的数量\n\n\nHGETALL  key \n返回哈希表key中所有的键值\n\n\nHINCRBY  key  field  increment  \n为哈希表key中field键的值加上增量increment\n\n\n应用场景对象缓存HMSET  user  &#123;userId&#125;:name  zhuge  &#123;userId&#125;:balance  1888HMSET  user  1:name  zhuge  1:balance  1888HMGET  user  1:name  1:balance  \n\n对象缓存可能会造成大key产生，并且在集群架构模式下，Hash结构的key只会存储在一个机器上，可能会造成热点key，其他服务不会平摊流量。所以如果用hash存储对象的话需要评估对象的大小，避免大key产生。\n电商购物车\n以用户id为key\n商品id为field\n商品数量为value\n\n\n购物车的操作\n\n添加商品 hset cart:1001 10088 1\n增加数量 hincrby cart:1001 10088 1\n商品总数 hlen cart:1001\n删除商品 hdel cart:1001 10088\n获取购物车所有商品 hgetall cart:1001\n\nHash结构优缺点\n优点\n同类数据归类整合存储，方便数据管理\n相比string操作消耗内存与cpu更小\n相比string存储更节省空间\n\n\n缺点\n过期功能不能使用在field上，只能用在key上\nredis集群架构下不适合大规模使用\n\n\n\nList结构基本操作\n\n\n\n命令\n含义\n\n\n\nLPUSH  key  value [value ...] \n将一个或多个值value插入到key列表的表头(最左边)\n\n\nRPUSH  key  value [value ...]\n将一个或多个值value插入到key列表的表尾(最右边)\n\n\nLPOP  key \n移除并返回key列表的头元素\n\n\nRPOP  key\n移除并返回key列表的尾元素\n\n\nLRANGE  key  start  stop\n返回列表key中指定区间内的元素，区间以偏移量start和stop指定\n\n\nBLPOP  key  [key ...]  timeout\n从key列表表头弹出一个元素，若列表中没有元素，阻塞等待。timeout秒,如果timeout=0,一直阻塞等待\n\n\nBRPOP  key  [key ...]  timeout \n从key列表表尾弹出一个元素，若列表中没有元素，阻塞等待。timeout秒,如果timeout=0,一直阻塞等待\n\n\nList应用场景栈、队列Stack(栈) = LPUSH + LPOP\nQueue(队列）= LPUSH + RPOP\nBlocking MQ(阻塞队列）= LPUSH + BRPOP\n消息流比如说关注了MacTalk，备胎说车等大V\n\nMacTalk发微博，消息ID为10018LPUSH msg:{user-ID} 10018\n备胎说车发微博，消息ID为10086LPUSH msg:{user-ID} 10086\n查看最新微博消息LRANGE msg:{user-ID} 0 4\n\n\nSet结构基本操作\n\n\n命令\n含义\n\n\n\nSADD key member [member ...]\n往集合key中存入元素，元素存在则忽略，若key不存在则新建\n\n\nSREM  key  member  [member ...]\n从集合key中删除元素\n\n\nSMEMBERS key\n获取集合key中所有元素\n\n\nSCARD  key\n获取集合key的元素个数\n\n\nSISMEMBER  key  member\n判断member元素是否存在于集合key中\n\n\nSRANDMEMBER  key  [count]\n从集合key中选出count个元素，元素不从key中删除\n\n\nSPOP key [count]\n从集合key中选出count个元素，元素从key中删除\n\n\nSINTER key [key ...]\n交集运算\n\n\nSINTERSTORE destination key [key ..]\n将交集结果存入新集合destination中\n\n\nSUNION key [key ..]\n并集运算\n\n\nSUNIONSTORE destination key [key ...]\n将并集结果存入新集合destination中\n\n\nSDIFF key [key ...]\n差集运算\n\n\nSDIFFSTORE destination key [key ...]\n将差集结果存入新集合destination中\n\n\n使用场景抽奖\n点击参与抽奖加入集合SADD key {userlD}\n\n查看参与抽奖所有用户SMEMBERS key  \n\n抽取count名中奖者SRANDMEMBER key [count] //可以重复中奖SPOP key [count] //不可以重复中奖\n\n\n\n微信微博点赞，收藏，标签\n点赞SADD like:{消息ID} {用户ID}\n取消点赞SREM like:{消息ID} {用户ID}\n检查用户是否点过赞SISMEMBER like:{消息ID} {用户ID}\n获取点赞的用户列表SMEMBERS like:{消息ID}\n获取点赞用户数SCARD like:{消息ID}\n\n微信微博关注\nA关注的人 ASet -&gt; {C, F}\nB关注的人 BSet -&gt; {A, D, C, F}\nC关注的人 CSet -&gt; {A, B, D, F, G}\n\nA与B共同关注 SINTER ASet BSet –&gt; {E, F}\n对于B来讲：A关注的人也关注他（B） –&gt; SISMEMBER CSet B; SISMEMBER FSet B\nA可能认识的人：SDIFF ASet BSet -&gt; {A, D}\n\n电商商品筛选\nSADD brand:huawei P40\nSADD brand:xiaomi mi-10\nSADD brand:iPhone iphone12\nSADD os:android P40 mi-10\nSADD cpu:intel P40 mi-10\nSADD ram:8G P40 mi-10 iphone12\nSINTER os:android cpu:intel ram:8G -&gt; {P40，mi-10}\nZSet结构\n基本操作\n\n\n命令\n含义\n\n\n\nZADD key score member [[score member]…]\n往有序集合key中加入带分值元素\n\n\nZREM key member [member …]\n从有序集合key中删除元素\n\n\nZSCORE key member\n返回有序集合key中元素member的分值\n\n\nZINCRBY key increment member\n为有序集合key中元素member的分值加上increment\n\n\nZCARD key\n返回有序集合key中元素个数\n\n\nZRANGE key start stop [WITHSCORES]\n正序获取有序集合key从start下标到stop下标的元素\n\n\nZREVRANGE key start stop [WITHSCORES]\n倒序获取有序集合key从start下标到stop下标的元素\n\n\nZUNIONSTORE destkey numkeys key [key ...]\n并集计算\n\n\nZINTERSTORE destkey numkeys key [key …]\n交集计算\n\n\n使用场景实现排行榜\n\n点击新闻ZINCRBY hotNews:20190819 1 守护香港\n\n展示当日排行前十ZREVRANGE hotNews:20190819 0 9 WITHSCORES \n\n七日搜索榜单计算ZUNIONSTORE hotNews:20190813-20190819 7hotNews:20190813 hotNews:20190814… hotNews:20190819\n\n展示七日排行前十ZREVRANGE hotNews:20190813-20190819 0 9 WITHSCORES\n\n\n","categories":["中间件"],"tags":["Redis"]},{"title":"Redis简介","url":"/2021/11/29/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/Redis%E7%AE%80%E4%BB%8B/","content":"Redis 安装下载地址：http://redis.io/download安装步骤：# 安装gccyum install gcc# 把下载好的redis-5.0.3.tar.gz放在/usr/local文件夹下，并解压wget http://download.redis.io/releases/redis-5.0.3.tar.gztar xzf redis-5.0.3.tar.gzcd redis-5.0.3# 进入到解压好的redis-5.0.3目录下，进行编译与安装make# 修改配置daemonize yes  #后台启动protected-mode no  #关闭保护模式，开启的话，只有本机才可以访问redis# 需要注释掉bind#bind 127.0.0.1（bind绑定的是自己机器网卡的ip，如果有多块网卡可以配多个ip，代表允许客户端通过机器的哪些网卡ip去访问，内网一般可以不配置bind，注释掉即可）# 启动服务src/redis-server redis.conf# 验证启动是否成功 ps -ef | grep redis # 进入redis客户端 src/redis-cli # 退出客户端quit# 退出redis服务： （1）pkill redis-server （2）kill 进程号                       （3）src/redis-cli shutdown \n\nRedis的单线程与高性能Redis是单线程吗？\nRedis 的单线程主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。\nRedis 单线程为什么还能这么快？\n因为它所有的数据都在内存中，所有的运算都是内存级别的运算，而且单线程避免了多线程的切换性能损耗问题。正因为 Redis 是单线程，所以要小心使用 Redis 指令，对于那些耗时的指令(比如keys)，一定要谨慎使用，一不小心就可能会导致 Redis 卡顿。 \nRedis 单线程如何处理那么多的并发客户端连接？\nRedis的IO多路复用：redis利用epoll来实现IO多路复用，将连接信息和事件放到队列中，依次放到文件事件分派器，事件分派器将事件分发给事件处理器。\n\n# 查看redis支持的最大连接数，在redis.conf文件中可修改，# maxclients 10000127.0.0.1:6379&gt; CONFIG GET maxclients##1) &quot;maxclients&quot;##2) &quot;10000&quot;\n\n其他高级命令keys：全量遍历键，用来列出所有满足特定正则字符串规则的key，当redis数据量比较大时，性能比较差，要避免使用\n\nscan：渐进式遍历键\nSCAN cursor [MATCH pattern] [COUNT count] \nscan 参数提供了三个参数，第一个是 cursor 整数值(hash桶的索引值)，第二个是 key 的正则模式，第三个是一次遍历的key的数量(参考值，底层遍历的数量不一定)，并不是符合条件的结果数量。第一次遍历时，cursor 值为 0，然后将返回结果中第一个整数值作为下一次遍历的 cursor。一直遍历到返回的 cursor 值为 0 时结束。\n注意：但是scan并非完美无瑕， 如果在scan的过程中如果有键的变化（增加、 删除、 修改） ，那么遍历效果可能会碰到如下问题： 新增的键可能没有遍历到， 遍历出了重复的键等情况， 也就是说scan并不能保证完整的遍历出来所有的键， 这些是我们在开发时需要考虑的。\n\nInfo：查看redis服务运行信息\n分为 9 大块，每个块都有非常多的参数，这 9 个块分别是:\nServer 服务器运行的环境参数 \nClients 客户端相关信息 \nMemory 服务器运行内存统计数据 \nPersistence 持久化信息 \nStats 通用统计数据 \nReplication 主从复制相关信息 \nCPU CPU 使用情况 \nCluster 集群信息 \nKeySpace 键值对统计数量信息\n\nconnected_clients:2                  # 正在连接的客户端数量instantaneous_ops_per_sec:789        # 每秒执行多少次指令used_memory:929864                   # Redis分配的内存总量(byte)，包含redis进程内部的开销和数据占用的内存used_memory_human:908.07K            # Redis分配的内存总量(Kb，human会展示出单位)used_memory_rss_human:2.28M          # 向操作系统申请的内存大小(Mb)（这个值一般是大于used_memory的，因为Redis的内存分配策略会产生内存碎片）used_memory_peak:929864              # redis的内存消耗峰值(byte)used_memory_peak_human:908.07K       # redis的内存消耗峰值(KB)maxmemory:0                         # 配置中设置的最大可使用内存值(byte),默认0,不限制maxmemory_human:0B                  # 配置中设置的最大可使用内存值maxmemory_policy:noeviction         # 当达到maxmemory时的淘汰策略\n\n","categories":["中间件"],"tags":["Redis"]},{"title":"Redis缓存设计与性能优化","url":"/2021/11/29/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/Redis%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1%E4%B8%8E%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","content":"多级缓存架构\n缓存设计缓存穿透缓存穿透是指查询一个根本不存在的数据， 缓存层和存储层都不会命中， 通常出于容错的考虑， 如果从存储层查不到数据则不写入缓存层。\n缓存穿透将导致不存在的数据每次请求都要到存储层去查询， 失去了缓存保护后端存储的意义。\n造成缓存穿透的基本原因有两个：\n第一， 自身业务代码或者数据出现问题。\n第二， 一些恶意攻击、 爬虫等造成大量空命中。 \n\n解决方案：\n\n缓存空对象\nString get(String key) &#123;    // 从缓存中获取数据    String cacheValue = cache.get(key);    // 缓存为空    if (StringUtils.isBlank(cacheValue)) &#123;        // 从存储中获取        String storageValue = storage.get(key);        cache.set(key, storageValue);        // 如果存储数据为空， 需要设置一个过期时间(300秒)        if (storageValue == null) &#123;            cache.expire(key, 60 * 5);        &#125;        return storageValue;    &#125; else &#123;        // 缓存非空        return cacheValue;    &#125;&#125;\n布隆过滤器对于恶意攻击，向服务器请求大量不存在的数据造成的缓存穿透，还可以用布隆过滤器先做一次过滤，对于不存在的数据布隆过滤器一般都能够过滤掉，不让请求再往后端发送。当布隆过滤器说某个值存在时，这个值可能不存在；当它说不存在时，那就肯定不存在。\n布隆过滤器就是一个大型的位数组和几个不一样的无偏 hash 函数。所谓无偏就是能够把元素的 hash 值算得比较均匀。\n向布隆过滤器中添加 key 时，会使用多个 hash 函数对 key 进行 hash 算得一个整数索引值然后对位数组长度进行取模运算得到一个位置，每个 hash 函数都会算得一个不同的位置。再把位数组的这几个位置都置为 1 就完成了 add 操作。\n向布隆过滤器询问 key 是否存在时，跟 add 一样，也会把 hash 的几个位置都算出来，看看位数组中这几个位置是否都为 1，只要有一个位为 0，那么说明布隆过滤器中这个key 不存在。如果都是 1，这并不能说明这个 key 就一定存在，只是极有可能存在，因为这些位被置为 1 可能是因为其它的 key 存在所致。如果这个位数组比较稀疏，这个概率就会很大，如果这个位数组比较拥挤，这个概率就会降低。\n这种方法适用于数据命中不高、 数据相对固定、 实时性低（通常是数据集较大） 的应用场景， 代码维护较为复杂， 但是缓存空间占用很少。redisson实现布隆过滤器，引入依赖：\n&lt;dependency&gt;   &lt;groupId&gt;org.redisson&lt;/groupId&gt;   &lt;artifactId&gt;redisson&lt;/artifactId&gt;   &lt;version&gt;3.6.5&lt;/version&gt;&lt;/dependency&gt;\n\n伪代码:\npackage com.redisson;import org.redisson.Redisson;import org.redisson.api.RBloomFilter;import org.redisson.api.RedissonClient;import org.redisson.config.Config;public class RedissonBloomFilter &#123;    public static void main(String[] args) &#123;        Config config = new Config();        config.useSingleServer().setAddress(&quot;redis://localhost:6379&quot;);        //构造Redisson        RedissonClient redisson = Redisson.create(config);        RBloomFilter&lt;String&gt; bloomFilter = redisson.getBloomFilter(&quot;nameList&quot;);        //初始化布隆过滤器：预计元素为100000000L,误差率为3%,根据这两个参数会计算出底层的bit数组大小        bloomFilter.tryInit(100000000L,0.03);        //将zhuge插入到布隆过滤器中        bloomFilter.add(&quot;test1&quot;);        //判断下面号码是否在布隆过滤器中        System.out.println(bloomFilter.contains(&quot;test3&quot;));//false        System.out.println(bloomFilter.contains(&quot;test2&quot;));//false        System.out.println(bloomFilter.contains(&quot;test1&quot;));//true    &#125;&#125;\n\n使用布隆过滤器需要把所有数据提前放入布隆过滤器，并且在增加数据时也要往布隆过滤器里放，布隆过滤器缓存过滤伪代码：\n//初始化布隆过滤器RBloomFilter&lt;String&gt; bloomFilter = redisson.getBloomFilter(&quot;nameList&quot;);//初始化布隆过滤器：预计元素为100000000L,误差率为3%bloomFilter.tryInit(100000000L,0.03);//把所有数据存入布隆过滤器void init()&#123;    for (String key: keys) &#123;        bloomFilter.put(key);    &#125;&#125;String get(String key) &#123;    // 从布隆过滤器这一级缓存判断下key是否存在    Boolean exist = bloomFilter.contains(key);    if(!exist)&#123;        return &quot;&quot;;    &#125;    // 从缓存中获取数据    String cacheValue = cache.get(key);    // 缓存为空    if (StringUtils.isBlank(cacheValue)) &#123;        // 从存储中获取        String storageValue = storage.get(key);        cache.set(key, storageValue);        // 如果存储数据为空， 需要设置一个过期时间(300秒)        if (storageValue == null) &#123;            cache.expire(key, 60 * 5);        &#125;        return storageValue;    &#125; else &#123;        // 缓存非空        return cacheValue;    &#125;&#125;\n\n注意：布隆过滤器不能删除数据，如果要删除得重新初始化数据。如果要设计可以删除的布隆过滤器，参考布谷鸟过滤器\n\n\n缓存击穿由于热点key过期，导致大量请求直接访问数据库，可能会造成数据库瞬间压力过大而挂掉。\n\n解决方案：\n\n加锁更新，比如请求查询A，发现缓存中没有，对A这个key加锁，同时去数据库查询数据，写入缓存，再返回给用户，这样后面的请求就可以从缓存中拿到数据了。\n将过期时间组合写在value中，通过异步的方式不断的刷新过期时间，防止此类现象。\n\n缓存雪崩缓存雪崩指的是缓存层支撑不住或宕掉后， 流量会像奔逃的野牛一样， 打向后端存储层。\n\n由于缓存层承载着大量请求， 有效地保护了存储层， 但是如果缓存层由于某些原因不能提供服务(比如超大并发过来，缓存层支撑不住，或者由于缓存设计不好，类似大量请求访问bigkey，导致缓存能支撑的并发急剧下降)， 于是大量请求都会打到存储层， 存储层的调用量会暴增， 造成存储层也会级联宕机的情况。 \n预防和解决缓存雪崩问题， 可以从以下三个方面进行着手:\n\n保证缓存层服务高可用性，比如使用Redis Sentinel或Redis Cluster。\n\n依赖隔离组件为后端限流熔断并降级。比如使用Sentinel或Hystrix限流降级组件。\n\n比如服务降级，我们可以针对不同的数据采取不同的处理方式。当业务应用访问的是非核心数   &gt; 据（例如电商商品属性，用户信息等）时，暂时停止从缓存中查询这些数据，而是直接返回预定   &gt; 义的默认降级信息、空值或是错误提示信息；当业务应用访问的是核心数据（例如电商商品库   &gt; 存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。\n\n\n提前演练。 在项目上线前， 演练缓存层宕掉后， 应用以及后端的负载情况以及可能出现的问题， 在此基础上做一些预案设定。 \n\n\n热点缓存key重建优化开发人员使用“缓存+过期时间”的策略既可以加速数据读写， 又保证数据的定期更新， 这种模式基本能够满足绝大部分需求。 但是有两个问题如果同时出现， 可能就会对应用造成致命的危害：\n\n当前key是一个热点key（例如一个热门的娱乐新闻），并发量非常大。\n重建缓存不能在短时间完成， 可能是一个复杂计算， 例如复杂的SQL、 多次IO、 多个依赖等。\n\n在缓存失效的瞬间， 有大量线程来重建缓存， 造成后端负载加大， 甚至可能会让应用崩溃。\n要解决这个问题主要就是要避免大量线程同时重建缓存。\n我们可以利用互斥锁来解决，此方法只允许一个线程重建缓存， 其他线程等待重建缓存的线程执行完， 重新从缓存获取数据即可。\nString get(String key) &#123;    // 从Redis中获取数据    String value = redis.get(key);    // 如果value为空， 则开始重构缓存    if (value == null) &#123;        // 只允许一个线程重建缓存， 使用nx， 并设置过期时间ex        String mutexKey = &quot;mutext:key:&quot; + key;        if (redis.set(mutexKey, &quot;1&quot;, &quot;ex 180&quot;, &quot;nx&quot;)) &#123;            // 从数据源获取数据            value = db.get(key);            // 回写Redis， 并设置过期时间            redis.setex(key, timeout, value);            // 删除key_mutex            redis.delete(mutexKey);        &#125;// 其他线程休息50毫秒后重试        else &#123;            Thread.sleep(50);            get(key);        &#125;    &#125;    return value;&#125;\n\n缓存与数据库双写不一致在大并发下，同时操作数据库与缓存会存在数据不一致性问题\n\n双写不一致情况\n读写并发不一致\n\n解决方案：\n\n对于并发几率很小的数据(如个人维度的订单数据、用户数据等)，这种几乎不用考虑这个问题，很少会发生缓存不一致，可以给缓存数据加上过期时间，每隔一段时间触发读的主动更新即可。\n\n就算并发很高，如果业务上能容忍短时间的缓存数据不一致(如商品名称，商品分类菜单等)，缓存加上过期时间依然可以解决大部分业务对于缓存的要求。\n\n如果不能容忍缓存数据不一致，可以通过加读写锁保证并发读写或写写的时候按顺序排好队，读读的时候相当于无锁。\n\n也可以用阿里开源的canal通过监听数据库的binlog日志及时的去修改缓存，但是引入了新的中间件，增加了系统的复杂度。\n\n\n总结：\n以上我们针对的都是读多写少的情况加入缓存提高性能，如果写多读多的情况又不能容忍缓存数据不一致，那就没必要加缓存了，可以直接操作数据库。放入缓存的数据应该是对实时性、一致性要求不是很高的数据。切记不要为了用缓存，同时又要保证绝对的一致性做大量的过度设计和控制，增加系统复杂性！对于延时双删，也无法解决读写并发不一致的情况，也有可能导致缓存数据与数据库数据不一致的情况。\n开发规范与性能优化键值设计key名设计\n【建议】: 可读性和可管理性以业务名(或数据库名)为前缀(防止key冲突)，用冒号分隔，比如业务名:表名:id trade:order:1\n\n【建议】：简洁性保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视，例如：\nuser:&#123;uid&#125;:friends:messages:&#123;mid&#125; 简化为 u:&#123;uid&#125;:fr:m:&#123;mid&#125;\n【强制】：不要包含特殊字符反例：包含空格、换行、单双引号以及其他转义字符\n\n\nvalue设计\n【强制】：拒绝bigkey(防止网卡流量、慢查询)在Redis中，一个字符串最大512MB，一个二级数据结构（例如hash、list、set、zset）可以存储大约40亿个(2^32-1)个元素，但实际中如果下面两种情况，我就会认为它是bigkey\n\n字符串类型：它的big体现在单个value值很大，一般认为超过10KB就是bigkey\n非字符串类型：哈希、列表、集合、有序集合，它们的big体现在元素个数太多,一般来说，string类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000\n\n反例：一个包含200万个元素的list非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞）\n\n【推荐】：选择适合的数据类型实体类型(要合理控制和使用数据结构，但也要注意节省内存和性能之间的平衡)\n\n【推荐】：控制key的生命周期，redis不是垃圾桶建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)\n\n\nbigkey的危害\n导致redis阻塞\n网络拥塞bigkey也就意味着每次获取要产生的网络流量较大，假设一个bigkey为1MB，客户端每秒访问量为1000，那么每秒产生1000MB的流量，对于普通的千兆网卡(按照字节算是128MB/s)的服务器来说简直是灭顶之灾，而且一般服务器会采用单机多实例的方式来部署，也就是说一个bigkey可能会对其他实例也造成影响，其后果不堪设想\n过期删除有个bigkey，它安分守己（只执行简单的命令，例如hget、lpop、zscore等），但它设置了过期时间，当它过期后，会被删除，如果没有使用Redis 4.0的过期异步删除(lazyfree-lazy-expire yes)，就会存在阻塞Redis的可能性\n\nbigkey的产生一般来说，bigkey的产生都是由于程序设计不当，或者对于数据规模预料不清楚造成的\n\n社交类：粉丝列表，如果某些明星或者大v不精心设计下，必是bigkey\n统计类：例如按天存储某项功能或者网站的用户集合，除非没几个人用，否则必是bigkey\n缓存类：将数据从数据库load出来序列化放到Redis里，这个方式非常常用，但有两个地方需要注意，第一，是不是有必要把所有字段都缓存；第二，有没有相关关联的数据，有的同学为了图方便把相关数据都存一个key下，产生bigkey\n\n如何优化bigkey\n拆\nbig list： list1、list2、…listN\nbig hash：可以讲数据分段存储，比如一个大的key，假设存了1百万的用户数据，可以拆分成200个key，每个key下面存放5000个用户数据\n\n 如果bigkey不可避免，也要思考一下要不要每次把所有元素都取出来(例如有时候仅仅需要hmget，而不是hgetall)，删除也是一样，尽量使用优雅的方式来处理\n\n\n命令使用\n【推荐】 O(N)命令关注N的数量例如hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值。有遍历的需求可以使用hscan、sscan、zscan代替。\n\n【推荐】：禁用命令禁止线上使用keys、flushall、flushdb等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理\n\n【推荐】合理使用selectredis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理，会有干扰\n\n【推荐】使用批量操作提高效率原生命令：例如mget、mset。非原生命令：可以使用pipeline提高效率。但要注意控制一次批量操作的元素个数(例如500以内，实际也和元素字节数有关)。\n\n注意两者不同：\n\n原生命令是原子操作，pipeline是非原子操作\npipeline可以打包不同的命令，原生命令做不到\npipeline需要客户端和服务端同时支持\n\n\n\n【建议】Redis事务功能较弱，不建议过多使用，可以用lua替代\n\n\n客户端使用\n【推荐】避免多个应用使用一个Redis实例正例：不相干的业务拆分，公共数据做服务化\n\n【推荐】池化连接使用带有连接池的客户端，可以有效控制连接，同时提高效率以Jedis为例：\nJedisPoolConfig jedisPoolConfig = new JedisPoolConfig();jedisPoolConfig.setMaxTotal(5);jedisPoolConfig.setMaxIdle(2);jedisPoolConfig.setTestOnBorrow(true);JedisPool jedisPool = new JedisPool(jedisPoolConfig, &quot;192.168.0.60&quot;, 6379, 3000, null);Jedis jedis = null;try &#123;    jedis = jedisPool.getResource();    //具体的命令    jedis.executeCommand()&#125; catch (Exception e) &#123;    logger.error(&quot;op key &#123;&#125; error: &quot; + e.getMessage(), key, e);&#125; finally &#123;    //注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。    if (jedis != null)         jedis.close();&#125;\n\n连接池参数含义：\n\n\n\n序号\n参数名\n含义\n默认值\n使用建议\n\n\n\n1\nmaxTotal\n资源池中最大连接数\n8\n设置建议见下面\n\n\n2\nmaxIdle\n资源池允许最大空闲的连接数\n8\n设置建议见下面\n\n\n3\nminIdle\n资源池确保最少空闲的连接数\n0\n设置建议见下面\n\n\n4\nblockWhenExhausted\n当资源池用尽后，调用者是否要等待。只有当为true时，下面的maxWaitMillis才会生效\ntrue\n建议使用默认值\n\n\n5\nmaxWaitMillis\n当资源池连接用尽后，调用者的最大等待时间(单位为毫秒)\n-1：表示永不超时\n不建议使用默认值\n\n\n6\ntestOnBorrow\n向资源池借用连接时是否做连接有效性检测(ping)，无效连接会被移除\nfalse\n业务量很大时候建议设置为false(多一次ping的开销)。\n\n\n7\ntestOnReturn\n向资源池归还连接时是否做连接有效性检测(ping)，无效连接会被移除\nfalse\n业务量很大时候建议设置为false(多一次ping的开销)。\n\n\n8\njmxEnabled\n是否开启jmx监控，可用于监控\ntrue\n建议开启，但应用本身也要开启\n\n\n优化建议：\n\nmaxTotal：最大连接数，早期的版本叫maxActive实际上这个是一个很难回答的问题，考虑的因素比较多：\n\n业务希望Redis并发量\n客户端执行命令时间\nRedis资源：例如 nodes(例如应用个数) * maxTotal 是不能超过redis的最大连接数maxclients\n资源开销：例如虽然希望控制空闲连接(连接池此刻可马上使用的连接)，但是不希望因为连接池的频繁释放创建连接造成不必靠开销\n\n假设:\n\n一次命令时间（borrow|return resource + Jedis执行命令(含网络) ）的平均耗时约为1ms，一个连接的QPS大约是1000\n业务期望的QPS是50000\n\n那么理论上需要的资源池大小是50000 / 1000 = 50个。但事实上这是个理论值，还要考虑到要比理论值预留一些资源，通常来讲maxTotal可以比理论值大一些\n但这个值不是越大越好，一方面连接太多占用客户端和服务端资源，另一方面对于Redis这种高QPS的服务器，一个大命令的阻塞即使设置再大资源池仍然会无济于事\n\nmaxIdle和minIdlemaxIdle实际上才是业务需要的最大连接数，maxTotal是为了给出余量，所以maxIdle不要设置过小，否则会有new Jedis(新连接)开销连接池的最佳性能是maxTotal = maxIdle，这样就避免连接池伸缩带来的性能干扰。但是如果并发量不大或者maxTotal设置过高，会导致不必要的连接资源浪费。一般推荐maxIdle可以设置为按上面的业务期望QPS计算出来的理论连接数，maxTotal可以再放大一倍\nminIdle与其说是最小空闲连接数，不如说是”至少需要保持的空闲连接数“，在使用连接的过程中，如果连接数超过了minIdle，那么继续建立连接，如果超过了maxIdle，当超过的连接执行完业务后会慢慢被移出连接池释放掉\n\n\n\n【建议】高并发下建议客户端添加熔断功能(例如sentinel、hystrix)\n\n【推荐】设置合理的密码，如有必要可以使用SSL加密访问\n\n【建议】设置主动清理策略Redis对于过期键有三种清除策略：\n\n被动删除：当读/写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期key\n主动删除：由于惰性删除策略无法保证冷数据被及时删掉，所以Redis会定期主动淘汰一批已过期的key\n当前已用内存超过maxmemory限定时，触发主动清理策略\n\n主动清理策略在Redis 4.0 之前一共实现了 6 种内存淘汰策略，在 4.0 之后，又增加了 2 种策略，总共8种：\n\n针对设置了过期时间的key做处理：\nvolatile-ttl：在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除\nvolatile-random：就像它的名称一样，在设置了过期时间的键值对中，进行随机删除\nvolatile-lru：会使用 LRU 算法筛选设置了过期时间的键值对删除\nvolatile-lfu：会使用 LFU 算法筛选设置了过期时间的键值对删除\n\n\n针对所有的key做处理：\nallkeys-random：从所有键值对中随机选择并删除数据\nallkeys-lru：使用 LRU 算法在所有数据中进行筛选删除\nallkeys-lfu：使用 LFU 算法在所有数据中进行筛选删除\n\n\n不处理：\nnoeviction：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息”(error) OOM command not allowed when used memory”，此时Redis只响应读操作\n\n\n\nLRU 算法（Least Recently Used，最近最少使用）淘汰很久没被访问过的数据，以最近一次访问时间作为参考LFU 算法（Least Frequently Used，最不经常使用）淘汰最近一段时间被访问次数最少的数据，以次数作为参考\n当存在热点数据时，LRU的效率很好，但偶发性的、周期性的批量操作会导致LRU命中率急剧下降，缓存污染情况比较严重。这时使用LFU可能更好点。\n根据自身业务类型，配置好maxmemory-policy(默认是noeviction)，推荐使用volatile-lru。如果不设置最大内存，当 Redis 内存超出物理内存限制时，内存的数据会开始和磁盘产生频繁的交换 (swap)，会让 Redis 的性能急剧下降。\n当Redis运行在主从模式时，只有主结点才会执行过期删除策略，然后把删除操作”del key”同步到从结点删除数据。\n\n\n","categories":["中间件"],"tags":["Redis"]},{"title":"Redis缓存高可用集群","url":"/2021/11/29/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/Redis%E7%BC%93%E5%AD%98%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/","content":"Redis集群方案比较哨兵模式\n在redis3.0以前的版本要实现集群一般是借助哨兵sentinel工具来监控master节点的状态，如果master节点异常，则会做主从切换，将某一台slave作为master，哨兵的配置略微复杂，并且性能和高可用性等各方面表现一般，特别是在主从切换的瞬间存在访问瞬断的情况，而且哨兵模式只有一个主节点对外提供服务，没法支持很高的并发，且单个主节点内存也不宜设置得过大，否则会导致持久化文件过大，影响数据恢复或主从同步的效率\n高可用集群模式\nredis集群是一个由多个主从节点群组成的分布式服务器群，它具有复制、高可用和分片特性。Redis集群不需要sentinel哨兵·也能完成节点移除和故障转移的功能。需要将每个节点设置成集群模式，这种集群模式没有中心节点，可水平扩展，据官方文档称可以线性扩展到上万个节点(官方推荐不超过1000个节点)。redis集群的性能和高可用性均优于之前版本的哨兵模式，且集群配置非常简单 \nRedis高可用集群搭建redis集群搭建redis集群需要至少三个master节点，我们这里搭建三个master节点，并且给每个master再搭建一个slave节点，总共6个redis节点，这里用三台机器部署6个redis实例，每台机器一主一从，搭建集群的步骤如下：\n第一步：在第一台机器的/usr/local下创建文件夹redis-cluster，然后在其下面分别创建2个文件夾如下（1）mkdir -p /usr/local/redis-cluster（2）mkdir 8001 8004第一步：把之前的redis.conf配置文件copy到8001下，修改如下内容：（1）daemonize yes（2）port 8001（分别对每个机器的端口号进行设置）（3）pidfile /var/run/redis_8001.pid  # 把pid进程号写入pidfile配置的文件（4）dir /usr/local/redis-cluster/8001/（指定数据文件存放位置，必须要指定不同的目录位置，不然会丢失数据）（5）cluster-enabled yes（启动集群模式）（6）cluster-config-file nodes-8001.conf（集群节点信息文件，这里800x最好和port对应上）（7）cluster-node-timeout 10000 (8)# bind 127.0.0.1（bind绑定的是自己机器网卡的ip，如果有多块网卡可以配多个ip，代表允许客户端通过机器的哪些网卡ip去访问，内网一般可以不配置bind，注释掉即可） (9)protected-mode  no   （关闭保护模式） (10)appendonly yes如果要设置密码需要增加如下配置： (11)requirepass zhuge     (设置redis访问密码) (12)masterauth zhuge      (设置集群节点间访问密码，跟上面一致)第三步：把修改后的配置文件，copy到8004，修改第2、3、4、6项里的端口号，可以用批量替换：:%s/源字符串/目的字符串/g 第四步：另外两台机器也需要做上面几步操作，第二台机器用8002和8005，第三台机器用8003和8006第五步：分别启动6个redis实例，然后检查是否启动成功（1）/usr/local/redis-5.0.3/src/redis-server /usr/local/redis-cluster/800*/redis.conf（2）ps -ef | grep redis 查看是否启动成功    第六步：用redis-cli创建整个redis集群(redis5以前的版本集群是依靠ruby脚本redis-trib.rb实现)# 下面命令里的1代表为每个创建的主服务器节点创建一个从服务器节点# 执行这条命令需要确认三台机器之间的redis实例要能相互访问，可以先简单把所有机器防火墙关掉，如果不关闭防火墙则需要打开redis服务端口和集群节点gossip通信端口16379(默认是在redis端口号上加1W)# 关闭防火墙# systemctl stop firewalld # 临时关闭防火墙# systemctl disable firewalld # 禁止开机启动# 注意：下面这条创建集群的命令大家不要直接复制，里面的空格编码可能有问题导致创建集群不成功（1）/usr/local/redis-5.0.3/src/redis-cli -a zhuge --cluster create --cluster-replicas 1 192.168.0.61:8001 192.168.0.62:8002 192.168.0.63:8003 192.168.0.61:8004 192.168.0.62:8005 192.168.0.63:8006 第七步：验证集群：（1）连接任意一个客户端即可：./redis-cli -c -h -p (-a访问服务端密码，-c表示集群模式，指定ip地址和端口号）    如：/usr/local/redis-5.0.3/src/redis-cli -a zhuge -c -h 192.168.0.61 -p 800*（2）进行验证： cluster info（查看集群信息）、cluster nodes（查看节点列表）（3）进行数据操作验证（4）关闭集群则需要逐个进行关闭，使用命令：/usr/local/redis-5.0.3/src/redis-cli -a zhuge -c -h 192.168.0.60 -p 800* shutdown\n\nRedis集群原理分析Redis Cluster 将所有数据划分为 16384 个 slots(槽位)，每个节点负责其中一部分槽位。槽位的信息存储于每个节点中。\n当 Redis Cluster 的客户端来连接集群时，它也会得到一份集群的槽位配置信息并将其缓存在客户端本地。这样当客户端要查找某个 key 时，可以直接定位到目标节点。同时因为槽位的信息可能会存在客户端与服务器不一致的情况，还需要纠正机制来实现槽位信息的校验调整。\n槽位定位算法Cluster 默认会对 key 值使用 crc16 算法进行 hash 得到一个整数值，然后用这个整数值对 16384 进行取模来得到具体槽位。\nHASH_SLOT = CRC16(key) mod 16384\n跳转重定位当客户端向一个错误的节点发出了指令，该节点会发现指令的 key 所在的槽位并不归自己管理，这时它会向客户端发送一个特殊的跳转指令携带目标操作的节点地址，告诉客户端去连这个节点去获取数据。客户端收到指令后除了跳转到正确的节点上去操作，还会同步更新纠正本地的槽位映射表缓存，后续所有 key 将使用新的槽位映射表。\n\nRedis集群节点间的通信机制\nredis cluster节点间采取gossip协议进行通信 \n维护集群的元数据(集群节点信息，主从角色，节点数量，各节点共享的数据等)有两种方式：集中式和gossip \n集中式优点在于元数据的更新和读取，时效性非常好，一旦元数据出现变更立即就会更新到集中式的存储中，其他节点读取的时候立即就可以立即感知到；不足在于所有的元数据的更新压力全部集中在一个地方，可能导致元数据的存储压力。 很多中间件都会借助zookeeper集中式存储元数据。\ngossip\ngossip协议包含多种消息，包括ping，pong，meet，fail等等。\nmeet：某个节点发送meet给新加入的节点，让新节点加入集群中，然后新节点就会开始与其他节点进行通信；ping：每个节点都会频繁给其他节点发送ping，其中包含自己的状态还有自己维护的集群元数据，互相通过ping交换元数据(类似自己感知到的集群节点增加和移除，hash slot信息等)；pong: 对ping和meet消息的返回，包含自己的状态和其他信息，也可以用于信息广播和更新；fail: 某个节点判断另一个节点fail之后，就发送fail给其他节点，通知其他节点，指定的节点宕机了。\ngossip协议的优点在于元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续，打到所有节点上去更新，有一定的延时，降低了压力；缺点在于元数据更新有延时可能导致集群的一些操作会有一些滞后。\ngossip通信的10000端口\n每个节点都有一个专门用于节点间gossip通信的端口，就是自己提供服务的端口号+10000，比如7001，那么用于节点间通信的就是17001端口。 每个节点每隔一段时间都会往另外几个节点发送ping消息，同时其他几点接收到ping消息之后返回pong消息。\n网络抖动真实世界的机房网络往往并不是风平浪静的，它们经常会发生各种各样的小问题。比如网络抖动就是非常常见的一种现象，突然之间部分连接变得不可访问，然后很快又恢复正常。\n为解决这种问题，Redis Cluster 提供了一种选项cluster-node-timeout，表示当某个节点持续 timeout 的时间失联时，才可以认定该节点出现故障，需要进行主从切换。如果没有这个选项，网络抖动会导致主从频繁切换 (数据的重新复制)。\nRedis集群选举原理分析当slave发现自己的master变为FAIL状态时，便尝试进行Failover，以期成为新的master。由于挂掉的master可能会有多个slave，从而存在多个slave竞争成为master节点的过程， 其过程如下：\n\nslave发现自己的master变为FAIL\n将自己记录的集群currentEpoch加1，并广播FAILOVER_AUTH_REQUEST 信息\n其他节点收到该信息，只有master响应，判断请求者的合法性，并发送FAILOVER_AUTH_ACK，对每一个epoch只发送一次ack\n尝试failover的slave收集master返回的FAILOVER_AUTH_ACK\nslave收到超过半数master的ack后变成新Master(这里解释了集群为什么至少需要三个主节点，如果只有两个，当其中一个挂了，只剩一个主节点是不能选举成功的)\nslave广播Pong消息通知其他集群节点。\n\n从节点并不是在主节点一进入 FAIL 状态就马上尝试发起选举，而是有一定延迟，一定的延迟确保我们等待FAIL状态在集群中传播，slave如果立即尝试选举，其它masters或许尚未意识到FAIL状态，可能会拒绝投票\n\n延迟计算公式：\nDELAY = 500ms + random(0 ~ 500ms) + SLAVE_RANK * 1000ms \n\n\n\nSLAVE_RANK表示此slave已经从master复制数据的总量的rank。Rank越小代表已复制的数据越新。这种方式下，持有最新数据的slave将会首先发起选举（理论上）。\n\n集群脑裂数据丢失问题redis集群没有过半机制会有脑裂问题，网络分区导致脑裂后多个主节点对外提供写服务，一旦网络分区恢复，会将其中一个主节点变为从节点，这时会有大量数据丢失。\n规避方法可以在redis配置里加上参数(这种方法不可能百分百避免数据丢失，参考集群leader选举机制)：\nmin-replicas-to-write 1  #写数据成功最少同步的slave数量，这个数量可以模仿大于半数机制配置，比如集群总共三个节点可以配置1，加上leader就是2，超过了半数\n\n注意：这个配置在一定程度上会影响集群的可用性，比如slave要是少于1个，这个集群就算leader正常也不能提供服务了，需要具体场景权衡选择。\n集群是否完整才能对外提供服务当redis.conf的配置cluster-require-full-coverage为no时，表示当负责一个插槽的主库下线且没有相应的从库进行故障恢复时，集群仍然可用，如果为yes则集群不可用。\n奇数master节点Redis集群为什么至少需要三个master节点，并且推荐节点数为奇数呢，原因在于新master的选举需要大于半数的集群master节点同意才能选举成功，如果只有两个master节点，当其中一个挂了，是达不到选举新master的条件的。\n 奇数个master节点可以在满足选举该条件的基础上节省一个节点，比如三个master节点和四个master节点的集群相比，大家如果都挂了一个master节点都能选举新master节点，如果都挂了两个master节点都没法选举新master节点了，所以奇数的master节点更多的是从节省机器资源角度出发说的。\nRedis集群对批量操作命令的支持对于类似mset，mget这样的多个key的原生批量操作命令，redis集群只支持所有key落在同一slot的情况，如果有多个key一定要用mset命令在redis集群上操作，则可以在key的前面加上{XX}，这样参数数据分片hash计算的只会是大括号里的值，这样能确保不同的key能落到同一slot里去，示例如下：\nmset &#123;user1&#125;:1:name zhuge &#123;user1&#125;:1:age 18\n\n假设name和age计算的hash slot值不一样，但是这条命令在集群下执行，redis只会用大括号里的 user1 做hash slot计算，所以算出来的slot值肯定相同，最后都能落在同一slot。\n哨兵leader选举流程当一个master服务器被某sentinel视为下线状态后，该sentinel会与其他sentinel协商选出sentinel的leader进行故障转移工作。每个发现master服务器进入下线的sentinel都可以要求其他sentinel选自己为sentinel的leader，选举是先到先得。同时每个sentinel每次选举都会自增配置纪元(选举周期)，每个纪元中只会选择一个sentinel的leader。如果所有超过一半的sentinel选举某sentinel作为leader。之后该sentinel进行故障转移操作，从存活的slave中选举出新的master，这个选举过程跟集群的master选举很类似。哨兵集群只有一个哨兵节点，redis的主从也能正常运行以及选举master，如果master挂了，那唯一的那个哨兵节点就是哨兵leader了，可以正常选举新master。不过为了高可用一般都推荐至少部署三个哨兵节点。为什么推荐奇数个哨兵节点原理跟集群奇数个master节点类似。\nRedis集群水平扩展Redis3.0以后的版本虽然有了集群功能，提供了比之前版本的哨兵模式更高的性能与可用性，但是集群的水平扩展却比较麻烦，今天就来带大家看看redis高可用集群如何做水平扩展，原始集群(见下图)由6个节点组成，6个节点分布在三台机器上，采用三主三从的模式\n\n启动集群\n启动整个集群\n/usr/local/redis-5.0.3/src/redis-server /usr/local/redis-cluster/8001/redis.conf/usr/local/redis-5.0.3/src/redis-server /usr/local/redis-cluster/8002/redis.conf/usr/local/redis-5.0.3/src/redis-server /usr/local/redis-cluster/8003/redis.conf/usr/local/redis-5.0.3/src/redis-server /usr/local/redis-cluster/8004/redis.conf/usr/local/redis-5.0.3/src/redis-server /usr/local/redis-cluster/8005/redis.conf/usr/local/redis-5.0.3/src/redis-server /usr/local/redis-cluster/8006/redis.conf\n客户端连接8001端口的redis实例\n/usr/local/redis-5.0.3/src/redis-cli -a zhuge -c -h 192.168.0.61 -p 8001\n查看集群状态\n192.168.0.61:8001&gt; cluster  nodes\n\n整个集群运行正常，三个master节点和三个slave节点，8001端口的实例节点存储0-5460这些hash槽，8002端口的实例节点存储5461-10922这些hash槽，8003端口的实例节点存储10923-16383这些hash槽，这三个master节点存储的所有hash槽组成redis集群的存储槽位，slave点是每个主节点的备份从节点，不显示存储槽位  \n\n\n集群操作我们在原始集群基础上再增加一主(8007)一从(8008)，增加节点后的集群参见下图，新增节点用虚线框表示\n\n增加redis实例在/usr/local/redis-cluster下创建8007和8008文件夹，并拷贝8001文件夹下的redis.conf文件到8007和8008这两个文件夹下\nmkdir 8007 8008cd 8001cp redis.conf /usr/local/redis-cluster/8007/cp redis.conf /usr/local/redis-cluster/8008/# 修改8007文件夹下的redis.conf配置文件vim /usr/local/redis-cluster/8007/redis.conf# 修改如下内容：port:8007dir /usr/local/redis-cluster/8007/cluster-config-file nodes-8007.conf# 修改8008文件夹下的redis.conf配置文件vim /usr/local/redis-cluster/8008/redis.conf修改内容如下：port:8008dir /usr/local/redis-cluster/8008/cluster-config-file nodes-8008.conf# 启动8007和8008俩个服务并查看服务状态/usr/local/redis-5.0.3/src/redis-server /usr/local/redis-cluster/8007/redis.conf/usr/local/redis-5.0.3/src/redis-server /usr/local/redis-cluster/8008/redis.confps -el | grep redis\n\n查看redis集群的命令帮助cd /usr/local/redis-5.0.3src/redis-cli --cluster help\n\n\n\ncreate  创建一个集群环境host1:port1 … hostN:portN\ncall  可以执行redis命令\nadd-node  将一个节点添加到集群里，第一个参数为新节点的ip:port，第二个参数为集群中任意一个已经存在的节点的ip:port \ndel-node  移除一个节点\nreshard  重新分片\ncheck  检查集群状态 \n\n配置8007为集群主节点使用add-node命令新增一个主节点8007(master)，前面的ip:port为新增节点，后面的ip:port为已知存在节点，看到日志最后有&quot;[OK] New node added correctly&quot;提示代表新节点加入成功\n/usr/local/redis-5.0.3/src/redis-cli -a zhuge --cluster add-node 192.168.0.61:8007 192.168.0.61:8001\n\n\n查看集群状态\n/usr/local/redis-5.0.3/src/redis-cli -a zhuge -c -h 192.168.0.61 -p 8001192.168.0.61:8001&gt; cluster nodes\n\n\n注意：当添加节点成功以后，新增的节点不会有任何数据，因为它还没有分配任何的slot(hash槽)，我们需要为新节点手工分配hash槽\n\n使用redis-cli命令为8007分配hash槽，找到集群中的任意一个主节点，对其进行重新分片工作\n/usr/local/redis-5.0.3/src/redis-cli -a zhuge --cluster reshard 192.168.0.61:8001\n\n输出如下：\n... ...How many slots do you want to move (from 1 to 16384)? 600(ps:需要多少个槽移动到新的节点上，自己设置，比如600个hash槽)What is the receiving node ID? 2728a594a0498e98e4b83a537e19f9a0a3790f38(ps:把这600个hash槽移动到哪个节点上去，需要指定节点id)Please enter all the source node IDs.  Type &#x27;all&#x27; to use all the nodes as source nodes for the hash slots.  Type &#x27;done&#x27; once you entered all the source nodes IDs.Source node 1:all(ps:输入all为从所有主节点(8001,8002,8003)中分别抽取相应的槽数指定到新节点中，抽取的总槽数为600个) ... ...Do you want to proceed with the proposed reshard plan (yes/no)? yes(ps:输入yes确认开始执行分片任务)... ...\n查看下最新的集群状态\n/usr/local/redis-5.0.3/src/redis-cli -a zhuge -c -h 192.168.0.61 -p 8001192.168.0.61:8001&gt; cluster nodes\n\n现在我们的8007已经有hash槽了，也就是说可以在8007上进行读写数据！到此为止我们的8007已经加入到集群中，并且是主节点(Master)\n\n\n配置8008为8007的从节点\n添加从节点8008到集群中去并查看集群状态\n/usr/local/redis-5.0.3/src/redis-cli -a zhuge --cluster add-node 192.168.0.61:8008 192.168.0.61:8001\n\n如图所示，还是一个master节点，没有被分配任何的hash槽。\n\n设置当前slave节点的主节点我们需要执行replicate命令来指定当前节点(从节点)的主节点id为哪个,首先需要连接新加的8008节点的客户端，然后使用集群命令进行操作，把当前的8008(slave)节点指定到一个主节点下(这里使用之前创建的8007主节点)\n/usr/local/redis-5.0.3/src/redis-cli -a zhuge -c -h 192.168.0.61 -p 8008192.168.0.61:8008&gt; cluster replicate 2728a594a0498e98e4b83a537e19f9a0a3790f38  #后面这串id为8007的节点id\n查看集群状态8008节点已成功添加为8007节点的从节点\n\n\n删除8008从节点\n用del-node删除从节点8008指定删除节点ip和端口，以及节点id(红色为8008节点id)\n/usr/local/redis-5.0.3/src/redis-cli -a zhuge --cluster del-node 192.168.0.61:8008 a1cfe35722d151cf70585cee21275565393c0956\n查看集群状态再次查看集群状态，如下图所示，8008这个slave节点已经移除，并且该节点的redis服务也已被停止\n\n\n删除8007主节点最后，我们尝试删除之前加入的主节点8007，这个步骤相对比较麻烦一些，因为主节点的里面是有分配了hash槽的，所以我们这里必须先把8007里的hash槽放入到其他的可用主节点中去，然后再进行移除节点操作，不然会出现数据丢失问题(目前只能把master的数据迁移到一个节点上，暂时做不了平均分配功能)，执行命令如下：\n/usr/local/redis-5.0.3/src/redis-cli -a zhuge --cluster reshard 192.168.0.61:8007\n\n ... ...How many slots do you want to move (from 1 to 16384)? 600What is the receiving node ID? dfca1388f124dec92f394a7cc85cf98cfa02f86f(ps:这里是需要把数据移动到哪？8001的主节点id)Please enter all the source node IDs.  Type &#x27;all&#x27; to use all the nodes as source nodes for the hash slots.  Type &#x27;done&#x27; once you entered all the source nodes IDs.Source node 1:2728a594a0498e98e4b83a537e19f9a0a3790f38(ps:这里是需要数据源，也就是我们的8007节点id)Source node 2:done(ps:这里直接输入done 开始生成迁移计划) ... ...Do you want to proceed with the proposed reshard plan (yes/no)? Yes(ps:这里输入yes开始迁移)\n\n至此，我们已经成功的把8007主节点的数据迁移到8001上去了，我们可以看一下现在的集群状态如下图，你会发现8007下面已经没有任何hash槽了，证明迁移成功！\n\n\ndel-node命令删除8007主节点\n/usr/local/redis-5.0.3/src/redis-cli -a zhuge --cluster del-node 192.168.0.61:8007 2728a594a0498e98e4b83a537e19f9a0a3790f38\n查看集群状态\n\n\n","categories":["中间件"],"tags":["Redis"]}]